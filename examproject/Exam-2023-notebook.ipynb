{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Problem 1: Optimal taxation with government consumption](#toc1_)    \n",
    "- 2. [Problem 2: Labor adjustment costs](#toc2_)    \n",
    "- 3. [Problem 3: Global optimizer with refined multi-start](#toc3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "import sympy as sm\n",
    "from sympy import Symbol\n",
    "from sympy.solvers import solve\n",
    "from scipy.optimize import root_scalar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "sm.init_printing(use_unicode=True) # for pretty printing\n",
    "\n",
    "# Autoreload modules when code is run. Otherwise, python will not see recent changes. \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Problem 1: Optimal taxation with government consumption](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consider a worker choosing hours of labor, $L\\in[0,24]$, to maximize utility: \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "V(w,\\tau,G)&=\\max_{L\\in[0,24]}\\ln\\left(C^{\\alpha}G^{1-\\alpha}\\right)-\\nu\\frac{L^{2}}{2}\\\\&\\text{s.t.}\\\\&C=\\kappa+(1-\\tau)wL\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $C$ is *private* consumption with weight $\\alpha\\in(0,1)$.\n",
    "* $\\kappa > 0$ is the *free private* consumption component.\n",
    "* $(1-\\tau)wL$ is the *costly private* consumption component.\n",
    "* $w > 0 $ is the real wage.\n",
    "* $\\tau \\in (0,1)$ is the labor-income tax rate.\n",
    "* $G > 0 $ is *government* consumption with weight $1-\\alpha$.\n",
    "* $\\nu > 0$ is the disutility of labor scaling factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The baseline parameters are:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\alpha &= 0.5\\\\\n",
    "\\kappa &= 1.0\\\\\n",
    "\\nu &= \\frac{1}{2\\cdot16^2} \\\\\n",
    "w &= 1.0 \\\\ \n",
    "\\tau &= 0.30 \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining baseline parameters:\n",
    "alpha = 0.5\n",
    "kappa = 1.0\n",
    "nu = 1/(2*16**2)\n",
    "w = 1.0\n",
    "tau = 0.30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Verify that the optimal labor supply choice is $L^{\\star}(\\tilde{w}) =\\frac{-\\kappa+\\sqrt{\\kappa^{2}+4\\frac{\\alpha}{\\nu}\\tilde{w}^2}}{2\\tilde{w}}$, where $\\tilde{w} = (1-\\tau)w$, for $G\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify this by using the Lagrangian method. We begin by defining the Lagrangian function:\n",
    "$$\\mathcal{L}(C,G,L,\\lambda)=\\ln(C^{\\alpha}G^{1-\\alpha})-\\nu\\frac{L^{2}}{2}+\\lambda\\left[\\kappa+(1-\\tau)wL-C\\right]$$\n",
    "We find the FOC wrt. $L$ by setting the derivative of the function equal to $0$:\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial L} = 0$$\n",
    "$$\\Rightarrow \\lambda(1-\\tau)w - \\nu L = 0$$\n",
    "$$\\Rightarrow \\lambda(1-\\tau)w  = \\nu L$$\n",
    "$$\\Rightarrow L = \\frac{\\lambda(1-\\tau)w}{\\nu}$$\n",
    "Then, we find the expression for $C$:\n",
    "$$C=\\kappa+(1-\\tau)wL = \\kappa+(1-\\tau)w\\frac{\\lambda(1-\\tau)w}{\\nu} $$\n",
    "As $\\tilde{w} = (1-\\tau)w$, we get:\n",
    "$$C=\\kappa+\\tilde{w}L = \\kappa+\\tilde{w}\\frac{\\lambda(\\tilde{w})}{\\nu} $$\n",
    "\n",
    "$$\\Rightarrow \\lambda = \\frac{\\sqrt{\\kappa^{2}+4\\frac{\\alpha G}{\\nu}\\tilde{w}^2}-\\kappa}{2\\tilde{w}}$$\n",
    "\n",
    "Which result in:\n",
    "$$L^{\\star}(\\tilde{w}) =\\frac{-\\kappa+\\sqrt{\\kappa^{2}+4\\frac{\\alpha G}{\\nu}\\tilde{w}^2}}{2\\tilde{w}}$$\n",
    "Hereby, it is vertified that the optimal labor supply choice is $L^{\\star}(\\tilde{w}) =\\frac{-\\kappa+\\sqrt{\\kappa^{2}+4\\frac{\\alpha G}{\\nu}\\tilde{w}^2}}{2\\tilde{w}}$, where $\\tilde{w} = (1-\\tau)w$, for $G\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Illustrate how $L^{\\star}(\\tilde{w})$ depends on $w$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the expression for $L^{\\star}(\\tilde{w})$ to illustrate how the optimal labor supply choice depends on $w$ for different values of $G$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining function for optimal labor supply\n",
    "def L_star(w, G):\n",
    "    return (-kappa + np.sqrt(kappa**2 + 4*alpha*G/(nu)*((1-tau)*w)**2))/(2*((1-tau)*w))\n",
    "\n",
    "# Defining a range of values for tilde_w\n",
    "w_values = np.linspace(0.000001, 1, 1000)\n",
    "\n",
    "# Defining values for G\n",
    "G_values = [1.0, 1.25, 1.5, 1.75, 2.0]\n",
    "\n",
    "# Plotting L_star as a function of tilde_w for different values of G\n",
    "for G in G_values:\n",
    "    L_values = L_star(w_values, G)\n",
    "    plt.plot(w_values, L_values, label='G = {}'.format(G))\n",
    "\n",
    "# Adding axis labels and legend\n",
    "plt.xlabel('$w$')\n",
    "plt.ylabel('$L^*$')\n",
    "plt.title('Illustration of how $L^*(\\\\tilde{w})$ depends on $w$')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now consider a government, who chooses $\\tau$ and spend all of the taxes on government consumption so:\n",
    "\n",
    "$$\n",
    "G = \\tau w L^{\\star}((1-\\tau)w)\n",
    "$$\n",
    "\n",
    "**Question 3:** Plot the implied $L$, $G$ and worker utility for a grid of $\\tau$-values.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the labor supply $L^{\\star}$, government consumption $G$, and worker utility $V(w,\\tau,G)$ for different values of $\\tau$. Afterwards, we plot all three variables against $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining function for optimal labor supply\n",
    "def L_star(tau, w):\n",
    "    return (-kappa+np.sqrt(kappa**2+4*alpha*tau*w**2/nu))/(2*tau*w)\n",
    "\n",
    "# Defining function for government consumption\n",
    "def G(tau, w):\n",
    "    return tau*w*L_star(tau, w)\n",
    "\n",
    "# Defining function for worker utility\n",
    "def utility(tau, w):\n",
    "    L = L_star(tau, w)\n",
    "    C = kappa+(1-tau)*w*L\n",
    "    return np.log(C**alpha*G(tau, w)**(1-alpha))-nu*L**2/2\n",
    "\n",
    "# Defining a range of values for tau\n",
    "tau_values = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Calculating optimal labor supply, government consumption, and worker utility for different values of tau\n",
    "L_values = L_star(tau_values, w)\n",
    "G_values = G(tau_values, w)\n",
    "utility_values = utility(tau_values, w)\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(3, 1, sharex=True, figsize=(10,12))\n",
    "fig.suptitle('The implied labor supply, government consumption, and worker utility for different values of $\\\\tau$', fontsize=14)\n",
    "ax[0].plot(tau_values, L_values, color='red')\n",
    "ax[0].set_ylabel('$L$')\n",
    "ax[0].set_xlabel('$\\\\tau$')\n",
    "ax[0].set_title('Labor supply')\n",
    "ax[1].plot(tau_values, G_values, color='orange')\n",
    "ax[1].set_ylabel('$G$')\n",
    "ax[1].set_xlabel('$\\\\tau$')\n",
    "ax[1].set_title('Government consumption')\n",
    "ax[2].plot(tau_values, utility_values, color='green')\n",
    "ax[2].set_ylabel('$V$')\n",
    "ax[2].set_xlabel('$\\\\tau$')\n",
    "ax[2].set_title('Worker utility')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that when labor-income tax rate is close to 0, labor supply is high, government consumption is low and worker utility is low. This is because there is incentive to work as the workers keep a bigger part of their wage, but as the tax rate is low, government does not have an income and cannot consume. Worker utility is low, which can be explained by government not being able to provide public goods for the workers. As the labor-income taxe rate increases, labor supply decreases, government consumption increases, and worker utility increases to a certain point, but if the tax rate is too high, worker utility begins to decrease as a too high income-tax reduces incentive to work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Find the socially optimal tax rate $\\tau^{\\star}\\in(0,1)$ maximizing worker utility. Illustrate your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The socially optimal tax rate is 0.521\n"
     ]
    }
   ],
   "source": [
    "# Define the utility function\n",
    "def utility(L, tau):\n",
    "    C = kappa+(1-tau)*w*L\n",
    "    G = tau*w*L**2\n",
    "    return np.log(C**alpha*G**(1-alpha))-nu*(L**2)/2\n",
    "\n",
    "# Define the objective function to maximize utility subject to the government budget constraint\n",
    "def objective(tau):\n",
    "    def gov_constraint(L):\n",
    "        return tau*w*L**2-utility(L, tau)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, tau),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return -1*utility(L_star, tau)\n",
    "\n",
    "# Find the optimal tax rate that maximizes utility\n",
    "res = minimize_scalar(objective, bounds=(0, 1), method='bounded', options={'disp': 0})\n",
    "tau_star = res.x\n",
    "print(f\"The socially optimal tax rate is {tau_star:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more general preference formulation for the worker is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{V}(w,\\tau,G)&=\\max_{L\\in[0,24]}\\frac{\\left[ \\left( \\alpha C^{\\frac{\\sigma-1}{\\sigma}}+(1-\\alpha) G^{\\frac{\\sigma-1}{\\sigma}} \\right)^{\\frac{\\sigma}{\\sigma - 1} }\\right]^{1-\\rho}-1}{1-\\rho}- \\nu\\frac{L^{1+\\varepsilon}}{1+\\varepsilon},\\,\\,\\,\\varepsilon,\\rho,\\sigma>0,\\,\\,\\,\\rho,\\sigma\\neq1\\\\&\\text{s.t.}\\\\&C=\\kappa+(1-\\tau)wL\n",
    "\\end{align*}    \n",
    "$$\n",
    "\n",
    "Optimal labor supply is now $L^{\\star}(\\tilde{w},G)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions 5 and 6 must be answered with the general formulation, and for 2 different set of parameters:\n",
    "\n",
    "- Set 1:  $\\sigma = 1.001$, $\\rho = 1.001$ and $\\varepsilon = 1.0$.\n",
    "- Set 2:  $\\sigma = 1.5$, $\\rho = 1.5$ and $\\varepsilon = 1.0 $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Find the $G$ that solves $G = \\tau w L^{\\star}((1-\\tau)w,G)$ using the $\\tau$ found in question 4.\n",
    "\n",
    "*Hint: First write code that solves the worker problem for given values of $G$ and $\\tau$. Then find the correct G based on this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to G = tau*w*L_star*((1-tau)*w) for tau = 0.52, sigma = 1.001, rho = 1.001, epsilon = 1.0 is G = 1.5486\n"
     ]
    }
   ],
   "source": [
    "# Define the utility function with general formulation\n",
    "def utility(L, C, G, sigma, rho, epsilon):\n",
    "    return (((alpha*C**( (sigma-1)/sigma ) + (1-alpha)*G**( (sigma-1)/sigma ))**(sigma/(sigma-1)))**(1-rho)-1)/(1-rho) - nu*L**(1+epsilon)/(1+epsilon)\n",
    "\n",
    "# Define the objective function to solve for labor supply\n",
    "def objective(L, tau, G, sigma, rho, epsilon):\n",
    "    C = kappa + (1-tau)*w*L\n",
    "    return -utility(L, C, G, sigma, rho, epsilon)\n",
    "\n",
    "# Define the constraint function to solve for G\n",
    "def constraint(G, tau, sigma, rho, epsilon):\n",
    "    def objective_internal(L):\n",
    "        return -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return G - tau*w*L_star*((1-tau)*w)\n",
    "\n",
    "# Set 1 parameters\n",
    "sigma = 1.001\n",
    "rho = 1.001\n",
    "epsilon = 1.0\n",
    "\n",
    "\n",
    "\n",
    "# Find the G that solves the equation G = tau*w*L_star*((1-tau)*w) for a given tau\n",
    "def get_G(tau, sigma, rho, epsilon):\n",
    "    res = minimize(lambda G: constraint(G, tau, sigma, rho, epsilon), 0.5, method='SLSQP', bounds=[(0, None)])\n",
    "    return res.x[0]\n",
    "\n",
    "\n",
    "tau = 0.521\n",
    "G = get_G(tau, sigma, rho, epsilon)\n",
    "print(f\"The solution to G = tau*w*L_star*((1-tau)*w) for tau = {tau:.2f}, sigma = {sigma:.3f}, rho = {rho:.3f}, epsilon = {epsilon:.1f} is G = {G:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to G = tau*w*L_star*((1-tau)*w) for tau = 0.52, sigma = 1.500, rho = 1.500, epsilon = 1.0 is G = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Define the utility function with general formulation\n",
    "def utility(L, C, G, sigma, rho, epsilon):\n",
    "    return (((alpha*C**( (sigma-1)/sigma ) + (1-alpha)*G**( (sigma-1)/sigma ))**(sigma/(sigma-1)))**(1-rho)-1)/(1-rho) - nu*L**(1+epsilon)/(1+epsilon)\n",
    "\n",
    "# Define the objective function to solve for labor supply\n",
    "def objective(L, tau, G, sigma, rho, epsilon):\n",
    "    C = kappa + (1-tau)*w*L\n",
    "    return -utility(L, C, G, sigma, rho, epsilon)\n",
    "\n",
    "# Define the constraint function to solve for G\n",
    "def constraint(G, tau, sigma, rho, epsilon):\n",
    "    def objective_internal(L):\n",
    "        return -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return G - tau*w*L_star*((1-tau)*w)\n",
    "\n",
    "# Set 2 parameters\n",
    "sigma = 1.5\n",
    "rho = 1.5\n",
    "epsilon = 1.0\n",
    "\n",
    "\n",
    "\n",
    "# Find the G that solves the equation G = tau*w*L_star*((1-tau)*w) for a given tau\n",
    "def get_G(tau, sigma, rho, epsilon):\n",
    "    res = minimize(lambda G: constraint(G, tau, sigma, rho, epsilon), 0.5, method='SLSQP', bounds=[(0, None)])\n",
    "    return res.x[0]\n",
    "\n",
    "\n",
    "tau = 0.521\n",
    "G = get_G(tau, sigma, rho, epsilon)\n",
    "print(f\"The solution to G = tau*w*L_star*((1-tau)*w) for tau = {tau:.2f}, sigma = {sigma:.3f}, rho = {rho:.3f}, epsilon = {epsilon:.1f} is G = {G:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** Find the socially optimal tax rate, $\\tau^{\\star}$, maximizing worker utility, while keeping $G = \\tau w L^{\\star}((1-\\tau)w,G)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The socially optimal tax rate for sigma = 1.010, rho = 1.010, epsilon = 1.0 is tau = 0.3955\n"
     ]
    }
   ],
   "source": [
    "# Define the utility function with general formulation\n",
    "def utility(L, C, G, sigma, rho, epsilon):\n",
    "    return (((alpha*C**( (sigma-1)/sigma ) + (1-alpha)*G**( (sigma-1)/sigma ))**(sigma/(sigma-1)))**(1-rho)-1)/(1-rho) - nu*L**(1+epsilon)/(1+epsilon)\n",
    "\n",
    "# Define the objective function to solve for labor supply\n",
    "def objective(L, tau, G, sigma, rho, epsilon):\n",
    "    C = kappa + (1-tau)*w*L\n",
    "    return -utility(L, C, G, sigma, rho, epsilon)\n",
    "\n",
    "# Define the constraint function to solve for G\n",
    "def constraint(G, tau, sigma, rho, epsilon):\n",
    "    def objective_internal(L):\n",
    "        return -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return G - tau*w*L_star*((1-tau)*w)\n",
    "\n",
    "# Find the G that solves the equation G = tau*w*L_star*((1-tau)*w) for a given tau\n",
    "def get_G(tau, sigma, rho, epsilon):\n",
    "    res = minimize(lambda G: constraint(G, tau, sigma, rho, epsilon), 0.5, method='SLSQP', bounds=[(0, None)])\n",
    "    return res.x[0]\n",
    "\n",
    "# Define the objective function to maximize utility subject to the government budget constraint\n",
    "def objective_social(tau, G, sigma, rho, epsilon):\n",
    "    def gov_constraint(L):\n",
    "        C = kappa + (1-tau) * w * L\n",
    "        return G - tau * w * L * ((1 - tau) * w)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return -1*utility(L_star, kappa+(1-tau)*w*L_star, G, sigma, rho, epsilon)\n",
    "\n",
    "# Set 1 parameters\n",
    "sigma = 1.01\n",
    "rho = 1.01\n",
    "epsilon = 1.0\n",
    "\n",
    "# Find the socially optimal tax rate that maximizes utility subject to the government budget constraint\n",
    "res = minimize_scalar(lambda tau: -1*objective_social(tau, get_G(tau, sigma, rho, epsilon), sigma, rho, epsilon),\n",
    "                      bounds=(0, 1), method='bounded', options={'disp': 0})\n",
    "tau_star = res.x\n",
    "\n",
    "print(f\"The socially optimal tax rate for sigma = {sigma:.3f}, rho = {rho:.3f}, epsilon = {epsilon:.1f} is tau = {tau_star:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Problem 2: Labor adjustment costs](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You own a hair salon. You employ hairdressers, $\\ell_t$, to produce haircuts, $y_t = \\ell_t$.\n",
    "\n",
    "The wage for each haridresser is $w$.\n",
    "\n",
    "The demand for haircuts implies that the price of haircuts you can charge is $p_t = \\kappa_t y_t^{-\\eta}$, where $\\kappa_t$ is a demand-shock and $\\eta \\in (0,1)$ measures the elasticity of demand.\n",
    "\n",
    "Profits are:\n",
    "\n",
    "$$\n",
    "\\Pi_t = p_t y_t - w \\ell_t = \\kappa_t \\ell_t^{1-\\eta} - w \\ell_t\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline parameters are:\n",
    "- $\\eta = 0.5$\n",
    "- $w = 1.0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Verify numerically that $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ maximises profits, for $\\kappa\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vertify numerically that $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ maximises profits, for $\\kappa\\in\\left\\{1.0 , 2.0\\right\\}$ by using sympy. First we find the derivative of profit wrt. $\\ell$. Hereafter we find the equation that maximises profits by putting this equation equal to zero and solve for $\\ell$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = sm.symbols('eta')\n",
    "w = sm.symbols('w')\n",
    "kappa = sm.symbols('kappa')\n",
    "ell = sm.symbols('ell')\n",
    "p=sm.symbols('p')\n",
    "y=sm.symbols('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMUAAAAaCAYAAAAHUJgKAAAG0ElEQVR4nO2be2xURRSHPwro1iLII1RESdOIBES7Cyj6T1MVQWMMYCAxPgBf+AIVo1ECJsUYfGACKBEhClXEoAkWBF/RgCIai4IFI2gUKIoQEcEiCqJY//jNdW+nsw+6d3dbuF+ymd2Ze+eeu3vOmXPO3G1TWVlJSEhInIJ8C9BCKQdWALuABmBUfsUJySWhUbgpAjYCE/ItSEjuOVGNIgLMB/YByxzj7wBTgTdyIEstMA2YA/wK7AEeCWjul818RQHN15IYiFbxW5p5fkIdOFGNYgowGngRGA60y5Mc7YG+wA1ADTAYmIeMpDjDuQeZeZ8A/rDGRgHPAh8DB5ByvZLh9XLNeqTMjwEdUhxbDBwFnvH1JdSBE9Eo2gF3AHORlzgI/JMnWfoBJwH3A4uA74EXgDZApwznno4Ufq5jbCoKDaPATxleJ588DpwO3JPiuOFI16vN56Q60FqNYhzybhXNOLcC6AYsAQYA3wUgT6WRJ9mrwnFeFNiLknqPYnP87gzkOQcYArwOHHKMTzLHdATuzOA6+WYd8A1wO9A2yXEjUWi6xnyuIIkOBGkUQ9CP+ajVP5i4YpRYY4uBf4E+AcqRiiuBn4GvUJVpVQBzzkFhULLXOsd5ZcAX6DvwiALbgN99fX3R92fnOIORp99hzvO4Ga02ryWQdzVShIZkN5UHvgb+BE4BJgObgcPIQczArfhLgF5I/1x0Ai5Fjueo6UuqA0HG0vtMe6rV/5DvfRegzrw/A8V0K4BvA5QjFRXAWqRQ3YGVAcy517yOlSjKJey+WqtvgGm/9PWNRflHDcoRfvGNDUEK8FkzZMoXhcg57kBGG0HKuha4DngA2AnMts77xLSXA+855r0Khah+h1JBEh0IcqXYb1q/UfRG8dwy87mzb+xulGjOCFCGVBQR987XI4/8keO4Dkg5o+ZziXnfK2B5zqepAcRorPwQN4oNyFvOBKqABcgA/AZRhGTdQtMEuyVThu6tFClwFOU9480L5PFtPjdteYJ5R6Lv4X3zOaUOZNsoHkRhwFPmcxfTRtCN1iCLzRUx9MXXAWNQouUKIQYhxfSUc4Z5b4eGmXAm0JXGRlEAnEdio9gOvAvcBdxm2r+tY3uie8wkJ8kHMdNWA0/S+HfZYFqXvtajEMvlsCLAFajEfth3naQ6YF+kjtQJo//lL+PVo9jYM4pic9F5wI+mzzOKG1Gi87TjRmxcMi00Y6sdY1VJ5jrXtBXAEeD5BMd9iGJy+zUuDXnTZaeZ0x869kaezDaKKJL3TbQy1KIqlYuupt2fYDwo6mi+rrjwDH++Y6y7abclOHcf0ieboWjVr/b1pdQBO6fYStyi0mGX730DMgzPKO5FP/ps4kljZ9/YVtLbHJsFnGb1RVFY9hLxHMWjNslcPYyco9HqdTCN6+eSGEoA/V6+lPj970GJ6IXA1TSuWnl41aZIdkT8n0x0xUUM5UGucLbMtLaz8CjEXWUbiRT/LV9fSh2wjeKyhCKnx35kFB1QHfhV4l/GUbRSDEXWOoHGVZdEzHL0jUNGUYW8erpEkKHW0zRhawlESZxkVwPXAsPQijEd/dj2d7jHtF3JLpnqip/2QH+UB7mUe6Bp1zvGCpDT2G71t0WOYxX6vT1S6kDQ+xSeUYw3gvrDowPIKO5DNeOF5B5vxZrEsXm5XPEwioH9eEaxGHm9Faiq1B/tWNvsRol3LsvcmdIPOBm30oOM4hAyGps+SMlrrf5y5Biqrf6UOpANo+iMFP9tVHf2qEclsCuA51AYkEsKkOdoIL6JEyH1IwL5xlWO9Z6NmobKjX68++sGnJ1d0QLDX12zKUT7NBtxP3lwkWlXW/3XoFV0ua8vLR3IllGcRdNS62/Iu/2FNrtyzUTkkY6g0K0HsAmV5VoyMeRQ/OHBByhsLMG9I73UtMMSzDkChZ5VaHUCuNjXl04BJEi8ypNrpYiiUCjRKjIUhebLrf4RwKcoR/NISweyYRSg2rGdMHlx3SLicW+u6IiqDeOBW1EpcwPKV+blWJZjoSeqvNTStHQ8xdfaG6ZLkTKMSTBvFG3+jSVuOKW+vlz/fySGvHqtY8xbRVxG0Qkp/0riFU6AC1DJ2x86pa0DbcJ/3h23TEbJ+AASV21aAwuAm1AFapM1NhE9+VqOnvj1mI7uv5SmCXhKWusDgSGpmQn8QLAbjvlgIEqIN1v9hUjxl9LYIECl2I00wyAgf/8jCMk+h9Em6SVoQ7A1PfLhEUE5wHqaJtklaKOvynFe30wuGhrF8c0a4lWW1kgZ0lFXPrEFPbIfOKFRhLRkatAeRE4Jc4qQEIvQKEJCLEKjCAmx+A9MWqtXDR2i3QAAAABJRU5ErkJggg==",
      "text/latex": [
       "$\\displaystyle - w + \\frac{\\ell^{1 - \\eta} \\kappa \\left(1 - \\eta\\right)}{\\ell}$"
      ],
      "text/plain": [
       "        1 -           \n",
       "     ell     (1 - )\n",
       "-w + \n",
       "            ell        "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit=kappa*ell**(1-eta)-w*ell\n",
    "diffprofit=profit.diff(ell)\n",
    "diffprofit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/latex": [
       "$\\displaystyle \\left[ \\left(\\frac{\\kappa \\left(1 - \\eta\\right)}{w}\\right)^{\\frac{1}{\\eta}}\\right]$"
      ],
      "text/plain": [
       "    ___________\n",
       "    (1 - ) \n",
       "    \n",
       "       w     "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit=sm.Eq(kappa*(1-eta)*ell**(-eta)-w)\n",
    "result = sm.solve(profit,ell)\n",
    "result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vertifies that $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ maximises profits, for $\\kappa\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given values of $\\eta$ and $w$, and the two values of $\\kappa_t$, we can calculate profit-maximizing value of $\\ell_t$ for each $\\kappa_t$ to be:\n",
    "\n",
    "For $\\kappa_t = 1.0$:\n",
    "\n",
    "$$\\ell_t=\\left(\\frac{(1-0.5)\\times 1.0}{1.0}\\right)^{\\frac{1}{0.5}}\\approx 0.709$$\n",
    "\n",
    "For $\\kappa_t = 2.0$:\n",
    "\n",
    "$$\\ell_t=\\left(\\frac{(1-0.5)\\times 2.0}{1.0}\\right)^{\\frac{1}{0.5}}\\approx 1.140$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider a *dynamic* version of the model.\n",
    "\n",
    "* The demand-shock is a so-called AR(1) in logs, \n",
    "\n",
    "$$\n",
    "\\log \\kappa_{t} = \\rho \\log \\kappa_{t-1} + \\epsilon_{t},\\,\\,\\, \\epsilon_{t+1} \\sim \\mathcal{N}(-0.5\\sigma_{\\epsilon}^2,\\sigma_{\\epsilon})\n",
    "$$\n",
    "\n",
    "* Any hiring or firing implies a fixed adjustment cost, $\\iota > 0 $.\n",
    "* Future profits are discounted with a monthly factor of $R \\in (0,1)$.\n",
    "\n",
    "The initial demand shock is $\\kappa_{-1} = 1$ and the planning horizon is 10 years, i.e. 120 months so $t \\in \\{0,1,2,\\dots,119\\}$. Initially you don't have any employees, $\\ell_{-1}=0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The *ex post* value of the salon is *conditional* on the shock series is:\n",
    "\n",
    "$$\n",
    "h(\\epsilon_0,\\epsilon_1,\\dots,\\epsilon_{119}) = \\left[\\sum_{t=0}^{119}R^{-t}\\left[\\kappa_{t}\\ell_{t}^{1-\\eta}-w\\ell_{t}-\\boldsymbol{1}_{\\ell_{t}\\neq\\ell_{t-1}}\\iota\\right]\\right]\n",
    "$$\n",
    "\n",
    "The *ex ante* expected value of the salon can be approximated by\n",
    "\n",
    "$$\n",
    "H = \\mathbb{E}[h(\\epsilon_0,\\epsilon_1,\\dots,\\epsilon_{119})] \\approx \\frac{1}{K}\\sum_{k=0}^{K} h(\\epsilon_0^k,\\epsilon_1^k,\\dots,\\epsilon_{119}^k)\n",
    "$$\n",
    "\n",
    "where each $k\\in\\{0,1,\\dots,K-1\\}$ is a random shock series. Maximizing profitability means maximizing $H$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline parameters are: \n",
    "\n",
    "- $\\rho = 0.90$\n",
    "- $\\iota = 0.01$\n",
    "- $\\sigma_{\\epsilon} = 0.10$\n",
    "- $R = \\left(1+0.01\\right)^{1/12}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Calculate $H$ if the policy  $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ from question 1 is followed. Choose $K$ so the approximation is good enough to not affect your results substantially."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate $H$, we choose $K=100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters\n",
    "eta = 0.5\n",
    "w = 1.0\n",
    "rho = 0.8\n",
    "sigma_eps = 0.1\n",
    "iota = 0.1\n",
    "R = 0.9\n",
    "T = 120\n",
    "\n",
    "# Choosing K\n",
    "K = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 2.506\n"
     ]
    }
   ],
   "source": [
    "# Set initial values\n",
    "kappa = np.ones(T+1)\n",
    "ell = np.zeros(T+1)\n",
    "h_vals = np.zeros(K)\n",
    "\n",
    "\n",
    "# Simulate shock series and calculate h for each\n",
    "for k in range(K):\n",
    "    eps = np.random.normal(loc=-0.5*sigma_eps**2, scale=sigma_eps, size=T+1)\n",
    "    for t in range(1, T+1):\n",
    "        kappa[t] = np.exp(rho*np.log(kappa[t-1]) + eps[t])\n",
    "    for t in range(T+1):\n",
    "        ell_new = ((1-eta)*kappa[t]/w)**(1/eta)\n",
    "        if t == 0:\n",
    "            adj_cost = 0\n",
    "        else:\n",
    "            adj_cost = np.abs(ell_new - ell[t-1])*iota\n",
    "        pi = kappa[t]*ell_new**(1-eta) - w*ell_new - adj_cost\n",
    "        h_vals[k] += R**t * pi\n",
    "        ell[t] = ell_new\n",
    "\n",
    "H = np.mean(h_vals)\n",
    "print(f\"H = {H:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the *ex ante* expected value of the salon is approximately 2.488"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider policies on the form:\n",
    "\n",
    "$$\n",
    "\n",
    "\\ell_{t}=\\begin{cases}\n",
    "\\ell_t^{\\ast}  & \\text{if }\\left|\\ell_{t-1}-\\ell_t^{\\ast} \\right|>\\Delta\\\\\n",
    "\\ell_{t-1} & \\text{else }\n",
    "\\end{cases}\n",
    "\\\\\n",
    "\\text{where}\\,\\,\\ell_t^{\\ast} = \\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}} \\\\\n",
    "\n",
    "$$\n",
    "With $\\Delta \\geq 0$ and $\\Delta = 0$ being the previous policy.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 3:** Calculate $H$ if the policy above was followed with $\\Delta = 0.05$. Does it improve profitability?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calcualte $H$, where $\\Delta = 0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 2.251\n"
     ]
    }
   ],
   "source": [
    "# Defining parameters\n",
    "Delta = 0.05\n",
    "\n",
    "# Set initial values\n",
    "kappa = np.ones(T+1)\n",
    "ell = np.zeros(T+1)\n",
    "h_vals = np.zeros(K)\n",
    "\n",
    "# Simulate shock series and calculate h for each\n",
    "for k in range(K):\n",
    "    eps = np.random.normal(loc=-0.5*sigma_eps**2, scale=sigma_eps, size=T+1)\n",
    "    for t in range(1, T+1):\n",
    "        kappa[t] = np.exp(rho*np.log(kappa[t-1]) + eps[t])\n",
    "    for t in range(T+1):\n",
    "        ell_new = ((1-eta)*kappa[t]/w)**(1/eta)\n",
    "        if t == 0:\n",
    "            adj_cost = 0\n",
    "        else:\n",
    "            if np.abs(ell_new - ell[t-1]) > Delta:\n",
    "                ell_new = np.round(ell_new, 2)\n",
    "                adj_cost = iota\n",
    "            else:\n",
    "                adj_cost = 0\n",
    "        pi = kappa[t]*ell_new**(1-eta) - w*ell_new - adj_cost\n",
    "        h_vals[k] += R**t * pi\n",
    "        ell[t] = ell_new\n",
    "\n",
    "H = np.mean(h_vals)\n",
    "print(f\"H = {H:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H$ is now a smaller value, which means that if the policy above was followed with $\\Delta = 0.05$, the profitability is not improved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Find the optimal $\\Delta$ maximizing $H$. Illustrate your result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the optimal $\\Delta$ that maximizes $H$, we try 100 different values of $\\Delta$ between 0 and 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Delta = 0.22\n",
      "H = 261.79\n"
     ]
    }
   ],
   "source": [
    "# Set initial values\n",
    "kappa = np.ones(T+1)\n",
    "ell = np.zeros(T+1)\n",
    "h_vals = np.zeros(K)\n",
    "\n",
    "for j, Delta in enumerate(np.linspace(0, 0.3, 100)):\n",
    "    for k in range(K):\n",
    "        eps = np.random.normal(loc=-0.5*sigma_eps**2, scale=sigma_eps, size=T+1)\n",
    "        for t in range(1, T+1):\n",
    "            kappa[t] = np.exp(rho*np.log(kappa[t-1]) + eps[t])\n",
    "        for t in range(T+1):\n",
    "            ell_new = ((1-eta)*kappa[t]/w)**(1/eta)\n",
    "            if t == 0:\n",
    "                adj_cost = 0\n",
    "            else:\n",
    "                if np.abs(ell_new - ell[t-1]) > Delta:\n",
    "                    ell_new = np.round(ell_new, 2)\n",
    "                    adj_cost = iota\n",
    "                else:\n",
    "                    adj_cost = 0\n",
    "            pi = kappa[t]*ell_new**(1-eta) - w*ell_new - adj_cost\n",
    "            h_vals[j] += R**t * pi\n",
    "            ell[t] = ell_new\n",
    "\n",
    "optimal_Delta = np.linspace(0, 0.3, 100)[np.argmax(h_vals)]\n",
    "H_optimal = np.max(h_vals)\n",
    "print(f\"Optimal Delta = {optimal_Delta:.2f}\")\n",
    "print(f\"H = {H_optimal:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value of $H$ is a lot higher than the values we have previously found, but the optimal value of $\\Delta$ is also a lot higher than the $\\Delta$ values used in the two previous questions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 5:** Suggest an alternative policy you believe might improve profitability. Implement and test your policy.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative policy that might improve profitability is to adjust the \n",
    "the number of hairdressers employed $\\ell_t$ based on the expected demand shock (forecast).\n",
    "\n",
    "We use a forecast of $\\log \\kappa_{t+1}$ based on $\\log \\kappa_t$ and the estimated parameters for AR(1). Then, we use the forecast to calculate the optimal number of hairdressers employed $\\ell_t^{\\ast}$, subject to the adjustment cost $\\iota$.\n",
    "\n",
    "This policy uses a 'noisy' forecast of future demand, so it might not always perform better than the other policies, but it has the potential to be more adaptive to changing demand conditions as it takes expected future shocks into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Delta = 0.29\n",
      "H = 223.27\n"
     ]
    }
   ],
   "source": [
    "kappa = np.ones(T+1)\n",
    "ell = np.zeros(T+1)\n",
    "h_vals = np.zeros(K)\n",
    "\n",
    "def forecast_kappa(log_kappa_t, eps_t):\n",
    "    return rho*log_kappa_t - 0.5*sigma_eps**2 + eps_t\n",
    "\n",
    "for j, Delta in enumerate(np.linspace(0, 0.3, 100)):\n",
    "    for k in range(K):\n",
    "        eps = np.random.normal(loc=-0.5*sigma_eps**2, scale=sigma_eps, size=T+1)\n",
    "        for t in range(1, T+1):\n",
    "            kappa[t] = np.exp(forecast_kappa(np.log(kappa[t-1]), eps[t]))\n",
    "            ell_new = ((1-eta)*kappa[t]/w)**(1/eta)\n",
    "            if t == 0:\n",
    "                adj_cost = 0\n",
    "            else:\n",
    "                if np.abs(ell_new - ell[t-1]) > Delta:\n",
    "                    ell_new = np.round(ell_new, 2)\n",
    "                    adj_cost = iota\n",
    "                else:\n",
    "                    adj_cost = 0\n",
    "            pi = kappa[t]*ell_new**(1-eta) - w*ell_new - adj_cost\n",
    "            h_vals[j] += R**t * pi\n",
    "            ell[t] = ell_new\n",
    "\n",
    "optimal_Delta = np.linspace(0, 0.3, 100)[np.argmax(h_vals)]\n",
    "H_optimal = np.max(h_vals)\n",
    "print(f\"Optimal Delta = {optimal_Delta:.2f}\")\n",
    "print(f\"H = {H_optimal:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that this alternative policy leads to a lower $H$ than in question 4 with the original policy. Therefore, we can conclude that adjusting the number of hairdressers employed based on the expected demand shock does not lead to higher profitability."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a id='toc3_'></a>[Problem 3: Global optimizer with refined multi-start](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the Griewank function:\n",
    "\n",
    "$$ f(\\boldsymbol{x}) = \\sum^n_{i=1} \\frac{x^2_i}{4000}-\\prod^n_{i=1}\\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right)+1$$\n",
    "\n",
    "The **global minimum** of this function is $f(0,0) = 0$ (remember: $\\cos(0)=1$).<br>\n",
    "But the function also have a lot of **local minima**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def griewank(x):\n",
    "    return griewank_(x[0],x[1])\n",
    "    \n",
    "def griewank_(x1,x2):\n",
    "    A = x1**2/4000 + x2**2/4000\n",
    "    B = np.cos(x1/np.sqrt(1))*np.cos(x2/np.sqrt(2))\n",
    "    return A-B+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **refined global optimizer with multi-start** is:\n",
    "\n",
    "1. Choose *bounds* for $\\mathbf{x}$ and *tolerance* $\\tau > 0$.\n",
    "2. Choose number of *warm-up iterations*, $\\underline{K} > 0$ and *maximum number of iterations*, $K > \\underline{K}$.\n",
    "3. In each iteration for $k \\in \\{0,1,\\dots,K-1\\}$:\n",
    "\n",
    "    A. Draw random $\\mathbf{x}^k$ uniformly within chosen bounds.\n",
    "\n",
    "    B. If $k < \\underline{K}$ go to step E.\n",
    "\n",
    "    C. Calculate $\\chi^k = 0.50\\cdot\\frac{2}{1+\\exp((k-\\underline{K})/100)}$  \n",
    "\n",
    "    D. Set $\\mathbf{x}^{k0} = \\chi^k \\mathbf{x}^k + (1-\\chi^k)\\mathbf{x}^{\\ast} $\n",
    "\n",
    "    E. Run optimizer with $\\mathbf{x}^{k0}$ as initial guess and $\\mathbf{x}^{k\\ast}$ as result.\n",
    "\n",
    "    F. Set $\\mathbf{x}^{\\ast} = \\mathbf{x}^{k\\ast}$ if $k = 0$ or $f(\\mathbf{x}^{k\\ast}) < f(\\mathbf{x}^{\\ast})$\n",
    "\n",
    "    G. If $f(\\mathbf{x}^{\\ast}) < \\tau$ go to step 4.\n",
    "\n",
    "4. Return the result $\\mathbf{x}^{\\ast}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As settings we choose:\n",
    "\n",
    "* $x_1,x_2 \\in  [-600,600]$\n",
    "* $\\tau = 10^{-8}$\n",
    "* $\\underline{K}=10$\n",
    "* $K=1000$\n",
    "\n",
    "The optimizer in Step 3.E is `BFGS` with a tolerance of $\\tau$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Implement the refined global optimizer with multi-start. Illustrate how the effective initial guesses $\\mathbf{x}^{k0}$ vary with the iteration counter $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def griewank(x):\n",
    "    return griewank_(x[0],x[1])\n",
    "    \n",
    "def griewank_(x1,x2):\n",
    "    A = x1**2/4000 + x2**2/4000\n",
    "    B = np.cos(x1/np.sqrt(1))*np.cos(x2/np.sqrt(2))\n",
    "    return A-B+1\n",
    "\n",
    "def global_opt(bounds, tau, K, K_warmup):\n",
    "    # Initialize best solution and value\n",
    "    x_best = None\n",
    "    f_best = np.inf\n",
    "\n",
    "    # Warm-up iterations without refinement step\n",
    "    for k in range(K_warmup):\n",
    "        # Draw random guess within bounds\n",
    "        x0 = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "        # Minimize function with BFGS\n",
    "        res = minimize(griewank, x0, method=\"BFGS\", tol=tau)\n",
    "\n",
    "        # Update best solution and value\n",
    "        if res.fun < f_best:\n",
    "            x_best = res.x\n",
    "            f_best = res.fun\n",
    "\n",
    "    # Refinement iterations with adjusted guess\n",
    "    for k in range(K_warmup, K):\n",
    "        # Draw random guess within bounds\n",
    "        xk = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "        if k == K_warmup:\n",
    "            # First refinement step\n",
    "            x_ref = x_best\n",
    "        else:\n",
    "            # Calculate chi_k\n",
    "            chi_k = 0.5*2/(1+np.exp((k - K_warmup)/100))\n",
    "\n",
    "            # Adjust initial guess\n",
    "            x_ref = chi_k * xk + (1 - chi_k) * x_best\n",
    "\n",
    "        # Minimize function with BFGS\n",
    "        res = minimize(griewank, x_ref, method=\"BFGS\", tol=tau)\n",
    "\n",
    "        # Update best solution if improvement\n",
    "        if res.fun < f_best:\n",
    "            x_best = res.x\n",
    "            f_best = res.fun\n",
    "\n",
    "        # Print current best value and effective initial guess\n",
    "        print(f\"iteration {k}: f_best = {f_best:.8f}\")\n",
    "        print(f\"x_eff  = {x_ref},\\n\")\n",
    "\n",
    "    return x_best, f_best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global_opt has three arguments: $1.$ lower and upper bounds for the variables $x_1$ and $x_2$, $2.$ tau is the tolerance, and $3.$ K is the maximum number of iterations (including warm-up iterations) and K_warmup is the number of warm-up iterations. The best solution found during the warm-up iterations is stored in x_best and f_best. \n",
    "\n",
    "The refinement iterations are done from K_warmup up to K. In each iteration, a new point (xk) is drawn uniformly within the bounds. x_best is used as the reference point x_ref if k==K_warmup, otherwise a parameter chi_k is used and x_ref is then used as the initial guess. The best solution is stored in x_best and f_best if it is improved compared to the previous best solution \n",
    "\n",
    "Finally, the effective initial guess is either: $1.$ the best point found during the warm-up, or $2.$ a point that is a combination of the new point and the best point.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the chosen settings, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10: f_best = 15.21566707\n",
      "x_eff  = [-191.54064327  155.34451346],\n",
      "\n",
      "iteration 11: f_best = 0.21693408\n",
      "x_eff  = [14.14381635 27.35572801],\n",
      "\n",
      "iteration 12: f_best = 0.21693408\n",
      "x_eff  = [-142.34731316   56.028193  ],\n",
      "\n",
      "iteration 13: f_best = 0.21693408\n",
      "x_eff  = [113.89991816  10.21404799],\n",
      "\n",
      "iteration 14: f_best = 0.21693408\n",
      "x_eff  = [-233.55075195   92.29196836],\n",
      "\n",
      "iteration 15: f_best = 0.21693408\n",
      "x_eff  = [-137.91259586   60.12960541],\n",
      "\n",
      "iteration 16: f_best = 0.21693408\n",
      "x_eff  = [-203.94630826  265.39217564],\n",
      "\n",
      "iteration 17: f_best = 0.21693408\n",
      "x_eff  = [-104.28125049   -6.05132491],\n",
      "\n",
      "iteration 18: f_best = 0.21693408\n",
      "x_eff  = [241.73740303 -39.96165625],\n",
      "\n",
      "iteration 19: f_best = 0.21693408\n",
      "x_eff  = [ -3.35152161 -45.28074786],\n",
      "\n",
      "iteration 20: f_best = 0.21693408\n",
      "x_eff  = [ -42.54554131 -245.02911072],\n",
      "\n",
      "iteration 21: f_best = 0.21693408\n",
      "x_eff  = [-173.58423803   23.58001988],\n",
      "\n",
      "iteration 22: f_best = 0.21693408\n",
      "x_eff  = [ -92.44616332 -241.89741042],\n",
      "\n",
      "iteration 23: f_best = 0.21693408\n",
      "x_eff  = [202.3386558  160.66188121],\n",
      "\n",
      "iteration 24: f_best = 0.21693408\n",
      "x_eff  = [228.70615377  94.9577596 ],\n",
      "\n",
      "iteration 25: f_best = 0.21693408\n",
      "x_eff  = [ -85.50791665 -160.80663699],\n",
      "\n",
      "iteration 26: f_best = 0.21693408\n",
      "x_eff  = [137.29589184  96.08690637],\n",
      "\n",
      "iteration 27: f_best = 0.21693408\n",
      "x_eff  = [-218.62266358   99.96702472],\n",
      "\n",
      "iteration 28: f_best = 0.21693408\n",
      "x_eff  = [-153.92229749  -57.00401837],\n",
      "\n",
      "iteration 29: f_best = 0.21693408\n",
      "x_eff  = [ 240.38109733 -240.6382688 ],\n",
      "\n",
      "iteration 30: f_best = 0.21693408\n",
      "x_eff  = [255.69458307  83.39436474],\n",
      "\n",
      "iteration 31: f_best = 0.21693408\n",
      "x_eff  = [239.67005977 132.22918188],\n",
      "\n",
      "iteration 32: f_best = 0.21693408\n",
      "x_eff  = [-209.67573754   87.91526067],\n",
      "\n",
      "iteration 33: f_best = 0.21693408\n",
      "x_eff  = [228.73587172 199.58746344],\n",
      "\n",
      "iteration 34: f_best = 0.21693408\n",
      "x_eff  = [155.74912492 166.74089189],\n",
      "\n",
      "iteration 35: f_best = 0.21693408\n",
      "x_eff  = [-148.93266475 -150.25032121],\n",
      "\n",
      "iteration 36: f_best = 0.21693408\n",
      "x_eff  = [161.48233108 224.2348674 ],\n",
      "\n",
      "iteration 37: f_best = 0.21693408\n",
      "x_eff  = [-234.78112038  -55.41561103],\n",
      "\n",
      "iteration 38: f_best = 0.21693408\n",
      "x_eff  = [-161.55032445 -210.28173726],\n",
      "\n",
      "iteration 39: f_best = 0.21693408\n",
      "x_eff  = [-69.57805037 202.37728617],\n",
      "\n",
      "iteration 40: f_best = 0.21693408\n",
      "x_eff  = [-75.30453352 105.38639105],\n",
      "\n",
      "iteration 41: f_best = 0.21693408\n",
      "x_eff  = [128.1505719  167.09052492],\n",
      "\n",
      "iteration 42: f_best = 0.21693408\n",
      "x_eff  = [  -8.08188623 -109.21585718],\n",
      "\n",
      "iteration 43: f_best = 0.21693408\n",
      "x_eff  = [-225.68519742  258.33302632],\n",
      "\n",
      "iteration 44: f_best = 0.21693408\n",
      "x_eff  = [  5.43500116 192.16469618],\n",
      "\n",
      "iteration 45: f_best = 0.21693408\n",
      "x_eff  = [133.92358729  11.04233901],\n",
      "\n",
      "iteration 46: f_best = 0.21693408\n",
      "x_eff  = [77.57191029 35.86421893],\n",
      "\n",
      "iteration 47: f_best = 0.21693408\n",
      "x_eff  = [-169.60349934   25.68952336],\n",
      "\n",
      "iteration 48: f_best = 0.21693408\n",
      "x_eff  = [-17.55273453 226.91881458],\n",
      "\n",
      "iteration 49: f_best = 0.21693408\n",
      "x_eff  = [ 234.04205801 -131.17896737],\n",
      "\n",
      "iteration 50: f_best = 0.21693408\n",
      "x_eff  = [-19.46399974 -37.21543102],\n",
      "\n",
      "iteration 51: f_best = 0.21693408\n",
      "x_eff  = [-92.73970921 184.0496586 ],\n",
      "\n",
      "iteration 52: f_best = 0.21693408\n",
      "x_eff  = [ 225.07362138 -193.14723589],\n",
      "\n",
      "iteration 53: f_best = 0.21693408\n",
      "x_eff  = [ 61.66039545 -57.46223315],\n",
      "\n",
      "iteration 54: f_best = 0.21693408\n",
      "x_eff  = [ 113.9818536 -160.4929275],\n",
      "\n",
      "iteration 55: f_best = 0.21693408\n",
      "x_eff  = [-119.75786577   -9.6364348 ],\n",
      "\n",
      "iteration 56: f_best = 0.21693408\n",
      "x_eff  = [-119.88222776 -147.68191782],\n",
      "\n",
      "iteration 57: f_best = 0.21693408\n",
      "x_eff  = [  99.45048557 -147.869167  ],\n",
      "\n",
      "iteration 58: f_best = 0.21693408\n",
      "x_eff  = [  7.36770797 210.63191968],\n",
      "\n",
      "iteration 59: f_best = 0.21693408\n",
      "x_eff  = [  92.8874439  -150.06917848],\n",
      "\n",
      "iteration 60: f_best = 0.21693408\n",
      "x_eff  = [-167.67921527  -51.67718974],\n",
      "\n",
      "iteration 61: f_best = 0.21693408\n",
      "x_eff  = [-163.09234313    6.07828337],\n",
      "\n",
      "iteration 62: f_best = 0.21693408\n",
      "x_eff  = [  98.32187153 -135.88334307],\n",
      "\n",
      "iteration 63: f_best = 0.21693408\n",
      "x_eff  = [-146.87744082  -95.3939989 ],\n",
      "\n",
      "iteration 64: f_best = 0.21693408\n",
      "x_eff  = [180.06762263 183.14324252],\n",
      "\n",
      "iteration 65: f_best = 0.21693408\n",
      "x_eff  = [93.14456304 63.34789039],\n",
      "\n",
      "iteration 66: f_best = 0.21693408\n",
      "x_eff  = [-78.60363566 119.42298353],\n",
      "\n",
      "iteration 67: f_best = 0.21693408\n",
      "x_eff  = [ 176.8197576 -133.2671467],\n",
      "\n",
      "iteration 68: f_best = 0.21693408\n",
      "x_eff  = [-155.49501469  -26.04916285],\n",
      "\n",
      "iteration 69: f_best = 0.21693408\n",
      "x_eff  = [95.1666186  -4.06113043],\n",
      "\n",
      "iteration 70: f_best = 0.21693408\n",
      "x_eff  = [ -51.57662494 -132.35458437],\n",
      "\n",
      "iteration 71: f_best = 0.21693408\n",
      "x_eff  = [172.7617333   27.65982633],\n",
      "\n",
      "iteration 72: f_best = 0.21693408\n",
      "x_eff  = [   0.81092251 -149.78380348],\n",
      "\n",
      "iteration 73: f_best = 0.21693408\n",
      "x_eff  = [126.27636945 198.75383943],\n",
      "\n",
      "iteration 74: f_best = 0.21693408\n",
      "x_eff  = [-51.57401313 -79.33894239],\n",
      "\n",
      "iteration 75: f_best = 0.21693408\n",
      "x_eff  = [-73.08912339 114.46059863],\n",
      "\n",
      "iteration 76: f_best = 0.21693408\n",
      "x_eff  = [-18.92274169  80.44027257],\n",
      "\n",
      "iteration 77: f_best = 0.21693408\n",
      "x_eff  = [ 183.70745218 -179.34383943],\n",
      "\n",
      "iteration 78: f_best = 0.21693408\n",
      "x_eff  = [-186.85921211   27.48187745],\n",
      "\n",
      "iteration 79: f_best = 0.21693408\n",
      "x_eff  = [151.4924975  -65.37798649],\n",
      "\n",
      "iteration 80: f_best = 0.21693408\n",
      "x_eff  = [119.6254715  -15.68613068],\n",
      "\n",
      "iteration 81: f_best = 0.21693408\n",
      "x_eff  = [-184.3710986   112.51606274],\n",
      "\n",
      "iteration 82: f_best = 0.21693408\n",
      "x_eff  = [-76.43950431 -71.12141869],\n",
      "\n",
      "iteration 83: f_best = 0.21693408\n",
      "x_eff  = [-34.59328311 -84.73542244],\n",
      "\n",
      "iteration 84: f_best = 0.21693408\n",
      "x_eff  = [-153.62223956    7.57663962],\n",
      "\n",
      "iteration 85: f_best = 0.21693408\n",
      "x_eff  = [73.44498563 75.86680642],\n",
      "\n",
      "iteration 86: f_best = 0.21693408\n",
      "x_eff  = [ 114.5237113  -119.74043596],\n",
      "\n",
      "iteration 87: f_best = 0.21693408\n",
      "x_eff  = [182.31517975 -67.21377727],\n",
      "\n",
      "iteration 88: f_best = 0.21693408\n",
      "x_eff  = [-60.66314015  85.58067739],\n",
      "\n",
      "iteration 89: f_best = 0.21693408\n",
      "x_eff  = [73.98513018 64.97667921],\n",
      "\n",
      "iteration 90: f_best = 0.21693408\n",
      "x_eff  = [153.25010739 179.26482075],\n",
      "\n",
      "iteration 91: f_best = 0.21693408\n",
      "x_eff  = [155.05992617 133.09909887],\n",
      "\n",
      "iteration 92: f_best = 0.21693408\n",
      "x_eff  = [ -10.4284415  -158.51999047],\n",
      "\n",
      "iteration 93: f_best = 0.21693408\n",
      "x_eff  = [ -38.28502675 -121.79377878],\n",
      "\n",
      "iteration 94: f_best = 0.21693408\n",
      "x_eff  = [-62.07041454   1.77062109],\n",
      "\n",
      "iteration 95: f_best = 0.21693408\n",
      "x_eff  = [40.50731691 86.41187447],\n",
      "\n",
      "iteration 96: f_best = 0.21693408\n",
      "x_eff  = [-111.45565302  -56.62174396],\n",
      "\n",
      "iteration 97: f_best = 0.21693408\n",
      "x_eff  = [125.2276687  161.81331537],\n",
      "\n",
      "iteration 98: f_best = 0.21693408\n",
      "x_eff  = [19.65858407 79.27586883],\n",
      "\n",
      "iteration 99: f_best = 0.21693408\n",
      "x_eff  = [ 41.67750394 -93.31996223],\n",
      "\n",
      "iteration 100: f_best = 0.21693408\n",
      "x_eff  = [  59.0028394  -105.45761122],\n",
      "\n",
      "iteration 101: f_best = 0.21693408\n",
      "x_eff  = [ 166.32392026 -121.2915875 ],\n",
      "\n",
      "iteration 102: f_best = 0.21693408\n",
      "x_eff  = [-146.16396898  170.53963113],\n",
      "\n",
      "iteration 103: f_best = 0.21693408\n",
      "x_eff  = [-113.93564051 -139.7955676 ],\n",
      "\n",
      "iteration 104: f_best = 0.21693408\n",
      "x_eff  = [ 22.71428609 -20.06655823],\n",
      "\n",
      "iteration 105: f_best = 0.21693408\n",
      "x_eff  = [63.44671597 25.41552313],\n",
      "\n",
      "iteration 106: f_best = 0.21693408\n",
      "x_eff  = [-89.50333672 -62.30094713],\n",
      "\n",
      "iteration 107: f_best = 0.21693408\n",
      "x_eff  = [-151.83906792  138.56723395],\n",
      "\n",
      "iteration 108: f_best = 0.21693408\n",
      "x_eff  = [ 49.66505158 108.50487558],\n",
      "\n",
      "iteration 109: f_best = 0.21693408\n",
      "x_eff  = [169.06336446 -35.61486042],\n",
      "\n",
      "iteration 110: f_best = 0.21693408\n",
      "x_eff  = [ -31.07674198 -101.0466945 ],\n",
      "\n",
      "iteration 111: f_best = 0.21693408\n",
      "x_eff  = [-52.02771433  66.04561752],\n",
      "\n",
      "iteration 112: f_best = 0.21693408\n",
      "x_eff  = [ 77.36276014 115.03187419],\n",
      "\n",
      "iteration 113: f_best = 0.21693408\n",
      "x_eff  = [ 1.65239139e+02 -1.61191107e-01],\n",
      "\n",
      "iteration 114: f_best = 0.18734007\n",
      "x_eff  = [ -4.51219608 -27.62241155],\n",
      "\n",
      "iteration 115: f_best = 0.18734007\n",
      "x_eff  = [-38.05579381 -17.06739384],\n",
      "\n",
      "iteration 116: f_best = 0.18734007\n",
      "x_eff  = [ 40.45241343 133.30873896],\n",
      "\n",
      "iteration 117: f_best = 0.18734007\n",
      "x_eff  = [-71.63175355  -7.75920507],\n",
      "\n",
      "iteration 118: f_best = 0.18734007\n",
      "x_eff  = [-66.54530648  60.36850576],\n",
      "\n",
      "iteration 119: f_best = 0.18734007\n",
      "x_eff  = [-133.47294511 -137.26836133],\n",
      "\n",
      "iteration 120: f_best = 0.10850154\n",
      "x_eff  = [-19.13620131  10.39135349],\n",
      "\n",
      "iteration 121: f_best = 0.10850154\n",
      "x_eff  = [-55.98643777  68.88712774],\n",
      "\n",
      "iteration 122: f_best = 0.10850154\n",
      "x_eff  = [-17.00689849  57.15620232],\n",
      "\n",
      "iteration 123: f_best = 0.10850154\n",
      "x_eff  = [112.30108537  35.52979823],\n",
      "\n",
      "iteration 124: f_best = 0.10850154\n",
      "x_eff  = [ 50.64164408 -66.29145228],\n",
      "\n",
      "iteration 125: f_best = 0.10850154\n",
      "x_eff  = [-20.07102631  45.33918667],\n",
      "\n",
      "iteration 126: f_best = 0.10850154\n",
      "x_eff  = [   1.9763588  -114.90574545],\n",
      "\n",
      "iteration 127: f_best = 0.10850154\n",
      "x_eff  = [-44.40472416 -86.0302002 ],\n",
      "\n",
      "iteration 128: f_best = 0.10850154\n",
      "x_eff  = [39.55749483 55.22295243],\n",
      "\n",
      "iteration 129: f_best = 0.10850154\n",
      "x_eff  = [-14.79959101  42.03114124],\n",
      "\n",
      "iteration 130: f_best = 0.10850154\n",
      "x_eff  = [-68.16961566  69.94431071],\n",
      "\n",
      "iteration 131: f_best = 0.10850154\n",
      "x_eff  = [-27.08576929 127.52357809],\n",
      "\n",
      "iteration 132: f_best = 0.10850154\n",
      "x_eff  = [116.76861808 110.49087795],\n",
      "\n",
      "iteration 133: f_best = 0.10850154\n",
      "x_eff  = [-138.51233789 -128.71159463],\n",
      "\n",
      "iteration 134: f_best = 0.10850154\n",
      "x_eff  = [  6.03976215 -36.51810207],\n",
      "\n",
      "iteration 135: f_best = 0.10850154\n",
      "x_eff  = [-43.4360057  -99.58634412],\n",
      "\n",
      "iteration 136: f_best = 0.10850154\n",
      "x_eff  = [-42.72931391 -63.0838536 ],\n",
      "\n",
      "iteration 137: f_best = 0.10850154\n",
      "x_eff  = [-144.48085534  -72.10872433],\n",
      "\n",
      "iteration 138: f_best = 0.10850154\n",
      "x_eff  = [30.19052319 94.11325091],\n",
      "\n",
      "iteration 139: f_best = 0.10850154\n",
      "x_eff  = [93.02492683 64.8086028 ],\n",
      "\n",
      "iteration 140: f_best = 0.10850154\n",
      "x_eff  = [-65.52999189 104.49352557],\n",
      "\n",
      "iteration 141: f_best = 0.10850154\n",
      "x_eff  = [-12.47659585  33.4256613 ],\n",
      "\n",
      "iteration 142: f_best = 0.10850154\n",
      "x_eff  = [-132.85526035  114.57922791],\n",
      "\n",
      "iteration 143: f_best = 0.10850154\n",
      "x_eff  = [ 26.72813747 -64.53103501],\n",
      "\n",
      "iteration 144: f_best = 0.10850154\n",
      "x_eff  = [94.66936198 -0.60879704],\n",
      "\n",
      "iteration 145: f_best = 0.10850154\n",
      "x_eff  = [29.69789492 57.79718211],\n",
      "\n",
      "iteration 146: f_best = 0.10850154\n",
      "x_eff  = [ 24.88957625 -80.1960438 ],\n",
      "\n",
      "iteration 147: f_best = 0.10850154\n",
      "x_eff  = [ 65.25384008 -87.34607057],\n",
      "\n",
      "iteration 148: f_best = 0.10850154\n",
      "x_eff  = [-65.64426503  92.59399732],\n",
      "\n",
      "iteration 149: f_best = 0.10850154\n",
      "x_eff  = [-63.74720126  43.39014626],\n",
      "\n",
      "iteration 150: f_best = 0.10850154\n",
      "x_eff  = [-15.72768212 124.34838604],\n",
      "\n",
      "iteration 151: f_best = 0.10850154\n",
      "x_eff  = [ 77.63071339 122.84820412],\n",
      "\n",
      "iteration 152: f_best = 0.10850154\n",
      "x_eff  = [-35.18700614 -71.57815573],\n",
      "\n",
      "iteration 153: f_best = 0.10850154\n",
      "x_eff  = [ 12.84132741 -56.47561809],\n",
      "\n",
      "iteration 154: f_best = 0.10850154\n",
      "x_eff  = [-77.44966308  27.99315214],\n",
      "\n",
      "iteration 155: f_best = 0.10850154\n",
      "x_eff  = [ -4.4961562  116.30250982],\n",
      "\n",
      "iteration 156: f_best = 0.10850154\n",
      "x_eff  = [  54.31217454 -105.19108767],\n",
      "\n",
      "iteration 157: f_best = 0.10850154\n",
      "x_eff  = [ 57.83302715 -19.21291432],\n",
      "\n",
      "iteration 158: f_best = 0.10850154\n",
      "x_eff  = [58.1637711  12.85749007],\n",
      "\n",
      "iteration 159: f_best = 0.10850154\n",
      "x_eff  = [-78.66225486 -73.25299086],\n",
      "\n",
      "iteration 160: f_best = 0.10850154\n",
      "x_eff  = [-12.82138331 -53.68152712],\n",
      "\n",
      "iteration 161: f_best = 0.10850154\n",
      "x_eff  = [-94.19051039 -73.51599606],\n",
      "\n",
      "iteration 162: f_best = 0.10850154\n",
      "x_eff  = [ 6.31319137 82.94805483],\n",
      "\n",
      "iteration 163: f_best = 0.10850154\n",
      "x_eff  = [19.92436727 15.77535536],\n",
      "\n",
      "iteration 164: f_best = 0.10850154\n",
      "x_eff  = [-34.93270243 -17.25417924],\n",
      "\n",
      "iteration 165: f_best = 0.10850154\n",
      "x_eff  = [45.05663782  1.19960089],\n",
      "\n",
      "iteration 166: f_best = 0.10850154\n",
      "x_eff  = [42.78671437 93.48364193],\n",
      "\n",
      "iteration 167: f_best = 0.10850154\n",
      "x_eff  = [-70.50836658 -19.98751859],\n",
      "\n",
      "iteration 168: f_best = 0.10850154\n",
      "x_eff  = [-30.20678994  84.26146874],\n",
      "\n",
      "iteration 169: f_best = 0.10850154\n",
      "x_eff  = [-89.17200914   0.95914711],\n",
      "\n",
      "iteration 170: f_best = 0.10850154\n",
      "x_eff  = [-73.88292161  62.24514525],\n",
      "\n",
      "iteration 171: f_best = 0.10850154\n",
      "x_eff  = [33.716779   84.63802206],\n",
      "\n",
      "iteration 172: f_best = 0.10850154\n",
      "x_eff  = [-87.30509033 -17.4075035 ],\n",
      "\n",
      "iteration 173: f_best = 0.10850154\n",
      "x_eff  = [ -7.1145784  -71.30721616],\n",
      "\n",
      "iteration 174: f_best = 0.10850154\n",
      "x_eff  = [-17.97318195  95.60710015],\n",
      "\n",
      "iteration 175: f_best = 0.10850154\n",
      "x_eff  = [-96.86012358 102.25856898],\n",
      "\n",
      "iteration 176: f_best = 0.10850154\n",
      "x_eff  = [ 7.84373051 52.14230969],\n",
      "\n",
      "iteration 177: f_best = 0.10850154\n",
      "x_eff  = [-102.0757314  -75.7910478],\n",
      "\n",
      "iteration 178: f_best = 0.00739604\n",
      "x_eff  = [ 1.93072167 -4.28477055],\n",
      "\n",
      "iteration 179: f_best = 0.00739604\n",
      "x_eff  = [ 29.38680548 -96.67179871],\n",
      "\n",
      "iteration 180: f_best = 0.00739604\n",
      "x_eff  = [-73.21551001  32.65738408],\n",
      "\n",
      "iteration 181: f_best = 0.00739604\n",
      "x_eff  = [ 13.10848996 -93.54733992],\n",
      "\n",
      "iteration 182: f_best = 0.00739604\n",
      "x_eff  = [-76.49851922  63.35727433],\n",
      "\n",
      "iteration 183: f_best = 0.00739604\n",
      "x_eff  = [ 3.53404433 50.99085626],\n",
      "\n",
      "iteration 184: f_best = 0.00739604\n",
      "x_eff  = [65.36564848 20.29555361],\n",
      "\n",
      "iteration 185: f_best = 0.00739604\n",
      "x_eff  = [-84.59113241  77.95305265],\n",
      "\n",
      "iteration 186: f_best = 0.00739604\n",
      "x_eff  = [-36.09178438 -87.59286851],\n",
      "\n",
      "iteration 187: f_best = 0.00739604\n",
      "x_eff  = [-48.11995468 -52.78018001],\n",
      "\n",
      "iteration 188: f_best = 0.00739604\n",
      "x_eff  = [  7.74735551 -42.32684172],\n",
      "\n",
      "iteration 189: f_best = 0.00739604\n",
      "x_eff  = [ 56.3089874  -53.26522354],\n",
      "\n",
      "iteration 190: f_best = 0.00739604\n",
      "x_eff  = [-78.81259487  48.15984275],\n",
      "\n",
      "iteration 191: f_best = 0.00739604\n",
      "x_eff  = [ 75.46719243 -62.05140544],\n",
      "\n",
      "iteration 192: f_best = 0.00739604\n",
      "x_eff  = [-29.57406677 -49.29051525],\n",
      "\n",
      "iteration 193: f_best = 0.00739604\n",
      "x_eff  = [ 4.40478708 26.04317284],\n",
      "\n",
      "iteration 194: f_best = 0.00739604\n",
      "x_eff  = [ 46.46366436 -85.02477158],\n",
      "\n",
      "iteration 195: f_best = 0.00739604\n",
      "x_eff  = [21.33391953 15.31698383],\n",
      "\n",
      "iteration 196: f_best = 0.00739604\n",
      "x_eff  = [-72.94704045  48.43454549],\n",
      "\n",
      "iteration 197: f_best = 0.00739604\n",
      "x_eff  = [26.19862552  9.58545562],\n",
      "\n",
      "iteration 198: f_best = 0.00739604\n",
      "x_eff  = [ 73.88785672 -20.82561109],\n",
      "\n",
      "iteration 199: f_best = 0.00739604\n",
      "x_eff  = [-68.29894232 -24.7611688 ],\n",
      "\n",
      "iteration 200: f_best = 0.00739604\n",
      "x_eff  = [-43.4782966  -35.27937117],\n",
      "\n",
      "iteration 201: f_best = 0.00739604\n",
      "x_eff  = [ 58.55255053 -12.88540331],\n",
      "\n",
      "iteration 202: f_best = 0.00739604\n",
      "x_eff  = [ 1.67458214 13.48979401],\n",
      "\n",
      "iteration 203: f_best = 0.00739604\n",
      "x_eff  = [-72.59459281  65.55294937],\n",
      "\n",
      "iteration 204: f_best = 0.00739604\n",
      "x_eff  = [62.47946499 53.18333449],\n",
      "\n",
      "iteration 205: f_best = 0.00739604\n",
      "x_eff  = [63.86843357 39.56258309],\n",
      "\n",
      "iteration 206: f_best = 0.00739604\n",
      "x_eff  = [53.3836851  -5.83799611],\n",
      "\n",
      "iteration 207: f_best = 0.00739604\n",
      "x_eff  = [-31.22291444 -24.43716853],\n",
      "\n",
      "iteration 208: f_best = 0.00739604\n",
      "x_eff  = [-40.27220666  47.40328422],\n",
      "\n",
      "iteration 209: f_best = 0.00739604\n",
      "x_eff  = [-42.82783715 -68.79392448],\n",
      "\n",
      "iteration 210: f_best = 0.00739604\n",
      "x_eff  = [-50.32232431  24.72822399],\n",
      "\n",
      "iteration 211: f_best = 0.00739604\n",
      "x_eff  = [35.15881865 43.29800422],\n",
      "\n",
      "iteration 212: f_best = 0.00739604\n",
      "x_eff  = [22.70850466 -9.52258166],\n",
      "\n",
      "iteration 213: f_best = 0.00739604\n",
      "x_eff  = [  9.15649999 -26.25053498],\n",
      "\n",
      "iteration 214: f_best = 0.00739604\n",
      "x_eff  = [ 65.99156008 -42.27290933],\n",
      "\n",
      "iteration 215: f_best = 0.00739604\n",
      "x_eff  = [34.89850683 47.33847183],\n",
      "\n",
      "iteration 216: f_best = 0.00739604\n",
      "x_eff  = [ 40.3068602  -47.49428195],\n",
      "\n",
      "iteration 217: f_best = 0.00739604\n",
      "x_eff  = [13.91067474 46.57960819],\n",
      "\n",
      "iteration 218: f_best = 0.00739604\n",
      "x_eff  = [51.22043579 24.38772367],\n",
      "\n",
      "iteration 219: f_best = 0.00739604\n",
      "x_eff  = [53.28704046 27.81655041],\n",
      "\n",
      "iteration 220: f_best = 0.00739604\n",
      "x_eff  = [ 16.41954337 -36.44260811],\n",
      "\n",
      "iteration 221: f_best = 0.00739604\n",
      "x_eff  = [20.22068509  6.03204   ],\n",
      "\n",
      "iteration 222: f_best = 0.00739604\n",
      "x_eff  = [  7.13904856 -55.21757921],\n",
      "\n",
      "iteration 223: f_best = 0.00739604\n",
      "x_eff  = [ 23.60030323 -20.73530704],\n",
      "\n",
      "iteration 224: f_best = 0.00739604\n",
      "x_eff  = [-12.07080872  54.24293282],\n",
      "\n",
      "iteration 225: f_best = 0.00739604\n",
      "x_eff  = [12.89185052  2.95153578],\n",
      "\n",
      "iteration 226: f_best = 0.00739604\n",
      "x_eff  = [-12.16659771  53.43001618],\n",
      "\n",
      "iteration 227: f_best = 0.00739604\n",
      "x_eff  = [ 24.37629355 -22.48231788],\n",
      "\n",
      "iteration 228: f_best = 0.00739604\n",
      "x_eff  = [-40.44898285   3.72592557],\n",
      "\n",
      "iteration 229: f_best = 0.00739604\n",
      "x_eff  = [ 2.94559239 32.05817239],\n",
      "\n",
      "iteration 230: f_best = 0.00739604\n",
      "x_eff  = [  5.61570636 -19.11748084],\n",
      "\n",
      "iteration 231: f_best = 0.00739604\n",
      "x_eff  = [ 12.1734877  -20.30049706],\n",
      "\n",
      "iteration 232: f_best = 0.00739604\n",
      "x_eff  = [-11.20974102  21.42938133],\n",
      "\n",
      "iteration 233: f_best = 0.00739604\n",
      "x_eff  = [-14.24694682  -5.4763077 ],\n",
      "\n",
      "iteration 234: f_best = 0.00739604\n",
      "x_eff  = [-8.71532244  1.5616276 ],\n",
      "\n",
      "iteration 235: f_best = 0.00739604\n",
      "x_eff  = [-51.63584112  -1.02729533],\n",
      "\n",
      "iteration 236: f_best = 0.00739604\n",
      "x_eff  = [ 36.45104192 -15.33160696],\n",
      "\n",
      "iteration 237: f_best = 0.00739604\n",
      "x_eff  = [ 56.83348561 -42.37339779],\n",
      "\n",
      "iteration 238: f_best = 0.00739604\n",
      "x_eff  = [  0.45845957 -20.14075634],\n",
      "\n",
      "iteration 239: f_best = 0.00739604\n",
      "x_eff  = [ -0.07159227 -56.39624372],\n",
      "\n",
      "iteration 240: f_best = 0.00739604\n",
      "x_eff  = [-23.13471895   9.36818197],\n",
      "\n",
      "iteration 241: f_best = 0.00739604\n",
      "x_eff  = [-48.98449935  11.6101257 ],\n",
      "\n",
      "iteration 242: f_best = 0.00739604\n",
      "x_eff  = [41.61053448 -2.02605836],\n",
      "\n",
      "iteration 243: f_best = 0.00739604\n",
      "x_eff  = [23.97502215 34.31975341],\n",
      "\n",
      "iteration 244: f_best = 0.00739604\n",
      "x_eff  = [-5.0135959  37.69803757],\n",
      "\n",
      "iteration 245: f_best = 0.00739604\n",
      "x_eff  = [24.20366917 36.88032982],\n",
      "\n",
      "iteration 246: f_best = 0.00739604\n",
      "x_eff  = [39.54366994 18.46560558],\n",
      "\n",
      "iteration 247: f_best = 0.00739604\n",
      "x_eff  = [49.36036108 -2.57588817],\n",
      "\n",
      "iteration 248: f_best = 0.00739604\n",
      "x_eff  = [19.25547509  6.68135184],\n",
      "\n",
      "iteration 249: f_best = 0.00739604\n",
      "x_eff  = [29.06175473 39.61123843],\n",
      "\n",
      "iteration 250: f_best = 0.00739604\n",
      "x_eff  = [-38.95886015 -49.51866745],\n",
      "\n",
      "iteration 251: f_best = 0.00739604\n",
      "x_eff  = [-13.53298623  -0.2710242 ],\n",
      "\n",
      "iteration 252: f_best = 0.00739604\n",
      "x_eff  = [-24.91732677  40.69511739],\n",
      "\n",
      "iteration 253: f_best = 0.00739604\n",
      "x_eff  = [40.24101767  6.41977163],\n",
      "\n",
      "iteration 254: f_best = 0.00739604\n",
      "x_eff  = [  2.73789278 -18.74474   ],\n",
      "\n",
      "iteration 255: f_best = 0.00739604\n",
      "x_eff  = [23.09194731 32.56123921],\n",
      "\n",
      "iteration 256: f_best = 0.00739604\n",
      "x_eff  = [-5.53803493  9.8913612 ],\n",
      "\n",
      "iteration 257: f_best = 0.00739604\n",
      "x_eff  = [12.06623551 22.75083295],\n",
      "\n",
      "iteration 258: f_best = 0.00739604\n",
      "x_eff  = [ 31.45582459 -40.51334196],\n",
      "\n",
      "iteration 259: f_best = 0.00739604\n",
      "x_eff  = [-33.55205187 -48.50410997],\n",
      "\n",
      "iteration 260: f_best = 0.00739604\n",
      "x_eff  = [ 43.25844914 -28.71250484],\n",
      "\n",
      "iteration 261: f_best = 0.00739604\n",
      "x_eff  = [-35.828658   -13.02013917],\n",
      "\n",
      "iteration 262: f_best = 0.00739604\n",
      "x_eff  = [13.15082684  7.94876178],\n",
      "\n",
      "iteration 263: f_best = 0.00739604\n",
      "x_eff  = [-28.38533679  37.78942402],\n",
      "\n",
      "iteration 264: f_best = 0.00739604\n",
      "x_eff  = [-5.32718417 13.13065043],\n",
      "\n",
      "iteration 265: f_best = 0.00739604\n",
      "x_eff  = [40.38937188 -2.96850107],\n",
      "\n",
      "iteration 266: f_best = 0.00739604\n",
      "x_eff  = [11.18905386  3.15519547],\n",
      "\n",
      "iteration 267: f_best = 0.00739604\n",
      "x_eff  = [33.11400854 -4.58136021],\n",
      "\n",
      "iteration 268: f_best = 0.00739604\n",
      "x_eff  = [14.14542828 35.50090715],\n",
      "\n",
      "iteration 269: f_best = 0.00739604\n",
      "x_eff  = [10.26427701 -1.5873264 ],\n",
      "\n",
      "iteration 270: f_best = 0.00739604\n",
      "x_eff  = [-35.343519   -19.08908179],\n",
      "\n",
      "iteration 271: f_best = 0.00739604\n",
      "x_eff  = [-15.99845758  -2.5831103 ],\n",
      "\n",
      "iteration 272: f_best = 0.00739604\n",
      "x_eff  = [12.24422067  6.27100221],\n",
      "\n",
      "iteration 273: f_best = 0.00739604\n",
      "x_eff  = [23.77608918 24.19052987],\n",
      "\n",
      "iteration 274: f_best = 0.00739604\n",
      "x_eff  = [ 5.67076546 35.69329743],\n",
      "\n",
      "iteration 275: f_best = 0.00739604\n",
      "x_eff  = [-26.12661865  31.42333148],\n",
      "\n",
      "iteration 276: f_best = 0.00739604\n",
      "x_eff  = [ 14.94212949 -33.492793  ],\n",
      "\n",
      "iteration 277: f_best = 0.00739604\n",
      "x_eff  = [41.31561398 -6.58230065],\n",
      "\n",
      "iteration 278: f_best = 0.00739604\n",
      "x_eff  = [-31.08159499 -22.54788663],\n",
      "\n",
      "iteration 279: f_best = 0.00739604\n",
      "x_eff  = [-5.94181514  6.55662115],\n",
      "\n",
      "iteration 280: f_best = 0.00739604\n",
      "x_eff  = [-27.45339988 -40.33189062],\n",
      "\n",
      "iteration 281: f_best = 0.00739604\n",
      "x_eff  = [-27.2362899    7.35913732],\n",
      "\n",
      "iteration 282: f_best = 0.00739604\n",
      "x_eff  = [5.47301136 7.42093295],\n",
      "\n",
      "iteration 283: f_best = 0.00739604\n",
      "x_eff  = [ 37.71598575 -32.03147549],\n",
      "\n",
      "iteration 284: f_best = 0.00739604\n",
      "x_eff  = [ 37.57614475 -24.49821402],\n",
      "\n",
      "iteration 285: f_best = 0.00739604\n",
      "x_eff  = [-3.11099188 -1.75550269],\n",
      "\n",
      "iteration 286: f_best = 0.00739604\n",
      "x_eff  = [-18.76370633  -9.11466215],\n",
      "\n",
      "iteration 287: f_best = 0.00739604\n",
      "x_eff  = [ -9.36933284 -26.71313405],\n",
      "\n",
      "iteration 288: f_best = 0.00739604\n",
      "x_eff  = [18.22221029 19.12555951],\n",
      "\n",
      "iteration 289: f_best = 0.00739604\n",
      "x_eff  = [25.94711514 25.44578559],\n",
      "\n",
      "iteration 290: f_best = 0.00739604\n",
      "x_eff  = [ 27.23080906 -26.1295884 ],\n",
      "\n",
      "iteration 291: f_best = 0.00739604\n",
      "x_eff  = [ 1.60558682 10.75296831],\n",
      "\n",
      "iteration 292: f_best = 0.00739604\n",
      "x_eff  = [28.87418524  3.09585735],\n",
      "\n",
      "iteration 293: f_best = 0.00739604\n",
      "x_eff  = [13.21820289 15.2569948 ],\n",
      "\n",
      "iteration 294: f_best = 0.00739604\n",
      "x_eff  = [-22.14042994 -13.93477534],\n",
      "\n",
      "iteration 295: f_best = 0.00739604\n",
      "x_eff  = [ 32.83984155 -12.82008581],\n",
      "\n",
      "iteration 296: f_best = 0.00739604\n",
      "x_eff  = [-24.754499     1.59957846],\n",
      "\n",
      "iteration 297: f_best = 0.00739604\n",
      "x_eff  = [ 10.77284678 -14.21537773],\n",
      "\n",
      "iteration 298: f_best = 0.00739604\n",
      "x_eff  = [-10.82870722  25.95241481],\n",
      "\n",
      "iteration 299: f_best = 0.00739604\n",
      "x_eff  = [ -5.39676066 -27.28172295],\n",
      "\n",
      "iteration 300: f_best = 0.00739604\n",
      "x_eff  = [-21.5656399  -10.36328699],\n",
      "\n",
      "iteration 301: f_best = 0.00739604\n",
      "x_eff  = [ 13.61878269 -17.9321233 ],\n",
      "\n",
      "iteration 302: f_best = 0.00739604\n",
      "x_eff  = [  0.97218483 -24.75185274],\n",
      "\n",
      "iteration 303: f_best = 0.00739604\n",
      "x_eff  = [-19.50663293 -15.29398831],\n",
      "\n",
      "iteration 304: f_best = 0.00739604\n",
      "x_eff  = [31.23625298 18.50100593],\n",
      "\n",
      "iteration 305: f_best = 0.00739604\n",
      "x_eff  = [ -3.51681933 -22.12862936],\n",
      "\n",
      "iteration 306: f_best = 0.00739604\n",
      "x_eff  = [ 18.94316048 -12.46842144],\n",
      "\n",
      "iteration 307: f_best = 0.00739604\n",
      "x_eff  = [-20.10162676  10.63272767],\n",
      "\n",
      "iteration 308: f_best = 0.00739604\n",
      "x_eff  = [ 13.45540539 -20.98969286],\n",
      "\n",
      "iteration 309: f_best = 0.00739604\n",
      "x_eff  = [24.73698557  3.78927341],\n",
      "\n",
      "iteration 310: f_best = 0.00739604\n",
      "x_eff  = [ 18.15895147 -31.87128503],\n",
      "\n",
      "iteration 311: f_best = 0.00739604\n",
      "x_eff  = [-3.83199964  4.8102004 ],\n",
      "\n",
      "iteration 312: f_best = 0.00739604\n",
      "x_eff  = [13.08458473 20.91192624],\n",
      "\n",
      "iteration 313: f_best = 0.00739604\n",
      "x_eff  = [-11.92869473  -8.79394052],\n",
      "\n",
      "iteration 314: f_best = 0.00739604\n",
      "x_eff  = [-13.57186602 -10.60421464],\n",
      "\n",
      "iteration 315: f_best = 0.00739604\n",
      "x_eff  = [-14.52382841 -16.39092793],\n",
      "\n",
      "iteration 316: f_best = 0.00739604\n",
      "x_eff  = [-22.53634708 -10.68929909],\n",
      "\n",
      "iteration 317: f_best = 0.00739604\n",
      "x_eff  = [17.74053995 -0.77068055],\n",
      "\n",
      "iteration 318: f_best = 0.00739604\n",
      "x_eff  = [ 16.97986082 -17.81751196],\n",
      "\n",
      "iteration 319: f_best = 0.00739604\n",
      "x_eff  = [-15.83863728  -2.49732272],\n",
      "\n",
      "iteration 320: f_best = 0.00739604\n",
      "x_eff  = [-10.85964788   3.20825348],\n",
      "\n",
      "iteration 321: f_best = 0.00739604\n",
      "x_eff  = [11.14761809 10.75115376],\n",
      "\n",
      "iteration 322: f_best = 0.00739604\n",
      "x_eff  = [25.68703301  2.62962575],\n",
      "\n",
      "iteration 323: f_best = 0.00739604\n",
      "x_eff  = [  3.87881706 -28.80780009],\n",
      "\n",
      "iteration 324: f_best = 0.00739604\n",
      "x_eff  = [ -1.02596882 -24.25239332],\n",
      "\n",
      "iteration 325: f_best = 0.00739604\n",
      "x_eff  = [-11.97892517 -16.30230884],\n",
      "\n",
      "iteration 326: f_best = 0.00739604\n",
      "x_eff  = [-12.18510027  19.23013968],\n",
      "\n",
      "iteration 327: f_best = 0.00739604\n",
      "x_eff  = [-2.07068369 -4.28810885],\n",
      "\n",
      "iteration 328: f_best = 0.00739604\n",
      "x_eff  = [-20.06722978  15.82875654],\n",
      "\n",
      "iteration 329: f_best = 0.00739604\n",
      "x_eff  = [-14.33460999  -5.25177817],\n",
      "\n",
      "iteration 330: f_best = 0.00739604\n",
      "x_eff  = [-23.01712826 -26.08742203],\n",
      "\n",
      "iteration 331: f_best = 0.00739604\n",
      "x_eff  = [-20.63840197  -0.78002218],\n",
      "\n",
      "iteration 332: f_best = 0.00739604\n",
      "x_eff  = [-10.11530062  16.56295227],\n",
      "\n",
      "iteration 333: f_best = 0.00739604\n",
      "x_eff  = [ -5.06403653 -10.21951168],\n",
      "\n",
      "iteration 334: f_best = 0.00739604\n",
      "x_eff  = [-22.01942852   1.61608609],\n",
      "\n",
      "iteration 335: f_best = 0.00739604\n",
      "x_eff  = [-18.22093476   0.38567302],\n",
      "\n",
      "iteration 336: f_best = 0.00739604\n",
      "x_eff  = [ -9.12608215 -10.91467146],\n",
      "\n",
      "iteration 337: f_best = 0.00739604\n",
      "x_eff  = [ -2.38852684 -13.61278051],\n",
      "\n",
      "iteration 338: f_best = 0.00739604\n",
      "x_eff  = [-17.18265218 -23.75165676],\n",
      "\n",
      "iteration 339: f_best = 0.00739604\n",
      "x_eff  = [17.52758692 -9.27920885],\n",
      "\n",
      "iteration 340: f_best = 0.00739604\n",
      "x_eff  = [-19.08823509   9.31760581],\n",
      "\n",
      "iteration 341: f_best = 0.00739604\n",
      "x_eff  = [-16.07284764  -6.5312929 ],\n",
      "\n",
      "iteration 342: f_best = 0.00739604\n",
      "x_eff  = [17.89756452 15.47399242],\n",
      "\n",
      "iteration 343: f_best = 0.00739604\n",
      "x_eff  = [16.02807085 -8.54152712],\n",
      "\n",
      "iteration 344: f_best = 0.00739604\n",
      "x_eff  = [ 11.95991385 -12.39876135],\n",
      "\n",
      "iteration 345: f_best = 0.00739604\n",
      "x_eff  = [-1.80203997 -7.70890394],\n",
      "\n",
      "iteration 346: f_best = 0.00739604\n",
      "x_eff  = [-6.24210863  9.23680134],\n",
      "\n",
      "iteration 347: f_best = 0.00739604\n",
      "x_eff  = [-8.9660605  -7.00598431],\n",
      "\n",
      "iteration 348: f_best = 0.00739604\n",
      "x_eff  = [  1.48452218 -20.08545161],\n",
      "\n",
      "iteration 349: f_best = 0.00739604\n",
      "x_eff  = [  0.56392751 -15.25013076],\n",
      "\n",
      "iteration 350: f_best = 0.00739604\n",
      "x_eff  = [ 13.37375844 -15.73474921],\n",
      "\n",
      "iteration 351: f_best = 0.00739604\n",
      "x_eff  = [ 6.46305767 -4.00346578],\n",
      "\n",
      "iteration 352: f_best = 0.00739604\n",
      "x_eff  = [  7.50082744 -19.96535317],\n",
      "\n",
      "iteration 353: f_best = 0.00739604\n",
      "x_eff  = [3.68057948 1.37671359],\n",
      "\n",
      "iteration 354: f_best = 0.00739604\n",
      "x_eff  = [-12.7047419    1.16572816],\n",
      "\n",
      "iteration 355: f_best = 0.00739604\n",
      "x_eff  = [-19.87148572  13.77384775],\n",
      "\n",
      "iteration 356: f_best = 0.00739604\n",
      "x_eff  = [-2.48901367  3.70686715],\n",
      "\n",
      "iteration 357: f_best = 0.00739604\n",
      "x_eff  = [ -2.81364358 -16.37531172],\n",
      "\n",
      "iteration 358: f_best = 0.00739604\n",
      "x_eff  = [-4.17094884 -3.57656185],\n",
      "\n",
      "iteration 359: f_best = 0.00739604\n",
      "x_eff  = [9.33534149 9.91395084],\n",
      "\n",
      "iteration 360: f_best = 0.00739604\n",
      "x_eff  = [-20.28881973 -10.11357399],\n",
      "\n",
      "iteration 361: f_best = 0.00739604\n",
      "x_eff  = [-5.38448811 -6.59112225],\n",
      "\n",
      "iteration 362: f_best = 0.00739604\n",
      "x_eff  = [-13.43773243  -6.26339028],\n",
      "\n",
      "iteration 363: f_best = 0.00739604\n",
      "x_eff  = [-15.36654119 -20.403025  ],\n",
      "\n",
      "iteration 364: f_best = 0.00739604\n",
      "x_eff  = [  7.63274973 -19.75182436],\n",
      "\n",
      "iteration 365: f_best = 0.00739604\n",
      "x_eff  = [-14.16763487 -16.91517919],\n",
      "\n",
      "iteration 366: f_best = 0.00739604\n",
      "x_eff  = [ 1.01749065 11.36151851],\n",
      "\n",
      "iteration 367: f_best = 0.00739604\n",
      "x_eff  = [ 4.02561077 11.52738106],\n",
      "\n",
      "iteration 368: f_best = 0.00739604\n",
      "x_eff  = [-9.56546941  1.07474543],\n",
      "\n",
      "iteration 369: f_best = 0.00739604\n",
      "x_eff  = [ -3.3323677  -11.52440159],\n",
      "\n",
      "iteration 370: f_best = 0.00739604\n",
      "x_eff  = [ 9.31649216 11.15869648],\n",
      "\n",
      "iteration 371: f_best = 0.00739604\n",
      "x_eff  = [-12.92688734  -4.89430164],\n",
      "\n",
      "iteration 372: f_best = 0.00739604\n",
      "x_eff  = [ -9.14305985 -11.69453533],\n",
      "\n",
      "iteration 373: f_best = 0.00739604\n",
      "x_eff  = [ 12.01775315 -18.16257118],\n",
      "\n",
      "iteration 374: f_best = 0.00739604\n",
      "x_eff  = [-14.99428556   4.16877507],\n",
      "\n",
      "iteration 375: f_best = 0.00739604\n",
      "x_eff  = [-4.00192441 -1.91141366],\n",
      "\n",
      "iteration 376: f_best = 0.00739604\n",
      "x_eff  = [  3.72207996 -11.43097588],\n",
      "\n",
      "iteration 377: f_best = 0.00739604\n",
      "x_eff  = [ 10.97708757 -11.96970225],\n",
      "\n",
      "iteration 378: f_best = 0.00739604\n",
      "x_eff  = [-11.55221102  -6.27747554],\n",
      "\n",
      "iteration 379: f_best = 0.00739604\n",
      "x_eff  = [ 10.91572478 -12.38253282],\n",
      "\n",
      "iteration 380: f_best = 0.00739604\n",
      "x_eff  = [-15.012512  -11.3611704],\n",
      "\n",
      "iteration 381: f_best = 0.00739604\n",
      "x_eff  = [1.21480668 3.07952569],\n",
      "\n",
      "iteration 382: f_best = 0.00739604\n",
      "x_eff  = [-7.49000943  3.4500055 ],\n",
      "\n",
      "iteration 383: f_best = 0.00739604\n",
      "x_eff  = [-8.86690879 -2.39717624],\n",
      "\n",
      "iteration 384: f_best = 0.00739604\n",
      "x_eff  = [  2.00728599 -12.04280121],\n",
      "\n",
      "iteration 385: f_best = 0.00739604\n",
      "x_eff  = [10.4071837  -0.81379393],\n",
      "\n",
      "iteration 386: f_best = 0.00739604\n",
      "x_eff  = [  4.48501815 -10.94565783],\n",
      "\n",
      "iteration 387: f_best = 0.00739604\n",
      "x_eff  = [ -7.99019264 -12.89920457],\n",
      "\n",
      "iteration 388: f_best = 0.00739604\n",
      "x_eff  = [-15.42009555 -11.35744861],\n",
      "\n",
      "iteration 389: f_best = 0.00739604\n",
      "x_eff  = [8.52194154 2.5650706 ],\n",
      "\n",
      "iteration 390: f_best = 0.00739604\n",
      "x_eff  = [3.47182304 1.30707111],\n",
      "\n",
      "iteration 391: f_best = 0.00739604\n",
      "x_eff  = [ 3.98235625 -8.7629592 ],\n",
      "\n",
      "iteration 392: f_best = 0.00739604\n",
      "x_eff  = [  0.11933489 -12.67434598],\n",
      "\n",
      "iteration 393: f_best = 0.00739604\n",
      "x_eff  = [  4.55754391 -15.15641816],\n",
      "\n",
      "iteration 394: f_best = 0.00739604\n",
      "x_eff  = [2.58889444 6.08115345],\n",
      "\n",
      "iteration 395: f_best = 0.00739604\n",
      "x_eff  = [ -0.12696347 -12.67318779],\n",
      "\n",
      "iteration 396: f_best = 0.00739604\n",
      "x_eff  = [ 6.2632713  -8.73331972],\n",
      "\n",
      "iteration 397: f_best = 0.00739604\n",
      "x_eff  = [-5.99267452  5.8786412 ],\n",
      "\n",
      "iteration 398: f_best = 0.00739604\n",
      "x_eff  = [ 5.39081201 -9.41083901],\n",
      "\n",
      "iteration 399: f_best = 0.00739604\n",
      "x_eff  = [-12.18991047 -13.94150482],\n",
      "\n",
      "iteration 400: f_best = 0.00739604\n",
      "x_eff  = [ 2.1747127 -2.5137771],\n",
      "\n",
      "iteration 401: f_best = 0.00739604\n",
      "x_eff  = [8.01696037 7.21810074],\n",
      "\n",
      "iteration 402: f_best = 0.00739604\n",
      "x_eff  = [-12.33733087 -11.14810898],\n",
      "\n",
      "iteration 403: f_best = 0.00739604\n",
      "x_eff  = [-11.28558466  -8.26074578],\n",
      "\n",
      "iteration 404: f_best = 0.00739604\n",
      "x_eff  = [-4.38597864  3.5945599 ],\n",
      "\n",
      "iteration 405: f_best = 0.00000000\n",
      "x_eff  = [0.20705637 3.59275202],\n",
      "\n",
      "iteration 406: f_best = 0.00000000\n",
      "x_eff  = [9.18283955 5.16057347],\n",
      "\n",
      "iteration 407: f_best = 0.00000000\n",
      "x_eff  = [ 4.81643567 -6.87129032],\n",
      "\n",
      "iteration 408: f_best = 0.00000000\n",
      "x_eff  = [ 5.48732868 -4.80744469],\n",
      "\n",
      "iteration 409: f_best = 0.00000000\n",
      "x_eff  = [-5.72059006 -5.72648972],\n",
      "\n",
      "iteration 410: f_best = 0.00000000\n",
      "x_eff  = [2.72309627 3.45882985],\n",
      "\n",
      "iteration 411: f_best = 0.00000000\n",
      "x_eff  = [-5.1755692  -1.66692207],\n",
      "\n",
      "iteration 412: f_best = 0.00000000\n",
      "x_eff  = [-3.6144004 -9.7623473],\n",
      "\n",
      "iteration 413: f_best = 0.00000000\n",
      "x_eff  = [-6.41063365  9.0724782 ],\n",
      "\n",
      "iteration 414: f_best = 0.00000000\n",
      "x_eff  = [-1.22120789 -1.56864811],\n",
      "\n",
      "iteration 415: f_best = 0.00000000\n",
      "x_eff  = [3.45634392 4.97510757],\n",
      "\n",
      "iteration 416: f_best = 0.00000000\n",
      "x_eff  = [1.61637234 3.39449754],\n",
      "\n",
      "iteration 417: f_best = 0.00000000\n",
      "x_eff  = [-4.54621477 -2.37962719],\n",
      "\n",
      "iteration 418: f_best = 0.00000000\n",
      "x_eff  = [9.51558777 6.36909007],\n",
      "\n",
      "iteration 419: f_best = 0.00000000\n",
      "x_eff  = [ 3.26798716 -2.32532873],\n",
      "\n",
      "iteration 420: f_best = 0.00000000\n",
      "x_eff  = [-7.35129867 -9.22769396],\n",
      "\n",
      "iteration 421: f_best = 0.00000000\n",
      "x_eff  = [ 0.21598101 -9.00381971],\n",
      "\n",
      "iteration 422: f_best = 0.00000000\n",
      "x_eff  = [1.15277385 9.01757185],\n",
      "\n",
      "iteration 423: f_best = 0.00000000\n",
      "x_eff  = [-2.4688705   1.86255297],\n",
      "\n",
      "iteration 424: f_best = 0.00000000\n",
      "x_eff  = [1.22558279 1.09301503],\n",
      "\n",
      "iteration 425: f_best = 0.00000000\n",
      "x_eff  = [-6.31258536  6.14961256],\n",
      "\n",
      "iteration 426: f_best = 0.00000000\n",
      "x_eff  = [-5.52820893 -6.37377585],\n",
      "\n",
      "iteration 427: f_best = 0.00000000\n",
      "x_eff  = [7.74077511 3.82807263],\n",
      "\n",
      "iteration 428: f_best = 0.00000000\n",
      "x_eff  = [-3.03648385 -3.14051235],\n",
      "\n",
      "iteration 429: f_best = 0.00000000\n",
      "x_eff  = [-6.34610257 -3.08151815],\n",
      "\n",
      "iteration 430: f_best = 0.00000000\n",
      "x_eff  = [-8.23454058  3.32032658],\n",
      "\n",
      "iteration 431: f_best = 0.00000000\n",
      "x_eff  = [0.55967041 6.14565693],\n",
      "\n",
      "iteration 432: f_best = 0.00000000\n",
      "x_eff  = [-0.92996439 -5.06406834],\n",
      "\n",
      "iteration 433: f_best = 0.00000000\n",
      "x_eff  = [-8.19663137  4.7920502 ],\n",
      "\n",
      "iteration 434: f_best = 0.00000000\n",
      "x_eff  = [ 4.52348307 -1.53967152],\n",
      "\n",
      "iteration 435: f_best = 0.00000000\n",
      "x_eff  = [-5.55525673 -4.53940923],\n",
      "\n",
      "iteration 436: f_best = 0.00000000\n",
      "x_eff  = [-2.14627455 -7.43761939],\n",
      "\n",
      "iteration 437: f_best = 0.00000000\n",
      "x_eff  = [-5.02880969  5.88895479],\n",
      "\n",
      "iteration 438: f_best = 0.00000000\n",
      "x_eff  = [7.6215571  1.98728598],\n",
      "\n",
      "iteration 439: f_best = 0.00000000\n",
      "x_eff  = [ 4.46305749 -6.84095463],\n",
      "\n",
      "iteration 440: f_best = 0.00000000\n",
      "x_eff  = [4.88965148 1.6698426 ],\n",
      "\n",
      "iteration 441: f_best = 0.00000000\n",
      "x_eff  = [-6.46044107  3.63156159],\n",
      "\n",
      "iteration 442: f_best = 0.00000000\n",
      "x_eff  = [-3.30352361  2.86950276],\n",
      "\n",
      "iteration 443: f_best = 0.00000000\n",
      "x_eff  = [2.03582515 5.5617654 ],\n",
      "\n",
      "iteration 444: f_best = 0.00000000\n",
      "x_eff  = [-4.30164414 -4.85692636],\n",
      "\n",
      "iteration 445: f_best = 0.00000000\n",
      "x_eff  = [-3.41060649  7.49338267],\n",
      "\n",
      "iteration 446: f_best = 0.00000000\n",
      "x_eff  = [-6.30445796  2.79781323],\n",
      "\n",
      "iteration 447: f_best = 0.00000000\n",
      "x_eff  = [-1.54559344  6.90416082],\n",
      "\n",
      "iteration 448: f_best = 0.00000000\n",
      "x_eff  = [6.30357782 3.23041625],\n",
      "\n",
      "iteration 449: f_best = 0.00000000\n",
      "x_eff  = [-0.06973113  5.51098769],\n",
      "\n",
      "iteration 450: f_best = 0.00000000\n",
      "x_eff  = [-3.64935843  2.96485134],\n",
      "\n",
      "iteration 451: f_best = 0.00000000\n",
      "x_eff  = [ 1.82068626 -6.55908078],\n",
      "\n",
      "iteration 452: f_best = 0.00000000\n",
      "x_eff  = [4.43573658 4.07284686],\n",
      "\n",
      "iteration 453: f_best = 0.00000000\n",
      "x_eff  = [ 2.50856495 -1.13650711],\n",
      "\n",
      "iteration 454: f_best = 0.00000000\n",
      "x_eff  = [ 0.22897185 -0.0604728 ],\n",
      "\n",
      "iteration 455: f_best = 0.00000000\n",
      "x_eff  = [1.06070331 1.10102165],\n",
      "\n",
      "iteration 456: f_best = 0.00000000\n",
      "x_eff  = [-2.49118675  5.4569905 ],\n",
      "\n",
      "iteration 457: f_best = 0.00000000\n",
      "x_eff  = [3.83030418 6.36635268],\n",
      "\n",
      "iteration 458: f_best = 0.00000000\n",
      "x_eff  = [-5.04148933 -1.29698997],\n",
      "\n",
      "iteration 459: f_best = 0.00000000\n",
      "x_eff  = [-0.62836077 -0.91125694],\n",
      "\n",
      "iteration 460: f_best = 0.00000000\n",
      "x_eff  = [-3.35823472  2.40014887],\n",
      "\n",
      "iteration 461: f_best = 0.00000000\n",
      "x_eff  = [-2.16334887  5.69120751],\n",
      "\n",
      "iteration 462: f_best = 0.00000000\n",
      "x_eff  = [ 4.27352503 -5.97515982],\n",
      "\n",
      "iteration 463: f_best = 0.00000000\n",
      "x_eff  = [-2.77832074 -2.72621963],\n",
      "\n",
      "iteration 464: f_best = 0.00000000\n",
      "x_eff  = [-0.28275394  5.27487049],\n",
      "\n",
      "iteration 465: f_best = 0.00000000\n",
      "x_eff  = [-3.47452456 -0.90283415],\n",
      "\n",
      "iteration 466: f_best = 0.00000000\n",
      "x_eff  = [5.60322765 5.66291005],\n",
      "\n",
      "iteration 467: f_best = 0.00000000\n",
      "x_eff  = [2.12512903 5.45314628],\n",
      "\n",
      "iteration 468: f_best = 0.00000000\n",
      "x_eff  = [-2.66131719  2.42766775],\n",
      "\n",
      "iteration 469: f_best = 0.00000000\n",
      "x_eff  = [-0.03251115  3.71948505],\n",
      "\n",
      "iteration 470: f_best = 0.00000000\n",
      "x_eff  = [ 3.11590186 -0.10291263],\n",
      "\n",
      "iteration 471: f_best = 0.00000000\n",
      "x_eff  = [2.75791161 1.01363779],\n",
      "\n",
      "iteration 472: f_best = 0.00000000\n",
      "x_eff  = [-3.18538125  1.34590353],\n",
      "\n",
      "iteration 473: f_best = 0.00000000\n",
      "x_eff  = [2.15922589 1.69451595],\n",
      "\n",
      "iteration 474: f_best = 0.00000000\n",
      "x_eff  = [-2.30210528  1.1492284 ],\n",
      "\n",
      "iteration 475: f_best = 0.00000000\n",
      "x_eff  = [0.46898469 2.53138092],\n",
      "\n",
      "iteration 476: f_best = 0.00000000\n",
      "x_eff  = [ 2.175201   -3.92400906],\n",
      "\n",
      "iteration 477: f_best = 0.00000000\n",
      "x_eff  = [ 0.55076937 -0.99479392],\n",
      "\n",
      "iteration 478: f_best = 0.00000000\n",
      "x_eff  = [5.4579756  5.31752837],\n",
      "\n",
      "iteration 479: f_best = 0.00000000\n",
      "x_eff  = [-3.75203835 -5.02556416],\n",
      "\n",
      "iteration 480: f_best = 0.00000000\n",
      "x_eff  = [-4.24425555  3.56985194],\n",
      "\n",
      "iteration 481: f_best = 0.00000000\n",
      "x_eff  = [-3.06784344  4.71779921],\n",
      "\n",
      "iteration 482: f_best = 0.00000000\n",
      "x_eff  = [ 2.89321568 -2.94760821],\n",
      "\n",
      "iteration 483: f_best = 0.00000000\n",
      "x_eff  = [-5.02496465 -3.39893726],\n",
      "\n",
      "iteration 484: f_best = 0.00000000\n",
      "x_eff  = [-3.88349547  4.3374284 ],\n",
      "\n",
      "iteration 485: f_best = 0.00000000\n",
      "x_eff  = [-1.7880368  -0.60494232],\n",
      "\n",
      "iteration 486: f_best = 0.00000000\n",
      "x_eff  = [ 1.5081201  -2.08938227],\n",
      "\n",
      "iteration 487: f_best = 0.00000000\n",
      "x_eff  = [ 2.34053318 -4.18248038],\n",
      "\n",
      "iteration 488: f_best = 0.00000000\n",
      "x_eff  = [-4.96505427 -1.38719127],\n",
      "\n",
      "iteration 489: f_best = 0.00000000\n",
      "x_eff  = [-4.07233932 -1.64731627],\n",
      "\n",
      "iteration 490: f_best = 0.00000000\n",
      "x_eff  = [-3.996568    4.08699545],\n",
      "\n",
      "iteration 491: f_best = 0.00000000\n",
      "x_eff  = [-0.68183997 -3.78431363],\n",
      "\n",
      "iteration 492: f_best = 0.00000000\n",
      "x_eff  = [-3.69916536 -2.79943383],\n",
      "\n",
      "iteration 493: f_best = 0.00000000\n",
      "x_eff  = [-0.28466221  2.87851713],\n",
      "\n",
      "iteration 494: f_best = 0.00000000\n",
      "x_eff  = [-3.65778539  1.88388032],\n",
      "\n",
      "iteration 495: f_best = 0.00000000\n",
      "x_eff  = [-4.45988564 -3.94027462],\n",
      "\n",
      "iteration 496: f_best = 0.00000000\n",
      "x_eff  = [ 1.61904685 -2.5337407 ],\n",
      "\n",
      "iteration 497: f_best = 0.00000000\n",
      "x_eff  = [-0.41058985 -3.98979426],\n",
      "\n",
      "iteration 498: f_best = 0.00000000\n",
      "x_eff  = [1.93730792 3.69417018],\n",
      "\n",
      "iteration 499: f_best = 0.00000000\n",
      "x_eff  = [-1.66116299 -0.21401292],\n",
      "\n",
      "iteration 500: f_best = 0.00000000\n",
      "x_eff  = [0.02209756 0.0064723 ],\n",
      "\n",
      "iteration 501: f_best = 0.00000000\n",
      "x_eff  = [ 1.95247061 -3.12199168],\n",
      "\n",
      "iteration 502: f_best = 0.00000000\n",
      "x_eff  = [-3.13885191  0.43157702],\n",
      "\n",
      "iteration 503: f_best = 0.00000000\n",
      "x_eff  = [-1.78995616  1.22126099],\n",
      "\n",
      "iteration 504: f_best = 0.00000000\n",
      "x_eff  = [-1.55987111 -0.56962248],\n",
      "\n",
      "iteration 505: f_best = 0.00000000\n",
      "x_eff  = [-1.10077516  0.32770858],\n",
      "\n",
      "iteration 506: f_best = 0.00000000\n",
      "x_eff  = [-4.13119661  0.77629464],\n",
      "\n",
      "iteration 507: f_best = 0.00000000\n",
      "x_eff  = [-3.92836006 -3.68745111],\n",
      "\n",
      "iteration 508: f_best = 0.00000000\n",
      "x_eff  = [-0.67738064 -1.46666803],\n",
      "\n",
      "iteration 509: f_best = 0.00000000\n",
      "x_eff  = [-1.92768479  2.76754914],\n",
      "\n",
      "iteration 510: f_best = 0.00000000\n",
      "x_eff  = [-3.40401988 -0.78785111],\n",
      "\n",
      "iteration 511: f_best = 0.00000000\n",
      "x_eff  = [-1.15566532 -0.47959452],\n",
      "\n",
      "iteration 512: f_best = 0.00000000\n",
      "x_eff  = [ 1.70959507 -3.8552863 ],\n",
      "\n",
      "iteration 513: f_best = 0.00000000\n",
      "x_eff  = [0.19685924 1.70465313],\n",
      "\n",
      "iteration 514: f_best = 0.00000000\n",
      "x_eff  = [1.86212988 2.71571862],\n",
      "\n",
      "iteration 515: f_best = 0.00000000\n",
      "x_eff  = [-0.33548947 -1.32479522],\n",
      "\n",
      "iteration 516: f_best = 0.00000000\n",
      "x_eff  = [ 1.41464822 -1.23528246],\n",
      "\n",
      "iteration 517: f_best = 0.00000000\n",
      "x_eff  = [ 0.29771424 -3.53711827],\n",
      "\n",
      "iteration 518: f_best = 0.00000000\n",
      "x_eff  = [-0.82144082  0.84243799],\n",
      "\n",
      "iteration 519: f_best = 0.00000000\n",
      "x_eff  = [ 2.85186756 -3.59040058],\n",
      "\n",
      "iteration 520: f_best = 0.00000000\n",
      "x_eff  = [2.79831263 3.24706006],\n",
      "\n",
      "iteration 521: f_best = 0.00000000\n",
      "x_eff  = [ 0.86297924 -2.48606393],\n",
      "\n",
      "iteration 522: f_best = 0.00000000\n",
      "x_eff  = [-0.66895794 -2.01867324],\n",
      "\n",
      "iteration 523: f_best = 0.00000000\n",
      "x_eff  = [ 0.73678573 -2.74175425],\n",
      "\n",
      "iteration 524: f_best = 0.00000000\n",
      "x_eff  = [-0.51333222  1.61379237],\n",
      "\n",
      "iteration 525: f_best = 0.00000000\n",
      "x_eff  = [1.7097715 0.7642521],\n",
      "\n",
      "iteration 526: f_best = 0.00000000\n",
      "x_eff  = [-1.32876701 -0.60303258],\n",
      "\n",
      "iteration 527: f_best = 0.00000000\n",
      "x_eff  = [-1.00173767  2.52606966],\n",
      "\n",
      "iteration 528: f_best = 0.00000000\n",
      "x_eff  = [1.93798772 1.00329778],\n",
      "\n",
      "iteration 529: f_best = 0.00000000\n",
      "x_eff  = [-1.0815447   2.94466316],\n",
      "\n",
      "iteration 530: f_best = 0.00000000\n",
      "x_eff  = [ 1.42251899 -1.7721004 ],\n",
      "\n",
      "iteration 531: f_best = 0.00000000\n",
      "x_eff  = [ 3.13899403 -0.02290734],\n",
      "\n",
      "iteration 532: f_best = 0.00000000\n",
      "x_eff  = [-2.56999797 -3.13619895],\n",
      "\n",
      "iteration 533: f_best = 0.00000000\n",
      "x_eff  = [-1.33185572  0.10794815],\n",
      "\n",
      "iteration 534: f_best = 0.00000000\n",
      "x_eff  = [-1.33088731  1.88336461],\n",
      "\n",
      "iteration 535: f_best = 0.00000000\n",
      "x_eff  = [-1.02304901  0.06206009],\n",
      "\n",
      "iteration 536: f_best = 0.00000000\n",
      "x_eff  = [-2.44981613 -0.85229159],\n",
      "\n",
      "iteration 537: f_best = 0.00000000\n",
      "x_eff  = [-1.26349003 -1.27370878],\n",
      "\n",
      "iteration 538: f_best = 0.00000000\n",
      "x_eff  = [2.88832607 1.44347989],\n",
      "\n",
      "iteration 539: f_best = 0.00000000\n",
      "x_eff  = [ 2.5979989  -2.28858351],\n",
      "\n",
      "iteration 540: f_best = 0.00000000\n",
      "x_eff  = [-1.11082584 -0.04513864],\n",
      "\n",
      "iteration 541: f_best = 0.00000000\n",
      "x_eff  = [ 1.02859713 -1.72830092],\n",
      "\n",
      "iteration 542: f_best = 0.00000000\n",
      "x_eff  = [-1.83472608 -0.72425296],\n",
      "\n",
      "iteration 543: f_best = 0.00000000\n",
      "x_eff  = [2.07137514 0.2580602 ],\n",
      "\n",
      "iteration 544: f_best = 0.00000000\n",
      "x_eff  = [ 2.35297558 -2.6360584 ],\n",
      "\n",
      "iteration 545: f_best = 0.00000000\n",
      "x_eff  = [-1.76694287  0.98695105],\n",
      "\n",
      "iteration 546: f_best = 0.00000000\n",
      "x_eff  = [-2.37090794 -1.56955478],\n",
      "\n",
      "iteration 547: f_best = 0.00000000\n",
      "x_eff  = [-0.45414829  0.33148047],\n",
      "\n",
      "iteration 548: f_best = 0.00000000\n",
      "x_eff  = [ 0.03743174 -0.93324742],\n",
      "\n",
      "iteration 549: f_best = 0.00000000\n",
      "x_eff  = [1.57462715 1.11131251],\n",
      "\n",
      "iteration 550: f_best = 0.00000000\n",
      "x_eff  = [1.27600943 0.31349574],\n",
      "\n",
      "iteration 551: f_best = 0.00000000\n",
      "x_eff  = [ 1.90375935 -2.21801076],\n",
      "\n",
      "iteration 552: f_best = 0.00000000\n",
      "x_eff  = [ 1.19363835 -2.11865062],\n",
      "\n",
      "iteration 553: f_best = 0.00000000\n",
      "x_eff  = [-2.14616184 -1.512067  ],\n",
      "\n",
      "iteration 554: f_best = 0.00000000\n",
      "x_eff  = [ 1.05913215 -0.04590501],\n",
      "\n",
      "iteration 555: f_best = 0.00000000\n",
      "x_eff  = [-1.91706491 -2.09474968],\n",
      "\n",
      "iteration 556: f_best = 0.00000000\n",
      "x_eff  = [ 2.26434546 -1.70404328],\n",
      "\n",
      "iteration 557: f_best = 0.00000000\n",
      "x_eff  = [-1.44912595 -2.43714014],\n",
      "\n",
      "iteration 558: f_best = 0.00000000\n",
      "x_eff  = [-0.21528295 -1.03761154],\n",
      "\n",
      "iteration 559: f_best = 0.00000000\n",
      "x_eff  = [-2.20703771 -0.92932052],\n",
      "\n",
      "iteration 560: f_best = 0.00000000\n",
      "x_eff  = [-0.63412321  0.61977331],\n",
      "\n",
      "iteration 561: f_best = 0.00000000\n",
      "x_eff  = [2.13358221 0.11614493],\n",
      "\n",
      "iteration 562: f_best = 0.00000000\n",
      "x_eff  = [1.69129604 1.95083411],\n",
      "\n",
      "iteration 563: f_best = 0.00000000\n",
      "x_eff  = [ 1.25052996 -0.97276789],\n",
      "\n",
      "iteration 564: f_best = 0.00000000\n",
      "x_eff  = [-1.8444204   0.48323374],\n",
      "\n",
      "iteration 565: f_best = 0.00000000\n",
      "x_eff  = [-0.99611314  0.04691883],\n",
      "\n",
      "iteration 566: f_best = 0.00000000\n",
      "x_eff  = [-1.10511377 -0.38814656],\n",
      "\n",
      "iteration 567: f_best = 0.00000000\n",
      "x_eff  = [ 2.09619176 -2.06194668],\n",
      "\n",
      "iteration 568: f_best = 0.00000000\n",
      "x_eff  = [1.11131005 0.77595402],\n",
      "\n",
      "iteration 569: f_best = 0.00000000\n",
      "x_eff  = [ 2.09809627 -0.92750739],\n",
      "\n",
      "iteration 570: f_best = 0.00000000\n",
      "x_eff  = [0.91714004 1.32481576],\n",
      "\n",
      "iteration 571: f_best = 0.00000000\n",
      "x_eff  = [-1.36590366  0.37958737],\n",
      "\n",
      "iteration 572: f_best = 0.00000000\n",
      "x_eff  = [ 0.74757564 -1.03254993],\n",
      "\n",
      "iteration 573: f_best = 0.00000000\n",
      "x_eff  = [ 0.69600283 -1.77140385],\n",
      "\n",
      "iteration 574: f_best = 0.00000000\n",
      "x_eff  = [-1.98417142  1.45909065],\n",
      "\n",
      "iteration 575: f_best = 0.00000000\n",
      "x_eff  = [-1.36161327 -1.40426603],\n",
      "\n",
      "iteration 576: f_best = 0.00000000\n",
      "x_eff  = [ 1.91421246 -0.28308178],\n",
      "\n",
      "iteration 577: f_best = 0.00000000\n",
      "x_eff  = [ 0.86790703 -1.99815554],\n",
      "\n",
      "iteration 578: f_best = 0.00000000\n",
      "x_eff  = [0.15770617 0.74257637],\n",
      "\n",
      "iteration 579: f_best = 0.00000000\n",
      "x_eff  = [1.9026345  0.07203389],\n",
      "\n",
      "iteration 580: f_best = 0.00000000\n",
      "x_eff  = [1.67512343 0.86640857],\n",
      "\n",
      "iteration 581: f_best = 0.00000000\n",
      "x_eff  = [ 1.1957501  -0.72146229],\n",
      "\n",
      "iteration 582: f_best = 0.00000000\n",
      "x_eff  = [1.31038829 0.15381558],\n",
      "\n",
      "iteration 583: f_best = 0.00000000\n",
      "x_eff  = [-1.03766005 -1.70942923],\n",
      "\n",
      "iteration 584: f_best = 0.00000000\n",
      "x_eff  = [0.07776185 0.99902077],\n",
      "\n",
      "iteration 585: f_best = 0.00000000\n",
      "x_eff  = [ 0.45603125 -1.68455977],\n",
      "\n",
      "iteration 586: f_best = 0.00000000\n",
      "x_eff  = [-0.06898608 -0.61987667],\n",
      "\n",
      "iteration 587: f_best = 0.00000000\n",
      "x_eff  = [0.21728488 1.2861923 ],\n",
      "\n",
      "iteration 588: f_best = 0.00000000\n",
      "x_eff  = [ 1.64764078 -1.19572043],\n",
      "\n",
      "iteration 589: f_best = 0.00000000\n",
      "x_eff  = [-0.61239733  0.98528202],\n",
      "\n",
      "iteration 590: f_best = 0.00000000\n",
      "x_eff  = [-0.73386517  0.27822646],\n",
      "\n",
      "iteration 591: f_best = 0.00000000\n",
      "x_eff  = [-0.49273541 -1.72911417],\n",
      "\n",
      "iteration 592: f_best = 0.00000000\n",
      "x_eff  = [ 0.84302757 -0.41701931],\n",
      "\n",
      "iteration 593: f_best = 0.00000000\n",
      "x_eff  = [0.54183566 0.36098754],\n",
      "\n",
      "iteration 594: f_best = 0.00000000\n",
      "x_eff  = [ 0.792992   -0.07806945],\n",
      "\n",
      "iteration 595: f_best = 0.00000000\n",
      "x_eff  = [ 1.43443591 -1.44183094],\n",
      "\n",
      "iteration 596: f_best = 0.00000000\n",
      "x_eff  = [0.28644509 1.61535686],\n",
      "\n",
      "iteration 597: f_best = 0.00000000\n",
      "x_eff  = [ 0.53869953 -0.94559191],\n",
      "\n",
      "iteration 598: f_best = 0.00000000\n",
      "x_eff  = [-0.09590823  1.14330371],\n",
      "\n",
      "iteration 599: f_best = 0.00000000\n",
      "x_eff  = [-1.64683099 -1.07465198],\n",
      "\n",
      "iteration 600: f_best = 0.00000000\n",
      "x_eff  = [-1.33522122  0.1348674 ],\n",
      "\n",
      "iteration 601: f_best = 0.00000000\n",
      "x_eff  = [1.49731209 0.47090696],\n",
      "\n",
      "iteration 602: f_best = 0.00000000\n",
      "x_eff  = [1.56973507 0.58800139],\n",
      "\n",
      "iteration 603: f_best = 0.00000000\n",
      "x_eff  = [0.94693096 0.74937824],\n",
      "\n",
      "iteration 604: f_best = 0.00000000\n",
      "x_eff  = [ 1.17969955 -1.45258561],\n",
      "\n",
      "iteration 605: f_best = 0.00000000\n",
      "x_eff  = [-0.59434437  1.42679611],\n",
      "\n",
      "iteration 606: f_best = 0.00000000\n",
      "x_eff  = [-0.00857072 -0.0961124 ],\n",
      "\n",
      "iteration 607: f_best = 0.00000000\n",
      "x_eff  = [ 0.12571458 -1.46173164],\n",
      "\n",
      "iteration 608: f_best = 0.00000000\n",
      "x_eff  = [ 1.13610333 -1.2349463 ],\n",
      "\n",
      "iteration 609: f_best = 0.00000000\n",
      "x_eff  = [0.61318285 0.95552652],\n",
      "\n",
      "iteration 610: f_best = 0.00000000\n",
      "x_eff  = [ 0.41815    -1.14099815],\n",
      "\n",
      "iteration 611: f_best = 0.00000000\n",
      "x_eff  = [-0.38178718  0.85214964],\n",
      "\n",
      "iteration 612: f_best = 0.00000000\n",
      "x_eff  = [ 0.16741768 -0.47443098],\n",
      "\n",
      "iteration 613: f_best = 0.00000000\n",
      "x_eff  = [-1.02371279  1.08681259],\n",
      "\n",
      "iteration 614: f_best = 0.00000000\n",
      "x_eff  = [-0.8301421  -0.19493732],\n",
      "\n",
      "iteration 615: f_best = 0.00000000\n",
      "x_eff  = [-1.27345638 -0.08570187],\n",
      "\n",
      "iteration 616: f_best = 0.00000000\n",
      "x_eff  = [0.02690374 1.25161505],\n",
      "\n",
      "iteration 617: f_best = 0.00000000\n",
      "x_eff  = [ 0.32378791 -0.19899978],\n",
      "\n",
      "iteration 618: f_best = 0.00000000\n",
      "x_eff  = [ 0.22321874 -1.06618981],\n",
      "\n",
      "iteration 619: f_best = 0.00000000\n",
      "x_eff  = [-0.68783363  1.29786875],\n",
      "\n",
      "iteration 620: f_best = 0.00000000\n",
      "x_eff  = [-0.14865201 -0.28526039],\n",
      "\n",
      "iteration 621: f_best = 0.00000000\n",
      "x_eff  = [ 0.05745745 -0.96803164],\n",
      "\n",
      "iteration 622: f_best = 0.00000000\n",
      "x_eff  = [-0.18252041  0.71421947],\n",
      "\n",
      "iteration 623: f_best = 0.00000000\n",
      "x_eff  = [-1.2131155   0.05531858],\n",
      "\n",
      "iteration 624: f_best = 0.00000000\n",
      "x_eff  = [-0.28247668  0.55312985],\n",
      "\n",
      "iteration 625: f_best = 0.00000000\n",
      "x_eff  = [ 0.63550368 -0.95386375],\n",
      "\n",
      "iteration 626: f_best = 0.00000000\n",
      "x_eff  = [-0.6700182   0.74910613],\n",
      "\n",
      "iteration 627: f_best = 0.00000000\n",
      "x_eff  = [1.22156085 1.19852178],\n",
      "\n",
      "iteration 628: f_best = 0.00000000\n",
      "x_eff  = [0.69881631 1.20665126],\n",
      "\n",
      "iteration 629: f_best = 0.00000000\n",
      "x_eff  = [ 0.48981751 -0.26096816],\n",
      "\n",
      "iteration 630: f_best = 0.00000000\n",
      "x_eff  = [0.4184099  0.03808954],\n",
      "\n",
      "iteration 631: f_best = 0.00000000\n",
      "x_eff  = [-0.79100651 -0.01962335],\n",
      "\n",
      "iteration 632: f_best = 0.00000000\n",
      "x_eff  = [ 0.52629229 -0.5211034 ],\n",
      "\n",
      "iteration 633: f_best = 0.00000000\n",
      "x_eff  = [-0.60197219  1.07216458],\n",
      "\n",
      "iteration 634: f_best = 0.00000000\n",
      "x_eff  = [-0.50590672  0.63951436],\n",
      "\n",
      "iteration 635: f_best = 0.00000000\n",
      "x_eff  = [-0.78425067  0.50281213],\n",
      "\n",
      "iteration 636: f_best = 0.00000000\n",
      "x_eff  = [1.06421625 0.97394672],\n",
      "\n",
      "iteration 637: f_best = 0.00000000\n",
      "x_eff  = [-1.06583802  0.51384761],\n",
      "\n",
      "iteration 638: f_best = 0.00000000\n",
      "x_eff  = [-0.51403968  0.54215553],\n",
      "\n",
      "iteration 639: f_best = 0.00000000\n",
      "x_eff  = [0.58067587 0.8599935 ],\n",
      "\n",
      "iteration 640: f_best = 0.00000000\n",
      "x_eff  = [ 0.50806033 -0.49999403],\n",
      "\n",
      "iteration 641: f_best = 0.00000000\n",
      "x_eff  = [-1.0434328   0.09567163],\n",
      "\n",
      "iteration 642: f_best = 0.00000000\n",
      "x_eff  = [-0.77489056  0.42938648],\n",
      "\n",
      "iteration 643: f_best = 0.00000000\n",
      "x_eff  = [ 0.3333596  -0.50390407],\n",
      "\n",
      "iteration 644: f_best = 0.00000000\n",
      "x_eff  = [-0.72618408 -0.44587412],\n",
      "\n",
      "iteration 645: f_best = 0.00000000\n",
      "x_eff  = [ 0.65496236 -0.28879272],\n",
      "\n",
      "iteration 646: f_best = 0.00000000\n",
      "x_eff  = [-0.86477866  0.22853444],\n",
      "\n",
      "iteration 647: f_best = 0.00000000\n",
      "x_eff  = [0.54644254 0.97275564],\n",
      "\n",
      "iteration 648: f_best = 0.00000000\n",
      "x_eff  = [-0.56427446 -0.77239481],\n",
      "\n",
      "iteration 649: f_best = 0.00000000\n",
      "x_eff  = [-0.5490904  -0.21585928],\n",
      "\n",
      "iteration 650: f_best = 0.00000000\n",
      "x_eff  = [-0.69273128  0.39814929],\n",
      "\n",
      "iteration 651: f_best = 0.00000000\n",
      "x_eff  = [ 0.6305787  -0.58558539],\n",
      "\n",
      "iteration 652: f_best = 0.00000000\n",
      "x_eff  = [0.36962264 0.46420976],\n",
      "\n",
      "iteration 653: f_best = 0.00000000\n",
      "x_eff  = [-0.55151378  0.82091664],\n",
      "\n",
      "iteration 654: f_best = 0.00000000\n",
      "x_eff  = [-0.70105747 -0.00443979],\n",
      "\n",
      "iteration 655: f_best = 0.00000000\n",
      "x_eff  = [0.05912436 0.20063289],\n",
      "\n",
      "iteration 656: f_best = 0.00000000\n",
      "x_eff  = [0.11842921 0.29013316],\n",
      "\n",
      "iteration 657: f_best = 0.00000000\n",
      "x_eff  = [0.2484167  0.37886054],\n",
      "\n",
      "iteration 658: f_best = 0.00000000\n",
      "x_eff  = [ 0.22549104 -0.42001096],\n",
      "\n",
      "iteration 659: f_best = 0.00000000\n",
      "x_eff  = [-0.48552195  0.39641413],\n",
      "\n",
      "iteration 660: f_best = 0.00000000\n",
      "x_eff  = [0.1466663  0.03440352],\n",
      "\n",
      "iteration 661: f_best = 0.00000000\n",
      "x_eff  = [ 0.18112207 -0.21997776],\n",
      "\n",
      "iteration 662: f_best = 0.00000000\n",
      "x_eff  = [-0.76476331  0.62522504],\n",
      "\n",
      "iteration 663: f_best = 0.00000000\n",
      "x_eff  = [-0.31251028  0.3031487 ],\n",
      "\n",
      "iteration 664: f_best = 0.00000000\n",
      "x_eff  = [-0.54868764 -0.07309609],\n",
      "\n",
      "iteration 665: f_best = 0.00000000\n",
      "x_eff  = [ 0.63134373 -0.38634827],\n",
      "\n",
      "iteration 666: f_best = 0.00000000\n",
      "x_eff  = [-0.13826119 -0.26146296],\n",
      "\n",
      "iteration 667: f_best = 0.00000000\n",
      "x_eff  = [-0.73401039 -0.81902116],\n",
      "\n",
      "iteration 668: f_best = 0.00000000\n",
      "x_eff  = [-0.01775989  0.77741664],\n",
      "\n",
      "iteration 669: f_best = 0.00000000\n",
      "x_eff  = [0.45659344 0.56096186],\n",
      "\n",
      "iteration 670: f_best = 0.00000000\n",
      "x_eff  = [-0.1616699  -0.21419981],\n",
      "\n",
      "iteration 671: f_best = 0.00000000\n",
      "x_eff  = [0.5732664  0.80262474],\n",
      "\n",
      "iteration 672: f_best = 0.00000000\n",
      "x_eff  = [0.69696316 0.78820615],\n",
      "\n",
      "iteration 673: f_best = 0.00000000\n",
      "x_eff  = [ 0.01488262 -0.07772527],\n",
      "\n",
      "iteration 674: f_best = 0.00000000\n",
      "x_eff  = [-0.00720808  0.05269189],\n",
      "\n",
      "iteration 675: f_best = 0.00000000\n",
      "x_eff  = [-0.09440427 -0.05989128],\n",
      "\n",
      "iteration 676: f_best = 0.00000000\n",
      "x_eff  = [-0.0259377   0.73944906],\n",
      "\n",
      "iteration 677: f_best = 0.00000000\n",
      "x_eff  = [-0.70589455 -0.42652848],\n",
      "\n",
      "iteration 678: f_best = 0.00000000\n",
      "x_eff  = [ 0.73292904 -0.30412874],\n",
      "\n",
      "iteration 679: f_best = 0.00000000\n",
      "x_eff  = [-0.35844058  0.20334696],\n",
      "\n",
      "iteration 680: f_best = 0.00000000\n",
      "x_eff  = [-0.66586368 -0.39027664],\n",
      "\n",
      "iteration 681: f_best = 0.00000000\n",
      "x_eff  = [-0.24449295 -0.02558613],\n",
      "\n",
      "iteration 682: f_best = 0.00000000\n",
      "x_eff  = [-0.41274925  0.06533645],\n",
      "\n",
      "iteration 683: f_best = 0.00000000\n",
      "x_eff  = [-0.52110418  0.19434062],\n",
      "\n",
      "iteration 684: f_best = 0.00000000\n",
      "x_eff  = [-0.55512109 -0.40877982],\n",
      "\n",
      "iteration 685: f_best = 0.00000000\n",
      "x_eff  = [0.45411445 0.38013483],\n",
      "\n",
      "iteration 686: f_best = 0.00000000\n",
      "x_eff  = [-0.3954687  -0.55026989],\n",
      "\n",
      "iteration 687: f_best = 0.00000000\n",
      "x_eff  = [-0.05983306 -0.34997655],\n",
      "\n",
      "iteration 688: f_best = 0.00000000\n",
      "x_eff  = [0.43377267 0.5731355 ],\n",
      "\n",
      "iteration 689: f_best = 0.00000000\n",
      "x_eff  = [ 0.22514634 -0.6493375 ],\n",
      "\n",
      "iteration 690: f_best = 0.00000000\n",
      "x_eff  = [ 0.0484597  -0.62852088],\n",
      "\n",
      "iteration 691: f_best = 0.00000000\n",
      "x_eff  = [0.36480962 0.09729297],\n",
      "\n",
      "iteration 692: f_best = 0.00000000\n",
      "x_eff  = [ 0.5758471  -0.41883962],\n",
      "\n",
      "iteration 693: f_best = 0.00000000\n",
      "x_eff  = [ 0.63738218 -0.57622782],\n",
      "\n",
      "iteration 694: f_best = 0.00000000\n",
      "x_eff  = [ 0.52532759 -0.26902218],\n",
      "\n",
      "iteration 695: f_best = 0.00000000\n",
      "x_eff  = [-0.4254015   0.42405582],\n",
      "\n",
      "iteration 696: f_best = 0.00000000\n",
      "x_eff  = [-0.50959538 -0.32537492],\n",
      "\n",
      "iteration 697: f_best = 0.00000000\n",
      "x_eff  = [-0.06045814  0.29765247],\n",
      "\n",
      "iteration 698: f_best = 0.00000000\n",
      "x_eff  = [0.39864018 0.11479177],\n",
      "\n",
      "iteration 699: f_best = 0.00000000\n",
      "x_eff  = [0.56774847 0.03910094],\n",
      "\n",
      "iteration 700: f_best = 0.00000000\n",
      "x_eff  = [ 0.33978186 -0.25783931],\n",
      "\n",
      "iteration 701: f_best = 0.00000000\n",
      "x_eff  = [-0.19373562  0.47173467],\n",
      "\n",
      "iteration 702: f_best = 0.00000000\n",
      "x_eff  = [ 0.55963963 -0.56658213],\n",
      "\n",
      "iteration 703: f_best = 0.00000000\n",
      "x_eff  = [0.57142933 0.43636235],\n",
      "\n",
      "iteration 704: f_best = 0.00000000\n",
      "x_eff  = [0.08712754 0.15891652],\n",
      "\n",
      "iteration 705: f_best = 0.00000000\n",
      "x_eff  = [-0.5534395   0.04193323],\n",
      "\n",
      "iteration 706: f_best = 0.00000000\n",
      "x_eff  = [ 0.2448448  -0.12078586],\n",
      "\n",
      "iteration 707: f_best = 0.00000000\n",
      "x_eff  = [-0.29177702  0.16542249],\n",
      "\n",
      "iteration 708: f_best = 0.00000000\n",
      "x_eff  = [ 0.19294201 -0.18528258],\n",
      "\n",
      "iteration 709: f_best = 0.00000000\n",
      "x_eff  = [-0.51839198 -0.28173123],\n",
      "\n",
      "iteration 710: f_best = 0.00000000\n",
      "x_eff  = [-0.44622041  0.44767784],\n",
      "\n",
      "iteration 711: f_best = 0.00000000\n",
      "x_eff  = [ 0.04538455 -0.47692673],\n",
      "\n",
      "iteration 712: f_best = 0.00000000\n",
      "x_eff  = [0.49975032 0.48286693],\n",
      "\n",
      "iteration 713: f_best = 0.00000000\n",
      "x_eff  = [-0.34770376 -0.26812694],\n",
      "\n",
      "iteration 714: f_best = 0.00000000\n",
      "x_eff  = [0.08777368 0.43591449],\n",
      "\n",
      "iteration 715: f_best = 0.00000000\n",
      "x_eff  = [0.34755893 0.15092792],\n",
      "\n",
      "iteration 716: f_best = 0.00000000\n",
      "x_eff  = [0.0601511  0.21701799],\n",
      "\n",
      "iteration 717: f_best = 0.00000000\n",
      "x_eff  = [-0.23756168 -0.22097965],\n",
      "\n",
      "iteration 718: f_best = 0.00000000\n",
      "x_eff  = [0.35209918 0.17849576],\n",
      "\n",
      "iteration 719: f_best = 0.00000000\n",
      "x_eff  = [ 0.08408076 -0.36378881],\n",
      "\n",
      "iteration 720: f_best = 0.00000000\n",
      "x_eff  = [-0.33649956  0.05361217],\n",
      "\n",
      "iteration 721: f_best = 0.00000000\n",
      "x_eff  = [-0.11426353 -0.16097426],\n",
      "\n",
      "iteration 722: f_best = 0.00000000\n",
      "x_eff  = [0.0263236  0.20808561],\n",
      "\n",
      "iteration 723: f_best = 0.00000000\n",
      "x_eff  = [-0.35146647 -0.34606983],\n",
      "\n",
      "iteration 724: f_best = 0.00000000\n",
      "x_eff  = [0.37080866 0.09855258],\n",
      "\n",
      "iteration 725: f_best = 0.00000000\n",
      "x_eff  = [0.23009016 0.45360211],\n",
      "\n",
      "iteration 726: f_best = 0.00000000\n",
      "x_eff  = [0.39294484 0.28321226],\n",
      "\n",
      "iteration 727: f_best = 0.00000000\n",
      "x_eff  = [-2.95525252e-01 -2.33339522e-04],\n",
      "\n",
      "iteration 728: f_best = 0.00000000\n",
      "x_eff  = [0.34166874 0.04966871],\n",
      "\n",
      "iteration 729: f_best = 0.00000000\n",
      "x_eff  = [0.1192088  0.32386824],\n",
      "\n",
      "iteration 730: f_best = 0.00000000\n",
      "x_eff  = [0.43913812 0.20028512],\n",
      "\n",
      "iteration 731: f_best = 0.00000000\n",
      "x_eff  = [ 0.35569459 -0.32898608],\n",
      "\n",
      "iteration 732: f_best = 0.00000000\n",
      "x_eff  = [0.1430969  0.42957075],\n",
      "\n",
      "iteration 733: f_best = 0.00000000\n",
      "x_eff  = [ 0.36210486 -0.03708568],\n",
      "\n",
      "iteration 734: f_best = 0.00000000\n",
      "x_eff  = [ 0.21099352 -0.03979128],\n",
      "\n",
      "iteration 735: f_best = 0.00000000\n",
      "x_eff  = [ 0.06120527 -0.26397781],\n",
      "\n",
      "iteration 736: f_best = 0.00000000\n",
      "x_eff  = [-0.24223686 -0.3901081 ],\n",
      "\n",
      "iteration 737: f_best = 0.00000000\n",
      "x_eff  = [-0.12961828  0.2583507 ],\n",
      "\n",
      "iteration 738: f_best = 0.00000000\n",
      "x_eff  = [ 0.29597826 -0.35867799],\n",
      "\n",
      "iteration 739: f_best = 0.00000000\n",
      "x_eff  = [-0.34297248  0.32988167],\n",
      "\n",
      "iteration 740: f_best = 0.00000000\n",
      "x_eff  = [0.32639784 0.31802993],\n",
      "\n",
      "iteration 741: f_best = 0.00000000\n",
      "x_eff  = [-0.22809563  0.39728621],\n",
      "\n",
      "iteration 742: f_best = 0.00000000\n",
      "x_eff  = [0.14820986 0.31280186],\n",
      "\n",
      "iteration 743: f_best = 0.00000000\n",
      "x_eff  = [-0.02763703  0.04469917],\n",
      "\n",
      "iteration 744: f_best = 0.00000000\n",
      "x_eff  = [-0.17268724 -0.16930018],\n",
      "\n",
      "iteration 745: f_best = 0.00000000\n",
      "x_eff  = [0.10719545 0.0123096 ],\n",
      "\n",
      "iteration 746: f_best = 0.00000000\n",
      "x_eff  = [ 0.16024342 -0.04203998],\n",
      "\n",
      "iteration 747: f_best = 0.00000000\n",
      "x_eff  = [ 0.36459732 -0.26926342],\n",
      "\n",
      "iteration 748: f_best = 0.00000000\n",
      "x_eff  = [-0.27387677  0.32166894],\n",
      "\n",
      "iteration 749: f_best = 0.00000000\n",
      "x_eff  = [ 0.32175974 -0.17112252],\n",
      "\n",
      "iteration 750: f_best = 0.00000000\n",
      "x_eff  = [ 0.25206441 -0.28920435],\n",
      "\n",
      "iteration 751: f_best = 0.00000000\n",
      "x_eff  = [-0.06984126 -0.04220006],\n",
      "\n",
      "iteration 752: f_best = 0.00000000\n",
      "x_eff  = [0.00315863 0.20943334],\n",
      "\n",
      "iteration 753: f_best = 0.00000000\n",
      "x_eff  = [0.25529011 0.04000913],\n",
      "\n",
      "iteration 754: f_best = 0.00000000\n",
      "x_eff  = [0.2164559  0.00246184],\n",
      "\n",
      "iteration 755: f_best = 0.00000000\n",
      "x_eff  = [0.03119566 0.0034963 ],\n",
      "\n",
      "iteration 756: f_best = 0.00000000\n",
      "x_eff  = [-0.29629783  0.29032385],\n",
      "\n",
      "iteration 757: f_best = 0.00000000\n",
      "x_eff  = [0.11303715 0.17505539],\n",
      "\n",
      "iteration 758: f_best = 0.00000000\n",
      "x_eff  = [-0.0754697  -0.08335037],\n",
      "\n",
      "iteration 759: f_best = 0.00000000\n",
      "x_eff  = [-0.00472399 -0.32235477],\n",
      "\n",
      "iteration 760: f_best = 0.00000000\n",
      "x_eff  = [-0.07548932  0.24216851],\n",
      "\n",
      "iteration 761: f_best = 0.00000000\n",
      "x_eff  = [-0.31814333  0.04777096],\n",
      "\n",
      "iteration 762: f_best = 0.00000000\n",
      "x_eff  = [ 0.202432   -0.07347689],\n",
      "\n",
      "iteration 763: f_best = 0.00000000\n",
      "x_eff  = [ 0.26967004 -0.11596952],\n",
      "\n",
      "iteration 764: f_best = 0.00000000\n",
      "x_eff  = [-0.22478011 -0.18742007],\n",
      "\n",
      "iteration 765: f_best = 0.00000000\n",
      "x_eff  = [-0.21341604  0.11647921],\n",
      "\n",
      "iteration 766: f_best = 0.00000000\n",
      "x_eff  = [-0.19509745  0.25495569],\n",
      "\n",
      "iteration 767: f_best = 0.00000000\n",
      "x_eff  = [-0.19953419  0.29772829],\n",
      "\n",
      "iteration 768: f_best = 0.00000000\n",
      "x_eff  = [-0.22709501 -0.06847993],\n",
      "\n",
      "iteration 769: f_best = 0.00000000\n",
      "x_eff  = [0.14541941 0.22630987],\n",
      "\n",
      "iteration 770: f_best = 0.00000000\n",
      "x_eff  = [ 0.20770308 -0.25042012],\n",
      "\n",
      "iteration 771: f_best = 0.00000000\n",
      "x_eff  = [0.16986773 0.0809734 ],\n",
      "\n",
      "iteration 772: f_best = 0.00000000\n",
      "x_eff  = [0.26405662 0.05594323],\n",
      "\n",
      "iteration 773: f_best = 0.00000000\n",
      "x_eff  = [0.05586249 0.02082583],\n",
      "\n",
      "iteration 774: f_best = 0.00000000\n",
      "x_eff  = [ 0.17649685 -0.27529067],\n",
      "\n",
      "iteration 775: f_best = 0.00000000\n",
      "x_eff  = [0.1857499  0.01575871],\n",
      "\n",
      "iteration 776: f_best = 0.00000000\n",
      "x_eff  = [-0.14584467 -0.24058485],\n",
      "\n",
      "iteration 777: f_best = 0.00000000\n",
      "x_eff  = [0.15229928 0.26461465],\n",
      "\n",
      "iteration 778: f_best = 0.00000000\n",
      "x_eff  = [ 0.08342516 -0.14010801],\n",
      "\n",
      "iteration 779: f_best = 0.00000000\n",
      "x_eff  = [ 0.08565412 -0.26421775],\n",
      "\n",
      "iteration 780: f_best = 0.00000000\n",
      "x_eff  = [-0.1401328  -0.12155119],\n",
      "\n",
      "iteration 781: f_best = 0.00000000\n",
      "x_eff  = [0.05195653 0.08778325],\n",
      "\n",
      "iteration 782: f_best = 0.00000000\n",
      "x_eff  = [0.09290572 0.1144624 ],\n",
      "\n",
      "iteration 783: f_best = 0.00000000\n",
      "x_eff  = [-0.18251686 -0.22540359],\n",
      "\n",
      "iteration 784: f_best = 0.00000000\n",
      "x_eff  = [-0.02537861 -0.10022433],\n",
      "\n",
      "iteration 785: f_best = 0.00000000\n",
      "x_eff  = [-0.16938934 -0.12313681],\n",
      "\n",
      "iteration 786: f_best = 0.00000000\n",
      "x_eff  = [-0.06103503 -0.05293528],\n",
      "\n",
      "iteration 787: f_best = 0.00000000\n",
      "x_eff  = [-0.13771989  0.11803044],\n",
      "\n",
      "iteration 788: f_best = 0.00000000\n",
      "x_eff  = [-0.22984989 -0.09848325],\n",
      "\n",
      "iteration 789: f_best = 0.00000000\n",
      "x_eff  = [ 0.01662346 -0.2379731 ],\n",
      "\n",
      "iteration 790: f_best = 0.00000000\n",
      "x_eff  = [-0.2280268   0.12569048],\n",
      "\n",
      "iteration 791: f_best = 0.00000000\n",
      "x_eff  = [ 0.05899967 -0.18696432],\n",
      "\n",
      "iteration 792: f_best = 0.00000000\n",
      "x_eff  = [-0.00161573 -0.23576868],\n",
      "\n",
      "iteration 793: f_best = 0.00000000\n",
      "x_eff  = [-0.18597638 -0.05122512],\n",
      "\n",
      "iteration 794: f_best = 0.00000000\n",
      "x_eff  = [0.03561033 0.11551249],\n",
      "\n",
      "iteration 795: f_best = 0.00000000\n",
      "x_eff  = [ 0.13573939 -0.12982375],\n",
      "\n",
      "iteration 796: f_best = 0.00000000\n",
      "x_eff  = [-0.17159159 -0.1350348 ],\n",
      "\n",
      "iteration 797: f_best = 0.00000000\n",
      "x_eff  = [ 0.17196009 -0.09550856],\n",
      "\n",
      "iteration 798: f_best = 0.00000000\n",
      "x_eff  = [0.12101301 0.05087325],\n",
      "\n",
      "iteration 799: f_best = 0.00000000\n",
      "x_eff  = [-0.17453856 -0.0510785 ],\n",
      "\n",
      "iteration 800: f_best = 0.00000000\n",
      "x_eff  = [-0.01728477  0.1641899 ],\n",
      "\n",
      "iteration 801: f_best = 0.00000000\n",
      "x_eff  = [-0.17924685  0.18587116],\n",
      "\n",
      "iteration 802: f_best = 0.00000000\n",
      "x_eff  = [-0.00053573 -0.11809533],\n",
      "\n",
      "iteration 803: f_best = 0.00000000\n",
      "x_eff  = [0.13135467 0.01299678],\n",
      "\n",
      "iteration 804: f_best = 0.00000000\n",
      "x_eff  = [0.19636233 0.01609845],\n",
      "\n",
      "iteration 805: f_best = 0.00000000\n",
      "x_eff  = [ 0.04117182 -0.04145818],\n",
      "\n",
      "iteration 806: f_best = 0.00000000\n",
      "x_eff  = [0.07698368 0.12324405],\n",
      "\n",
      "iteration 807: f_best = 0.00000000\n",
      "x_eff  = [-0.17721253 -0.03764428],\n",
      "\n",
      "iteration 808: f_best = 0.00000000\n",
      "x_eff  = [-0.18743238 -0.00598754],\n",
      "\n",
      "iteration 809: f_best = 0.00000000\n",
      "x_eff  = [ 0.04783345 -0.09317356],\n",
      "\n",
      "iteration 810: f_best = 0.00000000\n",
      "x_eff  = [ 0.05898756 -0.12545051],\n",
      "\n",
      "iteration 811: f_best = 0.00000000\n",
      "x_eff  = [0.17182701 0.03447708],\n",
      "\n",
      "iteration 812: f_best = 0.00000000\n",
      "x_eff  = [-0.15888466  0.08908035],\n",
      "\n",
      "iteration 813: f_best = 0.00000000\n",
      "x_eff  = [ 0.10962236 -0.02133699],\n",
      "\n",
      "iteration 814: f_best = 0.00000000\n",
      "x_eff  = [-0.14752623  0.09223884],\n",
      "\n",
      "iteration 815: f_best = 0.00000000\n",
      "x_eff  = [-0.04123646 -0.03238933],\n",
      "\n",
      "iteration 816: f_best = 0.00000000\n",
      "x_eff  = [-0.08059545  0.15828778],\n",
      "\n",
      "iteration 817: f_best = 0.00000000\n",
      "x_eff  = [ 0.09328545 -0.0758389 ],\n",
      "\n",
      "iteration 818: f_best = 0.00000000\n",
      "x_eff  = [ 0.13776931 -0.07430642],\n",
      "\n",
      "iteration 819: f_best = 0.00000000\n",
      "x_eff  = [-0.16815566  0.10736013],\n",
      "\n",
      "iteration 820: f_best = 0.00000000\n",
      "x_eff  = [-0.07001728 -0.13835728],\n",
      "\n",
      "iteration 821: f_best = 0.00000000\n",
      "x_eff  = [ 0.12926632 -0.15338975],\n",
      "\n",
      "iteration 822: f_best = 0.00000000\n",
      "x_eff  = [-0.08340746  0.14883731],\n",
      "\n",
      "iteration 823: f_best = 0.00000000\n",
      "x_eff  = [-0.13827717  0.13350265],\n",
      "\n",
      "iteration 824: f_best = 0.00000000\n",
      "x_eff  = [0.05973254 0.08869926],\n",
      "\n",
      "iteration 825: f_best = 0.00000000\n",
      "x_eff  = [0.16592407 0.12432921],\n",
      "\n",
      "iteration 826: f_best = 0.00000000\n",
      "x_eff  = [-0.04119923  0.05777735],\n",
      "\n",
      "iteration 827: f_best = 0.00000000\n",
      "x_eff  = [ 0.0428826  -0.06712787],\n",
      "\n",
      "iteration 828: f_best = 0.00000000\n",
      "x_eff  = [-0.12673944  0.09860289],\n",
      "\n",
      "iteration 829: f_best = 0.00000000\n",
      "x_eff  = [-0.11649768 -0.07411062],\n",
      "\n",
      "iteration 830: f_best = 0.00000000\n",
      "x_eff  = [-0.11461758  0.13621051],\n",
      "\n",
      "iteration 831: f_best = 0.00000000\n",
      "x_eff  = [0.03037491 0.12019041],\n",
      "\n",
      "iteration 832: f_best = 0.00000000\n",
      "x_eff  = [0.02890838 0.13016836],\n",
      "\n",
      "iteration 833: f_best = 0.00000000\n",
      "x_eff  = [ 0.11745128 -0.05648509],\n",
      "\n",
      "iteration 834: f_best = 0.00000000\n",
      "x_eff  = [ 0.11377533 -0.11681256],\n",
      "\n",
      "iteration 835: f_best = 0.00000000\n",
      "x_eff  = [0.0278653  0.08454267],\n",
      "\n",
      "iteration 836: f_best = 0.00000000\n",
      "x_eff  = [ 0.1492824  -0.05052706],\n",
      "\n",
      "iteration 837: f_best = 0.00000000\n",
      "x_eff  = [-0.10909507  0.04439947],\n",
      "\n",
      "iteration 838: f_best = 0.00000000\n",
      "x_eff  = [-0.03956933  0.13757641],\n",
      "\n",
      "iteration 839: f_best = 0.00000000\n",
      "x_eff  = [ 0.02264279 -0.03859031],\n",
      "\n",
      "iteration 840: f_best = 0.00000000\n",
      "x_eff  = [ 0.04332975 -0.06665905],\n",
      "\n",
      "iteration 841: f_best = 0.00000000\n",
      "x_eff  = [-0.07289518 -0.09078916],\n",
      "\n",
      "iteration 842: f_best = 0.00000000\n",
      "x_eff  = [-0.08989549  0.07764927],\n",
      "\n",
      "iteration 843: f_best = 0.00000000\n",
      "x_eff  = [-0.06898257 -0.08071869],\n",
      "\n",
      "iteration 844: f_best = 0.00000000\n",
      "x_eff  = [ 0.07604266 -0.12368797],\n",
      "\n",
      "iteration 845: f_best = 0.00000000\n",
      "x_eff  = [-0.04217159  0.12169779],\n",
      "\n",
      "iteration 846: f_best = 0.00000000\n",
      "x_eff  = [-0.06302063 -0.07921578],\n",
      "\n",
      "iteration 847: f_best = 0.00000000\n",
      "x_eff  = [-0.07447102 -0.0232898 ],\n",
      "\n",
      "iteration 848: f_best = 0.00000000\n",
      "x_eff  = [0.04658009 0.12727361],\n",
      "\n",
      "iteration 849: f_best = 0.00000000\n",
      "x_eff  = [ 0.12560255 -0.06637677],\n",
      "\n",
      "iteration 850: f_best = 0.00000000\n",
      "x_eff  = [-0.12671107 -0.07619153],\n",
      "\n",
      "iteration 851: f_best = 0.00000000\n",
      "x_eff  = [-0.03589809  0.07248937],\n",
      "\n",
      "iteration 852: f_best = 0.00000000\n",
      "x_eff  = [ 0.03272    -0.08502376],\n",
      "\n",
      "iteration 853: f_best = 0.00000000\n",
      "x_eff  = [-0.05037832 -0.10530008],\n",
      "\n",
      "iteration 854: f_best = 0.00000000\n",
      "x_eff  = [0.11577258 0.12821568],\n",
      "\n",
      "iteration 855: f_best = 0.00000000\n",
      "x_eff  = [ 0.10955338 -0.07553798],\n",
      "\n",
      "iteration 856: f_best = 0.00000000\n",
      "x_eff  = [-0.09886437  0.0241085 ],\n",
      "\n",
      "iteration 857: f_best = 0.00000000\n",
      "x_eff  = [ 0.00468592 -0.09398854],\n",
      "\n",
      "iteration 858: f_best = 0.00000000\n",
      "x_eff  = [-0.11072332 -0.06727521],\n",
      "\n",
      "iteration 859: f_best = 0.00000000\n",
      "x_eff  = [ 0.02529001 -0.0129892 ],\n",
      "\n",
      "iteration 860: f_best = 0.00000000\n",
      "x_eff  = [-0.09752457 -0.02986254],\n",
      "\n",
      "iteration 861: f_best = 0.00000000\n",
      "x_eff  = [ 0.00652776 -0.04796406],\n",
      "\n",
      "iteration 862: f_best = 0.00000000\n",
      "x_eff  = [-0.04284153 -0.03284161],\n",
      "\n",
      "iteration 863: f_best = 0.00000000\n",
      "x_eff  = [-0.07956199 -0.01806931],\n",
      "\n",
      "iteration 864: f_best = 0.00000000\n",
      "x_eff  = [ 0.03212455 -0.03749333],\n",
      "\n",
      "iteration 865: f_best = 0.00000000\n",
      "x_eff  = [-0.0141434   0.01145538],\n",
      "\n",
      "iteration 866: f_best = 0.00000000\n",
      "x_eff  = [ 0.01512102 -0.03019472],\n",
      "\n",
      "iteration 867: f_best = 0.00000000\n",
      "x_eff  = [0.08752889 0.02753558],\n",
      "\n",
      "iteration 868: f_best = 0.00000000\n",
      "x_eff  = [0.00981677 0.10551462],\n",
      "\n",
      "iteration 869: f_best = 0.00000000\n",
      "x_eff  = [0.02458005 0.08561613],\n",
      "\n",
      "iteration 870: f_best = 0.00000000\n",
      "x_eff  = [-0.0681792 -0.0731263],\n",
      "\n",
      "iteration 871: f_best = 0.00000000\n",
      "x_eff  = [0.10247141 0.05655219],\n",
      "\n",
      "iteration 872: f_best = 0.00000000\n",
      "x_eff  = [-0.04305922 -0.01154097],\n",
      "\n",
      "iteration 873: f_best = 0.00000000\n",
      "x_eff  = [0.02335112 0.08929677],\n",
      "\n",
      "iteration 874: f_best = 0.00000000\n",
      "x_eff  = [-0.01132516  0.05746451],\n",
      "\n",
      "iteration 875: f_best = 0.00000000\n",
      "x_eff  = [0.05724604 0.05170582],\n",
      "\n",
      "iteration 876: f_best = 0.00000000\n",
      "x_eff  = [-0.01170118  0.07486052],\n",
      "\n",
      "iteration 877: f_best = 0.00000000\n",
      "x_eff  = [0.04103174 0.0405914 ],\n",
      "\n",
      "iteration 878: f_best = 0.00000000\n",
      "x_eff  = [-0.02207808  0.02524972],\n",
      "\n",
      "iteration 879: f_best = 0.00000000\n",
      "x_eff  = [ 0.0394113  -0.05232583],\n",
      "\n",
      "iteration 880: f_best = 0.00000000\n",
      "x_eff  = [-0.0497192   0.08969533],\n",
      "\n",
      "iteration 881: f_best = 0.00000000\n",
      "x_eff  = [-0.01700882 -0.051592  ],\n",
      "\n",
      "iteration 882: f_best = 0.00000000\n",
      "x_eff  = [-0.06360619  0.09052576],\n",
      "\n",
      "iteration 883: f_best = 0.00000000\n",
      "x_eff  = [ 0.02884979 -0.03400409],\n",
      "\n",
      "iteration 884: f_best = 0.00000000\n",
      "x_eff  = [ 0.04031375 -0.06964126],\n",
      "\n",
      "iteration 885: f_best = 0.00000000\n",
      "x_eff  = [0.00364247 0.07130904],\n",
      "\n",
      "iteration 886: f_best = 0.00000000\n",
      "x_eff  = [-0.02492014 -0.02086074],\n",
      "\n",
      "iteration 887: f_best = 0.00000000\n",
      "x_eff  = [0.07128421 0.06247773],\n",
      "\n",
      "iteration 888: f_best = 0.00000000\n",
      "x_eff  = [ 0.07534389 -0.01419799],\n",
      "\n",
      "iteration 889: f_best = 0.00000000\n",
      "x_eff  = [ 0.07364568 -0.02364835],\n",
      "\n",
      "iteration 890: f_best = 0.00000000\n",
      "x_eff  = [-0.02013543  0.06287496],\n",
      "\n",
      "iteration 891: f_best = 0.00000000\n",
      "x_eff  = [ 0.05290197 -0.0212008 ],\n",
      "\n",
      "iteration 892: f_best = 0.00000000\n",
      "x_eff  = [-0.02315145  0.04986949],\n",
      "\n",
      "iteration 893: f_best = 0.00000000\n",
      "x_eff  = [-0.0672436   0.06055943],\n",
      "\n",
      "iteration 894: f_best = 0.00000000\n",
      "x_eff  = [-0.0403262  0.0487722],\n",
      "\n",
      "iteration 895: f_best = 0.00000000\n",
      "x_eff  = [-0.00726235 -0.01314768],\n",
      "\n",
      "iteration 896: f_best = 0.00000000\n",
      "x_eff  = [ 0.06489789 -0.03728503],\n",
      "\n",
      "iteration 897: f_best = 0.00000000\n",
      "x_eff  = [-0.03124969  0.0755639 ],\n",
      "\n",
      "iteration 898: f_best = 0.00000000\n",
      "x_eff  = [ 0.07721387 -0.01839281],\n",
      "\n",
      "iteration 899: f_best = 0.00000000\n",
      "x_eff  = [0.0504728  0.02748411],\n",
      "\n",
      "iteration 900: f_best = 0.00000000\n",
      "x_eff  = [-0.02068872 -0.03513351],\n",
      "\n",
      "iteration 901: f_best = 0.00000000\n",
      "x_eff  = [-0.06882703 -0.01485794],\n",
      "\n",
      "iteration 902: f_best = 0.00000000\n",
      "x_eff  = [ 0.06919893 -0.02455068],\n",
      "\n",
      "iteration 903: f_best = 0.00000000\n",
      "x_eff  = [-0.07543731 -0.06131918],\n",
      "\n",
      "iteration 904: f_best = 0.00000000\n",
      "x_eff  = [ 0.07110622 -0.04481992],\n",
      "\n",
      "iteration 905: f_best = 0.00000000\n",
      "x_eff  = [-0.05327307 -0.04816988],\n",
      "\n",
      "iteration 906: f_best = 0.00000000\n",
      "x_eff  = [-0.05777721  0.05909291],\n",
      "\n",
      "iteration 907: f_best = 0.00000000\n",
      "x_eff  = [0.07603584 0.06480873],\n",
      "\n",
      "iteration 908: f_best = 0.00000000\n",
      "x_eff  = [ 0.05051856 -0.04531898],\n",
      "\n",
      "iteration 909: f_best = 0.00000000\n",
      "x_eff  = [-0.05146861 -0.02684832],\n",
      "\n",
      "iteration 910: f_best = 0.00000000\n",
      "x_eff  = [-0.0697244  0.0003862],\n",
      "\n",
      "iteration 911: f_best = 0.00000000\n",
      "x_eff  = [-0.01744326 -0.00728691],\n",
      "\n",
      "iteration 912: f_best = 0.00000000\n",
      "x_eff  = [-0.04018645 -0.02338555],\n",
      "\n",
      "iteration 913: f_best = 0.00000000\n",
      "x_eff  = [-0.02932227 -0.0071686 ],\n",
      "\n",
      "iteration 914: f_best = 0.00000000\n",
      "x_eff  = [-0.01127524 -0.01236874],\n",
      "\n",
      "iteration 915: f_best = 0.00000000\n",
      "x_eff  = [-0.00613891  0.06976954],\n",
      "\n",
      "iteration 916: f_best = 0.00000000\n",
      "x_eff  = [-0.03210336  0.06655765],\n",
      "\n",
      "iteration 917: f_best = 0.00000000\n",
      "x_eff  = [-0.03921585  0.00431398],\n",
      "\n",
      "iteration 918: f_best = 0.00000000\n",
      "x_eff  = [ 0.05995702 -0.03338024],\n",
      "\n",
      "iteration 919: f_best = 0.00000000\n",
      "x_eff  = [ 0.03476831 -0.06611496],\n",
      "\n",
      "iteration 920: f_best = 0.00000000\n",
      "x_eff  = [-0.03051982 -0.01741531],\n",
      "\n",
      "iteration 921: f_best = 0.00000000\n",
      "x_eff  = [-0.01264905  0.01453903],\n",
      "\n",
      "iteration 922: f_best = 0.00000000\n",
      "x_eff  = [0.03802732 0.01972453],\n",
      "\n",
      "iteration 923: f_best = 0.00000000\n",
      "x_eff  = [-0.00605682 -0.00603135],\n",
      "\n",
      "iteration 924: f_best = 0.00000000\n",
      "x_eff  = [0.05458158 0.04548366],\n",
      "\n",
      "iteration 925: f_best = 0.00000000\n",
      "x_eff  = [-0.06206154  0.03806717],\n",
      "\n",
      "iteration 926: f_best = 0.00000000\n",
      "x_eff  = [-0.00078223 -0.06106823],\n",
      "\n",
      "iteration 927: f_best = 0.00000000\n",
      "x_eff  = [0.05449017 0.00830027],\n",
      "\n",
      "iteration 928: f_best = 0.00000000\n",
      "x_eff  = [ 0.0431503  -0.06181336],\n",
      "\n",
      "iteration 929: f_best = 0.00000000\n",
      "x_eff  = [-0.03268952 -0.00448967],\n",
      "\n",
      "iteration 930: f_best = 0.00000000\n",
      "x_eff  = [ 0.00975154 -0.04596389],\n",
      "\n",
      "iteration 931: f_best = 0.00000000\n",
      "x_eff  = [-0.04794149 -0.03471827],\n",
      "\n",
      "iteration 932: f_best = 0.00000000\n",
      "x_eff  = [-0.00959799  0.0560234 ],\n",
      "\n",
      "iteration 933: f_best = 0.00000000\n",
      "x_eff  = [0.01096335 0.00538976],\n",
      "\n",
      "iteration 934: f_best = 0.00000000\n",
      "x_eff  = [-0.00516816 -0.029459  ],\n",
      "\n",
      "iteration 935: f_best = 0.00000000\n",
      "x_eff  = [-0.01067329 -0.05128635],\n",
      "\n",
      "iteration 936: f_best = 0.00000000\n",
      "x_eff  = [ 0.0109199  -0.03025314],\n",
      "\n",
      "iteration 937: f_best = 0.00000000\n",
      "x_eff  = [-0.00834038  0.02098433],\n",
      "\n",
      "iteration 938: f_best = 0.00000000\n",
      "x_eff  = [ 0.05276976 -0.0349113 ],\n",
      "\n",
      "iteration 939: f_best = 0.00000000\n",
      "x_eff  = [-0.02758368 -0.00052679],\n",
      "\n",
      "iteration 940: f_best = 0.00000000\n",
      "x_eff  = [ 0.00744764 -0.02447119],\n",
      "\n",
      "iteration 941: f_best = 0.00000000\n",
      "x_eff  = [-0.05254683 -0.03094026],\n",
      "\n",
      "iteration 942: f_best = 0.00000000\n",
      "x_eff  = [ 0.04222769 -0.01859051],\n",
      "\n",
      "iteration 943: f_best = 0.00000000\n",
      "x_eff  = [ 0.03129184 -0.01262637],\n",
      "\n",
      "iteration 944: f_best = 0.00000000\n",
      "x_eff  = [-0.03118471  0.01861526],\n",
      "\n",
      "iteration 945: f_best = 0.00000000\n",
      "x_eff  = [-0.03291457  0.03692534],\n",
      "\n",
      "iteration 946: f_best = 0.00000000\n",
      "x_eff  = [ 0.0401599  -0.00847668],\n",
      "\n",
      "iteration 947: f_best = 0.00000000\n",
      "x_eff  = [-0.0222527  -0.02910221],\n",
      "\n",
      "iteration 948: f_best = 0.00000000\n",
      "x_eff  = [ 0.00048908 -0.03677266],\n",
      "\n",
      "iteration 949: f_best = 0.00000000\n",
      "x_eff  = [ 0.02060615 -0.03294561],\n",
      "\n",
      "iteration 950: f_best = 0.00000000\n",
      "x_eff  = [-0.0475739   0.04842605],\n",
      "\n",
      "iteration 951: f_best = 0.00000000\n",
      "x_eff  = [-0.02544469 -0.00684342],\n",
      "\n",
      "iteration 952: f_best = 0.00000000\n",
      "x_eff  = [-0.02739613  0.04861393],\n",
      "\n",
      "iteration 953: f_best = 0.00000000\n",
      "x_eff  = [-0.0309642   0.03390613],\n",
      "\n",
      "iteration 954: f_best = 0.00000000\n",
      "x_eff  = [0.00092268 0.03362857],\n",
      "\n",
      "iteration 955: f_best = 0.00000000\n",
      "x_eff  = [0.01296652 0.01623925],\n",
      "\n",
      "iteration 956: f_best = 0.00000000\n",
      "x_eff  = [0.01977215 0.03756164],\n",
      "\n",
      "iteration 957: f_best = 0.00000000\n",
      "x_eff  = [-0.01804994 -0.01995962],\n",
      "\n",
      "iteration 958: f_best = 0.00000000\n",
      "x_eff  = [0.03433103 0.00227243],\n",
      "\n",
      "iteration 959: f_best = 0.00000000\n",
      "x_eff  = [-0.03071939 -0.01047271],\n",
      "\n",
      "iteration 960: f_best = 0.00000000\n",
      "x_eff  = [0.02470883 0.00013338],\n",
      "\n",
      "iteration 961: f_best = 0.00000000\n",
      "x_eff  = [-0.03397024  0.01391173],\n",
      "\n",
      "iteration 962: f_best = 0.00000000\n",
      "x_eff  = [ 0.04217068 -0.04046882],\n",
      "\n",
      "iteration 963: f_best = 0.00000000\n",
      "x_eff  = [0.01495291 0.0006741 ],\n",
      "\n",
      "iteration 964: f_best = 0.00000000\n",
      "x_eff  = [0.02418768 0.00958457],\n",
      "\n",
      "iteration 965: f_best = 0.00000000\n",
      "x_eff  = [-0.03205596 -0.00879347],\n",
      "\n",
      "iteration 966: f_best = 0.00000000\n",
      "x_eff  = [-0.02353611 -0.01670089],\n",
      "\n",
      "iteration 967: f_best = 0.00000000\n",
      "x_eff  = [0.0370453  0.01102162],\n",
      "\n",
      "iteration 968: f_best = 0.00000000\n",
      "x_eff  = [ 0.02909143 -0.0164543 ],\n",
      "\n",
      "iteration 969: f_best = 0.00000000\n",
      "x_eff  = [-0.03209798  0.00632589],\n",
      "\n",
      "iteration 970: f_best = 0.00000000\n",
      "x_eff  = [-0.0237003   0.01129337],\n",
      "\n",
      "iteration 971: f_best = 0.00000000\n",
      "x_eff  = [ 0.02248856 -0.00690101],\n",
      "\n",
      "iteration 972: f_best = 0.00000000\n",
      "x_eff  = [-0.02936038  0.01205027],\n",
      "\n",
      "iteration 973: f_best = 0.00000000\n",
      "x_eff  = [-0.00738763 -0.00885084],\n",
      "\n",
      "iteration 974: f_best = 0.00000000\n",
      "x_eff  = [-0.01567905  0.00822637],\n",
      "\n",
      "iteration 975: f_best = 0.00000000\n",
      "x_eff  = [0.01690626 0.02017763],\n",
      "\n",
      "iteration 976: f_best = 0.00000000\n",
      "x_eff  = [ 0.0195655  -0.01814355],\n",
      "\n",
      "iteration 977: f_best = 0.00000000\n",
      "x_eff  = [-0.01021638 -0.02442388],\n",
      "\n",
      "iteration 978: f_best = 0.00000000\n",
      "x_eff  = [-0.02827439 -0.03721338],\n",
      "\n",
      "iteration 979: f_best = 0.00000000\n",
      "x_eff  = [-0.01134436 -0.02780004],\n",
      "\n",
      "iteration 980: f_best = 0.00000000\n",
      "x_eff  = [ 0.0231009  -0.02803085],\n",
      "\n",
      "iteration 981: f_best = 0.00000000\n",
      "x_eff  = [ 0.03529387 -0.03334654],\n",
      "\n",
      "iteration 982: f_best = 0.00000000\n",
      "x_eff  = [0.01121485 0.03549436],\n",
      "\n",
      "iteration 983: f_best = 0.00000000\n",
      "x_eff  = [ 0.02480314 -0.01324061],\n",
      "\n",
      "iteration 984: f_best = 0.00000000\n",
      "x_eff  = [ 0.00252899 -0.02780224],\n",
      "\n",
      "iteration 985: f_best = 0.00000000\n",
      "x_eff  = [ 0.02637885 -0.00346315],\n",
      "\n",
      "iteration 986: f_best = 0.00000000\n",
      "x_eff  = [ 0.02019207 -0.00293616],\n",
      "\n",
      "iteration 987: f_best = 0.00000000\n",
      "x_eff  = [ 0.02560304 -0.00118803],\n",
      "\n",
      "iteration 988: f_best = 0.00000000\n",
      "x_eff  = [-0.01030936  0.0257735 ],\n",
      "\n",
      "iteration 989: f_best = 0.00000000\n",
      "x_eff  = [-0.0125077   0.02827465],\n",
      "\n",
      "iteration 990: f_best = 0.00000000\n",
      "x_eff  = [ 0.0292743  -0.01830623],\n",
      "\n",
      "iteration 991: f_best = 0.00000000\n",
      "x_eff  = [-0.00068056  0.03096007],\n",
      "\n",
      "iteration 992: f_best = 0.00000000\n",
      "x_eff  = [0.02926374 0.00610053],\n",
      "\n",
      "iteration 993: f_best = 0.00000000\n",
      "x_eff  = [ 0.02088651 -0.0289805 ],\n",
      "\n",
      "iteration 994: f_best = 0.00000000\n",
      "x_eff  = [-0.00518973  0.01760449],\n",
      "\n",
      "iteration 995: f_best = 0.00000000\n",
      "x_eff  = [ 0.01619732 -0.00310159],\n",
      "\n",
      "iteration 996: f_best = 0.00000000\n",
      "x_eff  = [ 0.02416616 -0.02095655],\n",
      "\n",
      "iteration 997: f_best = 0.00000000\n",
      "x_eff  = [0.01356982 0.01672308],\n",
      "\n",
      "iteration 998: f_best = 0.00000000\n",
      "x_eff  = [0.0226379  0.00745024],\n",
      "\n",
      "iteration 999: f_best = 0.00000000\n",
      "x_eff  = [ 0.03002211 -0.0034064 ],\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bounds = np.array([[-600, 600], [-600, 600]])\n",
    "tau = 1e-8\n",
    "K_warmup = 10\n",
    "K = 1000\n",
    "\n",
    "x_best, f_best = global_opt(bounds, tau, K, K_warmup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the effective initial guesses for the iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot effective initial guesses\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x_best[0], x_best[1], color=\"black\", s=50, label=\"Final solution\")\n",
    "plt.scatter(bounds[:, 0], bounds[:, 0], color=\"blue\", s=50, label=\"Bounds\")\n",
    "plt.scatter(bounds[:, 1], bounds[:, 1], color=\"blue\", s=50)\n",
    "for k in range(K):\n",
    "    if k < K_warmup:\n",
    "        # Use best point from warm-up iterations as reference\n",
    "        x_ref = x_best\n",
    "    else:\n",
    "        # Calculate chi_k\n",
    "        chi_k = 0.5*2/(1+np.exp((k - K_warmup)/100))\n",
    "\n",
    "        # Adjust initial guess\n",
    "        xk = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        x_ref = chi_k * xk + (1 - chi_k) * x_best\n",
    "\n",
    "    plt.scatter(x_ref[0], x_ref[1], color=\"#17becf\", \n",
    "                alpha=0.2, s=5)\n",
    "plt.scatter(-1000,-1000, alpha=0.2, s=25, color=\"#17becf\", label=\"Effective inital guesses\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(bounds[0])\n",
    "plt.ylim(bounds[1])\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\")\n",
    "plt.title(\"Effective initial guesses for iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the bounds, the final solution, and the effective initial guesses for iterations. The effective initial guesses are scattered around the final solution around (0,0). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Is it a better idea to set $\\underline{K} = 100$? Is the convergence faster?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare $\\underline{K}=10$ to $\\underline{K}=100$ to see which one converges faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10: f_best = 9.18123971\n",
      "x_eff  = [185.26114709  48.82266886],\n",
      "\n",
      "iteration 11: f_best = 5.66703168\n",
      "x_eff  = [-34.57581447 146.47400145],\n",
      "\n",
      "iteration 12: f_best = 5.66703168\n",
      "x_eff  = [207.34822862 -37.05836679],\n",
      "\n",
      "iteration 13: f_best = 5.66703168\n",
      "x_eff  = [223.39591464 133.59991015],\n",
      "\n",
      "iteration 14: f_best = 0.50285186\n",
      "x_eff  = [ 8.26961247 45.36894394],\n",
      "\n",
      "iteration 15: f_best = 0.50285186\n",
      "x_eff  = [-263.66336133  -37.43707432],\n",
      "\n",
      "iteration 16: f_best = 0.50285186\n",
      "x_eff  = [ 272.82108124 -223.86292795],\n",
      "\n",
      "iteration 17: f_best = 0.40178580\n",
      "x_eff  = [  0.30634608 -40.64653057],\n",
      "\n",
      "iteration 18: f_best = 0.40178580\n",
      "x_eff  = [-124.25782703  117.55087091],\n",
      "\n",
      "iteration 19: f_best = 0.40178580\n",
      "x_eff  = [  40.28121806 -240.8126086 ],\n",
      "\n",
      "iteration 20: f_best = 0.40178580\n",
      "x_eff  = [276.04919141 225.18563687],\n",
      "\n",
      "iteration 21: f_best = 0.40178580\n",
      "x_eff  = [232.37910315 224.33687293],\n",
      "\n",
      "iteration 22: f_best = 0.40178580\n",
      "x_eff  = [ -89.66396301 -261.09446965],\n",
      "\n",
      "iteration 23: f_best = 0.40178580\n",
      "x_eff  = [ 18.4866092 235.4748674],\n",
      "\n",
      "iteration 24: f_best = 0.40178580\n",
      "x_eff  = [-231.02203994   67.13873631],\n",
      "\n",
      "iteration 25: f_best = 0.40178580\n",
      "x_eff  = [-246.88726189  -53.05775189],\n",
      "\n",
      "iteration 26: f_best = 0.40178580\n",
      "x_eff  = [ -50.17487486 -110.05658723],\n",
      "\n",
      "iteration 27: f_best = 0.40178580\n",
      "x_eff  = [-148.87943639 -118.5655404 ],\n",
      "\n",
      "iteration 28: f_best = 0.40178580\n",
      "x_eff  = [ 214.23186428 -271.80105308],\n",
      "\n",
      "iteration 29: f_best = 0.40178580\n",
      "x_eff  = [-45.0900984  109.85948231],\n",
      "\n",
      "iteration 30: f_best = 0.40178580\n",
      "x_eff  = [252.9561636   91.68591762],\n",
      "\n",
      "iteration 31: f_best = 0.40178580\n",
      "x_eff  = [ 56.93027803 147.76506951],\n",
      "\n",
      "iteration 32: f_best = 0.40178580\n",
      "x_eff  = [-187.03596156   38.54072707],\n",
      "\n",
      "iteration 33: f_best = 0.40178580\n",
      "x_eff  = [143.94230449 -32.21855305],\n",
      "\n",
      "iteration 34: f_best = 0.40178580\n",
      "x_eff  = [  4.11679908 156.26207815],\n",
      "\n",
      "iteration 35: f_best = 0.40178580\n",
      "x_eff  = [241.93827033 -14.20780724],\n",
      "\n",
      "iteration 36: f_best = 0.40178580\n",
      "x_eff  = [ -86.10968217 -107.10107002],\n",
      "\n",
      "iteration 37: f_best = 0.40178580\n",
      "x_eff  = [ 207.28963508 -178.77922133],\n",
      "\n",
      "iteration 38: f_best = 0.40178580\n",
      "x_eff  = [-231.83792918 -267.4827358 ],\n",
      "\n",
      "iteration 39: f_best = 0.40178580\n",
      "x_eff  = [-241.01553861 -233.98857785],\n",
      "\n",
      "iteration 40: f_best = 0.40178580\n",
      "x_eff  = [202.38405433  12.71944911],\n",
      "\n",
      "iteration 41: f_best = 0.40178580\n",
      "x_eff  = [-213.66954392  -81.76883807],\n",
      "\n",
      "iteration 42: f_best = 0.40178580\n",
      "x_eff  = [142.53876231 -39.37550268],\n",
      "\n",
      "iteration 43: f_best = 0.40178580\n",
      "x_eff  = [-3.03932616 69.73329   ],\n",
      "\n",
      "iteration 44: f_best = 0.40178580\n",
      "x_eff  = [ 121.99248321 -179.74606414],\n",
      "\n",
      "iteration 45: f_best = 0.40178580\n",
      "x_eff  = [ -32.96288284 -266.70251652],\n",
      "\n",
      "iteration 46: f_best = 0.40178580\n",
      "x_eff  = [-163.28580712  145.63222258],\n",
      "\n",
      "iteration 47: f_best = 0.40178580\n",
      "x_eff  = [-105.26376967 -160.25514982],\n",
      "\n",
      "iteration 48: f_best = 0.40178580\n",
      "x_eff  = [ 36.92074706 -17.47215936],\n",
      "\n",
      "iteration 49: f_best = 0.40178580\n",
      "x_eff  = [-21.7495206   76.17010627],\n",
      "\n",
      "iteration 50: f_best = 0.40178580\n",
      "x_eff  = [-206.22397316  -70.87023653],\n",
      "\n",
      "iteration 51: f_best = 0.40178580\n",
      "x_eff  = [39.86164904 56.16822172],\n",
      "\n",
      "iteration 52: f_best = 0.40178580\n",
      "x_eff  = [ 43.32102208 186.81514133],\n",
      "\n",
      "iteration 53: f_best = 0.40178580\n",
      "x_eff  = [-82.27944499 120.29981826],\n",
      "\n",
      "iteration 54: f_best = 0.40178580\n",
      "x_eff  = [ 82.10277569 164.9452023 ],\n",
      "\n",
      "iteration 55: f_best = 0.40178580\n",
      "x_eff  = [ -68.45938582 -213.83487853],\n",
      "\n",
      "iteration 56: f_best = 0.40178580\n",
      "x_eff  = [-63.97005131 -10.32035022],\n",
      "\n",
      "iteration 57: f_best = 0.40178580\n",
      "x_eff  = [-101.98847779 -222.70918943],\n",
      "\n",
      "iteration 58: f_best = 0.40178580\n",
      "x_eff  = [-122.13414254  159.95182786],\n",
      "\n",
      "iteration 59: f_best = 0.40178580\n",
      "x_eff  = [-30.74607944  81.66231705],\n",
      "\n",
      "iteration 60: f_best = 0.40178580\n",
      "x_eff  = [167.09739783 -88.84689672],\n",
      "\n",
      "iteration 61: f_best = 0.40178580\n",
      "x_eff  = [-133.92816795   41.04638523],\n",
      "\n",
      "iteration 62: f_best = 0.40178580\n",
      "x_eff  = [217.48766233 -54.49268971],\n",
      "\n",
      "iteration 63: f_best = 0.40178580\n",
      "x_eff  = [-159.19937177 -224.54918512],\n",
      "\n",
      "iteration 64: f_best = 0.40178580\n",
      "x_eff  = [-72.87482424  44.26032803],\n",
      "\n",
      "iteration 65: f_best = 0.40178580\n",
      "x_eff  = [-55.07206544 122.22116617],\n",
      "\n",
      "iteration 66: f_best = 0.40178580\n",
      "x_eff  = [  -9.08136447 -192.75410642],\n",
      "\n",
      "iteration 67: f_best = 0.26375924\n",
      "x_eff  = [ 12.08491095 -31.91012509],\n",
      "\n",
      "iteration 68: f_best = 0.26375924\n",
      "x_eff  = [171.72961228 106.76658552],\n",
      "\n",
      "iteration 69: f_best = 0.26375924\n",
      "x_eff  = [ 94.4289409  141.99589095],\n",
      "\n",
      "iteration 70: f_best = 0.26375924\n",
      "x_eff  = [-186.71375091  -84.03843457],\n",
      "\n",
      "iteration 71: f_best = 0.26375924\n",
      "x_eff  = [-130.25621757  -35.85639751],\n",
      "\n",
      "iteration 72: f_best = 0.26375924\n",
      "x_eff  = [213.74508501  96.07153066],\n",
      "\n",
      "iteration 73: f_best = 0.26375924\n",
      "x_eff  = [-121.04077183   10.69886247],\n",
      "\n",
      "iteration 74: f_best = 0.16766000\n",
      "x_eff  = [-18.30103055  20.2487822 ],\n",
      "\n",
      "iteration 75: f_best = 0.16766000\n",
      "x_eff  = [  51.46481211 -172.83441107],\n",
      "\n",
      "iteration 76: f_best = 0.16766000\n",
      "x_eff  = [  2.61684231 -71.09294275],\n",
      "\n",
      "iteration 77: f_best = 0.16766000\n",
      "x_eff  = [-181.7008258  -102.12324386],\n",
      "\n",
      "iteration 78: f_best = 0.16766000\n",
      "x_eff  = [-138.75708033   52.9779424 ],\n",
      "\n",
      "iteration 79: f_best = 0.16766000\n",
      "x_eff  = [-147.52905719  -77.48537872],\n",
      "\n",
      "iteration 80: f_best = 0.16766000\n",
      "x_eff  = [  76.34614106 -102.96195768],\n",
      "\n",
      "iteration 81: f_best = 0.16766000\n",
      "x_eff  = [ 62.47435991 146.58333113],\n",
      "\n",
      "iteration 82: f_best = 0.16766000\n",
      "x_eff  = [-89.48431063 137.85215118],\n",
      "\n",
      "iteration 83: f_best = 0.16766000\n",
      "x_eff  = [ 141.78815878 -106.21453115],\n",
      "\n",
      "iteration 84: f_best = 0.16766000\n",
      "x_eff  = [60.61483634 -1.45133608],\n",
      "\n",
      "iteration 85: f_best = 0.16766000\n",
      "x_eff  = [-110.12907886 -175.04845156],\n",
      "\n",
      "iteration 86: f_best = 0.16766000\n",
      "x_eff  = [-105.69114391 -108.45557773],\n",
      "\n",
      "iteration 87: f_best = 0.16766000\n",
      "x_eff  = [40.70786777 15.77785749],\n",
      "\n",
      "iteration 88: f_best = 0.16766000\n",
      "x_eff  = [ 24.12029097 147.74235777],\n",
      "\n",
      "iteration 89: f_best = 0.16766000\n",
      "x_eff  = [-33.61716346 146.85600234],\n",
      "\n",
      "iteration 90: f_best = 0.16766000\n",
      "x_eff  = [-152.43242621 -173.13375177],\n",
      "\n",
      "iteration 91: f_best = 0.16766000\n",
      "x_eff  = [-99.80189412 -23.24045118],\n",
      "\n",
      "iteration 92: f_best = 0.16766000\n",
      "x_eff  = [58.42216551 99.15405799],\n",
      "\n",
      "iteration 93: f_best = 0.16766000\n",
      "x_eff  = [-166.04421773  186.26969128],\n",
      "\n",
      "iteration 94: f_best = 0.16766000\n",
      "x_eff  = [60.25031757 12.40566458],\n",
      "\n",
      "iteration 95: f_best = 0.16766000\n",
      "x_eff  = [-117.13480067  -50.40639948],\n",
      "\n",
      "iteration 96: f_best = 0.16766000\n",
      "x_eff  = [ 39.05950579 -21.78332405],\n",
      "\n",
      "iteration 97: f_best = 0.16766000\n",
      "x_eff  = [-123.12096501 -111.78492662],\n",
      "\n",
      "iteration 98: f_best = 0.16766000\n",
      "x_eff  = [-12.70052242  91.40859955],\n",
      "\n",
      "iteration 99: f_best = 0.16766000\n",
      "x_eff  = [156.55885183 -91.65245169],\n",
      "\n",
      "iteration 100: f_best = 0.16766000\n",
      "x_eff  = [-130.15815001    5.39463749],\n",
      "\n",
      "iteration 101: f_best = 0.16766000\n",
      "x_eff  = [-146.95106542  175.21028417],\n",
      "\n",
      "iteration 102: f_best = 0.16766000\n",
      "x_eff  = [-165.32633653 -126.44095634],\n",
      "\n",
      "iteration 103: f_best = 0.16766000\n",
      "x_eff  = [-30.16485875 -12.33655705],\n",
      "\n",
      "iteration 104: f_best = 0.16766000\n",
      "x_eff  = [-77.07053451 123.52005092],\n",
      "\n",
      "iteration 105: f_best = 0.16766000\n",
      "x_eff  = [-177.49973977  -98.01413062],\n",
      "\n",
      "iteration 106: f_best = 0.16766000\n",
      "x_eff  = [38.55262994 72.14740865],\n",
      "\n",
      "iteration 107: f_best = 0.16766000\n",
      "x_eff  = [ -37.58431935 -125.05985761],\n",
      "\n",
      "iteration 108: f_best = 0.16766000\n",
      "x_eff  = [140.49672087 -47.13851965],\n",
      "\n",
      "iteration 109: f_best = 0.16766000\n",
      "x_eff  = [148.32582988  86.50160517],\n",
      "\n",
      "iteration 110: f_best = 0.16766000\n",
      "x_eff  = [-126.81144277  159.81505768],\n",
      "\n",
      "iteration 111: f_best = 0.16766000\n",
      "x_eff  = [-39.99310882 159.67747917],\n",
      "\n",
      "iteration 112: f_best = 0.16766000\n",
      "x_eff  = [-135.93717928   77.59706051],\n",
      "\n",
      "iteration 113: f_best = 0.16766000\n",
      "x_eff  = [-70.36323168 -38.6007348 ],\n",
      "\n",
      "iteration 114: f_best = 0.16766000\n",
      "x_eff  = [-152.18661469  -74.32105674],\n",
      "\n",
      "iteration 115: f_best = 0.16766000\n",
      "x_eff  = [ 20.61249989 -82.92215905],\n",
      "\n",
      "iteration 116: f_best = 0.16766000\n",
      "x_eff  = [-74.64494872 134.89748975],\n",
      "\n",
      "iteration 117: f_best = 0.16766000\n",
      "x_eff  = [134.15652226  78.09736289],\n",
      "\n",
      "iteration 118: f_best = 0.16766000\n",
      "x_eff  = [-85.06227261 120.75792947],\n",
      "\n",
      "iteration 119: f_best = 0.16766000\n",
      "x_eff  = [82.20328156 43.50473201],\n",
      "\n",
      "iteration 120: f_best = 0.16766000\n",
      "x_eff  = [-92.63601213 107.45323674],\n",
      "\n",
      "iteration 121: f_best = 0.16766000\n",
      "x_eff  = [-57.42048544  90.77175719],\n",
      "\n",
      "iteration 122: f_best = 0.16766000\n",
      "x_eff  = [ 25.59480554 -65.79262073],\n",
      "\n",
      "iteration 123: f_best = 0.16766000\n",
      "x_eff  = [-150.53523779  -23.438042  ],\n",
      "\n",
      "iteration 124: f_best = 0.16766000\n",
      "x_eff  = [ 30.76700406 -84.91209292],\n",
      "\n",
      "iteration 125: f_best = 0.16766000\n",
      "x_eff  = [-99.9072905   -4.48111738],\n",
      "\n",
      "iteration 126: f_best = 0.16766000\n",
      "x_eff  = [ 10.32242662 -36.58984404],\n",
      "\n",
      "iteration 127: f_best = 0.16766000\n",
      "x_eff  = [107.57105355 144.43062313],\n",
      "\n",
      "iteration 128: f_best = 0.16766000\n",
      "x_eff  = [-78.22979576  -7.50074693],\n",
      "\n",
      "iteration 129: f_best = 0.16766000\n",
      "x_eff  = [ 61.56623294 -52.86990801],\n",
      "\n",
      "iteration 130: f_best = 0.16766000\n",
      "x_eff  = [-6.95818195 63.93803459],\n",
      "\n",
      "iteration 131: f_best = 0.16766000\n",
      "x_eff  = [ 100.47725304 -101.39875718],\n",
      "\n",
      "iteration 132: f_best = 0.16766000\n",
      "x_eff  = [  87.94104203 -112.5536069 ],\n",
      "\n",
      "iteration 133: f_best = 0.16766000\n",
      "x_eff  = [ 14.14714683 -38.79061679],\n",
      "\n",
      "iteration 134: f_best = 0.16766000\n",
      "x_eff  = [ 93.64353041 100.54393005],\n",
      "\n",
      "iteration 135: f_best = 0.16766000\n",
      "x_eff  = [-105.90579171  -96.871217  ],\n",
      "\n",
      "iteration 136: f_best = 0.16766000\n",
      "x_eff  = [-90.07963378  13.6959174 ],\n",
      "\n",
      "iteration 137: f_best = 0.16766000\n",
      "x_eff  = [  85.97862868 -114.35627967],\n",
      "\n",
      "iteration 138: f_best = 0.16766000\n",
      "x_eff  = [-98.11173182  94.43388551],\n",
      "\n",
      "iteration 139: f_best = 0.16766000\n",
      "x_eff  = [41.35120956 19.77812854],\n",
      "\n",
      "iteration 140: f_best = 0.16766000\n",
      "x_eff  = [-133.4492728   131.23099105],\n",
      "\n",
      "iteration 141: f_best = 0.16766000\n",
      "x_eff  = [112.14469995  98.36687377],\n",
      "\n",
      "iteration 142: f_best = 0.16766000\n",
      "x_eff  = [106.62473214 -55.38755861],\n",
      "\n",
      "iteration 143: f_best = 0.16766000\n",
      "x_eff  = [-111.5344231   -99.73601909],\n",
      "\n",
      "iteration 144: f_best = 0.16766000\n",
      "x_eff  = [100.80199898  54.91363674],\n",
      "\n",
      "iteration 145: f_best = 0.16766000\n",
      "x_eff  = [-33.95900885 124.20009357],\n",
      "\n",
      "iteration 146: f_best = 0.16766000\n",
      "x_eff  = [-67.47298582  63.61272068],\n",
      "\n",
      "iteration 147: f_best = 0.16766000\n",
      "x_eff  = [-46.65553043  -4.37063708],\n",
      "\n",
      "iteration 148: f_best = 0.16766000\n",
      "x_eff  = [ 38.05133886 -34.29439861],\n",
      "\n",
      "iteration 149: f_best = 0.16766000\n",
      "x_eff  = [-86.93516213 -95.77472918],\n",
      "\n",
      "iteration 150: f_best = 0.16766000\n",
      "x_eff  = [31.84507174 26.70350958],\n",
      "\n",
      "iteration 151: f_best = 0.16766000\n",
      "x_eff  = [-113.29637513   52.47701479],\n",
      "\n",
      "iteration 152: f_best = 0.16766000\n",
      "x_eff  = [67.41501375 -1.54983097],\n",
      "\n",
      "iteration 153: f_best = 0.16766000\n",
      "x_eff  = [ 88.35144425 -16.25968351],\n",
      "\n",
      "iteration 154: f_best = 0.16766000\n",
      "x_eff  = [-70.33164082  28.70246193],\n",
      "\n",
      "iteration 155: f_best = 0.16766000\n",
      "x_eff  = [88.79493083 75.32650724],\n",
      "\n",
      "iteration 156: f_best = 0.16766000\n",
      "x_eff  = [ 84.73406165 -76.25163985],\n",
      "\n",
      "iteration 157: f_best = 0.16766000\n",
      "x_eff  = [-56.6489018   13.93944651],\n",
      "\n",
      "iteration 158: f_best = 0.16766000\n",
      "x_eff  = [85.09549775 60.93691304],\n",
      "\n",
      "iteration 159: f_best = 0.16766000\n",
      "x_eff  = [ 55.2290915  102.52943276],\n",
      "\n",
      "iteration 160: f_best = 0.16766000\n",
      "x_eff  = [22.70811395 21.03677391],\n",
      "\n",
      "iteration 161: f_best = 0.16766000\n",
      "x_eff  = [53.40561315 23.67348166],\n",
      "\n",
      "iteration 162: f_best = 0.16766000\n",
      "x_eff  = [-122.78149202  -46.67517099],\n",
      "\n",
      "iteration 163: f_best = 0.16766000\n",
      "x_eff  = [ -6.63013892 -30.87415447],\n",
      "\n",
      "iteration 164: f_best = 0.12577210\n",
      "x_eff  = [20.46596628 -3.27649377],\n",
      "\n",
      "iteration 165: f_best = 0.12577210\n",
      "x_eff  = [ 60.13607835 -48.60723789],\n",
      "\n",
      "iteration 166: f_best = 0.12577210\n",
      "x_eff  = [32.81250952 41.68158142],\n",
      "\n",
      "iteration 167: f_best = 0.12577210\n",
      "x_eff  = [ 3.65363569 60.54298425],\n",
      "\n",
      "iteration 168: f_best = 0.12577210\n",
      "x_eff  = [29.71750254 49.90286983],\n",
      "\n",
      "iteration 169: f_best = 0.12577210\n",
      "x_eff  = [59.66489169 83.46889341],\n",
      "\n",
      "iteration 170: f_best = 0.12577210\n",
      "x_eff  = [-25.53204687  94.68066547],\n",
      "\n",
      "iteration 171: f_best = 0.12577210\n",
      "x_eff  = [-44.389511    6.5055054],\n",
      "\n",
      "iteration 172: f_best = 0.12577210\n",
      "x_eff  = [44.78734117 60.95134668],\n",
      "\n",
      "iteration 173: f_best = 0.12577210\n",
      "x_eff  = [ 87.9836337  -13.34784257],\n",
      "\n",
      "iteration 174: f_best = 0.12577210\n",
      "x_eff  = [ 40.59617219 -61.32315407],\n",
      "\n",
      "iteration 175: f_best = 0.12577210\n",
      "x_eff  = [ 45.22801202 -60.50966232],\n",
      "\n",
      "iteration 176: f_best = 0.12577210\n",
      "x_eff  = [-55.74209023 -47.1245334 ],\n",
      "\n",
      "iteration 177: f_best = 0.12577210\n",
      "x_eff  = [93.91046224 -7.92234195],\n",
      "\n",
      "iteration 178: f_best = 0.12577210\n",
      "x_eff  = [-42.47787542 -46.39859238],\n",
      "\n",
      "iteration 179: f_best = 0.12577210\n",
      "x_eff  = [  7.8730071  -84.12067305],\n",
      "\n",
      "iteration 180: f_best = 0.12577210\n",
      "x_eff  = [-39.40056605 -41.84621392],\n",
      "\n",
      "iteration 181: f_best = 0.12577210\n",
      "x_eff  = [96.28754192 55.75379974],\n",
      "\n",
      "iteration 182: f_best = 0.12577210\n",
      "x_eff  = [-22.74633487   2.63889984],\n",
      "\n",
      "iteration 183: f_best = 0.12577210\n",
      "x_eff  = [-10.88907287 -55.11697928],\n",
      "\n",
      "iteration 184: f_best = 0.12577210\n",
      "x_eff  = [-33.71736289  61.94310487],\n",
      "\n",
      "iteration 185: f_best = 0.12577210\n",
      "x_eff  = [ 30.61742817 -92.56393913],\n",
      "\n",
      "iteration 186: f_best = 0.12577210\n",
      "x_eff  = [ 3.95768716 83.64727784],\n",
      "\n",
      "iteration 187: f_best = 0.12577210\n",
      "x_eff  = [106.08165994  58.09697257],\n",
      "\n",
      "iteration 188: f_best = 0.12577210\n",
      "x_eff  = [ 23.71337681 -79.44434589],\n",
      "\n",
      "iteration 189: f_best = 0.12577210\n",
      "x_eff  = [-50.57070488  55.64604358],\n",
      "\n",
      "iteration 190: f_best = 0.12577210\n",
      "x_eff  = [ 70.25871109 -87.49192878],\n",
      "\n",
      "iteration 191: f_best = 0.12577210\n",
      "x_eff  = [100.1003186  -51.59837148],\n",
      "\n",
      "iteration 192: f_best = 0.12577210\n",
      "x_eff  = [85.08935899 59.61468013],\n",
      "\n",
      "iteration 193: f_best = 0.12577210\n",
      "x_eff  = [88.9779088  46.40872603],\n",
      "\n",
      "iteration 194: f_best = 0.12577210\n",
      "x_eff  = [ 85.6041955  -85.03961222],\n",
      "\n",
      "iteration 195: f_best = 0.12577210\n",
      "x_eff  = [ -3.8248249  -83.03303087],\n",
      "\n",
      "iteration 196: f_best = 0.12577210\n",
      "x_eff  = [ 6.31914722 53.23642968],\n",
      "\n",
      "iteration 197: f_best = 0.12577210\n",
      "x_eff  = [-38.96508954 -43.59552431],\n",
      "\n",
      "iteration 198: f_best = 0.12577210\n",
      "x_eff  = [-27.02237878  -8.8364052 ],\n",
      "\n",
      "iteration 199: f_best = 0.12577210\n",
      "x_eff  = [ 21.13393713 -19.75218091],\n",
      "\n",
      "iteration 200: f_best = 0.12577210\n",
      "x_eff  = [83.28742283 58.48577546],\n",
      "\n",
      "iteration 201: f_best = 0.12577210\n",
      "x_eff  = [45.98496707 -0.46663109],\n",
      "\n",
      "iteration 202: f_best = 0.12577210\n",
      "x_eff  = [ 43.47591992 -46.55813821],\n",
      "\n",
      "iteration 203: f_best = 0.12577210\n",
      "x_eff  = [-26.29956582  20.69489675],\n",
      "\n",
      "iteration 204: f_best = 0.12577210\n",
      "x_eff  = [ -3.0734166  -53.63840391],\n",
      "\n",
      "iteration 205: f_best = 0.12577210\n",
      "x_eff  = [83.51659911 18.87692291],\n",
      "\n",
      "iteration 206: f_best = 0.12577210\n",
      "x_eff  = [-35.16113759  52.75689498],\n",
      "\n",
      "iteration 207: f_best = 0.10602305\n",
      "x_eff  = [ 13.870291   -12.33071812],\n",
      "\n",
      "iteration 208: f_best = 0.10602305\n",
      "x_eff  = [ 72.30392807 -29.74315569],\n",
      "\n",
      "iteration 209: f_best = 0.10602305\n",
      "x_eff  = [-31.44214417  28.93219926],\n",
      "\n",
      "iteration 210: f_best = 0.10602305\n",
      "x_eff  = [ 29.23231124 -64.28674478],\n",
      "\n",
      "iteration 211: f_best = 0.10602305\n",
      "x_eff  = [59.58239384 21.93199072],\n",
      "\n",
      "iteration 212: f_best = 0.10602305\n",
      "x_eff  = [ 79.89588432 -32.90238861],\n",
      "\n",
      "iteration 213: f_best = 0.10602305\n",
      "x_eff  = [77.73648573 24.92898652],\n",
      "\n",
      "iteration 214: f_best = 0.10602305\n",
      "x_eff  = [29.39895013 24.30670154],\n",
      "\n",
      "iteration 215: f_best = 0.10602305\n",
      "x_eff  = [ 75.65585292 -15.2823568 ],\n",
      "\n",
      "iteration 216: f_best = 0.10602305\n",
      "x_eff  = [-36.83828376 -72.68796054],\n",
      "\n",
      "iteration 217: f_best = 0.10602305\n",
      "x_eff  = [30.34395631  5.39077208],\n",
      "\n",
      "iteration 218: f_best = 0.10602305\n",
      "x_eff  = [32.71430082 31.94250811],\n",
      "\n",
      "iteration 219: f_best = 0.10602305\n",
      "x_eff  = [-47.87573513 -59.40852993],\n",
      "\n",
      "iteration 220: f_best = 0.10602305\n",
      "x_eff  = [62.72850728  9.28930261],\n",
      "\n",
      "iteration 221: f_best = 0.08874263\n",
      "x_eff  = [-5.92525257 14.18240842],\n",
      "\n",
      "iteration 222: f_best = 0.08874263\n",
      "x_eff  = [-0.59884691 34.40815031],\n",
      "\n",
      "iteration 223: f_best = 0.08874263\n",
      "x_eff  = [-53.90372238 -47.38619833],\n",
      "\n",
      "iteration 224: f_best = 0.08874263\n",
      "x_eff  = [-39.83125782   3.95803014],\n",
      "\n",
      "iteration 225: f_best = 0.08874263\n",
      "x_eff  = [-61.33606677  39.87226406],\n",
      "\n",
      "iteration 226: f_best = 0.08874263\n",
      "x_eff  = [ 6.06274521 47.47809258],\n",
      "\n",
      "iteration 227: f_best = 0.08874263\n",
      "x_eff  = [-66.9677071   23.38746583],\n",
      "\n",
      "iteration 228: f_best = 0.08874263\n",
      "x_eff  = [-40.49714051  -2.32610254],\n",
      "\n",
      "iteration 229: f_best = 0.08874263\n",
      "x_eff  = [46.04904378 22.26602461],\n",
      "\n",
      "iteration 230: f_best = 0.08874263\n",
      "x_eff  = [  4.93448217 -42.09265531],\n",
      "\n",
      "iteration 231: f_best = 0.08874263\n",
      "x_eff  = [32.05798934 50.3762376 ],\n",
      "\n",
      "iteration 232: f_best = 0.08874263\n",
      "x_eff  = [-19.21942699  -8.41620326],\n",
      "\n",
      "iteration 233: f_best = 0.08874263\n",
      "x_eff  = [16.51159603 26.57750034],\n",
      "\n",
      "iteration 234: f_best = 0.08874263\n",
      "x_eff  = [42.07746894 55.86234074],\n",
      "\n",
      "iteration 235: f_best = 0.08874263\n",
      "x_eff  = [ 1.25746826 60.09424719],\n",
      "\n",
      "iteration 236: f_best = 0.08874263\n",
      "x_eff  = [-4.66903675 59.2433393 ],\n",
      "\n",
      "iteration 237: f_best = 0.08874263\n",
      "x_eff  = [-42.99129828  43.12482675],\n",
      "\n",
      "iteration 238: f_best = 0.08874263\n",
      "x_eff  = [ 40.81693727 -35.81392542],\n",
      "\n",
      "iteration 239: f_best = 0.08874263\n",
      "x_eff  = [ 20.48806261 -34.64819985],\n",
      "\n",
      "iteration 240: f_best = 0.08874263\n",
      "x_eff  = [-42.75613547  63.75623634],\n",
      "\n",
      "iteration 241: f_best = 0.08874263\n",
      "x_eff  = [-46.459899    22.92302961],\n",
      "\n",
      "iteration 242: f_best = 0.08874263\n",
      "x_eff  = [45.36442254 66.52555188],\n",
      "\n",
      "iteration 243: f_best = 0.08874263\n",
      "x_eff  = [13.82074091 54.17467754],\n",
      "\n",
      "iteration 244: f_best = 0.08874263\n",
      "x_eff  = [-41.48960144 -21.46212149],\n",
      "\n",
      "iteration 245: f_best = 0.08874263\n",
      "x_eff  = [45.53891603 45.0437163 ],\n",
      "\n",
      "iteration 246: f_best = 0.08874263\n",
      "x_eff  = [-21.75439436 -20.75992122],\n",
      "\n",
      "iteration 247: f_best = 0.08874263\n",
      "x_eff  = [ 4.75199362 17.12195206],\n",
      "\n",
      "iteration 248: f_best = 0.08874263\n",
      "x_eff  = [30.47214311 27.92808413],\n",
      "\n",
      "iteration 249: f_best = 0.08874263\n",
      "x_eff  = [ 22.39904601 -11.06306098],\n",
      "\n",
      "iteration 250: f_best = 0.08874263\n",
      "x_eff  = [ 5.44320022 35.89128696],\n",
      "\n",
      "iteration 251: f_best = 0.08874263\n",
      "x_eff  = [-31.33197765 -21.60927513],\n",
      "\n",
      "iteration 252: f_best = 0.08874263\n",
      "x_eff  = [25.33193115 57.18042823],\n",
      "\n",
      "iteration 253: f_best = 0.08874263\n",
      "x_eff  = [-3.5646206  29.76056265],\n",
      "\n",
      "iteration 254: f_best = 0.08874263\n",
      "x_eff  = [30.64198299 61.03767076],\n",
      "\n",
      "iteration 255: f_best = 0.08874263\n",
      "x_eff  = [ 15.44927629 -30.39624752],\n",
      "\n",
      "iteration 256: f_best = 0.08874263\n",
      "x_eff  = [-23.25153572  -3.03625682],\n",
      "\n",
      "iteration 257: f_best = 0.08874263\n",
      "x_eff  = [-23.71494345  33.37326501],\n",
      "\n",
      "iteration 258: f_best = 0.08874263\n",
      "x_eff  = [-11.36229298  54.65318228],\n",
      "\n",
      "iteration 259: f_best = 0.08874263\n",
      "x_eff  = [ -1.70311968 -22.45287463],\n",
      "\n",
      "iteration 260: f_best = 0.08874263\n",
      "x_eff  = [-42.0684946   42.40435668],\n",
      "\n",
      "iteration 261: f_best = 0.08874263\n",
      "x_eff  = [-36.6047865   45.15761055],\n",
      "\n",
      "iteration 262: f_best = 0.08874263\n",
      "x_eff  = [-25.64688804  34.75417386],\n",
      "\n",
      "iteration 263: f_best = 0.08874263\n",
      "x_eff  = [ 7.17366354 31.81651557],\n",
      "\n",
      "iteration 264: f_best = 0.08874263\n",
      "x_eff  = [12.09464201 52.08212211],\n",
      "\n",
      "iteration 265: f_best = 0.00986467\n",
      "x_eff  = [ 5.51557359 -1.17447033],\n",
      "\n",
      "iteration 266: f_best = 0.00986467\n",
      "x_eff  = [-18.68178063  41.42935426],\n",
      "\n",
      "iteration 267: f_best = 0.00986467\n",
      "x_eff  = [-28.86164191 -37.21570064],\n",
      "\n",
      "iteration 268: f_best = 0.00986467\n",
      "x_eff  = [19.44252246 -8.75755719],\n",
      "\n",
      "iteration 269: f_best = 0.00986467\n",
      "x_eff  = [20.7872952   8.43562899],\n",
      "\n",
      "iteration 270: f_best = 0.00986467\n",
      "x_eff  = [ -0.27462208 -26.25685882],\n",
      "\n",
      "iteration 271: f_best = 0.00986467\n",
      "x_eff  = [  2.58124929 -18.70649282],\n",
      "\n",
      "iteration 272: f_best = 0.00986467\n",
      "x_eff  = [45.07228097 35.56608653],\n",
      "\n",
      "iteration 273: f_best = 0.00986467\n",
      "x_eff  = [  1.0673714  -26.53403074],\n",
      "\n",
      "iteration 274: f_best = 0.00986467\n",
      "x_eff  = [ 14.28924554 -13.87173541],\n",
      "\n",
      "iteration 275: f_best = 0.00986467\n",
      "x_eff  = [-5.11511542 20.50335882],\n",
      "\n",
      "iteration 276: f_best = 0.00986467\n",
      "x_eff  = [-5.44598311 27.76060256],\n",
      "\n",
      "iteration 277: f_best = 0.00986467\n",
      "x_eff  = [ 9.330653   -3.07897916],\n",
      "\n",
      "iteration 278: f_best = 0.00986467\n",
      "x_eff  = [33.89404708  5.80451724],\n",
      "\n",
      "iteration 279: f_best = 0.00986467\n",
      "x_eff  = [-8.00360999  8.78249399],\n",
      "\n",
      "iteration 280: f_best = 0.00986467\n",
      "x_eff  = [-11.41406976  33.67044871],\n",
      "\n",
      "iteration 281: f_best = 0.00986467\n",
      "x_eff  = [-10.02678993  -5.27885353],\n",
      "\n",
      "iteration 282: f_best = 0.00986467\n",
      "x_eff  = [-27.87519581  25.2288057 ],\n",
      "\n",
      "iteration 283: f_best = 0.00986467\n",
      "x_eff  = [-20.48567129 -23.5106255 ],\n",
      "\n",
      "iteration 284: f_best = 0.00986467\n",
      "x_eff  = [ 34.67822125 -35.04929357],\n",
      "\n",
      "iteration 285: f_best = 0.00986467\n",
      "x_eff  = [ 18.64768777 -12.04496103],\n",
      "\n",
      "iteration 286: f_best = 0.00986467\n",
      "x_eff  = [-11.06767677 -17.2781502 ],\n",
      "\n",
      "iteration 287: f_best = 0.00986467\n",
      "x_eff  = [-23.81989301 -21.09901812],\n",
      "\n",
      "iteration 288: f_best = 0.00986467\n",
      "x_eff  = [-6.60696991 34.79702199],\n",
      "\n",
      "iteration 289: f_best = 0.00986467\n",
      "x_eff  = [-21.11071527  15.14319524],\n",
      "\n",
      "iteration 290: f_best = 0.00986467\n",
      "x_eff  = [ 16.35936854 -30.23459367],\n",
      "\n",
      "iteration 291: f_best = 0.00986467\n",
      "x_eff  = [12.10852786 -2.45913974],\n",
      "\n",
      "iteration 292: f_best = 0.00986467\n",
      "x_eff  = [-26.08708508 -15.71560938],\n",
      "\n",
      "iteration 293: f_best = 0.00986467\n",
      "x_eff  = [  6.04489898 -27.20175198],\n",
      "\n",
      "iteration 294: f_best = 0.00986467\n",
      "x_eff  = [-8.81997668  3.25652502],\n",
      "\n",
      "iteration 295: f_best = 0.00986467\n",
      "x_eff  = [15.85489408 11.2699663 ],\n",
      "\n",
      "iteration 296: f_best = 0.00986467\n",
      "x_eff  = [-8.96321215 21.45618336],\n",
      "\n",
      "iteration 297: f_best = 0.00986467\n",
      "x_eff  = [-5.66535955 27.75993373],\n",
      "\n",
      "iteration 298: f_best = 0.00986467\n",
      "x_eff  = [ 5.30239546 30.41574864],\n",
      "\n",
      "iteration 299: f_best = 0.00986467\n",
      "x_eff  = [ 3.8996238  10.63298773],\n",
      "\n",
      "iteration 300: f_best = 0.00739604\n",
      "x_eff  = [-4.12024863  6.97327413],\n",
      "\n",
      "iteration 301: f_best = 0.00739604\n",
      "x_eff  = [-23.08368435 -16.7676019 ],\n",
      "\n",
      "iteration 302: f_best = 0.00739604\n",
      "x_eff  = [27.58974668 18.65052848],\n",
      "\n",
      "iteration 303: f_best = 0.00739604\n",
      "x_eff  = [-29.90423254  -0.32419905],\n",
      "\n",
      "iteration 304: f_best = 0.00739604\n",
      "x_eff  = [-16.78823081 -22.89395686],\n",
      "\n",
      "iteration 305: f_best = 0.00739604\n",
      "x_eff  = [12.27807873 -1.33669899],\n",
      "\n",
      "iteration 306: f_best = 0.00739604\n",
      "x_eff  = [19.20752245 20.07893041],\n",
      "\n",
      "iteration 307: f_best = 0.00739604\n",
      "x_eff  = [-22.28449794   9.86402168],\n",
      "\n",
      "iteration 308: f_best = 0.00739604\n",
      "x_eff  = [-21.55017723  -5.50120089],\n",
      "\n",
      "iteration 309: f_best = 0.00739604\n",
      "x_eff  = [-23.2394847  -10.01844111],\n",
      "\n",
      "iteration 310: f_best = 0.00739604\n",
      "x_eff  = [15.9541395  17.04509727],\n",
      "\n",
      "iteration 311: f_best = 0.00739604\n",
      "x_eff  = [-1.61463585 14.2820955 ],\n",
      "\n",
      "iteration 312: f_best = 0.00739604\n",
      "x_eff  = [-18.73070701  11.11309653],\n",
      "\n",
      "iteration 313: f_best = 0.00739604\n",
      "x_eff  = [12.63825567 -9.43658135],\n",
      "\n",
      "iteration 314: f_best = 0.00739604\n",
      "x_eff  = [-21.06334799 -16.53450738],\n",
      "\n",
      "iteration 315: f_best = 0.00739604\n",
      "x_eff  = [-3.55486318  4.73989394],\n",
      "\n",
      "iteration 316: f_best = 0.00739604\n",
      "x_eff  = [-29.438729     8.22455354],\n",
      "\n",
      "iteration 317: f_best = 0.00739604\n",
      "x_eff  = [ -4.0982301  -20.35791347],\n",
      "\n",
      "iteration 318: f_best = 0.00739604\n",
      "x_eff  = [6.3602112  6.67253695],\n",
      "\n",
      "iteration 319: f_best = 0.00739604\n",
      "x_eff  = [-25.60252613  -8.6001889 ],\n",
      "\n",
      "iteration 320: f_best = 0.00739604\n",
      "x_eff  = [ 18.79427547 -10.12484822],\n",
      "\n",
      "iteration 321: f_best = 0.00739604\n",
      "x_eff  = [-14.24285561   9.19375508],\n",
      "\n",
      "iteration 322: f_best = 0.00739604\n",
      "x_eff  = [-25.53994988  27.13094524],\n",
      "\n",
      "iteration 323: f_best = 0.00739604\n",
      "x_eff  = [-6.1882255   6.76287484],\n",
      "\n",
      "iteration 324: f_best = 0.00739604\n",
      "x_eff  = [14.78686948 15.23816646],\n",
      "\n",
      "iteration 325: f_best = 0.00739604\n",
      "x_eff  = [-27.26675363 -12.79589579],\n",
      "\n",
      "iteration 326: f_best = 0.00739604\n",
      "x_eff  = [-5.9071175  -5.66099658],\n",
      "\n",
      "iteration 327: f_best = 0.00739604\n",
      "x_eff  = [-21.69930692   1.98896556],\n",
      "\n",
      "iteration 328: f_best = 0.00739604\n",
      "x_eff  = [17.00163324  3.25489331],\n",
      "\n",
      "iteration 329: f_best = 0.00739604\n",
      "x_eff  = [ 19.32248345 -13.72936137],\n",
      "\n",
      "iteration 330: f_best = 0.00739604\n",
      "x_eff  = [-26.06207994  -3.81229495],\n",
      "\n",
      "iteration 331: f_best = 0.00739604\n",
      "x_eff  = [-16.6455234   2.5096798],\n",
      "\n",
      "iteration 332: f_best = 0.00739604\n",
      "x_eff  = [ -3.17858069 -13.15696791],\n",
      "\n",
      "iteration 333: f_best = 0.00739604\n",
      "x_eff  = [ -7.78124346 -11.89655675],\n",
      "\n",
      "iteration 334: f_best = 0.00739604\n",
      "x_eff  = [-24.52860598  17.02276373],\n",
      "\n",
      "iteration 335: f_best = 0.00739604\n",
      "x_eff  = [-3.87009033 12.7909315 ],\n",
      "\n",
      "iteration 336: f_best = 0.00739604\n",
      "x_eff  = [11.12602524 14.61301866],\n",
      "\n",
      "iteration 337: f_best = 0.00739604\n",
      "x_eff  = [ 0.45584901 18.63925203],\n",
      "\n",
      "iteration 338: f_best = 0.00739604\n",
      "x_eff  = [-22.67585656  -1.73254244],\n",
      "\n",
      "iteration 339: f_best = 0.00739604\n",
      "x_eff  = [-7.926545    8.26468825],\n",
      "\n",
      "iteration 340: f_best = 0.00739604\n",
      "x_eff  = [10.15207632 -7.82203335],\n",
      "\n",
      "iteration 341: f_best = 0.00739604\n",
      "x_eff  = [ 13.53401251 -12.53224991],\n",
      "\n",
      "iteration 342: f_best = 0.00739604\n",
      "x_eff  = [0.01209201 4.47142661],\n",
      "\n",
      "iteration 343: f_best = 0.00739604\n",
      "x_eff  = [ -9.82922006 -14.48239595],\n",
      "\n",
      "iteration 344: f_best = 0.00739604\n",
      "x_eff  = [10.24835988 22.29619415],\n",
      "\n",
      "iteration 345: f_best = 0.00739604\n",
      "x_eff  = [3.97435549 6.98635665],\n",
      "\n",
      "iteration 346: f_best = 0.00739604\n",
      "x_eff  = [ -3.25426385 -10.77085597],\n",
      "\n",
      "iteration 347: f_best = 0.00739604\n",
      "x_eff  = [19.6469382  24.16883861],\n",
      "\n",
      "iteration 348: f_best = 0.00739604\n",
      "x_eff  = [ 6.80617637 19.55917042],\n",
      "\n",
      "iteration 349: f_best = 0.00739604\n",
      "x_eff  = [-10.17793943 -11.69512871],\n",
      "\n",
      "iteration 350: f_best = 0.00739604\n",
      "x_eff  = [-13.61701075   0.11081302],\n",
      "\n",
      "iteration 351: f_best = 0.00739604\n",
      "x_eff  = [19.26498558  6.22398383],\n",
      "\n",
      "iteration 352: f_best = 0.00739604\n",
      "x_eff  = [15.897721   18.38782458],\n",
      "\n",
      "iteration 353: f_best = 0.00739604\n",
      "x_eff  = [ 20.84194337 -10.21883829],\n",
      "\n",
      "iteration 354: f_best = 0.00739604\n",
      "x_eff  = [-11.02358702  -8.11460808],\n",
      "\n",
      "iteration 355: f_best = 0.00739604\n",
      "x_eff  = [  4.08442312 -12.66962248],\n",
      "\n",
      "iteration 356: f_best = 0.00739604\n",
      "x_eff  = [ 2.08491377 -5.55714554],\n",
      "\n",
      "iteration 357: f_best = 0.00739604\n",
      "x_eff  = [ 2.32837288 16.40379567],\n",
      "\n",
      "iteration 358: f_best = 0.00739604\n",
      "x_eff  = [ 13.4724411  -13.58029508],\n",
      "\n",
      "iteration 359: f_best = 0.00739604\n",
      "x_eff  = [16.86274081 17.07221487],\n",
      "\n",
      "iteration 360: f_best = 0.00739604\n",
      "x_eff  = [-8.41477643  1.92337317],\n",
      "\n",
      "iteration 361: f_best = 0.00739604\n",
      "x_eff  = [13.50381143 19.82489719],\n",
      "\n",
      "iteration 362: f_best = 0.00739604\n",
      "x_eff  = [ 4.57859129 -3.3833056 ],\n",
      "\n",
      "iteration 363: f_best = 0.00739604\n",
      "x_eff  = [ 7.45480974 12.12887358],\n",
      "\n",
      "iteration 364: f_best = 0.00739604\n",
      "x_eff  = [10.66856755 13.13406205],\n",
      "\n",
      "iteration 365: f_best = 0.00739604\n",
      "x_eff  = [-5.58075993 17.63702173],\n",
      "\n",
      "iteration 366: f_best = 0.00739604\n",
      "x_eff  = [-6.7101379   8.78541587],\n",
      "\n",
      "iteration 367: f_best = 0.00739604\n",
      "x_eff  = [-3.35860372 -0.63058868],\n",
      "\n",
      "iteration 368: f_best = 0.00739604\n",
      "x_eff  = [ 6.33531392 10.76262541],\n",
      "\n",
      "iteration 369: f_best = 0.00739604\n",
      "x_eff  = [ 2.55659512 17.53989685],\n",
      "\n",
      "iteration 370: f_best = 0.00739604\n",
      "x_eff  = [13.91089577 15.638741  ],\n",
      "\n",
      "iteration 371: f_best = 0.00739604\n",
      "x_eff  = [-5.49917005  7.68229478],\n",
      "\n",
      "iteration 372: f_best = 0.00739604\n",
      "x_eff  = [ 10.813845   -10.33511777],\n",
      "\n",
      "iteration 373: f_best = 0.00739604\n",
      "x_eff  = [-9.55095938 13.26566359],\n",
      "\n",
      "iteration 374: f_best = 0.00739604\n",
      "x_eff  = [14.05122362  8.84924947],\n",
      "\n",
      "iteration 375: f_best = 0.00739604\n",
      "x_eff  = [8.61812805 8.31987004],\n",
      "\n",
      "iteration 376: f_best = 0.00739604\n",
      "x_eff  = [12.82806327 -0.6490535 ],\n",
      "\n",
      "iteration 377: f_best = 0.00739604\n",
      "x_eff  = [ 1.19155589 11.52576121],\n",
      "\n",
      "iteration 378: f_best = 0.00739604\n",
      "x_eff  = [ 4.03347314 11.67975199],\n",
      "\n",
      "iteration 379: f_best = 0.00739604\n",
      "x_eff  = [3.63881559 5.77835486],\n",
      "\n",
      "iteration 380: f_best = 0.00739604\n",
      "x_eff  = [-2.37499208 -7.41052405],\n",
      "\n",
      "iteration 381: f_best = 0.00739604\n",
      "x_eff  = [10.11703529 -3.29842473],\n",
      "\n",
      "iteration 382: f_best = 0.00739604\n",
      "x_eff  = [10.39888592  5.05285869],\n",
      "\n",
      "iteration 383: f_best = 0.00739604\n",
      "x_eff  = [12.1201694   5.45250128],\n",
      "\n",
      "iteration 384: f_best = 0.00739604\n",
      "x_eff  = [ 0.18846514 14.6110439 ],\n",
      "\n",
      "iteration 385: f_best = 0.00739604\n",
      "x_eff  = [-1.91865447 10.56497791],\n",
      "\n",
      "iteration 386: f_best = 0.00739604\n",
      "x_eff  = [ 0.76322191 -7.89676244],\n",
      "\n",
      "iteration 387: f_best = 0.00739604\n",
      "x_eff  = [ 3.1159788  17.36948871],\n",
      "\n",
      "iteration 388: f_best = 0.00739604\n",
      "x_eff  = [9.66465976 5.19426938],\n",
      "\n",
      "iteration 389: f_best = 0.00739604\n",
      "x_eff  = [-4.7884192 10.9179173],\n",
      "\n",
      "iteration 390: f_best = 0.00739604\n",
      "x_eff  = [-1.46271774 -3.06759978],\n",
      "\n",
      "iteration 391: f_best = 0.00739604\n",
      "x_eff  = [3.85291284 4.24962734],\n",
      "\n",
      "iteration 392: f_best = 0.00739604\n",
      "x_eff  = [10.5052276 -2.0075607],\n",
      "\n",
      "iteration 393: f_best = 0.00739604\n",
      "x_eff  = [-3.50293442  0.03840144],\n",
      "\n",
      "iteration 394: f_best = 0.00739604\n",
      "x_eff  = [13.69221341 -2.24673162],\n",
      "\n",
      "iteration 395: f_best = 0.00000000\n",
      "x_eff  = [-0.42557077 -0.508734  ],\n",
      "\n",
      "iteration 396: f_best = 0.00000000\n",
      "x_eff  = [-4.94908209 -3.13673869],\n",
      "\n",
      "iteration 397: f_best = 0.00000000\n",
      "x_eff  = [-9.37720984 -5.97478085],\n",
      "\n",
      "iteration 398: f_best = 0.00000000\n",
      "x_eff  = [-7.78054058 -0.92092592],\n",
      "\n",
      "iteration 399: f_best = 0.00000000\n",
      "x_eff  = [-9.73914464  9.06751265],\n",
      "\n",
      "iteration 400: f_best = 0.00000000\n",
      "x_eff  = [10.67785678  1.04180921],\n",
      "\n",
      "iteration 401: f_best = 0.00000000\n",
      "x_eff  = [-8.69727504 10.53034207],\n",
      "\n",
      "iteration 402: f_best = 0.00000000\n",
      "x_eff  = [5.77924829 5.9058829 ],\n",
      "\n",
      "iteration 403: f_best = 0.00000000\n",
      "x_eff  = [ 4.50807518 -8.69559234],\n",
      "\n",
      "iteration 404: f_best = 0.00000000\n",
      "x_eff  = [6.63163362 9.00702135],\n",
      "\n",
      "iteration 405: f_best = 0.00000000\n",
      "x_eff  = [-0.17334987 -7.97832246],\n",
      "\n",
      "iteration 406: f_best = 0.00000000\n",
      "x_eff  = [-9.42571421 -0.40677749],\n",
      "\n",
      "iteration 407: f_best = 0.00000000\n",
      "x_eff  = [6.43868343 4.95747622],\n",
      "\n",
      "iteration 408: f_best = 0.00000000\n",
      "x_eff  = [-1.06915764 -9.23096924],\n",
      "\n",
      "iteration 409: f_best = 0.00000000\n",
      "x_eff  = [  0.56323829 -10.08022639],\n",
      "\n",
      "iteration 410: f_best = 0.00000000\n",
      "x_eff  = [-2.6774505   0.61217674],\n",
      "\n",
      "iteration 411: f_best = 0.00000000\n",
      "x_eff  = [-10.35493466   5.24503824],\n",
      "\n",
      "iteration 412: f_best = 0.00000000\n",
      "x_eff  = [-2.70354734  1.15781121],\n",
      "\n",
      "iteration 413: f_best = 0.00000000\n",
      "x_eff  = [-5.88072103 -8.57437782],\n",
      "\n",
      "iteration 414: f_best = 0.00000000\n",
      "x_eff  = [ 1.79283273 -4.9578831 ],\n",
      "\n",
      "iteration 415: f_best = 0.00000000\n",
      "x_eff  = [-1.33449551 -5.22576054],\n",
      "\n",
      "iteration 416: f_best = 0.00000000\n",
      "x_eff  = [-8.89870107  8.68222678],\n",
      "\n",
      "iteration 417: f_best = 0.00000000\n",
      "x_eff  = [-9.19020605  0.42482017],\n",
      "\n",
      "iteration 418: f_best = 0.00000000\n",
      "x_eff  = [-3.14870743 -1.7641637 ],\n",
      "\n",
      "iteration 419: f_best = 0.00000000\n",
      "x_eff  = [-4.26204415  1.74689001],\n",
      "\n",
      "iteration 420: f_best = 0.00000000\n",
      "x_eff  = [ 0.70511398 -6.3156456 ],\n",
      "\n",
      "iteration 421: f_best = 0.00000000\n",
      "x_eff  = [ 7.96400902 -7.48921666],\n",
      "\n",
      "iteration 422: f_best = 0.00000000\n",
      "x_eff  = [5.5995713  1.45772791],\n",
      "\n",
      "iteration 423: f_best = 0.00000000\n",
      "x_eff  = [5.25573018 7.53890546],\n",
      "\n",
      "iteration 424: f_best = 0.00000000\n",
      "x_eff  = [ 2.25494345 -8.23219786],\n",
      "\n",
      "iteration 425: f_best = 0.00000000\n",
      "x_eff  = [-4.52000695  0.45134324],\n",
      "\n",
      "iteration 426: f_best = 0.00000000\n",
      "x_eff  = [-1.18305607  8.1521043 ],\n",
      "\n",
      "iteration 427: f_best = 0.00000000\n",
      "x_eff  = [-7.02969928 -5.05748543],\n",
      "\n",
      "iteration 428: f_best = 0.00000000\n",
      "x_eff  = [-7.24671054  7.08751974],\n",
      "\n",
      "iteration 429: f_best = 0.00000000\n",
      "x_eff  = [ 0.36808451 -6.64818707],\n",
      "\n",
      "iteration 430: f_best = 0.00000000\n",
      "x_eff  = [ 7.23040473 -0.0801296 ],\n",
      "\n",
      "iteration 431: f_best = 0.00000000\n",
      "x_eff  = [-1.0269745  -8.46288985],\n",
      "\n",
      "iteration 432: f_best = 0.00000000\n",
      "x_eff  = [ 7.96101995 -2.14303463],\n",
      "\n",
      "iteration 433: f_best = 0.00000000\n",
      "x_eff  = [1.4229267  6.54182024],\n",
      "\n",
      "iteration 434: f_best = 0.00000000\n",
      "x_eff  = [-1.50231581  3.42559013],\n",
      "\n",
      "iteration 435: f_best = 0.00000000\n",
      "x_eff  = [2.82408326 0.00462954],\n",
      "\n",
      "iteration 436: f_best = 0.00000000\n",
      "x_eff  = [-7.18313416  1.17581026],\n",
      "\n",
      "iteration 437: f_best = 0.00000000\n",
      "x_eff  = [-7.62258329 -0.49097456],\n",
      "\n",
      "iteration 438: f_best = 0.00000000\n",
      "x_eff  = [-3.44096014  6.29996711],\n",
      "\n",
      "iteration 439: f_best = 0.00000000\n",
      "x_eff  = [0.45323137 7.17362908],\n",
      "\n",
      "iteration 440: f_best = 0.00000000\n",
      "x_eff  = [-4.44796775  4.31514975],\n",
      "\n",
      "iteration 441: f_best = 0.00000000\n",
      "x_eff  = [ 4.89383656 -5.92511857],\n",
      "\n",
      "iteration 442: f_best = 0.00000000\n",
      "x_eff  = [ 0.76216729 -6.69513039],\n",
      "\n",
      "iteration 443: f_best = 0.00000000\n",
      "x_eff  = [ 1.78250577 -5.87595101],\n",
      "\n",
      "iteration 444: f_best = 0.00000000\n",
      "x_eff  = [-5.8665415   7.38169319],\n",
      "\n",
      "iteration 445: f_best = 0.00000000\n",
      "x_eff  = [ 0.69717453 -5.25915141],\n",
      "\n",
      "iteration 446: f_best = 0.00000000\n",
      "x_eff  = [-0.11457837  6.59728654],\n",
      "\n",
      "iteration 447: f_best = 0.00000000\n",
      "x_eff  = [ 6.16708608 -1.05121225],\n",
      "\n",
      "iteration 448: f_best = 0.00000000\n",
      "x_eff  = [-2.54379283 -4.67114546],\n",
      "\n",
      "iteration 449: f_best = 0.00000000\n",
      "x_eff  = [4.61569216 2.19986535],\n",
      "\n",
      "iteration 450: f_best = 0.00000000\n",
      "x_eff  = [-1.50140795 -6.05478996],\n",
      "\n",
      "iteration 451: f_best = 0.00000000\n",
      "x_eff  = [-5.66036983 -1.11004436],\n",
      "\n",
      "iteration 452: f_best = 0.00000000\n",
      "x_eff  = [2.04256051 4.52687269],\n",
      "\n",
      "iteration 453: f_best = 0.00000000\n",
      "x_eff  = [0.66611875 6.70322668],\n",
      "\n",
      "iteration 454: f_best = 0.00000000\n",
      "x_eff  = [-2.49642611 -2.30725918],\n",
      "\n",
      "iteration 455: f_best = 0.00000000\n",
      "x_eff  = [ 4.8644879  -4.94377772],\n",
      "\n",
      "iteration 456: f_best = 0.00000000\n",
      "x_eff  = [-4.12879098  3.73382163],\n",
      "\n",
      "iteration 457: f_best = 0.00000000\n",
      "x_eff  = [ 1.97718299 -6.55025432],\n",
      "\n",
      "iteration 458: f_best = 0.00000000\n",
      "x_eff  = [-3.18112706  1.99151313],\n",
      "\n",
      "iteration 459: f_best = 0.00000000\n",
      "x_eff  = [ 5.40392315 -6.12034537],\n",
      "\n",
      "iteration 460: f_best = 0.00000000\n",
      "x_eff  = [5.3928947  1.79936589],\n",
      "\n",
      "iteration 461: f_best = 0.00000000\n",
      "x_eff  = [-3.3642288  -4.82510842],\n",
      "\n",
      "iteration 462: f_best = 0.00000000\n",
      "x_eff  = [-3.30247379 -2.28642282],\n",
      "\n",
      "iteration 463: f_best = 0.00000000\n",
      "x_eff  = [-4.69339024 -3.31085059],\n",
      "\n",
      "iteration 464: f_best = 0.00000000\n",
      "x_eff  = [0.44255598 0.88876333],\n",
      "\n",
      "iteration 465: f_best = 0.00000000\n",
      "x_eff  = [ 0.24036158 -1.91536052],\n",
      "\n",
      "iteration 466: f_best = 0.00000000\n",
      "x_eff  = [ 1.00045719 -1.49786833],\n",
      "\n",
      "iteration 467: f_best = 0.00000000\n",
      "x_eff  = [-2.74637507 -4.87277777],\n",
      "\n",
      "iteration 468: f_best = 0.00000000\n",
      "x_eff  = [2.21934456 3.21497203],\n",
      "\n",
      "iteration 469: f_best = 0.00000000\n",
      "x_eff  = [-0.64783173 -1.24664689],\n",
      "\n",
      "iteration 470: f_best = 0.00000000\n",
      "x_eff  = [-1.89205744 -2.44201828],\n",
      "\n",
      "iteration 471: f_best = 0.00000000\n",
      "x_eff  = [-3.46579005  5.43999504],\n",
      "\n",
      "iteration 472: f_best = 0.00000000\n",
      "x_eff  = [1.29325115 4.91673804],\n",
      "\n",
      "iteration 473: f_best = 0.00000000\n",
      "x_eff  = [4.34321194 1.04785431],\n",
      "\n",
      "iteration 474: f_best = 0.00000000\n",
      "x_eff  = [ 2.40141562 -4.95764087],\n",
      "\n",
      "iteration 475: f_best = 0.00000000\n",
      "x_eff  = [ 1.14806716 -2.3582395 ],\n",
      "\n",
      "iteration 476: f_best = 0.00000000\n",
      "x_eff  = [2.28502249 4.75880408],\n",
      "\n",
      "iteration 477: f_best = 0.00000000\n",
      "x_eff  = [ 2.60509891 -0.7451192 ],\n",
      "\n",
      "iteration 478: f_best = 0.00000000\n",
      "x_eff  = [-2.69195277  2.88746678],\n",
      "\n",
      "iteration 479: f_best = 0.00000000\n",
      "x_eff  = [-2.25136004 -4.06371962],\n",
      "\n",
      "iteration 480: f_best = 0.00000000\n",
      "x_eff  = [-2.41369032  4.02236954],\n",
      "\n",
      "iteration 481: f_best = 0.00000000\n",
      "x_eff  = [ 0.07799535 -0.42978667],\n",
      "\n",
      "iteration 482: f_best = 0.00000000\n",
      "x_eff  = [0.25467921 0.66368957],\n",
      "\n",
      "iteration 483: f_best = 0.00000000\n",
      "x_eff  = [ 3.57669171 -2.139869  ],\n",
      "\n",
      "iteration 484: f_best = 0.00000000\n",
      "x_eff  = [ 1.13938268 -0.94025373],\n",
      "\n",
      "iteration 485: f_best = 0.00000000\n",
      "x_eff  = [ 1.00127362 -3.99975372],\n",
      "\n",
      "iteration 486: f_best = 0.00000000\n",
      "x_eff  = [-3.45191503 -2.94907103],\n",
      "\n",
      "iteration 487: f_best = 0.00000000\n",
      "x_eff  = [-4.08381528  4.93932122],\n",
      "\n",
      "iteration 488: f_best = 0.00000000\n",
      "x_eff  = [-2.64346515  2.60695654],\n",
      "\n",
      "iteration 489: f_best = 0.00000000\n",
      "x_eff  = [-4.60174845  4.67752286],\n",
      "\n",
      "iteration 490: f_best = 0.00000000\n",
      "x_eff  = [ 0.23064505 -2.93272049],\n",
      "\n",
      "iteration 491: f_best = 0.00000000\n",
      "x_eff  = [-4.70758891  4.66430247],\n",
      "\n",
      "iteration 492: f_best = 0.00000000\n",
      "x_eff  = [2.71405992 4.43390502],\n",
      "\n",
      "iteration 493: f_best = 0.00000000\n",
      "x_eff  = [-4.42210709  3.57355807],\n",
      "\n",
      "iteration 494: f_best = 0.00000000\n",
      "x_eff  = [-2.26266498  4.38610231],\n",
      "\n",
      "iteration 495: f_best = 0.00000000\n",
      "x_eff  = [-3.80053353  3.01367644],\n",
      "\n",
      "iteration 496: f_best = 0.00000000\n",
      "x_eff  = [-3.72071455  0.96720069],\n",
      "\n",
      "iteration 497: f_best = 0.00000000\n",
      "x_eff  = [3.53247704 3.06529872],\n",
      "\n",
      "iteration 498: f_best = 0.00000000\n",
      "x_eff  = [-2.46383944 -1.88255241],\n",
      "\n",
      "iteration 499: f_best = 0.00000000\n",
      "x_eff  = [-2.92642669 -2.06075099],\n",
      "\n",
      "iteration 500: f_best = 0.00000000\n",
      "x_eff  = [0.67858339 1.84285994],\n",
      "\n",
      "iteration 501: f_best = 0.00000000\n",
      "x_eff  = [3.90002042 3.15746933],\n",
      "\n",
      "iteration 502: f_best = 0.00000000\n",
      "x_eff  = [-2.96729802 -0.94075204],\n",
      "\n",
      "iteration 503: f_best = 0.00000000\n",
      "x_eff  = [0.05545278 3.17454226],\n",
      "\n",
      "iteration 504: f_best = 0.00000000\n",
      "x_eff  = [ 3.91986058 -2.79310671],\n",
      "\n",
      "iteration 505: f_best = 0.00000000\n",
      "x_eff  = [0.02159799 0.6311066 ],\n",
      "\n",
      "iteration 506: f_best = 0.00000000\n",
      "x_eff  = [3.76506421 3.8692913 ],\n",
      "\n",
      "iteration 507: f_best = 0.00000000\n",
      "x_eff  = [ 3.68906556 -1.05165806],\n",
      "\n",
      "iteration 508: f_best = 0.00000000\n",
      "x_eff  = [1.64716902 1.19338198],\n",
      "\n",
      "iteration 509: f_best = 0.00000000\n",
      "x_eff  = [-1.93715657  1.73366524],\n",
      "\n",
      "iteration 510: f_best = 0.00000000\n",
      "x_eff  = [-0.6924533  -3.03716912],\n",
      "\n",
      "iteration 511: f_best = 0.00000000\n",
      "x_eff  = [0.50914632 1.75658262],\n",
      "\n",
      "iteration 512: f_best = 0.00000000\n",
      "x_eff  = [-0.65675283  3.59949095],\n",
      "\n",
      "iteration 513: f_best = 0.00000000\n",
      "x_eff  = [-1.46618495  3.21620582],\n",
      "\n",
      "iteration 514: f_best = 0.00000000\n",
      "x_eff  = [ 1.26048672 -2.36369664],\n",
      "\n",
      "iteration 515: f_best = 0.00000000\n",
      "x_eff  = [-3.68913366 -1.4141549 ],\n",
      "\n",
      "iteration 516: f_best = 0.00000000\n",
      "x_eff  = [-1.31617512 -0.15375869],\n",
      "\n",
      "iteration 517: f_best = 0.00000000\n",
      "x_eff  = [-0.34547517 -3.18522221],\n",
      "\n",
      "iteration 518: f_best = 0.00000000\n",
      "x_eff  = [2.90871734 1.11644206],\n",
      "\n",
      "iteration 519: f_best = 0.00000000\n",
      "x_eff  = [ 3.18463414 -0.01731004],\n",
      "\n",
      "iteration 520: f_best = 0.00000000\n",
      "x_eff  = [-2.34947757  1.51399804],\n",
      "\n",
      "iteration 521: f_best = 0.00000000\n",
      "x_eff  = [1.01372155 0.85172542],\n",
      "\n",
      "iteration 522: f_best = 0.00000000\n",
      "x_eff  = [-3.46092252  1.84047031],\n",
      "\n",
      "iteration 523: f_best = 0.00000000\n",
      "x_eff  = [1.43560077 1.69845979],\n",
      "\n",
      "iteration 524: f_best = 0.00000000\n",
      "x_eff  = [0.01189513 2.09497265],\n",
      "\n",
      "iteration 525: f_best = 0.00000000\n",
      "x_eff  = [-0.35797388  1.85344348],\n",
      "\n",
      "iteration 526: f_best = 0.00000000\n",
      "x_eff  = [-1.07863523 -1.47337316],\n",
      "\n",
      "iteration 527: f_best = 0.00000000\n",
      "x_eff  = [ 1.93574502 -2.5394646 ],\n",
      "\n",
      "iteration 528: f_best = 0.00000000\n",
      "x_eff  = [0.55018504 2.86533947],\n",
      "\n",
      "iteration 529: f_best = 0.00000000\n",
      "x_eff  = [2.9719957  1.68826981],\n",
      "\n",
      "iteration 530: f_best = 0.00000000\n",
      "x_eff  = [2.4386395  1.42113759],\n",
      "\n",
      "iteration 531: f_best = 0.00000000\n",
      "x_eff  = [-2.24799948 -0.96604   ],\n",
      "\n",
      "iteration 532: f_best = 0.00000000\n",
      "x_eff  = [2.7392945  3.11133386],\n",
      "\n",
      "iteration 533: f_best = 0.00000000\n",
      "x_eff  = [0.67709709 1.40875678],\n",
      "\n",
      "iteration 534: f_best = 0.00000000\n",
      "x_eff  = [-2.82247208  1.13982449],\n",
      "\n",
      "iteration 535: f_best = 0.00000000\n",
      "x_eff  = [-1.33234941  0.76573026],\n",
      "\n",
      "iteration 536: f_best = 0.00000000\n",
      "x_eff  = [ 0.30486772 -0.96898141],\n",
      "\n",
      "iteration 537: f_best = 0.00000000\n",
      "x_eff  = [0.16826452 0.64939275],\n",
      "\n",
      "iteration 538: f_best = 0.00000000\n",
      "x_eff  = [-1.00029892  1.62036985],\n",
      "\n",
      "iteration 539: f_best = 0.00000000\n",
      "x_eff  = [-0.64492334  2.78847665],\n",
      "\n",
      "iteration 540: f_best = 0.00000000\n",
      "x_eff  = [ 1.71270644 -0.59174041],\n",
      "\n",
      "iteration 541: f_best = 0.00000000\n",
      "x_eff  = [-2.27766236 -0.34695191],\n",
      "\n",
      "iteration 542: f_best = 0.00000000\n",
      "x_eff  = [-2.62434796  1.47857126],\n",
      "\n",
      "iteration 543: f_best = 0.00000000\n",
      "x_eff  = [-1.13464178  1.20918927],\n",
      "\n",
      "iteration 544: f_best = 0.00000000\n",
      "x_eff  = [ 2.04675093 -0.95091769],\n",
      "\n",
      "iteration 545: f_best = 0.00000000\n",
      "x_eff  = [-0.24937666  2.18287427],\n",
      "\n",
      "iteration 546: f_best = 0.00000000\n",
      "x_eff  = [-0.13332648  1.24940623],\n",
      "\n",
      "iteration 547: f_best = 0.00000000\n",
      "x_eff  = [-1.80456985 -0.0542202 ],\n",
      "\n",
      "iteration 548: f_best = 0.00000000\n",
      "x_eff  = [1.39581736 2.06232842],\n",
      "\n",
      "iteration 549: f_best = 0.00000000\n",
      "x_eff  = [2.01384492 2.43818955],\n",
      "\n",
      "iteration 550: f_best = 0.00000000\n",
      "x_eff  = [0.5810677  2.59096341],\n",
      "\n",
      "iteration 551: f_best = 0.00000000\n",
      "x_eff  = [-1.56003643  0.18892359],\n",
      "\n",
      "iteration 552: f_best = 0.00000000\n",
      "x_eff  = [-0.51463797  0.56792599],\n",
      "\n",
      "iteration 553: f_best = 0.00000000\n",
      "x_eff  = [1.1086704  2.12634456],\n",
      "\n",
      "iteration 554: f_best = 0.00000000\n",
      "x_eff  = [ 0.8641055  -2.54325708],\n",
      "\n",
      "iteration 555: f_best = 0.00000000\n",
      "x_eff  = [ 0.22195212 -0.57310447],\n",
      "\n",
      "iteration 556: f_best = 0.00000000\n",
      "x_eff  = [0.79385597 2.50085787],\n",
      "\n",
      "iteration 557: f_best = 0.00000000\n",
      "x_eff  = [-1.54098369  1.37114035],\n",
      "\n",
      "iteration 558: f_best = 0.00000000\n",
      "x_eff  = [ 1.3420837  -0.40755196],\n",
      "\n",
      "iteration 559: f_best = 0.00000000\n",
      "x_eff  = [-0.13930567  1.05115207],\n",
      "\n",
      "iteration 560: f_best = 0.00000000\n",
      "x_eff  = [-1.22967485  1.88327738],\n",
      "\n",
      "iteration 561: f_best = 0.00000000\n",
      "x_eff  = [-1.50311979 -0.33599998],\n",
      "\n",
      "iteration 562: f_best = 0.00000000\n",
      "x_eff  = [ 1.93530698 -0.08395254],\n",
      "\n",
      "iteration 563: f_best = 0.00000000\n",
      "x_eff  = [ 1.1691502  -0.01591796],\n",
      "\n",
      "iteration 564: f_best = 0.00000000\n",
      "x_eff  = [1.94295855 1.29792711],\n",
      "\n",
      "iteration 565: f_best = 0.00000000\n",
      "x_eff  = [-1.26937255 -0.03554697],\n",
      "\n",
      "iteration 566: f_best = 0.00000000\n",
      "x_eff  = [-0.74758758  1.56484285],\n",
      "\n",
      "iteration 567: f_best = 0.00000000\n",
      "x_eff  = [ 1.13806312 -0.79069337],\n",
      "\n",
      "iteration 568: f_best = 0.00000000\n",
      "x_eff  = [-2.15586955  1.58431255],\n",
      "\n",
      "iteration 569: f_best = 0.00000000\n",
      "x_eff  = [0.28976614 1.92954278],\n",
      "\n",
      "iteration 570: f_best = 0.00000000\n",
      "x_eff  = [ 2.06628271 -1.49031815],\n",
      "\n",
      "iteration 571: f_best = 0.00000000\n",
      "x_eff  = [0.84003132 1.40118356],\n",
      "\n",
      "iteration 572: f_best = 0.00000000\n",
      "x_eff  = [-1.56363445 -0.90282859],\n",
      "\n",
      "iteration 573: f_best = 0.00000000\n",
      "x_eff  = [0.48743443 0.56231322],\n",
      "\n",
      "iteration 574: f_best = 0.00000000\n",
      "x_eff  = [-1.98349668 -2.00346647],\n",
      "\n",
      "iteration 575: f_best = 0.00000000\n",
      "x_eff  = [-1.96340334  1.1644244 ],\n",
      "\n",
      "iteration 576: f_best = 0.00000000\n",
      "x_eff  = [ 0.9032701  -0.39821582],\n",
      "\n",
      "iteration 577: f_best = 0.00000000\n",
      "x_eff  = [0.73326257 0.68661215],\n",
      "\n",
      "iteration 578: f_best = 0.00000000\n",
      "x_eff  = [-0.26995059  1.52469081],\n",
      "\n",
      "iteration 579: f_best = 0.00000000\n",
      "x_eff  = [0.07229241 1.66892402],\n",
      "\n",
      "iteration 580: f_best = 0.00000000\n",
      "x_eff  = [-0.06159497  1.24821898],\n",
      "\n",
      "iteration 581: f_best = 0.00000000\n",
      "x_eff  = [1.14466277 1.45774842],\n",
      "\n",
      "iteration 582: f_best = 0.00000000\n",
      "x_eff  = [1.69058367 0.21384644],\n",
      "\n",
      "iteration 583: f_best = 0.00000000\n",
      "x_eff  = [ 0.01936114 -1.63977612],\n",
      "\n",
      "iteration 584: f_best = 0.00000000\n",
      "x_eff  = [-1.24904268 -1.06497335],\n",
      "\n",
      "iteration 585: f_best = 0.00000000\n",
      "x_eff  = [0.64536615 0.70690717],\n",
      "\n",
      "iteration 586: f_best = 0.00000000\n",
      "x_eff  = [ 0.84537473 -0.65356116],\n",
      "\n",
      "iteration 587: f_best = 0.00000000\n",
      "x_eff  = [-1.12938045 -1.01409216],\n",
      "\n",
      "iteration 588: f_best = 0.00000000\n",
      "x_eff  = [ 0.66390096 -1.07261719],\n",
      "\n",
      "iteration 589: f_best = 0.00000000\n",
      "x_eff  = [-1.62793261  1.15190083],\n",
      "\n",
      "iteration 590: f_best = 0.00000000\n",
      "x_eff  = [-1.34240556 -1.01246692],\n",
      "\n",
      "iteration 591: f_best = 0.00000000\n",
      "x_eff  = [-0.89166503  1.20512978],\n",
      "\n",
      "iteration 592: f_best = 0.00000000\n",
      "x_eff  = [-1.23140932 -0.33769238],\n",
      "\n",
      "iteration 593: f_best = 0.00000000\n",
      "x_eff  = [-0.83825878  0.19573354],\n",
      "\n",
      "iteration 594: f_best = 0.00000000\n",
      "x_eff  = [ 1.68398713 -1.39209683],\n",
      "\n",
      "iteration 595: f_best = 0.00000000\n",
      "x_eff  = [0.79186846 0.39421335],\n",
      "\n",
      "iteration 596: f_best = 0.00000000\n",
      "x_eff  = [-0.94361006  1.04715787],\n",
      "\n",
      "iteration 597: f_best = 0.00000000\n",
      "x_eff  = [-0.717857    1.30384696],\n",
      "\n",
      "iteration 598: f_best = 0.00000000\n",
      "x_eff  = [0.94183937 0.71321406],\n",
      "\n",
      "iteration 599: f_best = 0.00000000\n",
      "x_eff  = [ 0.36953349 -0.40818758],\n",
      "\n",
      "iteration 600: f_best = 0.00000000\n",
      "x_eff  = [0.99955315 1.34194606],\n",
      "\n",
      "iteration 601: f_best = 0.00000000\n",
      "x_eff  = [-0.28073231 -0.32306223],\n",
      "\n",
      "iteration 602: f_best = 0.00000000\n",
      "x_eff  = [ 0.40984521 -1.37627648],\n",
      "\n",
      "iteration 603: f_best = 0.00000000\n",
      "x_eff  = [1.14769003 0.09658689],\n",
      "\n",
      "iteration 604: f_best = 0.00000000\n",
      "x_eff  = [-0.8316806  -1.49973484],\n",
      "\n",
      "iteration 605: f_best = 0.00000000\n",
      "x_eff  = [ 1.18806505 -0.74446499],\n",
      "\n",
      "iteration 606: f_best = 0.00000000\n",
      "x_eff  = [-0.46717067 -0.94195421],\n",
      "\n",
      "iteration 607: f_best = 0.00000000\n",
      "x_eff  = [-0.16242121  0.04925656],\n",
      "\n",
      "iteration 608: f_best = 0.00000000\n",
      "x_eff  = [ 0.35722481 -0.11265033],\n",
      "\n",
      "iteration 609: f_best = 0.00000000\n",
      "x_eff  = [-1.33103853  0.41573101],\n",
      "\n",
      "iteration 610: f_best = 0.00000000\n",
      "x_eff  = [ 1.37019073 -0.59566599],\n",
      "\n",
      "iteration 611: f_best = 0.00000000\n",
      "x_eff  = [-1.26795846 -1.41608208],\n",
      "\n",
      "iteration 612: f_best = 0.00000000\n",
      "x_eff  = [-0.65735028  1.09483704],\n",
      "\n",
      "iteration 613: f_best = 0.00000000\n",
      "x_eff  = [0.27682625 1.16768384],\n",
      "\n",
      "iteration 614: f_best = 0.00000000\n",
      "x_eff  = [-0.52415029  1.30470335],\n",
      "\n",
      "iteration 615: f_best = 0.00000000\n",
      "x_eff  = [-1.18939547 -0.86589621],\n",
      "\n",
      "iteration 616: f_best = 0.00000000\n",
      "x_eff  = [ 0.9225348  -1.10294251],\n",
      "\n",
      "iteration 617: f_best = 0.00000000\n",
      "x_eff  = [-0.82658265 -0.24501894],\n",
      "\n",
      "iteration 618: f_best = 0.00000000\n",
      "x_eff  = [-0.93001776  1.05648147],\n",
      "\n",
      "iteration 619: f_best = 0.00000000\n",
      "x_eff  = [-0.2576079   1.10079042],\n",
      "\n",
      "iteration 620: f_best = 0.00000000\n",
      "x_eff  = [-0.45452884  0.45635746],\n",
      "\n",
      "iteration 621: f_best = 0.00000000\n",
      "x_eff  = [-0.35311774 -0.88899603],\n",
      "\n",
      "iteration 622: f_best = 0.00000000\n",
      "x_eff  = [-0.90201597  0.24684171],\n",
      "\n",
      "iteration 623: f_best = 0.00000000\n",
      "x_eff  = [-1.24904011  0.82771207],\n",
      "\n",
      "iteration 624: f_best = 0.00000000\n",
      "x_eff  = [-1.15580648 -0.63193015],\n",
      "\n",
      "iteration 625: f_best = 0.00000000\n",
      "x_eff  = [-0.5175633  -0.38062607],\n",
      "\n",
      "iteration 626: f_best = 0.00000000\n",
      "x_eff  = [-1.09298393  1.01004025],\n",
      "\n",
      "iteration 627: f_best = 0.00000000\n",
      "x_eff  = [-0.02461732  0.33091125],\n",
      "\n",
      "iteration 628: f_best = 0.00000000\n",
      "x_eff  = [1.089459   0.40448477],\n",
      "\n",
      "iteration 629: f_best = 0.00000000\n",
      "x_eff  = [-1.22015825 -1.15862893],\n",
      "\n",
      "iteration 630: f_best = 0.00000000\n",
      "x_eff  = [-1.07123667  0.28408264],\n",
      "\n",
      "iteration 631: f_best = 0.00000000\n",
      "x_eff  = [ 0.50894006 -0.00789462],\n",
      "\n",
      "iteration 632: f_best = 0.00000000\n",
      "x_eff  = [-0.44900787 -0.92124679],\n",
      "\n",
      "iteration 633: f_best = 0.00000000\n",
      "x_eff  = [-0.30263213  0.92820958],\n",
      "\n",
      "iteration 634: f_best = 0.00000000\n",
      "x_eff  = [-1.01970217 -0.70257071],\n",
      "\n",
      "iteration 635: f_best = 0.00000000\n",
      "x_eff  = [-0.08705614 -0.33259476],\n",
      "\n",
      "iteration 636: f_best = 0.00000000\n",
      "x_eff  = [ 0.63863964 -0.26735994],\n",
      "\n",
      "iteration 637: f_best = 0.00000000\n",
      "x_eff  = [ 0.51286137 -0.51460343],\n",
      "\n",
      "iteration 638: f_best = 0.00000000\n",
      "x_eff  = [-0.55541632 -0.7529662 ],\n",
      "\n",
      "iteration 639: f_best = 0.00000000\n",
      "x_eff  = [-0.02955523  0.78194368],\n",
      "\n",
      "iteration 640: f_best = 0.00000000\n",
      "x_eff  = [ 1.06675804 -0.21340335],\n",
      "\n",
      "iteration 641: f_best = 0.00000000\n",
      "x_eff  = [1.08333331 0.77233141],\n",
      "\n",
      "iteration 642: f_best = 0.00000000\n",
      "x_eff  = [-0.1984225   1.07531609],\n",
      "\n",
      "iteration 643: f_best = 0.00000000\n",
      "x_eff  = [ 0.61144862 -0.08977229],\n",
      "\n",
      "iteration 644: f_best = 0.00000000\n",
      "x_eff  = [1.05431648 0.59714838],\n",
      "\n",
      "iteration 645: f_best = 0.00000000\n",
      "x_eff  = [0.23550236 0.08902112],\n",
      "\n",
      "iteration 646: f_best = 0.00000000\n",
      "x_eff  = [-0.63950462  0.16927771],\n",
      "\n",
      "iteration 647: f_best = 0.00000000\n",
      "x_eff  = [-0.84447504  0.09624974],\n",
      "\n",
      "iteration 648: f_best = 0.00000000\n",
      "x_eff  = [-0.39044045 -0.48404214],\n",
      "\n",
      "iteration 649: f_best = 0.00000000\n",
      "x_eff  = [-0.68402958  0.36785978],\n",
      "\n",
      "iteration 650: f_best = 0.00000000\n",
      "x_eff  = [-0.85472769  0.97223792],\n",
      "\n",
      "iteration 651: f_best = 0.00000000\n",
      "x_eff  = [ 0.91815091 -0.77661814],\n",
      "\n",
      "iteration 652: f_best = 0.00000000\n",
      "x_eff  = [-0.93049702  0.45116099],\n",
      "\n",
      "iteration 653: f_best = 0.00000000\n",
      "x_eff  = [0.04996412 0.59221741],\n",
      "\n",
      "iteration 654: f_best = 0.00000000\n",
      "x_eff  = [-0.47195251 -0.61375992],\n",
      "\n",
      "iteration 655: f_best = 0.00000000\n",
      "x_eff  = [-0.18806698 -0.60251049],\n",
      "\n",
      "iteration 656: f_best = 0.00000000\n",
      "x_eff  = [0.09269677 0.40597227],\n",
      "\n",
      "iteration 657: f_best = 0.00000000\n",
      "x_eff  = [-0.75354092  0.80280204],\n",
      "\n",
      "iteration 658: f_best = 0.00000000\n",
      "x_eff  = [-0.21151765  0.8480122 ],\n",
      "\n",
      "iteration 659: f_best = 0.00000000\n",
      "x_eff  = [0.50186908 0.05310955],\n",
      "\n",
      "iteration 660: f_best = 0.00000000\n",
      "x_eff  = [-0.07764114  0.60554637],\n",
      "\n",
      "iteration 661: f_best = 0.00000000\n",
      "x_eff  = [-0.60692114 -0.04460113],\n",
      "\n",
      "iteration 662: f_best = 0.00000000\n",
      "x_eff  = [-0.49724789  0.09057094],\n",
      "\n",
      "iteration 663: f_best = 0.00000000\n",
      "x_eff  = [0.71501264 0.49926188],\n",
      "\n",
      "iteration 664: f_best = 0.00000000\n",
      "x_eff  = [ 0.09225779 -0.64927288],\n",
      "\n",
      "iteration 665: f_best = 0.00000000\n",
      "x_eff  = [0.08390076 0.24514294],\n",
      "\n",
      "iteration 666: f_best = 0.00000000\n",
      "x_eff  = [-0.52647705 -0.12409584],\n",
      "\n",
      "iteration 667: f_best = 0.00000000\n",
      "x_eff  = [-0.16193621 -0.56446159],\n",
      "\n",
      "iteration 668: f_best = 0.00000000\n",
      "x_eff  = [-0.82041972  0.21179428],\n",
      "\n",
      "iteration 669: f_best = 0.00000000\n",
      "x_eff  = [0.7868914  0.66716897],\n",
      "\n",
      "iteration 670: f_best = 0.00000000\n",
      "x_eff  = [0.10544749 0.14022622],\n",
      "\n",
      "iteration 671: f_best = 0.00000000\n",
      "x_eff  = [ 0.52665831 -0.75427257],\n",
      "\n",
      "iteration 672: f_best = 0.00000000\n",
      "x_eff  = [ 0.23571356 -0.79460869],\n",
      "\n",
      "iteration 673: f_best = 0.00000000\n",
      "x_eff  = [-0.25206066 -0.55191255],\n",
      "\n",
      "iteration 674: f_best = 0.00000000\n",
      "x_eff  = [ 0.33557578 -0.70036973],\n",
      "\n",
      "iteration 675: f_best = 0.00000000\n",
      "x_eff  = [ 0.63933897 -0.08316265],\n",
      "\n",
      "iteration 676: f_best = 0.00000000\n",
      "x_eff  = [0.66879214 0.52919963],\n",
      "\n",
      "iteration 677: f_best = 0.00000000\n",
      "x_eff  = [-0.39288327  0.60610966],\n",
      "\n",
      "iteration 678: f_best = 0.00000000\n",
      "x_eff  = [-0.31731953 -0.61017177],\n",
      "\n",
      "iteration 679: f_best = 0.00000000\n",
      "x_eff  = [0.31047867 0.6446082 ],\n",
      "\n",
      "iteration 680: f_best = 0.00000000\n",
      "x_eff  = [ 0.11465849 -0.44160585],\n",
      "\n",
      "iteration 681: f_best = 0.00000000\n",
      "x_eff  = [-0.40670538  0.51628023],\n",
      "\n",
      "iteration 682: f_best = 0.00000000\n",
      "x_eff  = [-0.65447034 -0.22993603],\n",
      "\n",
      "iteration 683: f_best = 0.00000000\n",
      "x_eff  = [-0.03584632  0.5111275 ],\n",
      "\n",
      "iteration 684: f_best = 0.00000000\n",
      "x_eff  = [-0.56706988  0.34863978],\n",
      "\n",
      "iteration 685: f_best = 0.00000000\n",
      "x_eff  = [-0.23097894  0.36129945],\n",
      "\n",
      "iteration 686: f_best = 0.00000000\n",
      "x_eff  = [-0.56576205 -0.64442592],\n",
      "\n",
      "iteration 687: f_best = 0.00000000\n",
      "x_eff  = [0.43091559 0.46421401],\n",
      "\n",
      "iteration 688: f_best = 0.00000000\n",
      "x_eff  = [0.669013   0.47788116],\n",
      "\n",
      "iteration 689: f_best = 0.00000000\n",
      "x_eff  = [-0.29798232 -0.36507143],\n",
      "\n",
      "iteration 690: f_best = 0.00000000\n",
      "x_eff  = [-0.40092502 -0.04725275],\n",
      "\n",
      "iteration 691: f_best = 0.00000000\n",
      "x_eff  = [-0.47269689 -0.22572435],\n",
      "\n",
      "iteration 692: f_best = 0.00000000\n",
      "x_eff  = [ 0.20934968 -0.07911291],\n",
      "\n",
      "iteration 693: f_best = 0.00000000\n",
      "x_eff  = [0.29375274 0.19417622],\n",
      "\n",
      "iteration 694: f_best = 0.00000000\n",
      "x_eff  = [ 0.18445631 -0.02341993],\n",
      "\n",
      "iteration 695: f_best = 0.00000000\n",
      "x_eff  = [ 0.59832246 -0.49156816],\n",
      "\n",
      "iteration 696: f_best = 0.00000000\n",
      "x_eff  = [0.17074488 0.17559207],\n",
      "\n",
      "iteration 697: f_best = 0.00000000\n",
      "x_eff  = [ 0.10308804 -0.41312987],\n",
      "\n",
      "iteration 698: f_best = 0.00000000\n",
      "x_eff  = [-0.07156376 -0.43707036],\n",
      "\n",
      "iteration 699: f_best = 0.00000000\n",
      "x_eff  = [0.58008173 0.36864056],\n",
      "\n",
      "iteration 700: f_best = 0.00000000\n",
      "x_eff  = [-0.5590414  0.3669398],\n",
      "\n",
      "iteration 701: f_best = 0.00000000\n",
      "x_eff  = [-0.51593986  0.51974075],\n",
      "\n",
      "iteration 702: f_best = 0.00000000\n",
      "x_eff  = [-0.50495728  0.18728146],\n",
      "\n",
      "iteration 703: f_best = 0.00000000\n",
      "x_eff  = [0.02245356 0.00675729],\n",
      "\n",
      "iteration 704: f_best = 0.00000000\n",
      "x_eff  = [ 0.13368933 -0.49059603],\n",
      "\n",
      "iteration 705: f_best = 0.00000000\n",
      "x_eff  = [ 0.44583524 -0.26404268],\n",
      "\n",
      "iteration 706: f_best = 0.00000000\n",
      "x_eff  = [-0.4763306   0.26404243],\n",
      "\n",
      "iteration 707: f_best = 0.00000000\n",
      "x_eff  = [ 0.43930826 -0.4647897 ],\n",
      "\n",
      "iteration 708: f_best = 0.00000000\n",
      "x_eff  = [ 0.35181538 -0.3105561 ],\n",
      "\n",
      "iteration 709: f_best = 0.00000000\n",
      "x_eff  = [-0.49686318  0.09145503],\n",
      "\n",
      "iteration 710: f_best = 0.00000000\n",
      "x_eff  = [-0.29393811  0.02906742],\n",
      "\n",
      "iteration 711: f_best = 0.00000000\n",
      "x_eff  = [-0.36478695 -0.32777782],\n",
      "\n",
      "iteration 712: f_best = 0.00000000\n",
      "x_eff  = [ 0.51867287 -0.33902955],\n",
      "\n",
      "iteration 713: f_best = 0.00000000\n",
      "x_eff  = [ 0.25473528 -0.1338662 ],\n",
      "\n",
      "iteration 714: f_best = 0.00000000\n",
      "x_eff  = [0.32281074 0.38938472],\n",
      "\n",
      "iteration 715: f_best = 0.00000000\n",
      "x_eff  = [-0.04450645  0.38422595],\n",
      "\n",
      "iteration 716: f_best = 0.00000000\n",
      "x_eff  = [0.28312675 0.36762379],\n",
      "\n",
      "iteration 717: f_best = 0.00000000\n",
      "x_eff  = [-0.15129649  0.03702881],\n",
      "\n",
      "iteration 718: f_best = 0.00000000\n",
      "x_eff  = [-0.10177188 -0.20076285],\n",
      "\n",
      "iteration 719: f_best = 0.00000000\n",
      "x_eff  = [-0.36943269  0.44129508],\n",
      "\n",
      "iteration 720: f_best = 0.00000000\n",
      "x_eff  = [-0.43293623  0.20150919],\n",
      "\n",
      "iteration 721: f_best = 0.00000000\n",
      "x_eff  = [0.19922926 0.14333895],\n",
      "\n",
      "iteration 722: f_best = 0.00000000\n",
      "x_eff  = [-0.27816255  0.27988831],\n",
      "\n",
      "iteration 723: f_best = 0.00000000\n",
      "x_eff  = [0.34382447 0.2105245 ],\n",
      "\n",
      "iteration 724: f_best = 0.00000000\n",
      "x_eff  = [-0.20393044 -0.14107255],\n",
      "\n",
      "iteration 725: f_best = 0.00000000\n",
      "x_eff  = [0.31144876 0.09498983],\n",
      "\n",
      "iteration 726: f_best = 0.00000000\n",
      "x_eff  = [ 0.28621482 -0.14053586],\n",
      "\n",
      "iteration 727: f_best = 0.00000000\n",
      "x_eff  = [ 0.25788801 -0.09675164],\n",
      "\n",
      "iteration 728: f_best = 0.00000000\n",
      "x_eff  = [ 0.44240409 -0.06293359],\n",
      "\n",
      "iteration 729: f_best = 0.00000000\n",
      "x_eff  = [0.44834101 0.2188748 ],\n",
      "\n",
      "iteration 730: f_best = 0.00000000\n",
      "x_eff  = [-0.07340334 -0.07270785],\n",
      "\n",
      "iteration 731: f_best = 0.00000000\n",
      "x_eff  = [-0.2792451   0.24726671],\n",
      "\n",
      "iteration 732: f_best = 0.00000000\n",
      "x_eff  = [0.3066089  0.42006838],\n",
      "\n",
      "iteration 733: f_best = 0.00000000\n",
      "x_eff  = [-0.32680771  0.35212657],\n",
      "\n",
      "iteration 734: f_best = 0.00000000\n",
      "x_eff  = [ 0.22343914 -0.21927603],\n",
      "\n",
      "iteration 735: f_best = 0.00000000\n",
      "x_eff  = [0.41945597 0.16779463],\n",
      "\n",
      "iteration 736: f_best = 0.00000000\n",
      "x_eff  = [-0.23126237 -0.03030434],\n",
      "\n",
      "iteration 737: f_best = 0.00000000\n",
      "x_eff  = [-0.07600482  0.23885586],\n",
      "\n",
      "iteration 738: f_best = 0.00000000\n",
      "x_eff  = [0.03720108 0.13256046],\n",
      "\n",
      "iteration 739: f_best = 0.00000000\n",
      "x_eff  = [-0.239059    0.26732084],\n",
      "\n",
      "iteration 740: f_best = 0.00000000\n",
      "x_eff  = [ 0.26594036 -0.08460861],\n",
      "\n",
      "iteration 741: f_best = 0.00000000\n",
      "x_eff  = [ 0.22255767 -0.0441112 ],\n",
      "\n",
      "iteration 742: f_best = 0.00000000\n",
      "x_eff  = [-0.25325653 -0.06355109],\n",
      "\n",
      "iteration 743: f_best = 0.00000000\n",
      "x_eff  = [ 0.35327114 -0.26461152],\n",
      "\n",
      "iteration 744: f_best = 0.00000000\n",
      "x_eff  = [-0.30342215 -0.34213291],\n",
      "\n",
      "iteration 745: f_best = 0.00000000\n",
      "x_eff  = [-0.23651009  0.06413995],\n",
      "\n",
      "iteration 746: f_best = 0.00000000\n",
      "x_eff  = [0.19198915 0.31654456],\n",
      "\n",
      "iteration 747: f_best = 0.00000000\n",
      "x_eff  = [-0.22843148  0.28190713],\n",
      "\n",
      "iteration 748: f_best = 0.00000000\n",
      "x_eff  = [-0.2579567  -0.08333382],\n",
      "\n",
      "iteration 749: f_best = 0.00000000\n",
      "x_eff  = [ 0.21169661 -0.24019994],\n",
      "\n",
      "iteration 750: f_best = 0.00000000\n",
      "x_eff  = [-0.27537448  0.31867686],\n",
      "\n",
      "iteration 751: f_best = 0.00000000\n",
      "x_eff  = [0.29239498 0.17733682],\n",
      "\n",
      "iteration 752: f_best = 0.00000000\n",
      "x_eff  = [ 0.27131523 -0.07542407],\n",
      "\n",
      "iteration 753: f_best = 0.00000000\n",
      "x_eff  = [0.21308118 0.27669318],\n",
      "\n",
      "iteration 754: f_best = 0.00000000\n",
      "x_eff  = [-0.06133911  0.28817625],\n",
      "\n",
      "iteration 755: f_best = 0.00000000\n",
      "x_eff  = [-0.30866346 -0.16307985],\n",
      "\n",
      "iteration 756: f_best = 0.00000000\n",
      "x_eff  = [-0.11219    -0.04523495],\n",
      "\n",
      "iteration 757: f_best = 0.00000000\n",
      "x_eff  = [-0.22042112  0.16566379],\n",
      "\n",
      "iteration 758: f_best = 0.00000000\n",
      "x_eff  = [ 0.20269792 -0.15810489],\n",
      "\n",
      "iteration 759: f_best = 0.00000000\n",
      "x_eff  = [-0.07190205 -0.27754366],\n",
      "\n",
      "iteration 760: f_best = 0.00000000\n",
      "x_eff  = [-0.03769731  0.0090145 ],\n",
      "\n",
      "iteration 761: f_best = 0.00000000\n",
      "x_eff  = [-0.14811347 -0.10169378],\n",
      "\n",
      "iteration 762: f_best = 0.00000000\n",
      "x_eff  = [-0.01043149  0.25779417],\n",
      "\n",
      "iteration 763: f_best = 0.00000000\n",
      "x_eff  = [-0.23896676  0.2028467 ],\n",
      "\n",
      "iteration 764: f_best = 0.00000000\n",
      "x_eff  = [0.14817992 0.11751083],\n",
      "\n",
      "iteration 765: f_best = 0.00000000\n",
      "x_eff  = [0.02508331 0.0848673 ],\n",
      "\n",
      "iteration 766: f_best = 0.00000000\n",
      "x_eff  = [-0.25013534  0.21010806],\n",
      "\n",
      "iteration 767: f_best = 0.00000000\n",
      "x_eff  = [-0.07097943  0.09040879],\n",
      "\n",
      "iteration 768: f_best = 0.00000000\n",
      "x_eff  = [-0.23151386  0.03432348],\n",
      "\n",
      "iteration 769: f_best = 0.00000000\n",
      "x_eff  = [-0.16977687 -0.01230874],\n",
      "\n",
      "iteration 770: f_best = 0.00000000\n",
      "x_eff  = [-0.03254884  0.08460086],\n",
      "\n",
      "iteration 771: f_best = 0.00000000\n",
      "x_eff  = [-0.25935701 -0.0791583 ],\n",
      "\n",
      "iteration 772: f_best = 0.00000000\n",
      "x_eff  = [0.03084871 0.29383034],\n",
      "\n",
      "iteration 773: f_best = 0.00000000\n",
      "x_eff  = [0.1705192  0.21405075],\n",
      "\n",
      "iteration 774: f_best = 0.00000000\n",
      "x_eff  = [-0.25722    -0.05598136],\n",
      "\n",
      "iteration 775: f_best = 0.00000000\n",
      "x_eff  = [ 0.23257572 -0.08145965],\n",
      "\n",
      "iteration 776: f_best = 0.00000000\n",
      "x_eff  = [0.17066158 0.26198178],\n",
      "\n",
      "iteration 777: f_best = 0.00000000\n",
      "x_eff  = [-0.26637478 -0.0341748 ],\n",
      "\n",
      "iteration 778: f_best = 0.00000000\n",
      "x_eff  = [0.22208165 0.20853335],\n",
      "\n",
      "iteration 779: f_best = 0.00000000\n",
      "x_eff  = [-0.04493163 -0.15112897],\n",
      "\n",
      "iteration 780: f_best = 0.00000000\n",
      "x_eff  = [0.09055801 0.02719532],\n",
      "\n",
      "iteration 781: f_best = 0.00000000\n",
      "x_eff  = [-0.19227666 -0.02530012],\n",
      "\n",
      "iteration 782: f_best = 0.00000000\n",
      "x_eff  = [0.25034948 0.08638533],\n",
      "\n",
      "iteration 783: f_best = 0.00000000\n",
      "x_eff  = [-0.12937592  0.08108528],\n",
      "\n",
      "iteration 784: f_best = 0.00000000\n",
      "x_eff  = [-0.25106991  0.03227896],\n",
      "\n",
      "iteration 785: f_best = 0.00000000\n",
      "x_eff  = [0.17955987 0.16749606],\n",
      "\n",
      "iteration 786: f_best = 0.00000000\n",
      "x_eff  = [0.10239011 0.17502989],\n",
      "\n",
      "iteration 787: f_best = 0.00000000\n",
      "x_eff  = [0.23021726 0.01338597],\n",
      "\n",
      "iteration 788: f_best = 0.00000000\n",
      "x_eff  = [-0.04137804 -0.0051423 ],\n",
      "\n",
      "iteration 789: f_best = 0.00000000\n",
      "x_eff  = [ 0.10677927 -0.13791416],\n",
      "\n",
      "iteration 790: f_best = 0.00000000\n",
      "x_eff  = [ 0.0510309  -0.20249357],\n",
      "\n",
      "iteration 791: f_best = 0.00000000\n",
      "x_eff  = [ 0.09051884 -0.17116998],\n",
      "\n",
      "iteration 792: f_best = 0.00000000\n",
      "x_eff  = [0.03347436 0.21704326],\n",
      "\n",
      "iteration 793: f_best = 0.00000000\n",
      "x_eff  = [-0.10037076 -0.16905087],\n",
      "\n",
      "iteration 794: f_best = 0.00000000\n",
      "x_eff  = [ 0.04549296 -0.12480489],\n",
      "\n",
      "iteration 795: f_best = 0.00000000\n",
      "x_eff  = [ 0.09618639 -0.06710025],\n",
      "\n",
      "iteration 796: f_best = 0.00000000\n",
      "x_eff  = [ 0.04797399 -0.10982074],\n",
      "\n",
      "iteration 797: f_best = 0.00000000\n",
      "x_eff  = [0.0564883  0.16342686],\n",
      "\n",
      "iteration 798: f_best = 0.00000000\n",
      "x_eff  = [ 0.10215873 -0.05256794],\n",
      "\n",
      "iteration 799: f_best = 0.00000000\n",
      "x_eff  = [-0.01670117 -0.21167124],\n",
      "\n",
      "iteration 800: f_best = 0.00000000\n",
      "x_eff  = [0.13074145 0.08788465],\n",
      "\n",
      "iteration 801: f_best = 0.00000000\n",
      "x_eff  = [-0.03439062 -0.18350017],\n",
      "\n",
      "iteration 802: f_best = 0.00000000\n",
      "x_eff  = [ 0.03889513 -0.04995189],\n",
      "\n",
      "iteration 803: f_best = 0.00000000\n",
      "x_eff  = [-0.06130021  0.01649501],\n",
      "\n",
      "iteration 804: f_best = 0.00000000\n",
      "x_eff  = [-0.17030637  0.17989985],\n",
      "\n",
      "iteration 805: f_best = 0.00000000\n",
      "x_eff  = [-0.18708816 -0.102601  ],\n",
      "\n",
      "iteration 806: f_best = 0.00000000\n",
      "x_eff  = [ 0.09458187 -0.00589455],\n",
      "\n",
      "iteration 807: f_best = 0.00000000\n",
      "x_eff  = [0.18236525 0.11162286],\n",
      "\n",
      "iteration 808: f_best = 0.00000000\n",
      "x_eff  = [ 0.10526999 -0.02154265],\n",
      "\n",
      "iteration 809: f_best = 0.00000000\n",
      "x_eff  = [-0.0572988   0.00375793],\n",
      "\n",
      "iteration 810: f_best = 0.00000000\n",
      "x_eff  = [-0.20017676 -0.09972548],\n",
      "\n",
      "iteration 811: f_best = 0.00000000\n",
      "x_eff  = [0.18104583 0.08472177],\n",
      "\n",
      "iteration 812: f_best = 0.00000000\n",
      "x_eff  = [ 0.15758981 -0.04625989],\n",
      "\n",
      "iteration 813: f_best = 0.00000000\n",
      "x_eff  = [ 0.04099718 -0.08922048],\n",
      "\n",
      "iteration 814: f_best = 0.00000000\n",
      "x_eff  = [-0.10448576 -0.02548648],\n",
      "\n",
      "iteration 815: f_best = 0.00000000\n",
      "x_eff  = [ 0.17178903 -0.14999487],\n",
      "\n",
      "iteration 816: f_best = 0.00000000\n",
      "x_eff  = [-0.06556693 -0.02506712],\n",
      "\n",
      "iteration 817: f_best = 0.00000000\n",
      "x_eff  = [-0.12675783  0.12219443],\n",
      "\n",
      "iteration 818: f_best = 0.00000000\n",
      "x_eff  = [-0.03318059 -0.04394914],\n",
      "\n",
      "iteration 819: f_best = 0.00000000\n",
      "x_eff  = [-0.08954196 -0.18388052],\n",
      "\n",
      "iteration 820: f_best = 0.00000000\n",
      "x_eff  = [-0.15569568 -0.0340529 ],\n",
      "\n",
      "iteration 821: f_best = 0.00000000\n",
      "x_eff  = [0.14585314 0.09765438],\n",
      "\n",
      "iteration 822: f_best = 0.00000000\n",
      "x_eff  = [-0.16703584  0.0221914 ],\n",
      "\n",
      "iteration 823: f_best = 0.00000000\n",
      "x_eff  = [-0.00558064  0.11048845],\n",
      "\n",
      "iteration 824: f_best = 0.00000000\n",
      "x_eff  = [-0.13901525 -0.01910568],\n",
      "\n",
      "iteration 825: f_best = 0.00000000\n",
      "x_eff  = [ 0.07411944 -0.02306702],\n",
      "\n",
      "iteration 826: f_best = 0.00000000\n",
      "x_eff  = [-0.03151924  0.00425288],\n",
      "\n",
      "iteration 827: f_best = 0.00000000\n",
      "x_eff  = [-0.05174986 -0.15096474],\n",
      "\n",
      "iteration 828: f_best = 0.00000000\n",
      "x_eff  = [-0.07245196 -0.11950365],\n",
      "\n",
      "iteration 829: f_best = 0.00000000\n",
      "x_eff  = [-0.01280237 -0.14420092],\n",
      "\n",
      "iteration 830: f_best = 0.00000000\n",
      "x_eff  = [0.06617909 0.11804158],\n",
      "\n",
      "iteration 831: f_best = 0.00000000\n",
      "x_eff  = [-0.02775238  0.1140538 ],\n",
      "\n",
      "iteration 832: f_best = 0.00000000\n",
      "x_eff  = [ 0.01703329 -0.14198332],\n",
      "\n",
      "iteration 833: f_best = 0.00000000\n",
      "x_eff  = [-0.01215227  0.15247123],\n",
      "\n",
      "iteration 834: f_best = 0.00000000\n",
      "x_eff  = [-0.00093386  0.04901335],\n",
      "\n",
      "iteration 835: f_best = 0.00000000\n",
      "x_eff  = [ 0.09716451 -0.07257113],\n",
      "\n",
      "iteration 836: f_best = 0.00000000\n",
      "x_eff  = [-0.10267442  0.01272225],\n",
      "\n",
      "iteration 837: f_best = 0.00000000\n",
      "x_eff  = [ 0.11406571 -0.02030207],\n",
      "\n",
      "iteration 838: f_best = 0.00000000\n",
      "x_eff  = [0.09466184 0.10439372],\n",
      "\n",
      "iteration 839: f_best = 0.00000000\n",
      "x_eff  = [-0.13417576 -0.06217106],\n",
      "\n",
      "iteration 840: f_best = 0.00000000\n",
      "x_eff  = [-0.0851452   0.14712023],\n",
      "\n",
      "iteration 841: f_best = 0.00000000\n",
      "x_eff  = [ 1.44113744e-01 -1.30921650e-04],\n",
      "\n",
      "iteration 842: f_best = 0.00000000\n",
      "x_eff  = [-0.05663864  0.03022733],\n",
      "\n",
      "iteration 843: f_best = 0.00000000\n",
      "x_eff  = [ 0.10758294 -0.01937199],\n",
      "\n",
      "iteration 844: f_best = 0.00000000\n",
      "x_eff  = [ 0.12242507 -0.05239008],\n",
      "\n",
      "iteration 845: f_best = 0.00000000\n",
      "x_eff  = [ 0.00342099 -0.13175491],\n",
      "\n",
      "iteration 846: f_best = 0.00000000\n",
      "x_eff  = [-0.03508725  0.07282029],\n",
      "\n",
      "iteration 847: f_best = 0.00000000\n",
      "x_eff  = [-0.08235071 -0.06845357],\n",
      "\n",
      "iteration 848: f_best = 0.00000000\n",
      "x_eff  = [-0.02474129 -0.12203118],\n",
      "\n",
      "iteration 849: f_best = 0.00000000\n",
      "x_eff  = [0.09451259 0.11792708],\n",
      "\n",
      "iteration 850: f_best = 0.00000000\n",
      "x_eff  = [-0.04063215  0.12858747],\n",
      "\n",
      "iteration 851: f_best = 0.00000000\n",
      "x_eff  = [-0.10347969  0.07364607],\n",
      "\n",
      "iteration 852: f_best = 0.00000000\n",
      "x_eff  = [ 0.03278393 -0.10172112],\n",
      "\n",
      "iteration 853: f_best = 0.00000000\n",
      "x_eff  = [-0.11406019  0.11170979],\n",
      "\n",
      "iteration 854: f_best = 0.00000000\n",
      "x_eff  = [0.03584743 0.05271357],\n",
      "\n",
      "iteration 855: f_best = 0.00000000\n",
      "x_eff  = [-0.00803249 -0.04457314],\n",
      "\n",
      "iteration 856: f_best = 0.00000000\n",
      "x_eff  = [-0.02931459  0.11214227],\n",
      "\n",
      "iteration 857: f_best = 0.00000000\n",
      "x_eff  = [-0.05568777 -0.10924675],\n",
      "\n",
      "iteration 858: f_best = 0.00000000\n",
      "x_eff  = [ 0.03477738 -0.05313012],\n",
      "\n",
      "iteration 859: f_best = 0.00000000\n",
      "x_eff  = [ 0.08792499 -0.08771253],\n",
      "\n",
      "iteration 860: f_best = 0.00000000\n",
      "x_eff  = [0.06922195 0.0214542 ],\n",
      "\n",
      "iteration 861: f_best = 0.00000000\n",
      "x_eff  = [-0.08064424  0.02374935],\n",
      "\n",
      "iteration 862: f_best = 0.00000000\n",
      "x_eff  = [-0.05192533  0.09850836],\n",
      "\n",
      "iteration 863: f_best = 0.00000000\n",
      "x_eff  = [0.10221813 0.00364474],\n",
      "\n",
      "iteration 864: f_best = 0.00000000\n",
      "x_eff  = [-0.07797003 -0.08258206],\n",
      "\n",
      "iteration 865: f_best = 0.00000000\n",
      "x_eff  = [0.02739363 0.0804358 ],\n",
      "\n",
      "iteration 866: f_best = 0.00000000\n",
      "x_eff  = [0.1044153 0.0630863],\n",
      "\n",
      "iteration 867: f_best = 0.00000000\n",
      "x_eff  = [ 0.10251395 -0.08228575],\n",
      "\n",
      "iteration 868: f_best = 0.00000000\n",
      "x_eff  = [0.0371939  0.01007792],\n",
      "\n",
      "iteration 869: f_best = 0.00000000\n",
      "x_eff  = [ 0.0987166  -0.05898606],\n",
      "\n",
      "iteration 870: f_best = 0.00000000\n",
      "x_eff  = [-0.0895057  -0.01115744],\n",
      "\n",
      "iteration 871: f_best = 0.00000000\n",
      "x_eff  = [ 0.04414052 -0.06641156],\n",
      "\n",
      "iteration 872: f_best = 0.00000000\n",
      "x_eff  = [ 0.04473233 -0.02106956],\n",
      "\n",
      "iteration 873: f_best = 0.00000000\n",
      "x_eff  = [ 0.03637289 -0.07416611],\n",
      "\n",
      "iteration 874: f_best = 0.00000000\n",
      "x_eff  = [ 0.02504271 -0.05314814],\n",
      "\n",
      "iteration 875: f_best = 0.00000000\n",
      "x_eff  = [ 0.02654886 -0.0626705 ],\n",
      "\n",
      "iteration 876: f_best = 0.00000000\n",
      "x_eff  = [0.01816948 0.02804091],\n",
      "\n",
      "iteration 877: f_best = 0.00000000\n",
      "x_eff  = [-0.09687529 -0.03812941],\n",
      "\n",
      "iteration 878: f_best = 0.00000000\n",
      "x_eff  = [-0.04234663 -0.03954543],\n",
      "\n",
      "iteration 879: f_best = 0.00000000\n",
      "x_eff  = [-0.07251784 -0.01680309],\n",
      "\n",
      "iteration 880: f_best = 0.00000000\n",
      "x_eff  = [ 0.0249002  -0.02887662],\n",
      "\n",
      "iteration 881: f_best = 0.00000000\n",
      "x_eff  = [ 0.06957407 -0.03774873],\n",
      "\n",
      "iteration 882: f_best = 0.00000000\n",
      "x_eff  = [-0.09722626 -0.02036342],\n",
      "\n",
      "iteration 883: f_best = 0.00000000\n",
      "x_eff  = [-0.03289815 -0.06742432],\n",
      "\n",
      "iteration 884: f_best = 0.00000000\n",
      "x_eff  = [ 0.03915929 -0.07230706],\n",
      "\n",
      "iteration 885: f_best = 0.00000000\n",
      "x_eff  = [-0.02255428 -0.0124946 ],\n",
      "\n",
      "iteration 886: f_best = 0.00000000\n",
      "x_eff  = [-0.03471095 -0.0773743 ],\n",
      "\n",
      "iteration 887: f_best = 0.00000000\n",
      "x_eff  = [0.08375848 0.04011204],\n",
      "\n",
      "iteration 888: f_best = 0.00000000\n",
      "x_eff  = [ 0.08494901 -0.08281846],\n",
      "\n",
      "iteration 889: f_best = 0.00000000\n",
      "x_eff  = [ 0.06053856 -0.07110427],\n",
      "\n",
      "iteration 890: f_best = 0.00000000\n",
      "x_eff  = [-0.08733535  0.01327314],\n",
      "\n",
      "iteration 891: f_best = 0.00000000\n",
      "x_eff  = [-0.00291952  0.08043468],\n",
      "\n",
      "iteration 892: f_best = 0.00000000\n",
      "x_eff  = [-0.04877621  0.00050423],\n",
      "\n",
      "iteration 893: f_best = 0.00000000\n",
      "x_eff  = [-0.02367003 -0.00517416],\n",
      "\n",
      "iteration 894: f_best = 0.00000000\n",
      "x_eff  = [-0.04290523 -0.01928524],\n",
      "\n",
      "iteration 895: f_best = 0.00000000\n",
      "x_eff  = [0.02308285 0.03345631],\n",
      "\n",
      "iteration 896: f_best = 0.00000000\n",
      "x_eff  = [0.03579629 0.06466955],\n",
      "\n",
      "iteration 897: f_best = 0.00000000\n",
      "x_eff  = [ 0.03065297 -0.05870004],\n",
      "\n",
      "iteration 898: f_best = 0.00000000\n",
      "x_eff  = [-0.07487324 -0.03024473],\n",
      "\n",
      "iteration 899: f_best = 0.00000000\n",
      "x_eff  = [0.02366965 0.07832947],\n",
      "\n",
      "iteration 900: f_best = 0.00000000\n",
      "x_eff  = [ 0.01497228 -0.0039751 ],\n",
      "\n",
      "iteration 901: f_best = 0.00000000\n",
      "x_eff  = [ 0.03173644 -0.02596032],\n",
      "\n",
      "iteration 902: f_best = 0.00000000\n",
      "x_eff  = [-0.00949913 -0.06304472],\n",
      "\n",
      "iteration 903: f_best = 0.00000000\n",
      "x_eff  = [-0.0663179  -0.07215732],\n",
      "\n",
      "iteration 904: f_best = 0.00000000\n",
      "x_eff  = [-0.03825198  0.07697522],\n",
      "\n",
      "iteration 905: f_best = 0.00000000\n",
      "x_eff  = [ 0.05280917 -0.04947589],\n",
      "\n",
      "iteration 906: f_best = 0.00000000\n",
      "x_eff  = [ 0.00112138 -0.0767497 ],\n",
      "\n",
      "iteration 907: f_best = 0.00000000\n",
      "x_eff  = [-0.01098144 -0.0198236 ],\n",
      "\n",
      "iteration 908: f_best = 0.00000000\n",
      "x_eff  = [-0.00136301 -0.0409514 ],\n",
      "\n",
      "iteration 909: f_best = 0.00000000\n",
      "x_eff  = [0.03157366 0.01889941],\n",
      "\n",
      "iteration 910: f_best = 0.00000000\n",
      "x_eff  = [0.04593495 0.06910426],\n",
      "\n",
      "iteration 911: f_best = 0.00000000\n",
      "x_eff  = [-0.02884808  0.00019498],\n",
      "\n",
      "iteration 912: f_best = 0.00000000\n",
      "x_eff  = [0.02757369 0.07063416],\n",
      "\n",
      "iteration 913: f_best = 0.00000000\n",
      "x_eff  = [-0.0608868  -0.01277843],\n",
      "\n",
      "iteration 914: f_best = 0.00000000\n",
      "x_eff  = [-0.03531947 -0.06251019],\n",
      "\n",
      "iteration 915: f_best = 0.00000000\n",
      "x_eff  = [-0.06649406 -0.0042664 ],\n",
      "\n",
      "iteration 916: f_best = 0.00000000\n",
      "x_eff  = [-0.05152073 -0.05284974],\n",
      "\n",
      "iteration 917: f_best = 0.00000000\n",
      "x_eff  = [ 0.04744118 -0.0588194 ],\n",
      "\n",
      "iteration 918: f_best = 0.00000000\n",
      "x_eff  = [0.03014682 0.00127899],\n",
      "\n",
      "iteration 919: f_best = 0.00000000\n",
      "x_eff  = [ 0.0347242  -0.04878622],\n",
      "\n",
      "iteration 920: f_best = 0.00000000\n",
      "x_eff  = [0.04009652 0.00110182],\n",
      "\n",
      "iteration 921: f_best = 0.00000000\n",
      "x_eff  = [-0.06111798  0.01653464],\n",
      "\n",
      "iteration 922: f_best = 0.00000000\n",
      "x_eff  = [0.0279283  0.03117248],\n",
      "\n",
      "iteration 923: f_best = 0.00000000\n",
      "x_eff  = [-0.01915551  0.02636007],\n",
      "\n",
      "iteration 924: f_best = 0.00000000\n",
      "x_eff  = [0.00656217 0.05331297],\n",
      "\n",
      "iteration 925: f_best = 0.00000000\n",
      "x_eff  = [ 0.00073682 -0.03307302],\n",
      "\n",
      "iteration 926: f_best = 0.00000000\n",
      "x_eff  = [-0.04602318 -0.0556488 ],\n",
      "\n",
      "iteration 927: f_best = 0.00000000\n",
      "x_eff  = [0.03727667 0.02299529],\n",
      "\n",
      "iteration 928: f_best = 0.00000000\n",
      "x_eff  = [0.00354978 0.01445438],\n",
      "\n",
      "iteration 929: f_best = 0.00000000\n",
      "x_eff  = [-0.04936736  0.00881044],\n",
      "\n",
      "iteration 930: f_best = 0.00000000\n",
      "x_eff  = [ 0.0083804  -0.04474276],\n",
      "\n",
      "iteration 931: f_best = 0.00000000\n",
      "x_eff  = [0.0117093  0.02755001],\n",
      "\n",
      "iteration 932: f_best = 0.00000000\n",
      "x_eff  = [-0.03619785  0.04022118],\n",
      "\n",
      "iteration 933: f_best = 0.00000000\n",
      "x_eff  = [-0.02313544 -0.05233164],\n",
      "\n",
      "iteration 934: f_best = 0.00000000\n",
      "x_eff  = [ 0.04412899 -0.0386623 ],\n",
      "\n",
      "iteration 935: f_best = 0.00000000\n",
      "x_eff  = [ 0.05201708 -0.01839197],\n",
      "\n",
      "iteration 936: f_best = 0.00000000\n",
      "x_eff  = [ 0.02661498 -0.04861162],\n",
      "\n",
      "iteration 937: f_best = 0.00000000\n",
      "x_eff  = [ 0.03938353 -0.04309672],\n",
      "\n",
      "iteration 938: f_best = 0.00000000\n",
      "x_eff  = [ 0.00679584 -0.04330962],\n",
      "\n",
      "iteration 939: f_best = 0.00000000\n",
      "x_eff  = [-0.00999032  0.01316324],\n",
      "\n",
      "iteration 940: f_best = 0.00000000\n",
      "x_eff  = [-0.0143469  -0.01274202],\n",
      "\n",
      "iteration 941: f_best = 0.00000000\n",
      "x_eff  = [ 0.0432068  -0.00349011],\n",
      "\n",
      "iteration 942: f_best = 0.00000000\n",
      "x_eff  = [ 0.03389698 -0.01110245],\n",
      "\n",
      "iteration 943: f_best = 0.00000000\n",
      "x_eff  = [ 0.01016624 -0.05146113],\n",
      "\n",
      "iteration 944: f_best = 0.00000000\n",
      "x_eff  = [ 0.00621929 -0.04480973],\n",
      "\n",
      "iteration 945: f_best = 0.00000000\n",
      "x_eff  = [-0.01539309  0.02283585],\n",
      "\n",
      "iteration 946: f_best = 0.00000000\n",
      "x_eff  = [-0.04816457 -0.01034948],\n",
      "\n",
      "iteration 947: f_best = 0.00000000\n",
      "x_eff  = [-0.02113384  0.03871871],\n",
      "\n",
      "iteration 948: f_best = 0.00000000\n",
      "x_eff  = [-0.02064773  0.02893156],\n",
      "\n",
      "iteration 949: f_best = 0.00000000\n",
      "x_eff  = [0.01876008 0.00267075],\n",
      "\n",
      "iteration 950: f_best = 0.00000000\n",
      "x_eff  = [-0.02765882  0.00993109],\n",
      "\n",
      "iteration 951: f_best = 0.00000000\n",
      "x_eff  = [0.00259952 0.03715889],\n",
      "\n",
      "iteration 952: f_best = 0.00000000\n",
      "x_eff  = [0.02524731 0.00460044],\n",
      "\n",
      "iteration 953: f_best = 0.00000000\n",
      "x_eff  = [-0.01480844  0.00472275],\n",
      "\n",
      "iteration 954: f_best = 0.00000000\n",
      "x_eff  = [0.00484552 0.01481725],\n",
      "\n",
      "iteration 955: f_best = 0.00000000\n",
      "x_eff  = [ 0.0408268  -0.04087219],\n",
      "\n",
      "iteration 956: f_best = 0.00000000\n",
      "x_eff  = [ 0.03358012 -0.00496298],\n",
      "\n",
      "iteration 957: f_best = 0.00000000\n",
      "x_eff  = [-0.02567751  0.04599398],\n",
      "\n",
      "iteration 958: f_best = 0.00000000\n",
      "x_eff  = [-0.02998156  0.00332208],\n",
      "\n",
      "iteration 959: f_best = 0.00000000\n",
      "x_eff  = [-0.0437081   0.03822239],\n",
      "\n",
      "iteration 960: f_best = 0.00000000\n",
      "x_eff  = [0.0169807  0.00191592],\n",
      "\n",
      "iteration 961: f_best = 0.00000000\n",
      "x_eff  = [-0.0293142  -0.02314617],\n",
      "\n",
      "iteration 962: f_best = 0.00000000\n",
      "x_eff  = [ 0.01604136 -0.01637784],\n",
      "\n",
      "iteration 963: f_best = 0.00000000\n",
      "x_eff  = [-0.00616043  0.02037391],\n",
      "\n",
      "iteration 964: f_best = 0.00000000\n",
      "x_eff  = [-0.03452167  0.03288137],\n",
      "\n",
      "iteration 965: f_best = 0.00000000\n",
      "x_eff  = [ 0.03740091 -0.01741176],\n",
      "\n",
      "iteration 966: f_best = 0.00000000\n",
      "x_eff  = [0.03259901 0.00836425],\n",
      "\n",
      "iteration 967: f_best = 0.00000000\n",
      "x_eff  = [ 0.00937742 -0.02902919],\n",
      "\n",
      "iteration 968: f_best = 0.00000000\n",
      "x_eff  = [0.03912318 0.00430561],\n",
      "\n",
      "iteration 969: f_best = 0.00000000\n",
      "x_eff  = [-0.0184828   0.01937963],\n",
      "\n",
      "iteration 970: f_best = 0.00000000\n",
      "x_eff  = [ 0.02710915 -0.04048431],\n",
      "\n",
      "iteration 971: f_best = 0.00000000\n",
      "x_eff  = [-0.02162801  0.0064191 ],\n",
      "\n",
      "iteration 972: f_best = 0.00000000\n",
      "x_eff  = [ 0.00513429 -0.03727784],\n",
      "\n",
      "iteration 973: f_best = 0.00000000\n",
      "x_eff  = [-0.03515319  0.01433368],\n",
      "\n",
      "iteration 974: f_best = 0.00000000\n",
      "x_eff  = [ 0.02760603 -0.00602376],\n",
      "\n",
      "iteration 975: f_best = 0.00000000\n",
      "x_eff  = [ 0.02059686 -0.03100765],\n",
      "\n",
      "iteration 976: f_best = 0.00000000\n",
      "x_eff  = [-0.01154683 -0.00308958],\n",
      "\n",
      "iteration 977: f_best = 0.00000000\n",
      "x_eff  = [-0.02789612 -0.01212343],\n",
      "\n",
      "iteration 978: f_best = 0.00000000\n",
      "x_eff  = [-0.00638909  0.01493711],\n",
      "\n",
      "iteration 979: f_best = 0.00000000\n",
      "x_eff  = [-0.02488462  0.02539955],\n",
      "\n",
      "iteration 980: f_best = 0.00000000\n",
      "x_eff  = [0.0205802  0.03628166],\n",
      "\n",
      "iteration 981: f_best = 0.00000000\n",
      "x_eff  = [-0.0135068  0.0164692],\n",
      "\n",
      "iteration 982: f_best = 0.00000000\n",
      "x_eff  = [-0.02312732 -0.01507563],\n",
      "\n",
      "iteration 983: f_best = 0.00000000\n",
      "x_eff  = [ 0.0123273 -0.0291999],\n",
      "\n",
      "iteration 984: f_best = 0.00000000\n",
      "x_eff  = [-0.03426907  0.00144957],\n",
      "\n",
      "iteration 985: f_best = 0.00000000\n",
      "x_eff  = [-0.02373346 -0.01571897],\n",
      "\n",
      "iteration 986: f_best = 0.00000000\n",
      "x_eff  = [ 0.02358932 -0.00645019],\n",
      "\n",
      "iteration 987: f_best = 0.00000000\n",
      "x_eff  = [-0.01276292 -0.0285963 ],\n",
      "\n",
      "iteration 988: f_best = 0.00000000\n",
      "x_eff  = [ 0.01592529 -0.02527379],\n",
      "\n",
      "iteration 989: f_best = 0.00000000\n",
      "x_eff  = [-0.02286333  0.01963284],\n",
      "\n",
      "iteration 990: f_best = 0.00000000\n",
      "x_eff  = [-0.01539315  0.02792914],\n",
      "\n",
      "iteration 991: f_best = 0.00000000\n",
      "x_eff  = [-0.01231941 -0.02564749],\n",
      "\n",
      "iteration 992: f_best = 0.00000000\n",
      "x_eff  = [ 0.00833007 -0.03089706],\n",
      "\n",
      "iteration 993: f_best = 0.00000000\n",
      "x_eff  = [ 0.02714388 -0.02590436],\n",
      "\n",
      "iteration 994: f_best = 0.00000000\n",
      "x_eff  = [-0.02965259  0.00279765],\n",
      "\n",
      "iteration 995: f_best = 0.00000000\n",
      "x_eff  = [-0.02327523  0.0012838 ],\n",
      "\n",
      "iteration 996: f_best = 0.00000000\n",
      "x_eff  = [-0.01938333  0.01528196],\n",
      "\n",
      "iteration 997: f_best = 0.00000000\n",
      "x_eff  = [ 0.01658457 -0.01249943],\n",
      "\n",
      "iteration 998: f_best = 0.00000000\n",
      "x_eff  = [0.01949625 0.02227941],\n",
      "\n",
      "iteration 999: f_best = 0.00000000\n",
      "x_eff  = [-0.00783315 -0.02433848],\n",
      "\n",
      "iteration 100: f_best = 0.46097382\n",
      "x_eff  = [ 15.70011    -39.94599389],\n",
      "\n",
      "iteration 101: f_best = 0.46097382\n",
      "x_eff  = [  41.00746591 -252.35527531],\n",
      "\n",
      "iteration 102: f_best = 0.46097382\n",
      "x_eff  = [19.28606448 93.91378823],\n",
      "\n",
      "iteration 103: f_best = 0.46097382\n",
      "x_eff  = [ 184.73495443 -127.28103391],\n",
      "\n",
      "iteration 104: f_best = 0.46097382\n",
      "x_eff  = [282.40391058 154.39438397],\n",
      "\n",
      "iteration 105: f_best = 0.46097382\n",
      "x_eff  = [-232.52709404  116.98514513],\n",
      "\n",
      "iteration 106: f_best = 0.46097382\n",
      "x_eff  = [281.62596324 242.00943339],\n",
      "\n",
      "iteration 107: f_best = 0.46097382\n",
      "x_eff  = [  18.49887029 -176.32912993],\n",
      "\n",
      "iteration 108: f_best = 0.46097382\n",
      "x_eff  = [-61.85622047  87.38814945],\n",
      "\n",
      "iteration 109: f_best = 0.46097382\n",
      "x_eff  = [101.78988221 222.23130297],\n",
      "\n",
      "iteration 110: f_best = 0.46097382\n",
      "x_eff  = [ 231.28008396 -262.39186912],\n",
      "\n",
      "iteration 111: f_best = 0.46097382\n",
      "x_eff  = [  96.24213913 -181.08127575],\n",
      "\n",
      "iteration 112: f_best = 0.46097382\n",
      "x_eff  = [161.98309288 100.07938565],\n",
      "\n",
      "iteration 113: f_best = 0.46097382\n",
      "x_eff  = [124.45142545 193.53851902],\n",
      "\n",
      "iteration 114: f_best = 0.46097382\n",
      "x_eff  = [-256.19995624 -235.63973371],\n",
      "\n",
      "iteration 115: f_best = 0.46097382\n",
      "x_eff  = [-196.96008527   99.60240033],\n",
      "\n",
      "iteration 116: f_best = 0.46097382\n",
      "x_eff  = [-62.67015696 -17.23128313],\n",
      "\n",
      "iteration 117: f_best = 0.46097382\n",
      "x_eff  = [  19.6625014  -107.94697998],\n",
      "\n",
      "iteration 118: f_best = 0.46097382\n",
      "x_eff  = [ 247.42886675 -232.80756715],\n",
      "\n",
      "iteration 119: f_best = 0.42171226\n",
      "x_eff  = [234.26700735 -10.97246983],\n",
      "\n",
      "iteration 120: f_best = 0.42171226\n",
      "x_eff  = [-24.86409238 233.65626087],\n",
      "\n",
      "iteration 121: f_best = 0.42171226\n",
      "x_eff  = [ 33.17655659 239.70539688],\n",
      "\n",
      "iteration 122: f_best = 0.42171226\n",
      "x_eff  = [-23.08556647  59.82254941],\n",
      "\n",
      "iteration 123: f_best = 0.42171226\n",
      "x_eff  = [230.16076093 198.89821422],\n",
      "\n",
      "iteration 124: f_best = 0.42171226\n",
      "x_eff  = [  62.89264065 -176.81917998],\n",
      "\n",
      "iteration 125: f_best = 0.42171226\n",
      "x_eff  = [  -9.58561428 -123.88095321],\n",
      "\n",
      "iteration 126: f_best = 0.42171226\n",
      "x_eff  = [-114.91784584  -43.26541467],\n",
      "\n",
      "iteration 127: f_best = 0.42171226\n",
      "x_eff  = [-269.94794961    6.37252174],\n",
      "\n",
      "iteration 128: f_best = 0.42171226\n",
      "x_eff  = [ 62.52891644 146.56550615],\n",
      "\n",
      "iteration 129: f_best = 0.42171226\n",
      "x_eff  = [110.76499266 185.49136372],\n",
      "\n",
      "iteration 130: f_best = 0.42171226\n",
      "x_eff  = [ 30.67035741 188.41825048],\n",
      "\n",
      "iteration 131: f_best = 0.42171226\n",
      "x_eff  = [126.04916449 181.61267805],\n",
      "\n",
      "iteration 132: f_best = 0.42171226\n",
      "x_eff  = [ -14.8505942  -150.18156785],\n",
      "\n",
      "iteration 133: f_best = 0.42171226\n",
      "x_eff  = [-196.61326143  108.4227484 ],\n",
      "\n",
      "iteration 134: f_best = 0.42171226\n",
      "x_eff  = [-143.39373161   71.70872724],\n",
      "\n",
      "iteration 135: f_best = 0.42171226\n",
      "x_eff  = [54.15638826 41.17833323],\n",
      "\n",
      "iteration 136: f_best = 0.42171226\n",
      "x_eff  = [200.91154897 144.0111254 ],\n",
      "\n",
      "iteration 137: f_best = 0.42171226\n",
      "x_eff  = [-235.06251563 -192.4616098 ],\n",
      "\n",
      "iteration 138: f_best = 0.42171226\n",
      "x_eff  = [-32.01619023 227.94724815],\n",
      "\n",
      "iteration 139: f_best = 0.42171226\n",
      "x_eff  = [110.05661231 -57.99857533],\n",
      "\n",
      "iteration 140: f_best = 0.42171226\n",
      "x_eff  = [104.20035393  87.82871819],\n",
      "\n",
      "iteration 141: f_best = 0.42171226\n",
      "x_eff  = [-175.04119225  232.64373263],\n",
      "\n",
      "iteration 142: f_best = 0.42171226\n",
      "x_eff  = [177.2359281  194.95498567],\n",
      "\n",
      "iteration 143: f_best = 0.42171226\n",
      "x_eff  = [209.03625206 198.90802809],\n",
      "\n",
      "iteration 144: f_best = 0.42171226\n",
      "x_eff  = [  29.57012304 -205.31099188],\n",
      "\n",
      "iteration 145: f_best = 0.42171226\n",
      "x_eff  = [-144.63057248  233.12200548],\n",
      "\n",
      "iteration 146: f_best = 0.42171226\n",
      "x_eff  = [ 180.69731657 -149.88691111],\n",
      "\n",
      "iteration 147: f_best = 0.42171226\n",
      "x_eff  = [114.61703155 120.84168854],\n",
      "\n",
      "iteration 148: f_best = 0.42171226\n",
      "x_eff  = [  -4.32008819 -205.14025108],\n",
      "\n",
      "iteration 149: f_best = 0.42171226\n",
      "x_eff  = [-58.73256316 100.44593043],\n",
      "\n",
      "iteration 150: f_best = 0.42171226\n",
      "x_eff  = [-250.67843402 -222.10708098],\n",
      "\n",
      "iteration 151: f_best = 0.42171226\n",
      "x_eff  = [ -6.34787121 223.05280002],\n",
      "\n",
      "iteration 152: f_best = 0.42171226\n",
      "x_eff  = [185.5596977  -18.38531704],\n",
      "\n",
      "iteration 153: f_best = 0.42171226\n",
      "x_eff  = [-231.82854754  179.47943598],\n",
      "\n",
      "iteration 154: f_best = 0.42171226\n",
      "x_eff  = [-105.31226169  -48.84762409],\n",
      "\n",
      "iteration 155: f_best = 0.42171226\n",
      "x_eff  = [-22.7755888  121.75461316],\n",
      "\n",
      "iteration 156: f_best = 0.42171226\n",
      "x_eff  = [103.24526548 -31.73650936],\n",
      "\n",
      "iteration 157: f_best = 0.42171226\n",
      "x_eff  = [-218.25072018 -171.19189755],\n",
      "\n",
      "iteration 158: f_best = 0.42171226\n",
      "x_eff  = [113.90731401 143.6640849 ],\n",
      "\n",
      "iteration 159: f_best = 0.42171226\n",
      "x_eff  = [102.77790605 165.94974435],\n",
      "\n",
      "iteration 160: f_best = 0.42171226\n",
      "x_eff  = [-21.14968359 -43.58700253],\n",
      "\n",
      "iteration 161: f_best = 0.42171226\n",
      "x_eff  = [-75.84228199 -84.41647028],\n",
      "\n",
      "iteration 162: f_best = 0.42171226\n",
      "x_eff  = [150.60317587  12.9679915 ],\n",
      "\n",
      "iteration 163: f_best = 0.42171226\n",
      "x_eff  = [ 18.6255376  108.88757517],\n",
      "\n",
      "iteration 164: f_best = 0.42171226\n",
      "x_eff  = [  -6.2677723  -109.48272599],\n",
      "\n",
      "iteration 165: f_best = 0.24412845\n",
      "x_eff  = [28.47013037 -9.90942773],\n",
      "\n",
      "iteration 166: f_best = 0.24412845\n",
      "x_eff  = [103.48299783  93.5946622 ],\n",
      "\n",
      "iteration 167: f_best = 0.24412845\n",
      "x_eff  = [ -86.87613912 -205.68281217],\n",
      "\n",
      "iteration 168: f_best = 0.24412845\n",
      "x_eff  = [ 176.30236602 -181.87537361],\n",
      "\n",
      "iteration 169: f_best = 0.24412845\n",
      "x_eff  = [-159.03956805  -61.79192628],\n",
      "\n",
      "iteration 170: f_best = 0.24412845\n",
      "x_eff  = [-88.81922038 -32.17633277],\n",
      "\n",
      "iteration 171: f_best = 0.24412845\n",
      "x_eff  = [-134.88379228   10.47819395],\n",
      "\n",
      "iteration 172: f_best = 0.24412845\n",
      "x_eff  = [ -7.61251029 -44.07438129],\n",
      "\n",
      "iteration 173: f_best = 0.24412845\n",
      "x_eff  = [  11.41174103 -183.22700924],\n",
      "\n",
      "iteration 174: f_best = 0.24412845\n",
      "x_eff  = [189.40251869 -76.90272581],\n",
      "\n",
      "iteration 175: f_best = 0.24412845\n",
      "x_eff  = [-79.05469764  55.50007412],\n",
      "\n",
      "iteration 176: f_best = 0.24412845\n",
      "x_eff  = [-64.13030085 -73.22142286],\n",
      "\n",
      "iteration 177: f_best = 0.24412845\n",
      "x_eff  = [  1.91243135 -67.59280051],\n",
      "\n",
      "iteration 178: f_best = 0.24412845\n",
      "x_eff  = [-146.22663781  134.93676763],\n",
      "\n",
      "iteration 179: f_best = 0.24412845\n",
      "x_eff  = [-61.78913112 -40.46634281],\n",
      "\n",
      "iteration 180: f_best = 0.24412845\n",
      "x_eff  = [124.08359708 -74.9014019 ],\n",
      "\n",
      "iteration 181: f_best = 0.24412845\n",
      "x_eff  = [-107.97282811   -9.69603331],\n",
      "\n",
      "iteration 182: f_best = 0.24412845\n",
      "x_eff  = [-65.97532349   0.43278259],\n",
      "\n",
      "iteration 183: f_best = 0.24412845\n",
      "x_eff  = [ 191.91991744 -137.4561458 ],\n",
      "\n",
      "iteration 184: f_best = 0.02712538\n",
      "x_eff  = [-9.24339882 -7.89677751],\n",
      "\n",
      "iteration 185: f_best = 0.02712538\n",
      "x_eff  = [  7.91200071 -79.917044  ],\n",
      "\n",
      "iteration 186: f_best = 0.02712538\n",
      "x_eff  = [91.21266251  1.17931604],\n",
      "\n",
      "iteration 187: f_best = 0.02712538\n",
      "x_eff  = [149.12216579  56.35826077],\n",
      "\n",
      "iteration 188: f_best = 0.02712538\n",
      "x_eff  = [ 29.03972602 -35.85826651],\n",
      "\n",
      "iteration 189: f_best = 0.02712538\n",
      "x_eff  = [-146.4500289   154.04621534],\n",
      "\n",
      "iteration 190: f_best = 0.02712538\n",
      "x_eff  = [56.34206764 26.83738902],\n",
      "\n",
      "iteration 191: f_best = 0.02712538\n",
      "x_eff  = [-10.19556488  78.3501375 ],\n",
      "\n",
      "iteration 192: f_best = 0.02712538\n",
      "x_eff  = [101.13392058 -47.92091825],\n",
      "\n",
      "iteration 193: f_best = 0.02712538\n",
      "x_eff  = [-160.47885381  114.45498008],\n",
      "\n",
      "iteration 194: f_best = 0.02712538\n",
      "x_eff  = [151.75926369  87.95055318],\n",
      "\n",
      "iteration 195: f_best = 0.02712538\n",
      "x_eff  = [-127.07062475   75.58893088],\n",
      "\n",
      "iteration 196: f_best = 0.02712538\n",
      "x_eff  = [128.10546474 121.53479856],\n",
      "\n",
      "iteration 197: f_best = 0.02712538\n",
      "x_eff  = [ 23.74267576 -41.98153562],\n",
      "\n",
      "iteration 198: f_best = 0.02712538\n",
      "x_eff  = [-125.7302025   -38.15250408],\n",
      "\n",
      "iteration 199: f_best = 0.02712538\n",
      "x_eff  = [132.1679045  -40.52493563],\n",
      "\n",
      "iteration 200: f_best = 0.02712538\n",
      "x_eff  = [-128.08702518  -87.19260414],\n",
      "\n",
      "iteration 201: f_best = 0.02712538\n",
      "x_eff  = [ 14.36151858 125.39661014],\n",
      "\n",
      "iteration 202: f_best = 0.02712538\n",
      "x_eff  = [-39.43847184  42.12524436],\n",
      "\n",
      "iteration 203: f_best = 0.02712538\n",
      "x_eff  = [-60.43610841   8.99081592],\n",
      "\n",
      "iteration 204: f_best = 0.02712538\n",
      "x_eff  = [ 32.59925286 -65.0637544 ],\n",
      "\n",
      "iteration 205: f_best = 0.02712538\n",
      "x_eff  = [ -73.11311902 -114.07210258],\n",
      "\n",
      "iteration 206: f_best = 0.02712538\n",
      "x_eff  = [ 20.0062949  -80.85348091],\n",
      "\n",
      "iteration 207: f_best = 0.02712538\n",
      "x_eff  = [-45.64036567  -0.46869833],\n",
      "\n",
      "iteration 208: f_best = 0.02712538\n",
      "x_eff  = [-72.78685803 -27.34126179],\n",
      "\n",
      "iteration 209: f_best = 0.02712538\n",
      "x_eff  = [135.71133699 -15.4939625 ],\n",
      "\n",
      "iteration 210: f_best = 0.02712538\n",
      "x_eff  = [  30.0663739  -110.88862994],\n",
      "\n",
      "iteration 211: f_best = 0.02712538\n",
      "x_eff  = [-147.39418724  -70.4256071 ],\n",
      "\n",
      "iteration 212: f_best = 0.02712538\n",
      "x_eff  = [122.86835319 137.87572293],\n",
      "\n",
      "iteration 213: f_best = 0.02712538\n",
      "x_eff  = [-68.27212254 -86.53098718],\n",
      "\n",
      "iteration 214: f_best = 0.02712538\n",
      "x_eff  = [-89.75421437 -83.1882372 ],\n",
      "\n",
      "iteration 215: f_best = 0.02712538\n",
      "x_eff  = [ -75.49689792 -136.56745958],\n",
      "\n",
      "iteration 216: f_best = 0.02712538\n",
      "x_eff  = [114.10083036 134.22511119],\n",
      "\n",
      "iteration 217: f_best = 0.02712538\n",
      "x_eff  = [-80.14019904  94.10820198],\n",
      "\n",
      "iteration 218: f_best = 0.02712538\n",
      "x_eff  = [ 21.65290012 119.03868303],\n",
      "\n",
      "iteration 219: f_best = 0.02712538\n",
      "x_eff  = [-36.52800015  -2.46617374],\n",
      "\n",
      "iteration 220: f_best = 0.02712538\n",
      "x_eff  = [21.61630181 54.56186603],\n",
      "\n",
      "iteration 221: f_best = 0.02712538\n",
      "x_eff  = [58.77442852 76.37238122],\n",
      "\n",
      "iteration 222: f_best = 0.02712538\n",
      "x_eff  = [77.23525487 69.43222532],\n",
      "\n",
      "iteration 223: f_best = 0.02712538\n",
      "x_eff  = [15.92730324 18.40176871],\n",
      "\n",
      "iteration 224: f_best = 0.02712538\n",
      "x_eff  = [  60.32362048 -131.45754302],\n",
      "\n",
      "iteration 225: f_best = 0.02712538\n",
      "x_eff  = [ 57.19342549 113.79427518],\n",
      "\n",
      "iteration 226: f_best = 0.02712538\n",
      "x_eff  = [ 90.15264762 -23.76911518],\n",
      "\n",
      "iteration 227: f_best = 0.02712538\n",
      "x_eff  = [-41.37555672  16.63904424],\n",
      "\n",
      "iteration 228: f_best = 0.02712538\n",
      "x_eff  = [  90.36016783 -130.77644313],\n",
      "\n",
      "iteration 229: f_best = 0.02712538\n",
      "x_eff  = [ -12.56351273 -117.32079023],\n",
      "\n",
      "iteration 230: f_best = 0.02712538\n",
      "x_eff  = [-30.53241352  57.75678513],\n",
      "\n",
      "iteration 231: f_best = 0.02712538\n",
      "x_eff  = [-21.29507065   2.39036681],\n",
      "\n",
      "iteration 232: f_best = 0.02712538\n",
      "x_eff  = [65.92726679  2.72854373],\n",
      "\n",
      "iteration 233: f_best = 0.02712538\n",
      "x_eff  = [51.46862919 52.7851333 ],\n",
      "\n",
      "iteration 234: f_best = 0.02712538\n",
      "x_eff  = [ 86.02610504 -45.95729596],\n",
      "\n",
      "iteration 235: f_best = 0.02712538\n",
      "x_eff  = [-1.4668882  52.80855748],\n",
      "\n",
      "iteration 236: f_best = 0.02712538\n",
      "x_eff  = [ 77.86257388 -26.57404539],\n",
      "\n",
      "iteration 237: f_best = 0.02712538\n",
      "x_eff  = [12.22371744 98.63242719],\n",
      "\n",
      "iteration 238: f_best = 0.02712538\n",
      "x_eff  = [ 43.98865118 -36.08215152],\n",
      "\n",
      "iteration 239: f_best = 0.02712538\n",
      "x_eff  = [53.86442375 -0.45358584],\n",
      "\n",
      "iteration 240: f_best = 0.02712538\n",
      "x_eff  = [109.61577867  54.58991376],\n",
      "\n",
      "iteration 241: f_best = 0.02712538\n",
      "x_eff  = [-70.04017166  10.59360243],\n",
      "\n",
      "iteration 242: f_best = 0.02712538\n",
      "x_eff  = [-100.31239134  -34.45579899],\n",
      "\n",
      "iteration 243: f_best = 0.02712538\n",
      "x_eff  = [  50.96063142 -112.53832953],\n",
      "\n",
      "iteration 244: f_best = 0.02712538\n",
      "x_eff  = [ 14.52706812 -71.26844253],\n",
      "\n",
      "iteration 245: f_best = 0.02712538\n",
      "x_eff  = [101.96447218 100.72520864],\n",
      "\n",
      "iteration 246: f_best = 0.02712538\n",
      "x_eff  = [  1.773918   -88.25955935],\n",
      "\n",
      "iteration 247: f_best = 0.02712538\n",
      "x_eff  = [-21.85122886 -59.41748966],\n",
      "\n",
      "iteration 248: f_best = 0.02712538\n",
      "x_eff  = [35.63622335 -3.93226009],\n",
      "\n",
      "iteration 249: f_best = 0.02712538\n",
      "x_eff  = [ -12.21698893 -111.47166048],\n",
      "\n",
      "iteration 250: f_best = 0.02712538\n",
      "x_eff  = [  38.7637999  -110.17527481],\n",
      "\n",
      "iteration 251: f_best = 0.02712538\n",
      "x_eff  = [74.62906517 40.10917492],\n",
      "\n",
      "iteration 252: f_best = 0.02712538\n",
      "x_eff  = [24.56663249 69.60321621],\n",
      "\n",
      "iteration 253: f_best = 0.02712538\n",
      "x_eff  = [ 82.67900928 -95.38128095],\n",
      "\n",
      "iteration 254: f_best = 0.02712538\n",
      "x_eff  = [ 41.64042061 -26.63838212],\n",
      "\n",
      "iteration 255: f_best = 0.02712538\n",
      "x_eff  = [64.72611392  6.26709344],\n",
      "\n",
      "iteration 256: f_best = 0.02712538\n",
      "x_eff  = [21.60807783 52.59176782],\n",
      "\n",
      "iteration 257: f_best = 0.02712538\n",
      "x_eff  = [-6.9128961  44.34240453],\n",
      "\n",
      "iteration 258: f_best = 0.02712538\n",
      "x_eff  = [-89.67244563  54.28764943],\n",
      "\n",
      "iteration 259: f_best = 0.02712538\n",
      "x_eff  = [27.74131672  8.90183537],\n",
      "\n",
      "iteration 260: f_best = 0.02712538\n",
      "x_eff  = [ 7.73287644 60.52706557],\n",
      "\n",
      "iteration 261: f_best = 0.02712538\n",
      "x_eff  = [-50.8389234  72.8374659],\n",
      "\n",
      "iteration 262: f_best = 0.02712538\n",
      "x_eff  = [ 19.16022217 -73.78221657],\n",
      "\n",
      "iteration 263: f_best = 0.02712538\n",
      "x_eff  = [-28.89255734 -39.64448669],\n",
      "\n",
      "iteration 264: f_best = 0.02712538\n",
      "x_eff  = [-65.16251363 -71.70074983],\n",
      "\n",
      "iteration 265: f_best = 0.02712538\n",
      "x_eff  = [54.90258127 28.08632762],\n",
      "\n",
      "iteration 266: f_best = 0.02712538\n",
      "x_eff  = [ 13.52749952 -54.73853046],\n",
      "\n",
      "iteration 267: f_best = 0.02712538\n",
      "x_eff  = [ 71.11093074 -54.05690298],\n",
      "\n",
      "iteration 268: f_best = 0.02712538\n",
      "x_eff  = [ 69.89200496 -79.60001698],\n",
      "\n",
      "iteration 269: f_best = 0.02712538\n",
      "x_eff  = [ 39.81992507 -23.94425285],\n",
      "\n",
      "iteration 270: f_best = 0.02712538\n",
      "x_eff  = [36.74462943 62.90387691],\n",
      "\n",
      "iteration 271: f_best = 0.02712538\n",
      "x_eff  = [38.50886587 -3.90937656],\n",
      "\n",
      "iteration 272: f_best = 0.02712538\n",
      "x_eff  = [81.30348829 20.60581584],\n",
      "\n",
      "iteration 273: f_best = 0.02712538\n",
      "x_eff  = [  0.21304873 -65.89842878],\n",
      "\n",
      "iteration 274: f_best = 0.02712538\n",
      "x_eff  = [ 23.44261276 -87.82149876],\n",
      "\n",
      "iteration 275: f_best = 0.02712538\n",
      "x_eff  = [74.25648961 38.03478232],\n",
      "\n",
      "iteration 276: f_best = 0.02712538\n",
      "x_eff  = [-80.90477362 -26.84771777],\n",
      "\n",
      "iteration 277: f_best = 0.02712538\n",
      "x_eff  = [62.02140527 41.34832791],\n",
      "\n",
      "iteration 278: f_best = 0.02712538\n",
      "x_eff  = [-7.08556666 17.32618426],\n",
      "\n",
      "iteration 279: f_best = 0.02712538\n",
      "x_eff  = [  2.84859241 -77.68969198],\n",
      "\n",
      "iteration 280: f_best = 0.02712538\n",
      "x_eff  = [ 12.96758495 -51.55626884],\n",
      "\n",
      "iteration 281: f_best = 0.02712538\n",
      "x_eff  = [ 51.08388018 -18.88781987],\n",
      "\n",
      "iteration 282: f_best = 0.02712538\n",
      "x_eff  = [-74.42443803 -28.20538736],\n",
      "\n",
      "iteration 283: f_best = 0.02712538\n",
      "x_eff  = [ 9.29114809 32.88199347],\n",
      "\n",
      "iteration 284: f_best = 0.02712538\n",
      "x_eff  = [  9.19762403 -65.43390525],\n",
      "\n",
      "iteration 285: f_best = 0.02712538\n",
      "x_eff  = [-38.54221104  51.23499093],\n",
      "\n",
      "iteration 286: f_best = 0.02712538\n",
      "x_eff  = [-55.22219478  18.11651871],\n",
      "\n",
      "iteration 287: f_best = 0.02712538\n",
      "x_eff  = [ 40.0802486  -41.51221669],\n",
      "\n",
      "iteration 288: f_best = 0.02712538\n",
      "x_eff  = [66.12267597 74.40881453],\n",
      "\n",
      "iteration 289: f_best = 0.02712538\n",
      "x_eff  = [-42.59778528 -27.62670233],\n",
      "\n",
      "iteration 290: f_best = 0.02712538\n",
      "x_eff  = [-79.22594376 -13.81694851],\n",
      "\n",
      "iteration 291: f_best = 0.02712538\n",
      "x_eff  = [31.19477907  6.97800626],\n",
      "\n",
      "iteration 292: f_best = 0.02712538\n",
      "x_eff  = [16.89185431  8.52343928],\n",
      "\n",
      "iteration 293: f_best = 0.02712538\n",
      "x_eff  = [ 29.99106302 -41.15371606],\n",
      "\n",
      "iteration 294: f_best = 0.02712538\n",
      "x_eff  = [ 50.62387377 -56.61502478],\n",
      "\n",
      "iteration 295: f_best = 0.02712538\n",
      "x_eff  = [-62.6478054  -68.96757765],\n",
      "\n",
      "iteration 296: f_best = 0.02712538\n",
      "x_eff  = [-33.05987181  -1.84087778],\n",
      "\n",
      "iteration 297: f_best = 0.02712538\n",
      "x_eff  = [ 4.56190972 38.62674501],\n",
      "\n",
      "iteration 298: f_best = 0.02712538\n",
      "x_eff  = [16.65031123 57.55781328],\n",
      "\n",
      "iteration 299: f_best = 0.02712538\n",
      "x_eff  = [-59.68751325 -55.61380404],\n",
      "\n",
      "iteration 300: f_best = 0.02712538\n",
      "x_eff  = [ 0.06634753 36.96974017],\n",
      "\n",
      "iteration 301: f_best = 0.02712538\n",
      "x_eff  = [-37.82359019 -25.05463306],\n",
      "\n",
      "iteration 302: f_best = 0.02712538\n",
      "x_eff  = [ 38.73179242 -39.88397147],\n",
      "\n",
      "iteration 303: f_best = 0.02712538\n",
      "x_eff  = [ 26.89992932 -19.28359913],\n",
      "\n",
      "iteration 304: f_best = 0.02712538\n",
      "x_eff  = [ -8.36602621 -42.18765512],\n",
      "\n",
      "iteration 305: f_best = 0.02712538\n",
      "x_eff  = [ 3.77000035 51.41760192],\n",
      "\n",
      "iteration 306: f_best = 0.02712538\n",
      "x_eff  = [ 30.35104677 -37.35170412],\n",
      "\n",
      "iteration 307: f_best = 0.02712538\n",
      "x_eff  = [-17.10880848  25.36282714],\n",
      "\n",
      "iteration 308: f_best = 0.02712538\n",
      "x_eff  = [  4.30713966 -27.11291526],\n",
      "\n",
      "iteration 309: f_best = 0.02712538\n",
      "x_eff  = [49.96805211 32.5353296 ],\n",
      "\n",
      "iteration 310: f_best = 0.02712538\n",
      "x_eff  = [  2.07893323 -38.72501265],\n",
      "\n",
      "iteration 311: f_best = 0.02712538\n",
      "x_eff  = [-13.50590104   1.91012908],\n",
      "\n",
      "iteration 312: f_best = 0.02712538\n",
      "x_eff  = [27.81141736  3.47042041],\n",
      "\n",
      "iteration 313: f_best = 0.02712538\n",
      "x_eff  = [-23.84441545 -25.60046757],\n",
      "\n",
      "iteration 314: f_best = 0.02712538\n",
      "x_eff  = [53.972316   46.35955044],\n",
      "\n",
      "iteration 315: f_best = 0.02712538\n",
      "x_eff  = [ 45.33567047 -11.40839135],\n",
      "\n",
      "iteration 316: f_best = 0.02712538\n",
      "x_eff  = [24.58834565  9.09827174],\n",
      "\n",
      "iteration 317: f_best = 0.02712538\n",
      "x_eff  = [30.71440387 56.95538865],\n",
      "\n",
      "iteration 318: f_best = 0.02712538\n",
      "x_eff  = [ 6.62222289 53.60089124],\n",
      "\n",
      "iteration 319: f_best = 0.02712538\n",
      "x_eff  = [9.35443277 4.71628494],\n",
      "\n",
      "iteration 320: f_best = 0.02712538\n",
      "x_eff  = [-46.80155783 -39.02217733],\n",
      "\n",
      "iteration 321: f_best = 0.02712538\n",
      "x_eff  = [-20.94219086 -36.69516098],\n",
      "\n",
      "iteration 322: f_best = 0.02712538\n",
      "x_eff  = [-3.43491613 59.32754341],\n",
      "\n",
      "iteration 323: f_best = 0.02712538\n",
      "x_eff  = [-11.55014734  45.02672837],\n",
      "\n",
      "iteration 324: f_best = 0.02712538\n",
      "x_eff  = [-22.50074492 -15.04601437],\n",
      "\n",
      "iteration 325: f_best = 0.02712538\n",
      "x_eff  = [ 16.57491635 -29.47443634],\n",
      "\n",
      "iteration 326: f_best = 0.02712538\n",
      "x_eff  = [-45.1063324   16.55951078],\n",
      "\n",
      "iteration 327: f_best = 0.02712538\n",
      "x_eff  = [-28.14762432 -49.53819083],\n",
      "\n",
      "iteration 328: f_best = 0.02712538\n",
      "x_eff  = [  7.1226129  -11.64277799],\n",
      "\n",
      "iteration 329: f_best = 0.02712538\n",
      "x_eff  = [ 19.65987939 -30.04798293],\n",
      "\n",
      "iteration 330: f_best = 0.02712538\n",
      "x_eff  = [-36.42393144  -3.37032148],\n",
      "\n",
      "iteration 331: f_best = 0.02712538\n",
      "x_eff  = [45.4899364   7.00462552],\n",
      "\n",
      "iteration 332: f_best = 0.02712538\n",
      "x_eff  = [ 20.72343985 -44.7525438 ],\n",
      "\n",
      "iteration 333: f_best = 0.00739604\n",
      "x_eff  = [5.61725291 4.88868136],\n",
      "\n",
      "iteration 334: f_best = 0.00739604\n",
      "x_eff  = [-35.72055071  51.92230804],\n",
      "\n",
      "iteration 335: f_best = 0.00739604\n",
      "x_eff  = [-46.63397987  47.34016174],\n",
      "\n",
      "iteration 336: f_best = 0.00739604\n",
      "x_eff  = [-45.41388282  21.60431625],\n",
      "\n",
      "iteration 337: f_best = 0.00739604\n",
      "x_eff  = [45.92537543 45.45392205],\n",
      "\n",
      "iteration 338: f_best = 0.00739604\n",
      "x_eff  = [-17.33894409  23.28120107],\n",
      "\n",
      "iteration 339: f_best = 0.00739604\n",
      "x_eff  = [-4.07370326 27.89972589],\n",
      "\n",
      "iteration 340: f_best = 0.00739604\n",
      "x_eff  = [-38.91362051 -15.65683693],\n",
      "\n",
      "iteration 341: f_best = 0.00739604\n",
      "x_eff  = [-13.01875367 -19.21082645],\n",
      "\n",
      "iteration 342: f_best = 0.00739604\n",
      "x_eff  = [-1.59515266 39.93839049],\n",
      "\n",
      "iteration 343: f_best = 0.00739604\n",
      "x_eff  = [ 38.84897813 -25.15092758],\n",
      "\n",
      "iteration 344: f_best = 0.00739604\n",
      "x_eff  = [-38.93874372   0.77405921],\n",
      "\n",
      "iteration 345: f_best = 0.00739604\n",
      "x_eff  = [ -3.1118028  -28.16875718],\n",
      "\n",
      "iteration 346: f_best = 0.00739604\n",
      "x_eff  = [-24.5248509  32.0733786],\n",
      "\n",
      "iteration 347: f_best = 0.00739604\n",
      "x_eff  = [20.12465025  7.476135  ],\n",
      "\n",
      "iteration 348: f_best = 0.00739604\n",
      "x_eff  = [ 48.40666555 -23.35332214],\n",
      "\n",
      "iteration 349: f_best = 0.00739604\n",
      "x_eff  = [-35.0284323   39.39857577],\n",
      "\n",
      "iteration 350: f_best = 0.00739604\n",
      "x_eff  = [-14.31624857  27.00499352],\n",
      "\n",
      "iteration 351: f_best = 0.00739604\n",
      "x_eff  = [ 47.3865986 -40.8187097],\n",
      "\n",
      "iteration 352: f_best = 0.00739604\n",
      "x_eff  = [ -5.82733137 -18.47779552],\n",
      "\n",
      "iteration 353: f_best = 0.00739604\n",
      "x_eff  = [-37.73337553  -1.65311468],\n",
      "\n",
      "iteration 354: f_best = 0.00739604\n",
      "x_eff  = [-37.07645735  32.46283679],\n",
      "\n",
      "iteration 355: f_best = 0.00739604\n",
      "x_eff  = [-1.28761213 44.24166572],\n",
      "\n",
      "iteration 356: f_best = 0.00739604\n",
      "x_eff  = [ 44.07824644 -16.69008057],\n",
      "\n",
      "iteration 357: f_best = 0.00739604\n",
      "x_eff  = [18.22295229 -5.16226894],\n",
      "\n",
      "iteration 358: f_best = 0.00739604\n",
      "x_eff  = [18.67034747 -7.73128118],\n",
      "\n",
      "iteration 359: f_best = 0.00739604\n",
      "x_eff  = [ 42.19866175 -17.81095073],\n",
      "\n",
      "iteration 360: f_best = 0.00739604\n",
      "x_eff  = [-16.06078052 -12.32801003],\n",
      "\n",
      "iteration 361: f_best = 0.00739604\n",
      "x_eff  = [32.11936329 27.19631114],\n",
      "\n",
      "iteration 362: f_best = 0.00739604\n",
      "x_eff  = [24.21299783  0.68859573],\n",
      "\n",
      "iteration 363: f_best = 0.00739604\n",
      "x_eff  = [15.53529605 10.94726236],\n",
      "\n",
      "iteration 364: f_best = 0.00739604\n",
      "x_eff  = [-29.2586486   37.52297995],\n",
      "\n",
      "iteration 365: f_best = 0.00739604\n",
      "x_eff  = [-27.80431306  10.57017463],\n",
      "\n",
      "iteration 366: f_best = 0.00739604\n",
      "x_eff  = [ 32.88739023 -26.52756899],\n",
      "\n",
      "iteration 367: f_best = 0.00739604\n",
      "x_eff  = [-32.80164902  32.87697714],\n",
      "\n",
      "iteration 368: f_best = 0.00739604\n",
      "x_eff  = [-27.97963412  15.45465387],\n",
      "\n",
      "iteration 369: f_best = 0.00739604\n",
      "x_eff  = [29.5639495  -6.43123815],\n",
      "\n",
      "iteration 370: f_best = 0.00739604\n",
      "x_eff  = [-18.11074107  25.55651863],\n",
      "\n",
      "iteration 371: f_best = 0.00739604\n",
      "x_eff  = [ 36.30765731 -31.88803492],\n",
      "\n",
      "iteration 372: f_best = 0.00739604\n",
      "x_eff  = [ 37.70372901 -17.92393913],\n",
      "\n",
      "iteration 373: f_best = 0.00739604\n",
      "x_eff  = [32.46186621  7.66320764],\n",
      "\n",
      "iteration 374: f_best = 0.00739604\n",
      "x_eff  = [-19.92841012  -5.26326746],\n",
      "\n",
      "iteration 375: f_best = 0.00739604\n",
      "x_eff  = [26.67480764 35.7151735 ],\n",
      "\n",
      "iteration 376: f_best = 0.00739604\n",
      "x_eff  = [19.07727566 -8.85662929],\n",
      "\n",
      "iteration 377: f_best = 0.00739604\n",
      "x_eff  = [-7.85520238  2.43743393],\n",
      "\n",
      "iteration 378: f_best = 0.00739604\n",
      "x_eff  = [34.03320056 27.90298723],\n",
      "\n",
      "iteration 379: f_best = 0.00739604\n",
      "x_eff  = [ 7.50383626 29.8298358 ],\n",
      "\n",
      "iteration 380: f_best = 0.00739604\n",
      "x_eff  = [30.63273963 -4.3523281 ],\n",
      "\n",
      "iteration 381: f_best = 0.00739604\n",
      "x_eff  = [19.73207821 -8.21020544],\n",
      "\n",
      "iteration 382: f_best = 0.00739604\n",
      "x_eff  = [-29.83552287  -7.87865167],\n",
      "\n",
      "iteration 383: f_best = 0.00739604\n",
      "x_eff  = [-29.80300551   0.14187802],\n",
      "\n",
      "iteration 384: f_best = 0.00739604\n",
      "x_eff  = [-0.05038058 -7.99552432],\n",
      "\n",
      "iteration 385: f_best = 0.00739604\n",
      "x_eff  = [ 15.19529634 -26.38240322],\n",
      "\n",
      "iteration 386: f_best = 0.00739604\n",
      "x_eff  = [-8.97738227 14.88339925],\n",
      "\n",
      "iteration 387: f_best = 0.00739604\n",
      "x_eff  = [33.65662673 18.68987118],\n",
      "\n",
      "iteration 388: f_best = 0.00739604\n",
      "x_eff  = [-17.82548384  17.00125066],\n",
      "\n",
      "iteration 389: f_best = 0.00739604\n",
      "x_eff  = [-8.58935008 24.14638775],\n",
      "\n",
      "iteration 390: f_best = 0.00739604\n",
      "x_eff  = [10.75648789 -2.92117879],\n",
      "\n",
      "iteration 391: f_best = 0.00739604\n",
      "x_eff  = [9.92071022 9.20744011],\n",
      "\n",
      "iteration 392: f_best = 0.00739604\n",
      "x_eff  = [ -3.27811187 -21.77627627],\n",
      "\n",
      "iteration 393: f_best = 0.00739604\n",
      "x_eff  = [-25.29646692  -7.75119214],\n",
      "\n",
      "iteration 394: f_best = 0.00739604\n",
      "x_eff  = [-1.0644651  21.38231196],\n",
      "\n",
      "iteration 395: f_best = 0.00739604\n",
      "x_eff  = [ 8.93041957 -2.65365523],\n",
      "\n",
      "iteration 396: f_best = 0.00739604\n",
      "x_eff  = [-15.55638391  22.93147637],\n",
      "\n",
      "iteration 397: f_best = 0.00739604\n",
      "x_eff  = [ 24.13408197 -11.54682531],\n",
      "\n",
      "iteration 398: f_best = 0.00739604\n",
      "x_eff  = [ 0.99936245 -3.84790868],\n",
      "\n",
      "iteration 399: f_best = 0.00739604\n",
      "x_eff  = [8.55531813 5.63606786],\n",
      "\n",
      "iteration 400: f_best = 0.00739604\n",
      "x_eff  = [-12.52416306   4.29920182],\n",
      "\n",
      "iteration 401: f_best = 0.00739604\n",
      "x_eff  = [-24.76483267 -15.41710469],\n",
      "\n",
      "iteration 402: f_best = 0.00739604\n",
      "x_eff  = [-17.7651433   21.54517312],\n",
      "\n",
      "iteration 403: f_best = 0.00739604\n",
      "x_eff  = [ 1.11557471 11.49227744],\n",
      "\n",
      "iteration 404: f_best = 0.00739604\n",
      "x_eff  = [-1.04794651 14.1902964 ],\n",
      "\n",
      "iteration 405: f_best = 0.00739604\n",
      "x_eff  = [-13.42499119  -5.89104054],\n",
      "\n",
      "iteration 406: f_best = 0.00739604\n",
      "x_eff  = [-17.08680972 -10.47281406],\n",
      "\n",
      "iteration 407: f_best = 0.00739604\n",
      "x_eff  = [-18.01402207 -29.83296212],\n",
      "\n",
      "iteration 408: f_best = 0.00739604\n",
      "x_eff  = [-8.34281801 -1.24113181],\n",
      "\n",
      "iteration 409: f_best = 0.00739604\n",
      "x_eff  = [27.35610086 14.25502952],\n",
      "\n",
      "iteration 410: f_best = 0.00739604\n",
      "x_eff  = [  3.6346485  -23.83069758],\n",
      "\n",
      "iteration 411: f_best = 0.00739604\n",
      "x_eff  = [ 2.90762482 11.38397155],\n",
      "\n",
      "iteration 412: f_best = 0.00739604\n",
      "x_eff  = [-16.71826024  19.21333103],\n",
      "\n",
      "iteration 413: f_best = 0.00739604\n",
      "x_eff  = [-11.95147996  12.39528121],\n",
      "\n",
      "iteration 414: f_best = 0.00739604\n",
      "x_eff  = [15.37838373 -9.96283867],\n",
      "\n",
      "iteration 415: f_best = 0.00739604\n",
      "x_eff  = [-7.19782418 17.63683445],\n",
      "\n",
      "iteration 416: f_best = 0.00739604\n",
      "x_eff  = [-16.21708378  19.07196736],\n",
      "\n",
      "iteration 417: f_best = 0.00739604\n",
      "x_eff  = [-8.04286657  2.9121578 ],\n",
      "\n",
      "iteration 418: f_best = 0.00739604\n",
      "x_eff  = [15.15411408 -5.80472704],\n",
      "\n",
      "iteration 419: f_best = 0.00739604\n",
      "x_eff  = [-16.00187514 -18.0919945 ],\n",
      "\n",
      "iteration 420: f_best = 0.00739604\n",
      "x_eff  = [ 8.45567633 -0.1122107 ],\n",
      "\n",
      "iteration 421: f_best = 0.00739604\n",
      "x_eff  = [ 16.50481111 -15.81599064],\n",
      "\n",
      "iteration 422: f_best = 0.00739604\n",
      "x_eff  = [-8.19536541 15.82430733],\n",
      "\n",
      "iteration 423: f_best = 0.00739604\n",
      "x_eff  = [-17.9434908  -1.1939117],\n",
      "\n",
      "iteration 424: f_best = 0.00739604\n",
      "x_eff  = [-7.09217016 10.63291292],\n",
      "\n",
      "iteration 425: f_best = 0.00739604\n",
      "x_eff  = [-10.12969154  -5.26706147],\n",
      "\n",
      "iteration 426: f_best = 0.00739604\n",
      "x_eff  = [-10.01899888 -26.37418173],\n",
      "\n",
      "iteration 427: f_best = 0.00739604\n",
      "x_eff  = [18.25837816  5.12790457],\n",
      "\n",
      "iteration 428: f_best = 0.00739604\n",
      "x_eff  = [  5.90686773 -14.06779744],\n",
      "\n",
      "iteration 429: f_best = 0.00739604\n",
      "x_eff  = [ 16.85528646 -10.23188085],\n",
      "\n",
      "iteration 430: f_best = 0.00739604\n",
      "x_eff  = [ 0.53755039 14.25285997],\n",
      "\n",
      "iteration 431: f_best = 0.00739604\n",
      "x_eff  = [ 17.41783686 -24.25152927],\n",
      "\n",
      "iteration 432: f_best = 0.00739604\n",
      "x_eff  = [-7.49559626  9.21642646],\n",
      "\n",
      "iteration 433: f_best = 0.00739604\n",
      "x_eff  = [18.73044607  9.77121311],\n",
      "\n",
      "iteration 434: f_best = 0.00739604\n",
      "x_eff  = [10.33885405  1.28935812],\n",
      "\n",
      "iteration 435: f_best = 0.00739604\n",
      "x_eff  = [-14.90025197  -0.50166005],\n",
      "\n",
      "iteration 436: f_best = 0.00739604\n",
      "x_eff  = [  3.7728128  -22.85794983],\n",
      "\n",
      "iteration 437: f_best = 0.00739604\n",
      "x_eff  = [20.89657915 -2.47957264],\n",
      "\n",
      "iteration 438: f_best = 0.00739604\n",
      "x_eff  = [ -6.42716348 -15.08136026],\n",
      "\n",
      "iteration 439: f_best = 0.00739604\n",
      "x_eff  = [-15.07420033  -6.04165019],\n",
      "\n",
      "iteration 440: f_best = 0.00739604\n",
      "x_eff  = [ 19.28779563 -22.37970146],\n",
      "\n",
      "iteration 441: f_best = 0.00739604\n",
      "x_eff  = [17.61966138 -6.37054087],\n",
      "\n",
      "iteration 442: f_best = 0.00739604\n",
      "x_eff  = [ 10.46650302 -14.41153719],\n",
      "\n",
      "iteration 443: f_best = 0.00739604\n",
      "x_eff  = [12.25677145  0.68764047],\n",
      "\n",
      "iteration 444: f_best = 0.00739604\n",
      "x_eff  = [ 20.10260223 -10.94265846],\n",
      "\n",
      "iteration 445: f_best = 0.00739604\n",
      "x_eff  = [-2.86031945  6.61790051],\n",
      "\n",
      "iteration 446: f_best = 0.00739604\n",
      "x_eff  = [  3.26342117 -11.54958407],\n",
      "\n",
      "iteration 447: f_best = 0.00739604\n",
      "x_eff  = [-8.71888401  9.0023798 ],\n",
      "\n",
      "iteration 448: f_best = 0.00739604\n",
      "x_eff  = [  2.10548828 -12.13075913],\n",
      "\n",
      "iteration 449: f_best = 0.00739604\n",
      "x_eff  = [ -2.37055335 -15.71136014],\n",
      "\n",
      "iteration 450: f_best = 0.00739604\n",
      "x_eff  = [-4.38948515  2.6822565 ],\n",
      "\n",
      "iteration 451: f_best = 0.00739604\n",
      "x_eff  = [11.1630949  21.13129329],\n",
      "\n",
      "iteration 452: f_best = 0.00739604\n",
      "x_eff  = [-8.95128938 17.18772091],\n",
      "\n",
      "iteration 453: f_best = 0.00739604\n",
      "x_eff  = [-0.92610159 20.95093423],\n",
      "\n",
      "iteration 454: f_best = 0.00739604\n",
      "x_eff  = [-11.69776488 -10.79145296],\n",
      "\n",
      "iteration 455: f_best = 0.00739604\n",
      "x_eff  = [10.57376006 -1.26235514],\n",
      "\n",
      "iteration 456: f_best = 0.00739604\n",
      "x_eff  = [11.42482226 13.94333427],\n",
      "\n",
      "iteration 457: f_best = 0.00739604\n",
      "x_eff  = [-10.83845325 -10.77053941],\n",
      "\n",
      "iteration 458: f_best = 0.00739604\n",
      "x_eff  = [-17.03602943  10.96957232],\n",
      "\n",
      "iteration 459: f_best = 0.00739604\n",
      "x_eff  = [-5.41335962 18.55564593],\n",
      "\n",
      "iteration 460: f_best = 0.00739604\n",
      "x_eff  = [-12.91700808  18.46295203],\n",
      "\n",
      "iteration 461: f_best = 0.00739604\n",
      "x_eff  = [-2.16192381  2.71017048],\n",
      "\n",
      "iteration 462: f_best = 0.00739604\n",
      "x_eff  = [ 2.57367373 13.5891477 ],\n",
      "\n",
      "iteration 463: f_best = 0.00739604\n",
      "x_eff  = [ 1.26133657 17.52742028],\n",
      "\n",
      "iteration 464: f_best = 0.00739604\n",
      "x_eff  = [-15.16809767  -4.39886643],\n",
      "\n",
      "iteration 465: f_best = 0.00739604\n",
      "x_eff  = [-0.6662148  11.12804195],\n",
      "\n",
      "iteration 466: f_best = 0.00739604\n",
      "x_eff  = [-11.03346614   8.96454591],\n",
      "\n",
      "iteration 467: f_best = 0.00739604\n",
      "x_eff  = [-0.33621894 -4.9646526 ],\n",
      "\n",
      "iteration 468: f_best = 0.00739604\n",
      "x_eff  = [-3.16418743  7.65305853],\n",
      "\n",
      "iteration 469: f_best = 0.00739604\n",
      "x_eff  = [10.16832659 -6.4975002 ],\n",
      "\n",
      "iteration 470: f_best = 0.00739604\n",
      "x_eff  = [ 8.06436726 -2.68653208],\n",
      "\n",
      "iteration 471: f_best = 0.00739604\n",
      "x_eff  = [-2.49539268 12.30406337],\n",
      "\n",
      "iteration 472: f_best = 0.00739604\n",
      "x_eff  = [-16.00933434  10.68722312],\n",
      "\n",
      "iteration 473: f_best = 0.00739604\n",
      "x_eff  = [-16.13069041  -0.86894962],\n",
      "\n",
      "iteration 474: f_best = 0.00739604\n",
      "x_eff  = [9.55430275 5.13164278],\n",
      "\n",
      "iteration 475: f_best = 0.00739604\n",
      "x_eff  = [-12.26093761  10.3039787 ],\n",
      "\n",
      "iteration 476: f_best = 0.00739604\n",
      "x_eff  = [1.68159929 2.70023272],\n",
      "\n",
      "iteration 477: f_best = 0.00739604\n",
      "x_eff  = [-4.1119656  16.91228303],\n",
      "\n",
      "iteration 478: f_best = 0.00739604\n",
      "x_eff  = [ 0.84592177 17.38640979],\n",
      "\n",
      "iteration 479: f_best = 0.00739604\n",
      "x_eff  = [-12.72534754  -6.15066746],\n",
      "\n",
      "iteration 480: f_best = 0.00739604\n",
      "x_eff  = [-0.94850387  6.36354946],\n",
      "\n",
      "iteration 481: f_best = 0.00739604\n",
      "x_eff  = [-15.01235648  10.98150409],\n",
      "\n",
      "iteration 482: f_best = 0.00739604\n",
      "x_eff  = [-13.32450654   1.01852171],\n",
      "\n",
      "iteration 483: f_best = 0.00739604\n",
      "x_eff  = [-0.46375185 10.66811995],\n",
      "\n",
      "iteration 484: f_best = 0.00739604\n",
      "x_eff  = [-12.30063569  -5.33746248],\n",
      "\n",
      "iteration 485: f_best = 0.00739604\n",
      "x_eff  = [ 3.10622962 12.71263831],\n",
      "\n",
      "iteration 486: f_best = 0.00739604\n",
      "x_eff  = [-11.78838796  13.02234021],\n",
      "\n",
      "iteration 487: f_best = 0.00739604\n",
      "x_eff  = [-7.41844601  5.93489709],\n",
      "\n",
      "iteration 488: f_best = 0.00739604\n",
      "x_eff  = [-6.74312364 13.23864285],\n",
      "\n",
      "iteration 489: f_best = 0.00739604\n",
      "x_eff  = [-6.81202005  3.18515277],\n",
      "\n",
      "iteration 490: f_best = 0.00739604\n",
      "x_eff  = [-3.53042842  9.20960349],\n",
      "\n",
      "iteration 491: f_best = 0.00739604\n",
      "x_eff  = [-11.26624398  13.34042291],\n",
      "\n",
      "iteration 492: f_best = 0.00739604\n",
      "x_eff  = [ 5.94123056 -3.07961305],\n",
      "\n",
      "iteration 493: f_best = 0.00739604\n",
      "x_eff  = [ 1.53100563 10.55903845],\n",
      "\n",
      "iteration 494: f_best = 0.00000000\n",
      "x_eff  = [-1.72235735 -0.43494734],\n",
      "\n",
      "iteration 495: f_best = 0.00000000\n",
      "x_eff  = [-3.75330254  3.57414304],\n",
      "\n",
      "iteration 496: f_best = 0.00000000\n",
      "x_eff  = [ 3.85081521 -3.16812271],\n",
      "\n",
      "iteration 497: f_best = 0.00000000\n",
      "x_eff  = [-10.3954219   -9.54131317],\n",
      "\n",
      "iteration 498: f_best = 0.00000000\n",
      "x_eff  = [ 3.96485152 -4.96649499],\n",
      "\n",
      "iteration 499: f_best = 0.00000000\n",
      "x_eff  = [10.37976308 -0.18965066],\n",
      "\n",
      "iteration 500: f_best = 0.00000000\n",
      "x_eff  = [ 4.47520249 -7.29009746],\n",
      "\n",
      "iteration 501: f_best = 0.00000000\n",
      "x_eff  = [-2.1922554   0.74654765],\n",
      "\n",
      "iteration 502: f_best = 0.00000000\n",
      "x_eff  = [ 3.88944898 -5.01297119],\n",
      "\n",
      "iteration 503: f_best = 0.00000000\n",
      "x_eff  = [-3.98836549 -4.67184928],\n",
      "\n",
      "iteration 504: f_best = 0.00000000\n",
      "x_eff  = [-8.02464928 -4.03934879],\n",
      "\n",
      "iteration 505: f_best = 0.00000000\n",
      "x_eff  = [7.15986544 9.70627741],\n",
      "\n",
      "iteration 506: f_best = 0.00000000\n",
      "x_eff  = [2.83184338 2.83758518],\n",
      "\n",
      "iteration 507: f_best = 0.00000000\n",
      "x_eff  = [ 3.17755743 -9.07228076],\n",
      "\n",
      "iteration 508: f_best = 0.00000000\n",
      "x_eff  = [-0.30206618  6.80529865],\n",
      "\n",
      "iteration 509: f_best = 0.00000000\n",
      "x_eff  = [-0.79116711  8.60810319],\n",
      "\n",
      "iteration 510: f_best = 0.00000000\n",
      "x_eff  = [ 3.4981782  -0.16165494],\n",
      "\n",
      "iteration 511: f_best = 0.00000000\n",
      "x_eff  = [5.16944063 4.75021903],\n",
      "\n",
      "iteration 512: f_best = 0.00000000\n",
      "x_eff  = [5.21712394 3.30829592],\n",
      "\n",
      "iteration 513: f_best = 0.00000000\n",
      "x_eff  = [3.37697535 4.24233268],\n",
      "\n",
      "iteration 514: f_best = 0.00000000\n",
      "x_eff  = [-5.00578574 -7.34664298],\n",
      "\n",
      "iteration 515: f_best = 0.00000000\n",
      "x_eff  = [5.27300321 8.37521246],\n",
      "\n",
      "iteration 516: f_best = 0.00000000\n",
      "x_eff  = [ 3.58513492 -7.5984989 ],\n",
      "\n",
      "iteration 517: f_best = 0.00000000\n",
      "x_eff  = [1.52887505 0.97944262],\n",
      "\n",
      "iteration 518: f_best = 0.00000000\n",
      "x_eff  = [4.3155754  3.23118327],\n",
      "\n",
      "iteration 519: f_best = 0.00000000\n",
      "x_eff  = [ 8.730421   -4.97331757],\n",
      "\n",
      "iteration 520: f_best = 0.00000000\n",
      "x_eff  = [-2.23009786 -8.56301587],\n",
      "\n",
      "iteration 521: f_best = 0.00000000\n",
      "x_eff  = [2.8471311  8.31775564],\n",
      "\n",
      "iteration 522: f_best = 0.00000000\n",
      "x_eff  = [ 6.32598151 -6.7962447 ],\n",
      "\n",
      "iteration 523: f_best = 0.00000000\n",
      "x_eff  = [ 1.97669592 -8.45320597],\n",
      "\n",
      "iteration 524: f_best = 0.00000000\n",
      "x_eff  = [-3.74849268  3.66833169],\n",
      "\n",
      "iteration 525: f_best = 0.00000000\n",
      "x_eff  = [-4.85367335 -3.67244244],\n",
      "\n",
      "iteration 526: f_best = 0.00000000\n",
      "x_eff  = [-5.11594903  3.55860342],\n",
      "\n",
      "iteration 527: f_best = 0.00000000\n",
      "x_eff  = [-3.87450363 -6.09575357],\n",
      "\n",
      "iteration 528: f_best = 0.00000000\n",
      "x_eff  = [2.57199238 6.37480191],\n",
      "\n",
      "iteration 529: f_best = 0.00000000\n",
      "x_eff  = [ 6.6299599  -6.91509694],\n",
      "\n",
      "iteration 530: f_best = 0.00000000\n",
      "x_eff  = [-6.49852989  4.24378637],\n",
      "\n",
      "iteration 531: f_best = 0.00000000\n",
      "x_eff  = [ 1.11734706 -2.99782421],\n",
      "\n",
      "iteration 532: f_best = 0.00000000\n",
      "x_eff  = [ 0.69491312 -1.71957386],\n",
      "\n",
      "iteration 533: f_best = 0.00000000\n",
      "x_eff  = [-3.37647283 -5.1211363 ],\n",
      "\n",
      "iteration 534: f_best = 0.00000000\n",
      "x_eff  = [-4.06299993 -0.90530593],\n",
      "\n",
      "iteration 535: f_best = 0.00000000\n",
      "x_eff  = [-3.23993827 -0.26089122],\n",
      "\n",
      "iteration 536: f_best = 0.00000000\n",
      "x_eff  = [-1.3103651   1.63566224],\n",
      "\n",
      "iteration 537: f_best = 0.00000000\n",
      "x_eff  = [7.10522974 0.66593922],\n",
      "\n",
      "iteration 538: f_best = 0.00000000\n",
      "x_eff  = [-1.91642682  1.63895278],\n",
      "\n",
      "iteration 539: f_best = 0.00000000\n",
      "x_eff  = [-3.82693755 -0.71321292],\n",
      "\n",
      "iteration 540: f_best = 0.00000000\n",
      "x_eff  = [-4.06972699 -6.60996882],\n",
      "\n",
      "iteration 541: f_best = 0.00000000\n",
      "x_eff  = [-1.53089498  7.17033635],\n",
      "\n",
      "iteration 542: f_best = 0.00000000\n",
      "x_eff  = [4.79282986 4.44673119],\n",
      "\n",
      "iteration 543: f_best = 0.00000000\n",
      "x_eff  = [ 3.16106084 -5.13169832],\n",
      "\n",
      "iteration 544: f_best = 0.00000000\n",
      "x_eff  = [-2.57725502 -0.71754007],\n",
      "\n",
      "iteration 545: f_best = 0.00000000\n",
      "x_eff  = [-6.36062577  6.87051952],\n",
      "\n",
      "iteration 546: f_best = 0.00000000\n",
      "x_eff  = [-5.18028608 -0.09009443],\n",
      "\n",
      "iteration 547: f_best = 0.00000000\n",
      "x_eff  = [-6.0980376  -5.78447949],\n",
      "\n",
      "iteration 548: f_best = 0.00000000\n",
      "x_eff  = [1.42014832 4.3725242 ],\n",
      "\n",
      "iteration 549: f_best = 0.00000000\n",
      "x_eff  = [-2.97054886  4.3627827 ],\n",
      "\n",
      "iteration 550: f_best = 0.00000000\n",
      "x_eff  = [-5.22094977  0.33296084],\n",
      "\n",
      "iteration 551: f_best = 0.00000000\n",
      "x_eff  = [ 5.57499891 -6.19211126],\n",
      "\n",
      "iteration 552: f_best = 0.00000000\n",
      "x_eff  = [ 6.03076049 -6.26015543],\n",
      "\n",
      "iteration 553: f_best = 0.00000000\n",
      "x_eff  = [-1.09306014  2.10321641],\n",
      "\n",
      "iteration 554: f_best = 0.00000000\n",
      "x_eff  = [ 4.2741077  -3.67088776],\n",
      "\n",
      "iteration 555: f_best = 0.00000000\n",
      "x_eff  = [0.19797054 0.21596348],\n",
      "\n",
      "iteration 556: f_best = 0.00000000\n",
      "x_eff  = [3.09873644 5.69728729],\n",
      "\n",
      "iteration 557: f_best = 0.00000000\n",
      "x_eff  = [-1.92879123  2.46549891],\n",
      "\n",
      "iteration 558: f_best = 0.00000000\n",
      "x_eff  = [ 1.56888114 -1.7849082 ],\n",
      "\n",
      "iteration 559: f_best = 0.00000000\n",
      "x_eff  = [-0.78028469  0.33386017],\n",
      "\n",
      "iteration 560: f_best = 0.00000000\n",
      "x_eff  = [ 5.40586173 -4.23580922],\n",
      "\n",
      "iteration 561: f_best = 0.00000000\n",
      "x_eff  = [-2.07601153  4.64439454],\n",
      "\n",
      "iteration 562: f_best = 0.00000000\n",
      "x_eff  = [ 3.81735636 -1.8654936 ],\n",
      "\n",
      "iteration 563: f_best = 0.00000000\n",
      "x_eff  = [-4.31073053  3.33054821],\n",
      "\n",
      "iteration 564: f_best = 0.00000000\n",
      "x_eff  = [-2.14039774 -5.03600471],\n",
      "\n",
      "iteration 565: f_best = 0.00000000\n",
      "x_eff  = [-4.25925195  5.53113659],\n",
      "\n",
      "iteration 566: f_best = 0.00000000\n",
      "x_eff  = [5.31785859 0.16897979],\n",
      "\n",
      "iteration 567: f_best = 0.00000000\n",
      "x_eff  = [-3.06826824  5.1949499 ],\n",
      "\n",
      "iteration 568: f_best = 0.00000000\n",
      "x_eff  = [ 0.1785936  -4.80871288],\n",
      "\n",
      "iteration 569: f_best = 0.00000000\n",
      "x_eff  = [-4.48751806  4.34205184],\n",
      "\n",
      "iteration 570: f_best = 0.00000000\n",
      "x_eff  = [3.31195857 4.49786705],\n",
      "\n",
      "iteration 571: f_best = 0.00000000\n",
      "x_eff  = [-3.91457595  0.06370733],\n",
      "\n",
      "iteration 572: f_best = 0.00000000\n",
      "x_eff  = [ 1.33975164 -1.72605302],\n",
      "\n",
      "iteration 573: f_best = 0.00000000\n",
      "x_eff  = [ 2.3983084  -3.65549394],\n",
      "\n",
      "iteration 574: f_best = 0.00000000\n",
      "x_eff  = [-0.85551719 -2.75064833],\n",
      "\n",
      "iteration 575: f_best = 0.00000000\n",
      "x_eff  = [ 2.1302121  -3.89066302],\n",
      "\n",
      "iteration 576: f_best = 0.00000000\n",
      "x_eff  = [ 0.76368178 -3.92651833],\n",
      "\n",
      "iteration 577: f_best = 0.00000000\n",
      "x_eff  = [-1.64978426  0.93429533],\n",
      "\n",
      "iteration 578: f_best = 0.00000000\n",
      "x_eff  = [2.69884643 4.2549222 ],\n",
      "\n",
      "iteration 579: f_best = 0.00000000\n",
      "x_eff  = [-2.89152927  2.42597979],\n",
      "\n",
      "iteration 580: f_best = 0.00000000\n",
      "x_eff  = [ 0.43308188 -4.36410986],\n",
      "\n",
      "iteration 581: f_best = 0.00000000\n",
      "x_eff  = [-3.93535987  4.18845037],\n",
      "\n",
      "iteration 582: f_best = 0.00000000\n",
      "x_eff  = [ 0.42977522 -4.54102707],\n",
      "\n",
      "iteration 583: f_best = 0.00000000\n",
      "x_eff  = [-1.14193148  2.22902701],\n",
      "\n",
      "iteration 584: f_best = 0.00000000\n",
      "x_eff  = [ 0.46246256 -2.14825808],\n",
      "\n",
      "iteration 585: f_best = 0.00000000\n",
      "x_eff  = [ 0.72165459 -3.29779454],\n",
      "\n",
      "iteration 586: f_best = 0.00000000\n",
      "x_eff  = [ 2.49139741 -1.58473399],\n",
      "\n",
      "iteration 587: f_best = 0.00000000\n",
      "x_eff  = [-4.14102881 -2.61285491],\n",
      "\n",
      "iteration 588: f_best = 0.00000000\n",
      "x_eff  = [-4.49821803  2.51895794],\n",
      "\n",
      "iteration 589: f_best = 0.00000000\n",
      "x_eff  = [-2.46323152  0.7956428 ],\n",
      "\n",
      "iteration 590: f_best = 0.00000000\n",
      "x_eff  = [0.58132991 1.37072956],\n",
      "\n",
      "iteration 591: f_best = 0.00000000\n",
      "x_eff  = [-3.16849075  2.19139261],\n",
      "\n",
      "iteration 592: f_best = 0.00000000\n",
      "x_eff  = [-1.82788558  2.15923855],\n",
      "\n",
      "iteration 593: f_best = 0.00000000\n",
      "x_eff  = [2.33544334 0.81995065],\n",
      "\n",
      "iteration 594: f_best = 0.00000000\n",
      "x_eff  = [-3.67965641 -2.14894342],\n",
      "\n",
      "iteration 595: f_best = 0.00000000\n",
      "x_eff  = [-3.49038567  2.63864979],\n",
      "\n",
      "iteration 596: f_best = 0.00000000\n",
      "x_eff  = [3.06904977 2.38527642],\n",
      "\n",
      "iteration 597: f_best = 0.00000000\n",
      "x_eff  = [-3.20882964 -3.86368431],\n",
      "\n",
      "iteration 598: f_best = 0.00000000\n",
      "x_eff  = [-2.91784007 -1.60733039],\n",
      "\n",
      "iteration 599: f_best = 0.00000000\n",
      "x_eff  = [ 0.96541732 -0.66432974],\n",
      "\n",
      "iteration 600: f_best = 0.00000000\n",
      "x_eff  = [ 3.39770295 -3.74612522],\n",
      "\n",
      "iteration 601: f_best = 0.00000000\n",
      "x_eff  = [-1.91146224  0.92305216],\n",
      "\n",
      "iteration 602: f_best = 0.00000000\n",
      "x_eff  = [-3.16613978 -3.8474983 ],\n",
      "\n",
      "iteration 603: f_best = 0.00000000\n",
      "x_eff  = [ 1.10635375 -1.71205844],\n",
      "\n",
      "iteration 604: f_best = 0.00000000\n",
      "x_eff  = [ 1.90720603 -1.62724608],\n",
      "\n",
      "iteration 605: f_best = 0.00000000\n",
      "x_eff  = [-1.60427595 -0.85088804],\n",
      "\n",
      "iteration 606: f_best = 0.00000000\n",
      "x_eff  = [3.41900222 0.01814513],\n",
      "\n",
      "iteration 607: f_best = 0.00000000\n",
      "x_eff  = [-1.70199077 -0.11912799],\n",
      "\n",
      "iteration 608: f_best = 0.00000000\n",
      "x_eff  = [-2.96415371  1.25430756],\n",
      "\n",
      "iteration 609: f_best = 0.00000000\n",
      "x_eff  = [ 1.86961129 -2.27664717],\n",
      "\n",
      "iteration 610: f_best = 0.00000000\n",
      "x_eff  = [-1.95276149 -2.72785699],\n",
      "\n",
      "iteration 611: f_best = 0.00000000\n",
      "x_eff  = [ 2.28912835 -1.59862791],\n",
      "\n",
      "iteration 612: f_best = 0.00000000\n",
      "x_eff  = [-3.05065029 -1.23335843],\n",
      "\n",
      "iteration 613: f_best = 0.00000000\n",
      "x_eff  = [-1.00491772  3.16599204],\n",
      "\n",
      "iteration 614: f_best = 0.00000000\n",
      "x_eff  = [-0.57738086  2.75558228],\n",
      "\n",
      "iteration 615: f_best = 0.00000000\n",
      "x_eff  = [-2.37799363  1.59024397],\n",
      "\n",
      "iteration 616: f_best = 0.00000000\n",
      "x_eff  = [0.20122044 0.07563649],\n",
      "\n",
      "iteration 617: f_best = 0.00000000\n",
      "x_eff  = [0.83261339 2.57270863],\n",
      "\n",
      "iteration 618: f_best = 0.00000000\n",
      "x_eff  = [-2.12087072 -0.9376936 ],\n",
      "\n",
      "iteration 619: f_best = 0.00000000\n",
      "x_eff  = [-1.66708748 -2.21510729],\n",
      "\n",
      "iteration 620: f_best = 0.00000000\n",
      "x_eff  = [-2.56072389  0.21649644],\n",
      "\n",
      "iteration 621: f_best = 0.00000000\n",
      "x_eff  = [-3.15300636  2.73928798],\n",
      "\n",
      "iteration 622: f_best = 0.00000000\n",
      "x_eff  = [3.0809585  2.36895549],\n",
      "\n",
      "iteration 623: f_best = 0.00000000\n",
      "x_eff  = [1.4261455 0.1645735],\n",
      "\n",
      "iteration 624: f_best = 0.00000000\n",
      "x_eff  = [ 1.41522622 -2.58748394],\n",
      "\n",
      "iteration 625: f_best = 0.00000000\n",
      "x_eff  = [0.11240105 0.22353637],\n",
      "\n",
      "iteration 626: f_best = 0.00000000\n",
      "x_eff  = [-0.38066238 -0.29974845],\n",
      "\n",
      "iteration 627: f_best = 0.00000000\n",
      "x_eff  = [ 2.53230915 -2.73478181],\n",
      "\n",
      "iteration 628: f_best = 0.00000000\n",
      "x_eff  = [-0.88967718  1.94228767],\n",
      "\n",
      "iteration 629: f_best = 0.00000000\n",
      "x_eff  = [2.80675487 1.17619512],\n",
      "\n",
      "iteration 630: f_best = 0.00000000\n",
      "x_eff  = [1.95798968 1.18373962],\n",
      "\n",
      "iteration 631: f_best = 0.00000000\n",
      "x_eff  = [2.07392624 1.34532596],\n",
      "\n",
      "iteration 632: f_best = 0.00000000\n",
      "x_eff  = [1.55954251 2.54664919],\n",
      "\n",
      "iteration 633: f_best = 0.00000000\n",
      "x_eff  = [1.67432913 0.59768894],\n",
      "\n",
      "iteration 634: f_best = 0.00000000\n",
      "x_eff  = [-0.20664559  1.14328508],\n",
      "\n",
      "iteration 635: f_best = 0.00000000\n",
      "x_eff  = [ 0.09108245 -0.56933472],\n",
      "\n",
      "iteration 636: f_best = 0.00000000\n",
      "x_eff  = [2.41281984 0.74734639],\n",
      "\n",
      "iteration 637: f_best = 0.00000000\n",
      "x_eff  = [1.24408862 2.77461541],\n",
      "\n",
      "iteration 638: f_best = 0.00000000\n",
      "x_eff  = [ 2.7037357  -0.71488954],\n",
      "\n",
      "iteration 639: f_best = 0.00000000\n",
      "x_eff  = [-0.33089695 -1.19590387],\n",
      "\n",
      "iteration 640: f_best = 0.00000000\n",
      "x_eff  = [0.10877643 0.0059903 ],\n",
      "\n",
      "iteration 641: f_best = 0.00000000\n",
      "x_eff  = [ 0.41500616 -2.49042242],\n",
      "\n",
      "iteration 642: f_best = 0.00000000\n",
      "x_eff  = [-1.50537936 -0.48132664],\n",
      "\n",
      "iteration 643: f_best = 0.00000000\n",
      "x_eff  = [ 0.21665855 -1.16990827],\n",
      "\n",
      "iteration 644: f_best = 0.00000000\n",
      "x_eff  = [ 2.42797541 -0.6587002 ],\n",
      "\n",
      "iteration 645: f_best = 0.00000000\n",
      "x_eff  = [-0.34568351 -0.8994492 ],\n",
      "\n",
      "iteration 646: f_best = 0.00000000\n",
      "x_eff  = [2.42781982 2.14592194],\n",
      "\n",
      "iteration 647: f_best = 0.00000000\n",
      "x_eff  = [ 0.1424893  -1.67286904],\n",
      "\n",
      "iteration 648: f_best = 0.00000000\n",
      "x_eff  = [-2.45607353  0.08815724],\n",
      "\n",
      "iteration 649: f_best = 0.00000000\n",
      "x_eff  = [1.59462032 1.12374779],\n",
      "\n",
      "iteration 650: f_best = 0.00000000\n",
      "x_eff  = [ 1.54635951 -1.64247421],\n",
      "\n",
      "iteration 651: f_best = 0.00000000\n",
      "x_eff  = [2.10956059 0.59634359],\n",
      "\n",
      "iteration 652: f_best = 0.00000000\n",
      "x_eff  = [ 0.81833936 -0.34450908],\n",
      "\n",
      "iteration 653: f_best = 0.00000000\n",
      "x_eff  = [0.37642701 1.46016089],\n",
      "\n",
      "iteration 654: f_best = 0.00000000\n",
      "x_eff  = [-2.12284279  1.07221926],\n",
      "\n",
      "iteration 655: f_best = 0.00000000\n",
      "x_eff  = [1.87406349 0.25671459],\n",
      "\n",
      "iteration 656: f_best = 0.00000000\n",
      "x_eff  = [-0.50448196 -0.28645569],\n",
      "\n",
      "iteration 657: f_best = 0.00000000\n",
      "x_eff  = [ 1.94061057 -1.2281565 ],\n",
      "\n",
      "iteration 658: f_best = 0.00000000\n",
      "x_eff  = [1.41940016 0.67777945],\n",
      "\n",
      "iteration 659: f_best = 0.00000000\n",
      "x_eff  = [-1.88352576  0.4184626 ],\n",
      "\n",
      "iteration 660: f_best = 0.00000000\n",
      "x_eff  = [2.11852636 1.52045812],\n",
      "\n",
      "iteration 661: f_best = 0.00000000\n",
      "x_eff  = [-0.98506847  0.87823539],\n",
      "\n",
      "iteration 662: f_best = 0.00000000\n",
      "x_eff  = [-0.8224114  -1.28058408],\n",
      "\n",
      "iteration 663: f_best = 0.00000000\n",
      "x_eff  = [-0.8722342  -0.29931853],\n",
      "\n",
      "iteration 664: f_best = 0.00000000\n",
      "x_eff  = [-1.67450267 -0.33258079],\n",
      "\n",
      "iteration 665: f_best = 0.00000000\n",
      "x_eff  = [ 1.80454112 -1.0191672 ],\n",
      "\n",
      "iteration 666: f_best = 0.00000000\n",
      "x_eff  = [1.18655507 0.08974891],\n",
      "\n",
      "iteration 667: f_best = 0.00000000\n",
      "x_eff  = [0.88353299 0.67578405],\n",
      "\n",
      "iteration 668: f_best = 0.00000000\n",
      "x_eff  = [1.20208012 1.66243975],\n",
      "\n",
      "iteration 669: f_best = 0.00000000\n",
      "x_eff  = [-1.51265276  0.06079222],\n",
      "\n",
      "iteration 670: f_best = 0.00000000\n",
      "x_eff  = [-0.19079373 -0.74434056],\n",
      "\n",
      "iteration 671: f_best = 0.00000000\n",
      "x_eff  = [-1.04069252 -1.87513652],\n",
      "\n",
      "iteration 672: f_best = 0.00000000\n",
      "x_eff  = [-1.51593243  1.91507375],\n",
      "\n",
      "iteration 673: f_best = 0.00000000\n",
      "x_eff  = [-0.47672974  1.81947018],\n",
      "\n",
      "iteration 674: f_best = 0.00000000\n",
      "x_eff  = [ 0.71085812 -0.9130214 ],\n",
      "\n",
      "iteration 675: f_best = 0.00000000\n",
      "x_eff  = [ 1.52316799 -1.23764631],\n",
      "\n",
      "iteration 676: f_best = 0.00000000\n",
      "x_eff  = [-0.60683382  0.01490413],\n",
      "\n",
      "iteration 677: f_best = 0.00000000\n",
      "x_eff  = [-0.53931135 -0.18083601],\n",
      "\n",
      "iteration 678: f_best = 0.00000000\n",
      "x_eff  = [-0.15778647  1.15261902],\n",
      "\n",
      "iteration 679: f_best = 0.00000000\n",
      "x_eff  = [ 1.57351733 -0.53636086],\n",
      "\n",
      "iteration 680: f_best = 0.00000000\n",
      "x_eff  = [-1.18215912 -0.83509955],\n",
      "\n",
      "iteration 681: f_best = 0.00000000\n",
      "x_eff  = [-1.11235768  1.62467189],\n",
      "\n",
      "iteration 682: f_best = 0.00000000\n",
      "x_eff  = [0.51367513 0.10128998],\n",
      "\n",
      "iteration 683: f_best = 0.00000000\n",
      "x_eff  = [-1.46041265  0.81169944],\n",
      "\n",
      "iteration 684: f_best = 0.00000000\n",
      "x_eff  = [ 0.05928807 -0.2766515 ],\n",
      "\n",
      "iteration 685: f_best = 0.00000000\n",
      "x_eff  = [1.35658882 0.67823294],\n",
      "\n",
      "iteration 686: f_best = 0.00000000\n",
      "x_eff  = [-1.31062939  1.06264324],\n",
      "\n",
      "iteration 687: f_best = 0.00000000\n",
      "x_eff  = [1.68392126 1.51113624],\n",
      "\n",
      "iteration 688: f_best = 0.00000000\n",
      "x_eff  = [1.13485444 0.20305301],\n",
      "\n",
      "iteration 689: f_best = 0.00000000\n",
      "x_eff  = [-1.64819458 -0.70328587],\n",
      "\n",
      "iteration 690: f_best = 0.00000000\n",
      "x_eff  = [0.96001207 0.51691332],\n",
      "\n",
      "iteration 691: f_best = 0.00000000\n",
      "x_eff  = [1.15906761 1.51470855],\n",
      "\n",
      "iteration 692: f_best = 0.00000000\n",
      "x_eff  = [-1.53426096  1.57282609],\n",
      "\n",
      "iteration 693: f_best = 0.00000000\n",
      "x_eff  = [0.87616711 0.68214094],\n",
      "\n",
      "iteration 694: f_best = 0.00000000\n",
      "x_eff  = [-0.80957158  1.49328673],\n",
      "\n",
      "iteration 695: f_best = 0.00000000\n",
      "x_eff  = [ 1.11876725 -0.19890735],\n",
      "\n",
      "iteration 696: f_best = 0.00000000\n",
      "x_eff  = [-0.28447907 -0.92147019],\n",
      "\n",
      "iteration 697: f_best = 0.00000000\n",
      "x_eff  = [-1.34182148 -0.93412204],\n",
      "\n",
      "iteration 698: f_best = 0.00000000\n",
      "x_eff  = [-1.11530641 -0.54475229],\n",
      "\n",
      "iteration 699: f_best = 0.00000000\n",
      "x_eff  = [-1.02231273  1.05486514],\n",
      "\n",
      "iteration 700: f_best = 0.00000000\n",
      "x_eff  = [ 0.68273483 -0.18731913],\n",
      "\n",
      "iteration 701: f_best = 0.00000000\n",
      "x_eff  = [ 0.77652955 -1.20114727],\n",
      "\n",
      "iteration 702: f_best = 0.00000000\n",
      "x_eff  = [-0.39574289  1.21937694],\n",
      "\n",
      "iteration 703: f_best = 0.00000000\n",
      "x_eff  = [-0.08507369 -0.00828565],\n",
      "\n",
      "iteration 704: f_best = 0.00000000\n",
      "x_eff  = [-0.99785786 -0.76707451],\n",
      "\n",
      "iteration 705: f_best = 0.00000000\n",
      "x_eff  = [-0.69607799 -0.57085267],\n",
      "\n",
      "iteration 706: f_best = 0.00000000\n",
      "x_eff  = [ 0.18831959 -0.16266379],\n",
      "\n",
      "iteration 707: f_best = 0.00000000\n",
      "x_eff  = [-0.65097988  0.98203914],\n",
      "\n",
      "iteration 708: f_best = 0.00000000\n",
      "x_eff  = [ 0.46113269 -0.65679409],\n",
      "\n",
      "iteration 709: f_best = 0.00000000\n",
      "x_eff  = [-1.19723685 -0.07878252],\n",
      "\n",
      "iteration 710: f_best = 0.00000000\n",
      "x_eff  = [ 0.47964554 -0.90366494],\n",
      "\n",
      "iteration 711: f_best = 0.00000000\n",
      "x_eff  = [-0.36341428 -0.83874124],\n",
      "\n",
      "iteration 712: f_best = 0.00000000\n",
      "x_eff  = [-1.25296786  0.18526051],\n",
      "\n",
      "iteration 713: f_best = 0.00000000\n",
      "x_eff  = [-0.52414207 -1.27880042],\n",
      "\n",
      "iteration 714: f_best = 0.00000000\n",
      "x_eff  = [-1.13986219 -1.03746311],\n",
      "\n",
      "iteration 715: f_best = 0.00000000\n",
      "x_eff  = [0.83733115 0.71960737],\n",
      "\n",
      "iteration 716: f_best = 0.00000000\n",
      "x_eff  = [ 1.00203504 -0.17187208],\n",
      "\n",
      "iteration 717: f_best = 0.00000000\n",
      "x_eff  = [0.85465904 0.16510591],\n",
      "\n",
      "iteration 718: f_best = 0.00000000\n",
      "x_eff  = [-1.0851854 -0.686277 ],\n",
      "\n",
      "iteration 719: f_best = 0.00000000\n",
      "x_eff  = [ 0.61572687 -0.20397444],\n",
      "\n",
      "iteration 720: f_best = 0.00000000\n",
      "x_eff  = [ 0.14379864 -0.46054399],\n",
      "\n",
      "iteration 721: f_best = 0.00000000\n",
      "x_eff  = [0.63058842 0.05684641],\n",
      "\n",
      "iteration 722: f_best = 0.00000000\n",
      "x_eff  = [-1.05383439  1.10356337],\n",
      "\n",
      "iteration 723: f_best = 0.00000000\n",
      "x_eff  = [0.70781226 1.06262448],\n",
      "\n",
      "iteration 724: f_best = 0.00000000\n",
      "x_eff  = [-1.02944681 -0.93805648],\n",
      "\n",
      "iteration 725: f_best = 0.00000000\n",
      "x_eff  = [-0.84870144  0.4633547 ],\n",
      "\n",
      "iteration 726: f_best = 0.00000000\n",
      "x_eff  = [-0.8710525  -0.67203716],\n",
      "\n",
      "iteration 727: f_best = 0.00000000\n",
      "x_eff  = [-1.11285347  0.67503159],\n",
      "\n",
      "iteration 728: f_best = 0.00000000\n",
      "x_eff  = [-0.49024481  0.87169319],\n",
      "\n",
      "iteration 729: f_best = 0.00000000\n",
      "x_eff  = [-0.66941766 -0.29650289],\n",
      "\n",
      "iteration 730: f_best = 0.00000000\n",
      "x_eff  = [-1.0445445   0.37810412],\n",
      "\n",
      "iteration 731: f_best = 0.00000000\n",
      "x_eff  = [-0.01630399  0.12916062],\n",
      "\n",
      "iteration 732: f_best = 0.00000000\n",
      "x_eff  = [0.03632613 0.3483067 ],\n",
      "\n",
      "iteration 733: f_best = 0.00000000\n",
      "x_eff  = [-0.3624973   0.42269119],\n",
      "\n",
      "iteration 734: f_best = 0.00000000\n",
      "x_eff  = [-0.77075077 -1.03688495],\n",
      "\n",
      "iteration 735: f_best = 0.00000000\n",
      "x_eff  = [-0.88445954 -0.26569815],\n",
      "\n",
      "iteration 736: f_best = 0.00000000\n",
      "x_eff  = [ 0.61661985 -0.72908681],\n",
      "\n",
      "iteration 737: f_best = 0.00000000\n",
      "x_eff  = [-0.61861223 -0.28987715],\n",
      "\n",
      "iteration 738: f_best = 0.00000000\n",
      "x_eff  = [-0.06931182 -0.28141537],\n",
      "\n",
      "iteration 739: f_best = 0.00000000\n",
      "x_eff  = [-0.07608915  0.02758196],\n",
      "\n",
      "iteration 740: f_best = 0.00000000\n",
      "x_eff  = [0.51263368 0.34084364],\n",
      "\n",
      "iteration 741: f_best = 0.00000000\n",
      "x_eff  = [-0.09678309 -0.77404805],\n",
      "\n",
      "iteration 742: f_best = 0.00000000\n",
      "x_eff  = [-0.71948433  0.75442984],\n",
      "\n",
      "iteration 743: f_best = 0.00000000\n",
      "x_eff  = [-0.3310388   0.14285968],\n",
      "\n",
      "iteration 744: f_best = 0.00000000\n",
      "x_eff  = [0.74576377 0.25092583],\n",
      "\n",
      "iteration 745: f_best = 0.00000000\n",
      "x_eff  = [-0.18212263 -0.17905744],\n",
      "\n",
      "iteration 746: f_best = 0.00000000\n",
      "x_eff  = [-0.23594204  0.62900163],\n",
      "\n",
      "iteration 747: f_best = 0.00000000\n",
      "x_eff  = [ 0.51704919 -0.34802561],\n",
      "\n",
      "iteration 748: f_best = 0.00000000\n",
      "x_eff  = [-0.55908927  0.05670515],\n",
      "\n",
      "iteration 749: f_best = 0.00000000\n",
      "x_eff  = [-0.14604255 -0.31819708],\n",
      "\n",
      "iteration 750: f_best = 0.00000000\n",
      "x_eff  = [0.43504672 0.36396082],\n",
      "\n",
      "iteration 751: f_best = 0.00000000\n",
      "x_eff  = [0.51093918 0.30885532],\n",
      "\n",
      "iteration 752: f_best = 0.00000000\n",
      "x_eff  = [-0.26148555  0.18877424],\n",
      "\n",
      "iteration 753: f_best = 0.00000000\n",
      "x_eff  = [-0.8203173   0.77758617],\n",
      "\n",
      "iteration 754: f_best = 0.00000000\n",
      "x_eff  = [-0.52908908 -0.66306996],\n",
      "\n",
      "iteration 755: f_best = 0.00000000\n",
      "x_eff  = [-0.1862711  -0.06786635],\n",
      "\n",
      "iteration 756: f_best = 0.00000000\n",
      "x_eff  = [0.56769919 0.7936693 ],\n",
      "\n",
      "iteration 757: f_best = 0.00000000\n",
      "x_eff  = [0.61997385 0.74312498],\n",
      "\n",
      "iteration 758: f_best = 0.00000000\n",
      "x_eff  = [-0.13920452 -0.28071683],\n",
      "\n",
      "iteration 759: f_best = 0.00000000\n",
      "x_eff  = [-0.11928821 -0.24129316],\n",
      "\n",
      "iteration 760: f_best = 0.00000000\n",
      "x_eff  = [0.34651835 0.31266625],\n",
      "\n",
      "iteration 761: f_best = 0.00000000\n",
      "x_eff  = [-0.22102156 -0.20979353],\n",
      "\n",
      "iteration 762: f_best = 0.00000000\n",
      "x_eff  = [ 0.38713996 -0.49582168],\n",
      "\n",
      "iteration 763: f_best = 0.00000000\n",
      "x_eff  = [-0.75568779  0.25944506],\n",
      "\n",
      "iteration 764: f_best = 0.00000000\n",
      "x_eff  = [-0.51683298  0.38092105],\n",
      "\n",
      "iteration 765: f_best = 0.00000000\n",
      "x_eff  = [-0.61537364 -0.66182215],\n",
      "\n",
      "iteration 766: f_best = 0.00000000\n",
      "x_eff  = [-0.33943248  0.34749768],\n",
      "\n",
      "iteration 767: f_best = 0.00000000\n",
      "x_eff  = [-0.1241457   0.47775671],\n",
      "\n",
      "iteration 768: f_best = 0.00000000\n",
      "x_eff  = [ 0.19641632 -0.34477342],\n",
      "\n",
      "iteration 769: f_best = 0.00000000\n",
      "x_eff  = [-0.51839627 -0.21539798],\n",
      "\n",
      "iteration 770: f_best = 0.00000000\n",
      "x_eff  = [-0.03308783  0.0007408 ],\n",
      "\n",
      "iteration 771: f_best = 0.00000000\n",
      "x_eff  = [ 0.42317918 -0.18781672],\n",
      "\n",
      "iteration 772: f_best = 0.00000000\n",
      "x_eff  = [ 0.58053208 -0.07530721],\n",
      "\n",
      "iteration 773: f_best = 0.00000000\n",
      "x_eff  = [-0.40206005 -0.2464943 ],\n",
      "\n",
      "iteration 774: f_best = 0.00000000\n",
      "x_eff  = [0.34639724 0.60306806],\n",
      "\n",
      "iteration 775: f_best = 0.00000000\n",
      "x_eff  = [ 0.38336124 -0.61930176],\n",
      "\n",
      "iteration 776: f_best = 0.00000000\n",
      "x_eff  = [0.09848716 0.07160299],\n",
      "\n",
      "iteration 777: f_best = 0.00000000\n",
      "x_eff  = [ 0.51240207 -0.57174076],\n",
      "\n",
      "iteration 778: f_best = 0.00000000\n",
      "x_eff  = [0.29716635 0.61810951],\n",
      "\n",
      "iteration 779: f_best = 0.00000000\n",
      "x_eff  = [0.52950804 0.27636075],\n",
      "\n",
      "iteration 780: f_best = 0.00000000\n",
      "x_eff  = [0.22588067 0.34621085],\n",
      "\n",
      "iteration 781: f_best = 0.00000000\n",
      "x_eff  = [-0.65134597  0.16850331],\n",
      "\n",
      "iteration 782: f_best = 0.00000000\n",
      "x_eff  = [-0.4610175  -0.01140204],\n",
      "\n",
      "iteration 783: f_best = 0.00000000\n",
      "x_eff  = [0.60880761 0.37486804],\n",
      "\n",
      "iteration 784: f_best = 0.00000000\n",
      "x_eff  = [0.09936904 0.0011726 ],\n",
      "\n",
      "iteration 785: f_best = 0.00000000\n",
      "x_eff  = [-0.12535066 -0.3934241 ],\n",
      "\n",
      "iteration 786: f_best = 0.00000000\n",
      "x_eff  = [ 0.07113406 -0.39209962],\n",
      "\n",
      "iteration 787: f_best = 0.00000000\n",
      "x_eff  = [-0.57854196  0.4323783 ],\n",
      "\n",
      "iteration 788: f_best = 0.00000000\n",
      "x_eff  = [-0.14422441  0.2094395 ],\n",
      "\n",
      "iteration 789: f_best = 0.00000000\n",
      "x_eff  = [ 0.32592022 -0.23643913],\n",
      "\n",
      "iteration 790: f_best = 0.00000000\n",
      "x_eff  = [ 0.18212578 -0.3474346 ],\n",
      "\n",
      "iteration 791: f_best = 0.00000000\n",
      "x_eff  = [-0.4867853   0.38072838],\n",
      "\n",
      "iteration 792: f_best = 0.00000000\n",
      "x_eff  = [0.40322466 0.31292583],\n",
      "\n",
      "iteration 793: f_best = 0.00000000\n",
      "x_eff  = [0.24731731 0.48409839],\n",
      "\n",
      "iteration 794: f_best = 0.00000000\n",
      "x_eff  = [ 0.19961818 -0.39486543],\n",
      "\n",
      "iteration 795: f_best = 0.00000000\n",
      "x_eff  = [-0.47899624  0.32460398],\n",
      "\n",
      "iteration 796: f_best = 0.00000000\n",
      "x_eff  = [ 0.48721948 -0.49688779],\n",
      "\n",
      "iteration 797: f_best = 0.00000000\n",
      "x_eff  = [0.45861588 0.25512417],\n",
      "\n",
      "iteration 798: f_best = 0.00000000\n",
      "x_eff  = [ 0.39649822 -0.41268739],\n",
      "\n",
      "iteration 799: f_best = 0.00000000\n",
      "x_eff  = [ 0.51288207 -0.34414937],\n",
      "\n",
      "iteration 800: f_best = 0.00000000\n",
      "x_eff  = [-0.29104715 -0.17241533],\n",
      "\n",
      "iteration 801: f_best = 0.00000000\n",
      "x_eff  = [0.29011279 0.15500564],\n",
      "\n",
      "iteration 802: f_best = 0.00000000\n",
      "x_eff  = [ 0.06049826 -0.38971949],\n",
      "\n",
      "iteration 803: f_best = 0.00000000\n",
      "x_eff  = [0.45585656 0.50307399],\n",
      "\n",
      "iteration 804: f_best = 0.00000000\n",
      "x_eff  = [-0.03921442  0.07287821],\n",
      "\n",
      "iteration 805: f_best = 0.00000000\n",
      "x_eff  = [0.18692167 0.51122171],\n",
      "\n",
      "iteration 806: f_best = 0.00000000\n",
      "x_eff  = [ 0.25205546 -0.32028718],\n",
      "\n",
      "iteration 807: f_best = 0.00000000\n",
      "x_eff  = [0.38144967 0.30186745],\n",
      "\n",
      "iteration 808: f_best = 0.00000000\n",
      "x_eff  = [ 0.42902642 -0.33917415],\n",
      "\n",
      "iteration 809: f_best = 0.00000000\n",
      "x_eff  = [ 0.24657725 -0.11450277],\n",
      "\n",
      "iteration 810: f_best = 0.00000000\n",
      "x_eff  = [ 0.23099454 -0.05775314],\n",
      "\n",
      "iteration 811: f_best = 0.00000000\n",
      "x_eff  = [-0.14903894  0.4022993 ],\n",
      "\n",
      "iteration 812: f_best = 0.00000000\n",
      "x_eff  = [0.38947355 0.41000029],\n",
      "\n",
      "iteration 813: f_best = 0.00000000\n",
      "x_eff  = [ 0.28206323 -0.30438649],\n",
      "\n",
      "iteration 814: f_best = 0.00000000\n",
      "x_eff  = [-0.11824472  0.44248338],\n",
      "\n",
      "iteration 815: f_best = 0.00000000\n",
      "x_eff  = [0.26082706 0.13174565],\n",
      "\n",
      "iteration 816: f_best = 0.00000000\n",
      "x_eff  = [ 0.21473188 -0.22346158],\n",
      "\n",
      "iteration 817: f_best = 0.00000000\n",
      "x_eff  = [0.40906792 0.41753725],\n",
      "\n",
      "iteration 818: f_best = 0.00000000\n",
      "x_eff  = [0.05402616 0.00493902],\n",
      "\n",
      "iteration 819: f_best = 0.00000000\n",
      "x_eff  = [ 0.14469508 -0.29226826],\n",
      "\n",
      "iteration 820: f_best = 0.00000000\n",
      "x_eff  = [ 0.16315831 -0.20548247],\n",
      "\n",
      "iteration 821: f_best = 0.00000000\n",
      "x_eff  = [0.19561971 0.13940208],\n",
      "\n",
      "iteration 822: f_best = 0.00000000\n",
      "x_eff  = [-0.23044893 -0.27392956],\n",
      "\n",
      "iteration 823: f_best = 0.00000000\n",
      "x_eff  = [-0.31150947 -0.04951079],\n",
      "\n",
      "iteration 824: f_best = 0.00000000\n",
      "x_eff  = [ 0.24095004 -0.40119942],\n",
      "\n",
      "iteration 825: f_best = 0.00000000\n",
      "x_eff  = [-0.04003042  0.10673013],\n",
      "\n",
      "iteration 826: f_best = 0.00000000\n",
      "x_eff  = [-0.3634945   0.18651867],\n",
      "\n",
      "iteration 827: f_best = 0.00000000\n",
      "x_eff  = [-0.28325846  0.20453219],\n",
      "\n",
      "iteration 828: f_best = 0.00000000\n",
      "x_eff  = [-0.24111789 -0.24520091],\n",
      "\n",
      "iteration 829: f_best = 0.00000000\n",
      "x_eff  = [-0.22467178 -0.07030425],\n",
      "\n",
      "iteration 830: f_best = 0.00000000\n",
      "x_eff  = [ 0.21860514 -0.35684343],\n",
      "\n",
      "iteration 831: f_best = 0.00000000\n",
      "x_eff  = [-0.17224582  0.31811433],\n",
      "\n",
      "iteration 832: f_best = 0.00000000\n",
      "x_eff  = [-0.04472789  0.2960686 ],\n",
      "\n",
      "iteration 833: f_best = 0.00000000\n",
      "x_eff  = [-0.09303087 -0.20533294],\n",
      "\n",
      "iteration 834: f_best = 0.00000000\n",
      "x_eff  = [-0.09444598  0.27338626],\n",
      "\n",
      "iteration 835: f_best = 0.00000000\n",
      "x_eff  = [-0.00242948 -0.307751  ],\n",
      "\n",
      "iteration 836: f_best = 0.00000000\n",
      "x_eff  = [0.04961825 0.31638228],\n",
      "\n",
      "iteration 837: f_best = 0.00000000\n",
      "x_eff  = [ 0.05040854 -0.14758288],\n",
      "\n",
      "iteration 838: f_best = 0.00000000\n",
      "x_eff  = [-0.08965895 -0.29142276],\n",
      "\n",
      "iteration 839: f_best = 0.00000000\n",
      "x_eff  = [0.13248177 0.12702565],\n",
      "\n",
      "iteration 840: f_best = 0.00000000\n",
      "x_eff  = [0.15825918 0.28943977],\n",
      "\n",
      "iteration 841: f_best = 0.00000000\n",
      "x_eff  = [ 0.06520885 -0.10492996],\n",
      "\n",
      "iteration 842: f_best = 0.00000000\n",
      "x_eff  = [-0.0347759   0.02200951],\n",
      "\n",
      "iteration 843: f_best = 0.00000000\n",
      "x_eff  = [-0.2386589   0.12186482],\n",
      "\n",
      "iteration 844: f_best = 0.00000000\n",
      "x_eff  = [-0.02471495  0.20253056],\n",
      "\n",
      "iteration 845: f_best = 0.00000000\n",
      "x_eff  = [0.00860538 0.05556068],\n",
      "\n",
      "iteration 846: f_best = 0.00000000\n",
      "x_eff  = [0.14122517 0.22930463],\n",
      "\n",
      "iteration 847: f_best = 0.00000000\n",
      "x_eff  = [-0.24915386 -0.2877793 ],\n",
      "\n",
      "iteration 848: f_best = 0.00000000\n",
      "x_eff  = [ 0.32042628 -0.13643348],\n",
      "\n",
      "iteration 849: f_best = 0.00000000\n",
      "x_eff  = [-0.13120508 -0.11447641],\n",
      "\n",
      "iteration 850: f_best = 0.00000000\n",
      "x_eff  = [-0.18173181 -0.28251721],\n",
      "\n",
      "iteration 851: f_best = 0.00000000\n",
      "x_eff  = [ 0.00286271 -0.05954329],\n",
      "\n",
      "iteration 852: f_best = 0.00000000\n",
      "x_eff  = [-0.28235807 -0.02190768],\n",
      "\n",
      "iteration 853: f_best = 0.00000000\n",
      "x_eff  = [-0.06636906 -0.25852063],\n",
      "\n",
      "iteration 854: f_best = 0.00000000\n",
      "x_eff  = [ 0.10572638 -0.27078289],\n",
      "\n",
      "iteration 855: f_best = 0.00000000\n",
      "x_eff  = [-0.12228304  0.1128942 ],\n",
      "\n",
      "iteration 856: f_best = 0.00000000\n",
      "x_eff  = [0.27918601 0.1739583 ],\n",
      "\n",
      "iteration 857: f_best = 0.00000000\n",
      "x_eff  = [-0.00288738  0.07043207],\n",
      "\n",
      "iteration 858: f_best = 0.00000000\n",
      "x_eff  = [ 0.01319236 -0.08702482],\n",
      "\n",
      "iteration 859: f_best = 0.00000000\n",
      "x_eff  = [ 0.2330749  -0.07436814],\n",
      "\n",
      "iteration 860: f_best = 0.00000000\n",
      "x_eff  = [0.26679442 0.01237162],\n",
      "\n",
      "iteration 861: f_best = 0.00000000\n",
      "x_eff  = [0.11935104 0.23352262],\n",
      "\n",
      "iteration 862: f_best = 0.00000000\n",
      "x_eff  = [ 0.28917462 -0.12970109],\n",
      "\n",
      "iteration 863: f_best = 0.00000000\n",
      "x_eff  = [-0.1292102  0.2683858],\n",
      "\n",
      "iteration 864: f_best = 0.00000000\n",
      "x_eff  = [-0.14829174  0.17688964],\n",
      "\n",
      "iteration 865: f_best = 0.00000000\n",
      "x_eff  = [-0.19065001 -0.02747999],\n",
      "\n",
      "iteration 866: f_best = 0.00000000\n",
      "x_eff  = [0.2231974  0.14857509],\n",
      "\n",
      "iteration 867: f_best = 0.00000000\n",
      "x_eff  = [0.23731149 0.20405105],\n",
      "\n",
      "iteration 868: f_best = 0.00000000\n",
      "x_eff  = [0.24325239 0.04058869],\n",
      "\n",
      "iteration 869: f_best = 0.00000000\n",
      "x_eff  = [-0.26621029  0.14023374],\n",
      "\n",
      "iteration 870: f_best = 0.00000000\n",
      "x_eff  = [-0.02907603  0.16287644],\n",
      "\n",
      "iteration 871: f_best = 0.00000000\n",
      "x_eff  = [-0.19420189 -0.22327921],\n",
      "\n",
      "iteration 872: f_best = 0.00000000\n",
      "x_eff  = [ 0.14114969 -0.01182527],\n",
      "\n",
      "iteration 873: f_best = 0.00000000\n",
      "x_eff  = [-0.0912164  0.1477992],\n",
      "\n",
      "iteration 874: f_best = 0.00000000\n",
      "x_eff  = [-0.00578844 -0.05617165],\n",
      "\n",
      "iteration 875: f_best = 0.00000000\n",
      "x_eff  = [-0.05069972 -0.19413092],\n",
      "\n",
      "iteration 876: f_best = 0.00000000\n",
      "x_eff  = [-0.00716994  0.06429014],\n",
      "\n",
      "iteration 877: f_best = 0.00000000\n",
      "x_eff  = [ 0.05448815 -0.17801443],\n",
      "\n",
      "iteration 878: f_best = 0.00000000\n",
      "x_eff  = [-0.05983233 -0.06569096],\n",
      "\n",
      "iteration 879: f_best = 0.00000000\n",
      "x_eff  = [-0.22579089  0.11968067],\n",
      "\n",
      "iteration 880: f_best = 0.00000000\n",
      "x_eff  = [ 0.24228648 -0.20005661],\n",
      "\n",
      "iteration 881: f_best = 0.00000000\n",
      "x_eff  = [-0.09024282 -0.23042444],\n",
      "\n",
      "iteration 882: f_best = 0.00000000\n",
      "x_eff  = [-0.11455651 -0.1958345 ],\n",
      "\n",
      "iteration 883: f_best = 0.00000000\n",
      "x_eff  = [-0.18166103 -0.10632405],\n",
      "\n",
      "iteration 884: f_best = 0.00000000\n",
      "x_eff  = [ 0.13369459 -0.059784  ],\n",
      "\n",
      "iteration 885: f_best = 0.00000000\n",
      "x_eff  = [-0.08548625 -0.05957472],\n",
      "\n",
      "iteration 886: f_best = 0.00000000\n",
      "x_eff  = [-0.22313488 -0.00315835],\n",
      "\n",
      "iteration 887: f_best = 0.00000000\n",
      "x_eff  = [0.01173863 0.13388037],\n",
      "\n",
      "iteration 888: f_best = 0.00000000\n",
      "x_eff  = [-0.2101526  -0.02609677],\n",
      "\n",
      "iteration 889: f_best = 0.00000000\n",
      "x_eff  = [-0.07420508  0.01369729],\n",
      "\n",
      "iteration 890: f_best = 0.00000000\n",
      "x_eff  = [-0.00559386  0.12418704],\n",
      "\n",
      "iteration 891: f_best = 0.00000000\n",
      "x_eff  = [ 0.05836691 -0.03172751],\n",
      "\n",
      "iteration 892: f_best = 0.00000000\n",
      "x_eff  = [ 0.01051838 -0.03853964],\n",
      "\n",
      "iteration 893: f_best = 0.00000000\n",
      "x_eff  = [-0.12790179 -0.11196109],\n",
      "\n",
      "iteration 894: f_best = 0.00000000\n",
      "x_eff  = [ 0.08744689 -0.12699392],\n",
      "\n",
      "iteration 895: f_best = 0.00000000\n",
      "x_eff  = [ 0.1232012 -0.0055339],\n",
      "\n",
      "iteration 896: f_best = 0.00000000\n",
      "x_eff  = [-0.00933681  0.18544513],\n",
      "\n",
      "iteration 897: f_best = 0.00000000\n",
      "x_eff  = [0.10485032 0.0194433 ],\n",
      "\n",
      "iteration 898: f_best = 0.00000000\n",
      "x_eff  = [0.10583199 0.00976295],\n",
      "\n",
      "iteration 899: f_best = 0.00000000\n",
      "x_eff  = [-0.02259631  0.02136606],\n",
      "\n",
      "iteration 900: f_best = 0.00000000\n",
      "x_eff  = [-0.01107588 -0.08852196],\n",
      "\n",
      "iteration 901: f_best = 0.00000000\n",
      "x_eff  = [ 0.13685972 -0.03525131],\n",
      "\n",
      "iteration 902: f_best = 0.00000000\n",
      "x_eff  = [0.18340441 0.04628433],\n",
      "\n",
      "iteration 903: f_best = 0.00000000\n",
      "x_eff  = [0.09647123 0.16407872],\n",
      "\n",
      "iteration 904: f_best = 0.00000000\n",
      "x_eff  = [-0.03682335 -0.17572174],\n",
      "\n",
      "iteration 905: f_best = 0.00000000\n",
      "x_eff  = [ 0.16191915 -0.16998585],\n",
      "\n",
      "iteration 906: f_best = 0.00000000\n",
      "x_eff  = [ 0.07875012 -0.17712485],\n",
      "\n",
      "iteration 907: f_best = 0.00000000\n",
      "x_eff  = [-0.01026154 -0.15559642],\n",
      "\n",
      "iteration 908: f_best = 0.00000000\n",
      "x_eff  = [-0.09612953  0.04294984],\n",
      "\n",
      "iteration 909: f_best = 0.00000000\n",
      "x_eff  = [-0.16341417  0.06126341],\n",
      "\n",
      "iteration 910: f_best = 0.00000000\n",
      "x_eff  = [-0.0282002   0.06593265],\n",
      "\n",
      "iteration 911: f_best = 0.00000000\n",
      "x_eff  = [ 0.09046457 -0.0746973 ],\n",
      "\n",
      "iteration 912: f_best = 0.00000000\n",
      "x_eff  = [ 0.14326743 -0.08621883],\n",
      "\n",
      "iteration 913: f_best = 0.00000000\n",
      "x_eff  = [-0.07733304  0.10763713],\n",
      "\n",
      "iteration 914: f_best = 0.00000000\n",
      "x_eff  = [ 0.04956485 -0.05147306],\n",
      "\n",
      "iteration 915: f_best = 0.00000000\n",
      "x_eff  = [-0.04871253  0.10218817],\n",
      "\n",
      "iteration 916: f_best = 0.00000000\n",
      "x_eff  = [-0.04161346  0.00988441],\n",
      "\n",
      "iteration 917: f_best = 0.00000000\n",
      "x_eff  = [0.13905542 0.04176191],\n",
      "\n",
      "iteration 918: f_best = 0.00000000\n",
      "x_eff  = [-0.00902881 -0.11350036],\n",
      "\n",
      "iteration 919: f_best = 0.00000000\n",
      "x_eff  = [-0.10411437  0.08175575],\n",
      "\n",
      "iteration 920: f_best = 0.00000000\n",
      "x_eff  = [-0.12941882 -0.15755079],\n",
      "\n",
      "iteration 921: f_best = 0.00000000\n",
      "x_eff  = [-0.00132685 -0.02816293],\n",
      "\n",
      "iteration 922: f_best = 0.00000000\n",
      "x_eff  = [ 0.1276196  -0.06100848],\n",
      "\n",
      "iteration 923: f_best = 0.00000000\n",
      "x_eff  = [-0.0918878  -0.05219953],\n",
      "\n",
      "iteration 924: f_best = 0.00000000\n",
      "x_eff  = [ 0.1132993 -0.1516737],\n",
      "\n",
      "iteration 925: f_best = 0.00000000\n",
      "x_eff  = [0.02192749 0.08741583],\n",
      "\n",
      "iteration 926: f_best = 0.00000000\n",
      "x_eff  = [ 0.04175139 -0.13894173],\n",
      "\n",
      "iteration 927: f_best = 0.00000000\n",
      "x_eff  = [-0.03213752  0.11247252],\n",
      "\n",
      "iteration 928: f_best = 0.00000000\n",
      "x_eff  = [ 0.1387426  -0.09859621],\n",
      "\n",
      "iteration 929: f_best = 0.00000000\n",
      "x_eff  = [-0.12585832  0.05344117],\n",
      "\n",
      "iteration 930: f_best = 0.00000000\n",
      "x_eff  = [ 0.01431602 -0.07812303],\n",
      "\n",
      "iteration 931: f_best = 0.00000000\n",
      "x_eff  = [0.00453643 0.009407  ],\n",
      "\n",
      "iteration 932: f_best = 0.00000000\n",
      "x_eff  = [ 0.07565274 -0.1088516 ],\n",
      "\n",
      "iteration 933: f_best = 0.00000000\n",
      "x_eff  = [ 0.06336467 -0.12199424],\n",
      "\n",
      "iteration 934: f_best = 0.00000000\n",
      "x_eff  = [0.08717443 0.09722888],\n",
      "\n",
      "iteration 935: f_best = 0.00000000\n",
      "x_eff  = [0.00413637 0.03303795],\n",
      "\n",
      "iteration 936: f_best = 0.00000000\n",
      "x_eff  = [ 0.03444951 -0.00136468],\n",
      "\n",
      "iteration 937: f_best = 0.00000000\n",
      "x_eff  = [0.07897061 0.08716625],\n",
      "\n",
      "iteration 938: f_best = 0.00000000\n",
      "x_eff  = [0.06630239 0.03916809],\n",
      "\n",
      "iteration 939: f_best = 0.00000000\n",
      "x_eff  = [-0.05572057 -0.01498913],\n",
      "\n",
      "iteration 940: f_best = 0.00000000\n",
      "x_eff  = [0.11448539 0.00527684],\n",
      "\n",
      "iteration 941: f_best = 0.00000000\n",
      "x_eff  = [0.01924962 0.00592457],\n",
      "\n",
      "iteration 942: f_best = 0.00000000\n",
      "x_eff  = [0.08047121 0.12219945],\n",
      "\n",
      "iteration 943: f_best = 0.00000000\n",
      "x_eff  = [0.03337974 0.01194419],\n",
      "\n",
      "iteration 944: f_best = 0.00000000\n",
      "x_eff  = [-0.12164147  0.01253869],\n",
      "\n",
      "iteration 945: f_best = 0.00000000\n",
      "x_eff  = [-0.07550173  0.09484201],\n",
      "\n",
      "iteration 946: f_best = 0.00000000\n",
      "x_eff  = [-0.05808079  0.07173646],\n",
      "\n",
      "iteration 947: f_best = 0.00000000\n",
      "x_eff  = [-0.07278595 -0.1065103 ],\n",
      "\n",
      "iteration 948: f_best = 0.00000000\n",
      "x_eff  = [-0.045451  -0.1200646],\n",
      "\n",
      "iteration 949: f_best = 0.00000000\n",
      "x_eff  = [0.06990878 0.00264303],\n",
      "\n",
      "iteration 950: f_best = 0.00000000\n",
      "x_eff  = [-0.04292505 -0.03555958],\n",
      "\n",
      "iteration 951: f_best = 0.00000000\n",
      "x_eff  = [ 0.07230388 -0.09634845],\n",
      "\n",
      "iteration 952: f_best = 0.00000000\n",
      "x_eff  = [-0.02196992  0.01643172],\n",
      "\n",
      "iteration 953: f_best = 0.00000000\n",
      "x_eff  = [-0.1014582 -0.1088374],\n",
      "\n",
      "iteration 954: f_best = 0.00000000\n",
      "x_eff  = [-0.04424554  0.0304715 ],\n",
      "\n",
      "iteration 955: f_best = 0.00000000\n",
      "x_eff  = [-0.10867555 -0.07861818],\n",
      "\n",
      "iteration 956: f_best = 0.00000000\n",
      "x_eff  = [-0.00624473 -0.03773941],\n",
      "\n",
      "iteration 957: f_best = 0.00000000\n",
      "x_eff  = [ 0.06689298 -0.02956251],\n",
      "\n",
      "iteration 958: f_best = 0.00000000\n",
      "x_eff  = [-0.00148996 -0.02220846],\n",
      "\n",
      "iteration 959: f_best = 0.00000000\n",
      "x_eff  = [0.0902841  0.01949228],\n",
      "\n",
      "iteration 960: f_best = 0.00000000\n",
      "x_eff  = [0.03240639 0.07967144],\n",
      "\n",
      "iteration 961: f_best = 0.00000000\n",
      "x_eff  = [0.06058167 0.02936887],\n",
      "\n",
      "iteration 962: f_best = 0.00000000\n",
      "x_eff  = [-0.02012387 -0.0097647 ],\n",
      "\n",
      "iteration 963: f_best = 0.00000000\n",
      "x_eff  = [0.08147383 0.06177735],\n",
      "\n",
      "iteration 964: f_best = 0.00000000\n",
      "x_eff  = [-0.0769751   0.04653842],\n",
      "\n",
      "iteration 965: f_best = 0.00000000\n",
      "x_eff  = [0.00937777 0.02044667],\n",
      "\n",
      "iteration 966: f_best = 0.00000000\n",
      "x_eff  = [-0.07780585  0.03733718],\n",
      "\n",
      "iteration 967: f_best = 0.00000000\n",
      "x_eff  = [ 0.03377159 -0.09251818],\n",
      "\n",
      "iteration 968: f_best = 0.00000000\n",
      "x_eff  = [ 0.01950632 -0.0441481 ],\n",
      "\n",
      "iteration 969: f_best = 0.00000000\n",
      "x_eff  = [-0.05542119  0.00566705],\n",
      "\n",
      "iteration 970: f_best = 0.00000000\n",
      "x_eff  = [-0.06524173 -0.01403039],\n",
      "\n",
      "iteration 971: f_best = 0.00000000\n",
      "x_eff  = [0.03756769 0.08878989],\n",
      "\n",
      "iteration 972: f_best = 0.00000000\n",
      "x_eff  = [-0.00993791  0.03753719],\n",
      "\n",
      "iteration 973: f_best = 0.00000000\n",
      "x_eff  = [-0.05926216 -0.02509921],\n",
      "\n",
      "iteration 974: f_best = 0.00000000\n",
      "x_eff  = [0.04074605 0.02247364],\n",
      "\n",
      "iteration 975: f_best = 0.00000000\n",
      "x_eff  = [-0.08665088  0.06989165],\n",
      "\n",
      "iteration 976: f_best = 0.00000000\n",
      "x_eff  = [-0.06680285 -0.07848334],\n",
      "\n",
      "iteration 977: f_best = 0.00000000\n",
      "x_eff  = [-0.02911081 -0.0199704 ],\n",
      "\n",
      "iteration 978: f_best = 0.00000000\n",
      "x_eff  = [-0.0455072  -0.04640972],\n",
      "\n",
      "iteration 979: f_best = 0.00000000\n",
      "x_eff  = [ 0.06035244 -0.04931816],\n",
      "\n",
      "iteration 980: f_best = 0.00000000\n",
      "x_eff  = [0.01784191 0.08652653],\n",
      "\n",
      "iteration 981: f_best = 0.00000000\n",
      "x_eff  = [ 0.00934413 -0.05880752],\n",
      "\n",
      "iteration 982: f_best = 0.00000000\n",
      "x_eff  = [-0.06644891  0.03442995],\n",
      "\n",
      "iteration 983: f_best = 0.00000000\n",
      "x_eff  = [-0.00118624 -0.00515084],\n",
      "\n",
      "iteration 984: f_best = 0.00000000\n",
      "x_eff  = [ 0.04301217 -0.05523237],\n",
      "\n",
      "iteration 985: f_best = 0.00000000\n",
      "x_eff  = [ 0.07821167 -0.01389949],\n",
      "\n",
      "iteration 986: f_best = 0.00000000\n",
      "x_eff  = [0.03338464 0.00977613],\n",
      "\n",
      "iteration 987: f_best = 0.00000000\n",
      "x_eff  = [0.03691786 0.03041809],\n",
      "\n",
      "iteration 988: f_best = 0.00000000\n",
      "x_eff  = [-0.0020091  0.0434889],\n",
      "\n",
      "iteration 989: f_best = 0.00000000\n",
      "x_eff  = [0.06507069 0.01472058],\n",
      "\n",
      "iteration 990: f_best = 0.00000000\n",
      "x_eff  = [ 0.00620119 -0.01634143],\n",
      "\n",
      "iteration 991: f_best = 0.00000000\n",
      "x_eff  = [-0.06426436  0.00552084],\n",
      "\n",
      "iteration 992: f_best = 0.00000000\n",
      "x_eff  = [-0.00750883 -0.05638221],\n",
      "\n",
      "iteration 993: f_best = 0.00000000\n",
      "x_eff  = [-0.03036782  0.0194862 ],\n",
      "\n",
      "iteration 994: f_best = 0.00000000\n",
      "x_eff  = [-0.02014119  0.07620162],\n",
      "\n",
      "iteration 995: f_best = 0.00000000\n",
      "x_eff  = [-0.03445997 -0.05615129],\n",
      "\n",
      "iteration 996: f_best = 0.00000000\n",
      "x_eff  = [ 0.06607312 -0.06876243],\n",
      "\n",
      "iteration 997: f_best = 0.00000000\n",
      "x_eff  = [-0.07377495  0.00181074],\n",
      "\n",
      "iteration 998: f_best = 0.00000000\n",
      "x_eff  = [-0.07220211 -0.00017359],\n",
      "\n",
      "iteration 999: f_best = 0.00000000\n",
      "x_eff  = [-0.01714005 -0.06093243],\n",
      "\n",
      "Best value for K_warmup=10: 0.00000000\n",
      "Best value for K_warmup=100: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "bounds = np.array([[-600, 600], [-600, 600]])\n",
    "tau = 1e-8\n",
    "K_warmup1 = 10\n",
    "K_warmup2 = 100\n",
    "K = 1000\n",
    "\n",
    "x_best1, f_best1 = global_opt(bounds, tau, K, K_warmup1)\n",
    "x_best2, f_best2 = global_opt(bounds, tau, K, K_warmup2)\n",
    "\n",
    "print(f\"Best value for K_warmup={K_warmup1}: {f_best1:.8f}\")\n",
    "print(f\"Best value for K_warmup={K_warmup2}: {f_best2:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10: f_best = 19.77562170\n",
      "x_eff  = [273.1813859   66.57601136],\n",
      "\n",
      "iteration 11: f_best = 4.56487366\n",
      "x_eff  = [134.43987558  -2.38868893],\n",
      "\n",
      "iteration 12: f_best = 4.56487366\n",
      "x_eff  = [124.72078204 106.39214305],\n",
      "\n",
      "iteration 13: f_best = 4.56487366\n",
      "x_eff  = [-113.48379155 -122.38128808],\n",
      "\n",
      "iteration 14: f_best = 4.56487366\n",
      "x_eff  = [ 200.97273426 -111.34107898],\n",
      "\n",
      "iteration 15: f_best = 4.56487366\n",
      "x_eff  = [-121.48888928  -70.8970033 ],\n",
      "\n",
      "iteration 16: f_best = 4.56487366\n",
      "x_eff  = [256.82858714 207.69437914],\n",
      "\n",
      "iteration 17: f_best = 4.56487366\n",
      "x_eff  = [  39.50991655 -181.30255398],\n",
      "\n",
      "iteration 18: f_best = 4.56487366\n",
      "x_eff  = [281.94395303  34.50499241],\n",
      "\n",
      "iteration 19: f_best = 1.84220516\n",
      "x_eff  = [ 83.78010146 -15.47831369],\n",
      "\n",
      "iteration 20: f_best = 1.84220516\n",
      "x_eff  = [300.9429271  144.75577884],\n",
      "\n",
      "iteration 21: f_best = 1.49939059\n",
      "x_eff  = [ 76.83024493 -16.48127232],\n",
      "\n",
      "iteration 22: f_best = 1.49939059\n",
      "x_eff  = [   9.86238055 -276.89375947],\n",
      "\n",
      "iteration 23: f_best = 1.49939059\n",
      "x_eff  = [ -53.21618672 -142.61942042],\n",
      "\n",
      "iteration 24: f_best = 1.49939059\n",
      "x_eff  = [294.60255479 -35.23470417],\n",
      "\n",
      "iteration 25: f_best = 1.49939059\n",
      "x_eff  = [146.79910821  50.27409673],\n",
      "\n",
      "iteration 26: f_best = 1.49939059\n",
      "x_eff  = [121.39350654  39.20209574],\n",
      "\n",
      "iteration 27: f_best = 1.49939059\n",
      "x_eff  = [ 84.1449772  247.19188742],\n",
      "\n",
      "iteration 28: f_best = 1.49939059\n",
      "x_eff  = [155.11912046  24.39300475],\n",
      "\n",
      "iteration 29: f_best = 1.49939059\n",
      "x_eff  = [-41.48529623 158.36607349],\n",
      "\n",
      "iteration 30: f_best = 1.49939059\n",
      "x_eff  = [ -25.07460754 -229.61611353],\n",
      "\n",
      "iteration 31: f_best = 1.49939059\n",
      "x_eff  = [125.01869103 142.5278012 ],\n",
      "\n",
      "iteration 32: f_best = 1.49939059\n",
      "x_eff  = [293.34120285 124.75550602],\n",
      "\n",
      "iteration 33: f_best = 1.49939059\n",
      "x_eff  = [-51.22954773 110.6304503 ],\n",
      "\n",
      "iteration 34: f_best = 1.49939059\n",
      "x_eff  = [ 255.56064507 -222.86981298],\n",
      "\n",
      "iteration 35: f_best = 1.49939059\n",
      "x_eff  = [-209.75555382  203.26009903],\n",
      "\n",
      "iteration 36: f_best = 1.49939059\n",
      "x_eff  = [-84.00590665   6.01792758],\n",
      "\n",
      "iteration 37: f_best = 1.49939059\n",
      "x_eff  = [ 271.30004945 -129.4971377 ],\n",
      "\n",
      "iteration 38: f_best = 1.49939059\n",
      "x_eff  = [250.52145535  65.39416919],\n",
      "\n",
      "iteration 39: f_best = 1.49939059\n",
      "x_eff  = [ 249.00583938 -172.34573521],\n",
      "\n",
      "iteration 40: f_best = 1.49939059\n",
      "x_eff  = [ -40.94202533 -184.25838473],\n",
      "\n",
      "iteration 41: f_best = 1.49939059\n",
      "x_eff  = [258.79818614 -19.68614274],\n",
      "\n",
      "iteration 42: f_best = 1.49939059\n",
      "x_eff  = [-110.13528128 -187.81508725],\n",
      "\n",
      "iteration 43: f_best = 1.49939059\n",
      "x_eff  = [-135.66599193   13.72676019],\n",
      "\n",
      "iteration 44: f_best = 1.49939059\n",
      "x_eff  = [-110.41790591 -133.84917871],\n",
      "\n",
      "iteration 45: f_best = 0.61871000\n",
      "x_eff  = [  9.96594967 -49.31024098],\n",
      "\n",
      "iteration 46: f_best = 0.61871000\n",
      "x_eff  = [-222.07649043   40.18130398],\n",
      "\n",
      "iteration 47: f_best = 0.61871000\n",
      "x_eff  = [-37.57251201 157.57543663],\n",
      "\n",
      "iteration 48: f_best = 0.61871000\n",
      "x_eff  = [ -62.39418209 -167.22122669],\n",
      "\n",
      "iteration 49: f_best = 0.61871000\n",
      "x_eff  = [  88.37332331 -119.62166736],\n",
      "\n",
      "iteration 50: f_best = 0.61871000\n",
      "x_eff  = [  -1.54699222 -175.50044265],\n",
      "\n",
      "iteration 51: f_best = 0.61871000\n",
      "x_eff  = [-96.5193849   35.54996665],\n",
      "\n",
      "iteration 52: f_best = 0.61871000\n",
      "x_eff  = [236.96490552 194.00923441],\n",
      "\n",
      "iteration 53: f_best = 0.61871000\n",
      "x_eff  = [184.56452786 167.06200918],\n",
      "\n",
      "iteration 54: f_best = 0.61871000\n",
      "x_eff  = [-132.00126306   59.95478422],\n",
      "\n",
      "iteration 55: f_best = 0.61871000\n",
      "x_eff  = [182.3797882 146.7994275],\n",
      "\n",
      "iteration 56: f_best = 0.61871000\n",
      "x_eff  = [ 101.63522129 -251.51411856],\n",
      "\n",
      "iteration 57: f_best = 0.61871000\n",
      "x_eff  = [ 233.54195904 -197.07268864],\n",
      "\n",
      "iteration 58: f_best = 0.61871000\n",
      "x_eff  = [ 150.20098423 -177.87081288],\n",
      "\n",
      "iteration 59: f_best = 0.61871000\n",
      "x_eff  = [ -42.87198852 -175.48456222],\n",
      "\n",
      "iteration 60: f_best = 0.61871000\n",
      "x_eff  = [-83.71354565 -41.20608933],\n",
      "\n",
      "iteration 61: f_best = 0.42171226\n",
      "x_eff  = [42.33097238  4.62186294],\n",
      "\n",
      "iteration 62: f_best = 0.42171226\n",
      "x_eff  = [216.9395775   56.29032303],\n",
      "\n",
      "iteration 63: f_best = 0.42171226\n",
      "x_eff  = [ 1.09198911e-01 -1.14592210e+02],\n",
      "\n",
      "iteration 64: f_best = 0.08874263\n",
      "x_eff  = [-15.29715673  17.66784375],\n",
      "\n",
      "iteration 65: f_best = 0.08874263\n",
      "x_eff  = [111.94365566 -67.92666458],\n",
      "\n",
      "iteration 66: f_best = 0.08874263\n",
      "x_eff  = [183.92591413  83.2818083 ],\n",
      "\n",
      "iteration 67: f_best = 0.08874263\n",
      "x_eff  = [-151.54285846  213.72982726],\n",
      "\n",
      "iteration 68: f_best = 0.08874263\n",
      "x_eff  = [-93.16830808 174.00469121],\n",
      "\n",
      "iteration 69: f_best = 0.08874263\n",
      "x_eff  = [200.39243805 145.4250943 ],\n",
      "\n",
      "iteration 70: f_best = 0.08874263\n",
      "x_eff  = [ 86.61584387 161.8838764 ],\n",
      "\n",
      "iteration 71: f_best = 0.08874263\n",
      "x_eff  = [199.40004845 -92.59170089],\n",
      "\n",
      "iteration 72: f_best = 0.08874263\n",
      "x_eff  = [-190.50871771  177.68227362],\n",
      "\n",
      "iteration 73: f_best = 0.08874263\n",
      "x_eff  = [ 173.27439837 -129.28137069],\n",
      "\n",
      "iteration 74: f_best = 0.08874263\n",
      "x_eff  = [-205.48245311 -153.5073037 ],\n",
      "\n",
      "iteration 75: f_best = 0.08874263\n",
      "x_eff  = [ -91.46790004 -184.13632077],\n",
      "\n",
      "iteration 76: f_best = 0.08874263\n",
      "x_eff  = [98.90646094 40.48769085],\n",
      "\n",
      "iteration 77: f_best = 0.08874263\n",
      "x_eff  = [-37.46076212  91.08215644],\n",
      "\n",
      "iteration 78: f_best = 0.08874263\n",
      "x_eff  = [  36.00209521 -159.58459239],\n",
      "\n",
      "iteration 79: f_best = 0.08874263\n",
      "x_eff  = [-183.43675488   61.37716186],\n",
      "\n",
      "iteration 80: f_best = 0.08874263\n",
      "x_eff  = [130.74096639  61.25356307],\n",
      "\n",
      "iteration 81: f_best = 0.08874263\n",
      "x_eff  = [-125.32643443   97.97981555],\n",
      "\n",
      "iteration 82: f_best = 0.08874263\n",
      "x_eff  = [ -76.09592955 -123.85340795],\n",
      "\n",
      "iteration 83: f_best = 0.08874263\n",
      "x_eff  = [-63.72068358 156.13620578],\n",
      "\n",
      "iteration 84: f_best = 0.08874263\n",
      "x_eff  = [-98.43930677 134.68139885],\n",
      "\n",
      "iteration 85: f_best = 0.08874263\n",
      "x_eff  = [-119.39267783   97.85789704],\n",
      "\n",
      "iteration 86: f_best = 0.08874263\n",
      "x_eff  = [  32.37618225 -153.81484954],\n",
      "\n",
      "iteration 87: f_best = 0.08874263\n",
      "x_eff  = [156.82308176 152.39133265],\n",
      "\n",
      "iteration 88: f_best = 0.08874263\n",
      "x_eff  = [-191.37427824  -18.82640026],\n",
      "\n",
      "iteration 89: f_best = 0.08874263\n",
      "x_eff  = [  36.04579651 -122.79930482],\n",
      "\n",
      "iteration 90: f_best = 0.08874263\n",
      "x_eff  = [103.0591129 -23.5102118],\n",
      "\n",
      "iteration 91: f_best = 0.08874263\n",
      "x_eff  = [ -55.61337392 -153.00687394],\n",
      "\n",
      "iteration 92: f_best = 0.08874263\n",
      "x_eff  = [133.41806674  -0.64314139],\n",
      "\n",
      "iteration 93: f_best = 0.08874263\n",
      "x_eff  = [-134.53453308   84.64585253],\n",
      "\n",
      "iteration 94: f_best = 0.08874263\n",
      "x_eff  = [ 33.60515921 132.34239345],\n",
      "\n",
      "iteration 95: f_best = 0.08874263\n",
      "x_eff  = [-169.42202026 -162.41128979],\n",
      "\n",
      "iteration 96: f_best = 0.08874263\n",
      "x_eff  = [107.58101092  42.48758966],\n",
      "\n",
      "iteration 97: f_best = 0.08874263\n",
      "x_eff  = [23.07869363 26.97537658],\n",
      "\n",
      "iteration 98: f_best = 0.08874263\n",
      "x_eff  = [96.51583658 71.40277218],\n",
      "\n",
      "iteration 99: f_best = 0.08874263\n",
      "x_eff  = [-168.03267283 -138.41042025],\n",
      "\n",
      "iteration 100: f_best = 0.08874263\n",
      "x_eff  = [145.789043   158.02089828],\n",
      "\n",
      "iteration 101: f_best = 0.08874263\n",
      "x_eff  = [-31.88160934  40.1351444 ],\n",
      "\n",
      "iteration 102: f_best = 0.08874263\n",
      "x_eff  = [-47.89832347 -85.75883656],\n",
      "\n",
      "iteration 103: f_best = 0.08874263\n",
      "x_eff  = [  66.45331649 -104.59630077],\n",
      "\n",
      "iteration 104: f_best = 0.08874263\n",
      "x_eff  = [ 34.42682229 -75.56062567],\n",
      "\n",
      "iteration 105: f_best = 0.08874263\n",
      "x_eff  = [  69.38150244 -136.49153654],\n",
      "\n",
      "iteration 106: f_best = 0.08874263\n",
      "x_eff  = [ 52.80330172 -34.3640089 ],\n",
      "\n",
      "iteration 107: f_best = 0.08874263\n",
      "x_eff  = [-117.12867921  173.66683504],\n",
      "\n",
      "iteration 108: f_best = 0.08874263\n",
      "x_eff  = [-147.99547758 -105.72960746],\n",
      "\n",
      "iteration 109: f_best = 0.08874263\n",
      "x_eff  = [ 5.65919017 36.09785315],\n",
      "\n",
      "iteration 110: f_best = 0.08874263\n",
      "x_eff  = [ 141.53526378 -119.32991481],\n",
      "\n",
      "iteration 111: f_best = 0.08874263\n",
      "x_eff  = [ -86.72616097 -146.76852618],\n",
      "\n",
      "iteration 112: f_best = 0.08874263\n",
      "x_eff  = [-76.12696689 145.18265037],\n",
      "\n",
      "iteration 113: f_best = 0.08874263\n",
      "x_eff  = [-72.9520264  152.70997107],\n",
      "\n",
      "iteration 114: f_best = 0.08874263\n",
      "x_eff  = [ -96.48352523 -138.47745083],\n",
      "\n",
      "iteration 115: f_best = 0.08874263\n",
      "x_eff  = [ 14.72321648 -11.65534373],\n",
      "\n",
      "iteration 116: f_best = 0.08874263\n",
      "x_eff  = [146.2731187  31.7295354],\n",
      "\n",
      "iteration 117: f_best = 0.08874263\n",
      "x_eff  = [-125.04450378  -12.7644124 ],\n",
      "\n",
      "iteration 118: f_best = 0.08874263\n",
      "x_eff  = [-24.81768932 150.38172973],\n",
      "\n",
      "iteration 119: f_best = 0.08874263\n",
      "x_eff  = [ -52.6590987  -121.68143342],\n",
      "\n",
      "iteration 120: f_best = 0.08874263\n",
      "x_eff  = [   1.51981    -120.47501626],\n",
      "\n",
      "iteration 121: f_best = 0.08874263\n",
      "x_eff  = [-10.86005038  39.41575689],\n",
      "\n",
      "iteration 122: f_best = 0.08874263\n",
      "x_eff  = [ 73.83319631 102.70304728],\n",
      "\n",
      "iteration 123: f_best = 0.08874263\n",
      "x_eff  = [ 59.79338242 152.85918316],\n",
      "\n",
      "iteration 124: f_best = 0.08874263\n",
      "x_eff  = [  60.74622079 -103.61540589],\n",
      "\n",
      "iteration 125: f_best = 0.08874263\n",
      "x_eff  = [46.72182958 83.38390987],\n",
      "\n",
      "iteration 126: f_best = 0.08874263\n",
      "x_eff  = [ 13.77140135 130.96039931],\n",
      "\n",
      "iteration 127: f_best = 0.08874263\n",
      "x_eff  = [ 111.81828729 -126.33742064],\n",
      "\n",
      "iteration 128: f_best = 0.08874263\n",
      "x_eff  = [-1.20871735 62.60984147],\n",
      "\n",
      "iteration 129: f_best = 0.08874263\n",
      "x_eff  = [ 73.66456967 121.76014998],\n",
      "\n",
      "iteration 130: f_best = 0.08874263\n",
      "x_eff  = [-140.2894239   110.30124273],\n",
      "\n",
      "iteration 131: f_best = 0.08874263\n",
      "x_eff  = [106.224282   -26.10090989],\n",
      "\n",
      "iteration 132: f_best = 0.08874263\n",
      "x_eff  = [-48.39023704  55.45227458],\n",
      "\n",
      "iteration 133: f_best = 0.08874263\n",
      "x_eff  = [-76.2685375   99.03535464],\n",
      "\n",
      "iteration 134: f_best = 0.00000000\n",
      "x_eff  = [-0.43807306  0.95464634],\n",
      "\n",
      "iteration 135: f_best = 0.00000000\n",
      "x_eff  = [ -59.25200226 -102.7861097 ],\n",
      "\n",
      "iteration 136: f_best = 0.00000000\n",
      "x_eff  = [-4.64772786 33.23704985],\n",
      "\n",
      "iteration 137: f_best = 0.00000000\n",
      "x_eff  = [ -0.95700441 101.51061988],\n",
      "\n",
      "iteration 138: f_best = 0.00000000\n",
      "x_eff  = [42.55961874 72.22496164],\n",
      "\n",
      "iteration 139: f_best = 0.00000000\n",
      "x_eff  = [-42.55877101  81.44324393],\n",
      "\n",
      "iteration 140: f_best = 0.00000000\n",
      "x_eff  = [121.29687777 -49.93241684],\n",
      "\n",
      "iteration 141: f_best = 0.00000000\n",
      "x_eff  = [ 56.47239024 -78.85574003],\n",
      "\n",
      "iteration 142: f_best = 0.00000000\n",
      "x_eff  = [-37.9364607  102.00237491],\n",
      "\n",
      "iteration 143: f_best = 0.00000000\n",
      "x_eff  = [43.43673324 97.80804198],\n",
      "\n",
      "iteration 144: f_best = 0.00000000\n",
      "x_eff  = [ 73.55885131 -88.25996562],\n",
      "\n",
      "iteration 145: f_best = 0.00000000\n",
      "x_eff  = [110.07775391  41.82408737],\n",
      "\n",
      "iteration 146: f_best = 0.00000000\n",
      "x_eff  = [ 29.24519509 -75.97101412],\n",
      "\n",
      "iteration 147: f_best = 0.00000000\n",
      "x_eff  = [101.72997263  12.89920826],\n",
      "\n",
      "iteration 148: f_best = 0.00000000\n",
      "x_eff  = [ 69.18441694 -78.48654445],\n",
      "\n",
      "iteration 149: f_best = 0.00000000\n",
      "x_eff  = [-11.43273837 -68.53234758],\n",
      "\n",
      "iteration 150: f_best = 0.00000000\n",
      "x_eff  = [-54.86573644  78.89772964],\n",
      "\n",
      "iteration 151: f_best = 0.00000000\n",
      "x_eff  = [-7.75857345  1.92766613],\n",
      "\n",
      "iteration 152: f_best = 0.00000000\n",
      "x_eff  = [37.552294  77.0439788],\n",
      "\n",
      "iteration 153: f_best = 0.00000000\n",
      "x_eff  = [ 98.57723731 -96.52880338],\n",
      "\n",
      "iteration 154: f_best = 0.00000000\n",
      "x_eff  = [  2.18642839 -33.62748584],\n",
      "\n",
      "iteration 155: f_best = 0.00000000\n",
      "x_eff  = [ 53.70253298 -45.25765918],\n",
      "\n",
      "iteration 156: f_best = 0.00000000\n",
      "x_eff  = [ 32.01390654 -19.19590982],\n",
      "\n",
      "iteration 157: f_best = 0.00000000\n",
      "x_eff  = [ 46.50147856 -86.04937593],\n",
      "\n",
      "iteration 158: f_best = 0.00000000\n",
      "x_eff  = [ -8.78006891 -75.06573064],\n",
      "\n",
      "iteration 159: f_best = 0.00000000\n",
      "x_eff  = [ 55.80961315 -64.44984342],\n",
      "\n",
      "iteration 160: f_best = 0.00000000\n",
      "x_eff  = [71.94058016 73.1618358 ],\n",
      "\n",
      "iteration 161: f_best = 0.00000000\n",
      "x_eff  = [-17.16398523  74.0415488 ],\n",
      "\n",
      "iteration 162: f_best = 0.00000000\n",
      "x_eff  = [-55.1475779   49.59294809],\n",
      "\n",
      "iteration 163: f_best = 0.00000000\n",
      "x_eff  = [-67.73941701  89.18076021],\n",
      "\n",
      "iteration 164: f_best = 0.00000000\n",
      "x_eff  = [-95.28844307 -86.30097997],\n",
      "\n",
      "iteration 165: f_best = 0.00000000\n",
      "x_eff  = [-74.41593459 -46.24623914],\n",
      "\n",
      "iteration 166: f_best = 0.00000000\n",
      "x_eff  = [ 7.29719209 46.17929852],\n",
      "\n",
      "iteration 167: f_best = 0.00000000\n",
      "x_eff  = [ 42.47095616 -11.98507296],\n",
      "\n",
      "iteration 168: f_best = 0.00000000\n",
      "x_eff  = [-23.22437865 -28.59154272],\n",
      "\n",
      "iteration 169: f_best = 0.00000000\n",
      "x_eff  = [ 88.10421448 -34.77320568],\n",
      "\n",
      "iteration 170: f_best = 0.00000000\n",
      "x_eff  = [-49.15022071 -73.36314636],\n",
      "\n",
      "iteration 171: f_best = 0.00000000\n",
      "x_eff  = [-74.73082459  40.33878006],\n",
      "\n",
      "iteration 172: f_best = 0.00000000\n",
      "x_eff  = [-67.4170565  -55.86831665],\n",
      "\n",
      "iteration 173: f_best = 0.00000000\n",
      "x_eff  = [-18.31870572 -95.27965358],\n",
      "\n",
      "iteration 174: f_best = 0.00000000\n",
      "x_eff  = [28.46142403 86.01829601],\n",
      "\n",
      "iteration 175: f_best = 0.00000000\n",
      "x_eff  = [87.06327388 70.94112372],\n",
      "\n",
      "iteration 176: f_best = 0.00000000\n",
      "x_eff  = [ 3.29851169 66.11862377],\n",
      "\n",
      "iteration 177: f_best = 0.00000000\n",
      "x_eff  = [-10.72835232  75.14997426],\n",
      "\n",
      "iteration 178: f_best = 0.00000000\n",
      "x_eff  = [ -1.88481658 -67.53690501],\n",
      "\n",
      "iteration 179: f_best = 0.00000000\n",
      "x_eff  = [-25.08655926 -43.87980529],\n",
      "\n",
      "iteration 180: f_best = 0.00000000\n",
      "x_eff  = [39.2217763  90.64444012],\n",
      "\n",
      "iteration 181: f_best = 0.00000000\n",
      "x_eff  = [-63.02116166  53.89392201],\n",
      "\n",
      "iteration 182: f_best = 0.00000000\n",
      "x_eff  = [-55.93414214  57.96888469],\n",
      "\n",
      "iteration 183: f_best = 0.00000000\n",
      "x_eff  = [-78.8618462  -56.60992699],\n",
      "\n",
      "iteration 184: f_best = 0.00000000\n",
      "x_eff  = [ 79.63800486 -88.38423437],\n",
      "\n",
      "iteration 185: f_best = 0.00000000\n",
      "x_eff  = [67.84250614 -1.5831078 ],\n",
      "\n",
      "iteration 186: f_best = 0.00000000\n",
      "x_eff  = [53.29102134 43.73955207],\n",
      "\n",
      "iteration 187: f_best = 0.00000000\n",
      "x_eff  = [29.78604887 -2.3265305 ],\n",
      "\n",
      "iteration 188: f_best = 0.00000000\n",
      "x_eff  = [-83.14726964  15.10499492],\n",
      "\n",
      "iteration 189: f_best = 0.00000000\n",
      "x_eff  = [-69.19478112  64.79929724],\n",
      "\n",
      "iteration 190: f_best = 0.00000000\n",
      "x_eff  = [-81.91574168  11.42994202],\n",
      "\n",
      "iteration 191: f_best = 0.00000000\n",
      "x_eff  = [-79.06967838  67.63715273],\n",
      "\n",
      "iteration 192: f_best = 0.00000000\n",
      "x_eff  = [-41.91288656 -18.2233271 ],\n",
      "\n",
      "iteration 193: f_best = 0.00000000\n",
      "x_eff  = [-61.02095341 -11.27631206],\n",
      "\n",
      "iteration 194: f_best = 0.00000000\n",
      "x_eff  = [-52.43092042  -1.5697294 ],\n",
      "\n",
      "iteration 195: f_best = 0.00000000\n",
      "x_eff  = [ 53.57061659 -79.34187849],\n",
      "\n",
      "iteration 196: f_best = 0.00000000\n",
      "x_eff  = [ 57.76189464 -73.66943615],\n",
      "\n",
      "iteration 197: f_best = 0.00000000\n",
      "x_eff  = [39.25285531 63.78148697],\n",
      "\n",
      "iteration 198: f_best = 0.00000000\n",
      "x_eff  = [-69.44798292 -67.04165328],\n",
      "\n",
      "iteration 199: f_best = 0.00000000\n",
      "x_eff  = [ 69.9664742  -54.47942215],\n",
      "\n",
      "iteration 200: f_best = 0.00000000\n",
      "x_eff  = [ 56.1266913  -63.95387879],\n",
      "\n",
      "iteration 201: f_best = 0.00000000\n",
      "x_eff  = [-65.62685355  33.82466055],\n",
      "\n",
      "iteration 202: f_best = 0.00000000\n",
      "x_eff  = [-29.44644679  39.6206302 ],\n",
      "\n",
      "iteration 203: f_best = 0.00000000\n",
      "x_eff  = [62.45647581 12.02322792],\n",
      "\n",
      "iteration 204: f_best = 0.00000000\n",
      "x_eff  = [-16.58066477  -0.21165531],\n",
      "\n",
      "iteration 205: f_best = 0.00000000\n",
      "x_eff  = [ 44.83214562 -16.51401969],\n",
      "\n",
      "iteration 206: f_best = 0.00000000\n",
      "x_eff  = [ 8.07508459 25.15430178],\n",
      "\n",
      "iteration 207: f_best = 0.00000000\n",
      "x_eff  = [-21.19178256 -28.25498163],\n",
      "\n",
      "iteration 208: f_best = 0.00000000\n",
      "x_eff  = [11.81075592 65.81816564],\n",
      "\n",
      "iteration 209: f_best = 0.00000000\n",
      "x_eff  = [ -4.44884083 -44.14348247],\n",
      "\n",
      "iteration 210: f_best = 0.00000000\n",
      "x_eff  = [44.33947563 25.87822123],\n",
      "\n",
      "iteration 211: f_best = 0.00000000\n",
      "x_eff  = [17.80733139 28.56686968],\n",
      "\n",
      "iteration 212: f_best = 0.00000000\n",
      "x_eff  = [-59.82061053 -31.20896263],\n",
      "\n",
      "iteration 213: f_best = 0.00000000\n",
      "x_eff  = [-32.82573256 -51.00344297],\n",
      "\n",
      "iteration 214: f_best = 0.00000000\n",
      "x_eff  = [41.60002109 68.54485959],\n",
      "\n",
      "iteration 215: f_best = 0.00000000\n",
      "x_eff  = [-54.63583561  -7.05773862],\n",
      "\n",
      "iteration 216: f_best = 0.00000000\n",
      "x_eff  = [-32.97143186  13.77881615],\n",
      "\n",
      "iteration 217: f_best = 0.00000000\n",
      "x_eff  = [48.25025156 54.83815319],\n",
      "\n",
      "iteration 218: f_best = 0.00000000\n",
      "x_eff  = [-66.26764713 -35.85565001],\n",
      "\n",
      "iteration 219: f_best = 0.00000000\n",
      "x_eff  = [-52.66828564  64.34704529],\n",
      "\n",
      "iteration 220: f_best = 0.00000000\n",
      "x_eff  = [-57.97219851  57.10716182],\n",
      "\n",
      "iteration 221: f_best = 0.00000000\n",
      "x_eff  = [39.58551056 30.43912547],\n",
      "\n",
      "iteration 222: f_best = 0.00000000\n",
      "x_eff  = [-1.22784218 63.93599186],\n",
      "\n",
      "iteration 223: f_best = 0.00000000\n",
      "x_eff  = [ 6.98371825 25.26034993],\n",
      "\n",
      "iteration 224: f_best = 0.00000000\n",
      "x_eff  = [-43.60811907  33.47483546],\n",
      "\n",
      "iteration 225: f_best = 0.00000000\n",
      "x_eff  = [ 7.30079635 -1.82783955],\n",
      "\n",
      "iteration 226: f_best = 0.00000000\n",
      "x_eff  = [ 5.06114024 -7.72615989],\n",
      "\n",
      "iteration 227: f_best = 0.00000000\n",
      "x_eff  = [ 30.2138703  -55.86595677],\n",
      "\n",
      "iteration 228: f_best = 0.00000000\n",
      "x_eff  = [ 50.45676551 -44.7556126 ],\n",
      "\n",
      "iteration 229: f_best = 0.00000000\n",
      "x_eff  = [-57.96248268  28.40739733],\n",
      "\n",
      "iteration 230: f_best = 0.00000000\n",
      "x_eff  = [-32.12306853 -20.75654642],\n",
      "\n",
      "iteration 231: f_best = 0.00000000\n",
      "x_eff  = [53.36192272 -6.4303564 ],\n",
      "\n",
      "iteration 232: f_best = 0.00000000\n",
      "x_eff  = [39.17650894 30.83555976],\n",
      "\n",
      "iteration 233: f_best = 0.00000000\n",
      "x_eff  = [-54.20053144 -22.9479156 ],\n",
      "\n",
      "iteration 234: f_best = 0.00000000\n",
      "x_eff  = [38.69069825 50.23836661],\n",
      "\n",
      "iteration 235: f_best = 0.00000000\n",
      "x_eff  = [ -5.85628622 -44.22004519],\n",
      "\n",
      "iteration 236: f_best = 0.00000000\n",
      "x_eff  = [52.4453092  29.28800332],\n",
      "\n",
      "iteration 237: f_best = 0.00000000\n",
      "x_eff  = [-33.35422913  48.38037918],\n",
      "\n",
      "iteration 238: f_best = 0.00000000\n",
      "x_eff  = [33.18771494 -5.53045041],\n",
      "\n",
      "iteration 239: f_best = 0.00000000\n",
      "x_eff  = [18.59895988 39.43337928],\n",
      "\n",
      "iteration 240: f_best = 0.00000000\n",
      "x_eff  = [ 41.63798848 -46.58068681],\n",
      "\n",
      "iteration 241: f_best = 0.00000000\n",
      "x_eff  = [-44.13196837 -34.94432255],\n",
      "\n",
      "iteration 242: f_best = 0.00000000\n",
      "x_eff  = [9.17087082 3.61619825],\n",
      "\n",
      "iteration 243: f_best = 0.00000000\n",
      "x_eff  = [-22.55251571  33.42776216],\n",
      "\n",
      "iteration 244: f_best = 0.00000000\n",
      "x_eff  = [13.25959431 -0.95532996],\n",
      "\n",
      "iteration 245: f_best = 0.00000000\n",
      "x_eff  = [-42.3721089 -15.3418078],\n",
      "\n",
      "iteration 246: f_best = 0.00000000\n",
      "x_eff  = [-17.05414274 -29.68923943],\n",
      "\n",
      "iteration 247: f_best = 0.00000000\n",
      "x_eff  = [ 41.88569434 -31.76433887],\n",
      "\n",
      "iteration 248: f_best = 0.00000000\n",
      "x_eff  = [16.96415919 -0.97751179],\n",
      "\n",
      "iteration 249: f_best = 0.00000000\n",
      "x_eff  = [-50.18523988  26.71635335],\n",
      "\n",
      "iteration 250: f_best = 0.00000000\n",
      "x_eff  = [ 24.75252194 -24.94836821],\n",
      "\n",
      "iteration 251: f_best = 0.00000000\n",
      "x_eff  = [48.53854462 37.41244072],\n",
      "\n",
      "iteration 252: f_best = 0.00000000\n",
      "x_eff  = [-15.55398682 -48.18337267],\n",
      "\n",
      "iteration 253: f_best = 0.00000000\n",
      "x_eff  = [-11.91616977 -44.05331986],\n",
      "\n",
      "iteration 254: f_best = 0.00000000\n",
      "x_eff  = [29.91833662 32.81575111],\n",
      "\n",
      "iteration 255: f_best = 0.00000000\n",
      "x_eff  = [-20.05713742 -26.0721398 ],\n",
      "\n",
      "iteration 256: f_best = 0.00000000\n",
      "x_eff  = [ 10.84653359 -46.79640667],\n",
      "\n",
      "iteration 257: f_best = 0.00000000\n",
      "x_eff  = [ -6.17125593 -46.41831313],\n",
      "\n",
      "iteration 258: f_best = 0.00000000\n",
      "x_eff  = [ -8.42284214 -13.50423547],\n",
      "\n",
      "iteration 259: f_best = 0.00000000\n",
      "x_eff  = [ 36.26051348 -41.17123236],\n",
      "\n",
      "iteration 260: f_best = 0.00000000\n",
      "x_eff  = [-8.00533921 -3.10817179],\n",
      "\n",
      "iteration 261: f_best = 0.00000000\n",
      "x_eff  = [ -1.77255519 -28.48299318],\n",
      "\n",
      "iteration 262: f_best = 0.00000000\n",
      "x_eff  = [-23.17813895  33.65564748],\n",
      "\n",
      "iteration 263: f_best = 0.00000000\n",
      "x_eff  = [-9.02697502 25.70696648],\n",
      "\n",
      "iteration 264: f_best = 0.00000000\n",
      "x_eff  = [ 40.68166403 -19.2444673 ],\n",
      "\n",
      "iteration 265: f_best = 0.00000000\n",
      "x_eff  = [19.99618422  4.38470332],\n",
      "\n",
      "iteration 266: f_best = 0.00000000\n",
      "x_eff  = [  2.79020269 -43.02707632],\n",
      "\n",
      "iteration 267: f_best = 0.00000000\n",
      "x_eff  = [ 21.16063981 -13.51088983],\n",
      "\n",
      "iteration 268: f_best = 0.00000000\n",
      "x_eff  = [ 11.83447552 -39.52398782],\n",
      "\n",
      "iteration 269: f_best = 0.00000000\n",
      "x_eff  = [-2.28522905  3.99113528],\n",
      "\n",
      "iteration 270: f_best = 0.00000000\n",
      "x_eff  = [35.5131045  -2.28125536],\n",
      "\n",
      "iteration 271: f_best = 0.00000000\n",
      "x_eff  = [18.54292299 -6.16245315],\n",
      "\n",
      "iteration 272: f_best = 0.00000000\n",
      "x_eff  = [-16.65119341  12.63113655],\n",
      "\n",
      "iteration 273: f_best = 0.00000000\n",
      "x_eff  = [18.27465881  9.18395865],\n",
      "\n",
      "iteration 274: f_best = 0.00000000\n",
      "x_eff  = [ 30.61992966 -29.11168789],\n",
      "\n",
      "iteration 275: f_best = 0.00000000\n",
      "x_eff  = [-38.64781754  -5.40836798],\n",
      "\n",
      "iteration 276: f_best = 0.00000000\n",
      "x_eff  = [-16.42038891  34.39825756],\n",
      "\n",
      "iteration 277: f_best = 0.00000000\n",
      "x_eff  = [ 6.59914676 24.3606998 ],\n",
      "\n",
      "iteration 278: f_best = 0.00000000\n",
      "x_eff  = [ -6.36360024 -37.73834544],\n",
      "\n",
      "iteration 279: f_best = 0.00000000\n",
      "x_eff  = [-16.16572429  32.88423797],\n",
      "\n",
      "iteration 280: f_best = 0.00000000\n",
      "x_eff  = [-1.63587425e-02  2.99385025e+01],\n",
      "\n",
      "iteration 281: f_best = 0.00000000\n",
      "x_eff  = [-11.15332958  34.74397323],\n",
      "\n",
      "iteration 282: f_best = 0.00000000\n",
      "x_eff  = [-22.804612    32.53925531],\n",
      "\n",
      "iteration 283: f_best = 0.00000000\n",
      "x_eff  = [12.65244466 22.80766209],\n",
      "\n",
      "iteration 284: f_best = 0.00000000\n",
      "x_eff  = [ 31.77195529 -12.02915659],\n",
      "\n",
      "iteration 285: f_best = 0.00000000\n",
      "x_eff  = [-27.8278587    7.71041104],\n",
      "\n",
      "iteration 286: f_best = 0.00000000\n",
      "x_eff  = [-3.81702529 -8.21104591],\n",
      "\n",
      "iteration 287: f_best = 0.00000000\n",
      "x_eff  = [ -7.35014365 -28.64926789],\n",
      "\n",
      "iteration 288: f_best = 0.00000000\n",
      "x_eff  = [ 16.33454766 -12.44552509],\n",
      "\n",
      "iteration 289: f_best = 0.00000000\n",
      "x_eff  = [ 16.8837979  -29.76498761],\n",
      "\n",
      "iteration 290: f_best = 0.00000000\n",
      "x_eff  = [-11.84263954 -25.14578733],\n",
      "\n",
      "iteration 291: f_best = 0.00000000\n",
      "x_eff  = [-30.0803479  -15.89854078],\n",
      "\n",
      "iteration 292: f_best = 0.00000000\n",
      "x_eff  = [-8.68708305  1.57546955],\n",
      "\n",
      "iteration 293: f_best = 0.00000000\n",
      "x_eff  = [11.47595886  3.16909829],\n",
      "\n",
      "iteration 294: f_best = 0.00000000\n",
      "x_eff  = [11.72303602 21.49325751],\n",
      "\n",
      "iteration 295: f_best = 0.00000000\n",
      "x_eff  = [-11.76406687  19.71986135],\n",
      "\n",
      "iteration 296: f_best = 0.00000000\n",
      "x_eff  = [  9.34830934 -10.73276213],\n",
      "\n",
      "iteration 297: f_best = 0.00000000\n",
      "x_eff  = [12.8968996  11.10234536],\n",
      "\n",
      "iteration 298: f_best = 0.00000000\n",
      "x_eff  = [-15.58254691  24.31312773],\n",
      "\n",
      "iteration 299: f_best = 0.00000000\n",
      "x_eff  = [-24.67592861 -26.71767168],\n",
      "\n",
      "iteration 300: f_best = 0.00000000\n",
      "x_eff  = [21.02931489 24.18282343],\n",
      "\n",
      "iteration 301: f_best = 0.00000000\n",
      "x_eff  = [-24.55932966  30.79218613],\n",
      "\n",
      "iteration 302: f_best = 0.00000000\n",
      "x_eff  = [-28.60929619 -23.61213333],\n",
      "\n",
      "iteration 303: f_best = 0.00000000\n",
      "x_eff  = [-2.17985973 27.71020096],\n",
      "\n",
      "iteration 304: f_best = 0.00000000\n",
      "x_eff  = [-14.25620414   2.45028102],\n",
      "\n",
      "iteration 305: f_best = 0.00000000\n",
      "x_eff  = [ 8.30481329 -1.32394204],\n",
      "\n",
      "iteration 306: f_best = 0.00000000\n",
      "x_eff  = [-29.44383945  -1.21020632],\n",
      "\n",
      "iteration 307: f_best = 0.00000000\n",
      "x_eff  = [ 13.47682635 -19.27469996],\n",
      "\n",
      "iteration 308: f_best = 0.00000000\n",
      "x_eff  = [14.64125238 20.88353521],\n",
      "\n",
      "iteration 309: f_best = 0.00000000\n",
      "x_eff  = [-10.00661094  25.42075405],\n",
      "\n",
      "iteration 310: f_best = 0.00000000\n",
      "x_eff  = [  8.08026812 -20.87304942],\n",
      "\n",
      "iteration 311: f_best = 0.00000000\n",
      "x_eff  = [20.63344845  5.31540544],\n",
      "\n",
      "iteration 312: f_best = 0.00000000\n",
      "x_eff  = [ 17.17048288 -22.23661989],\n",
      "\n",
      "iteration 313: f_best = 0.00000000\n",
      "x_eff  = [-13.53527141 -21.45519458],\n",
      "\n",
      "iteration 314: f_best = 0.00000000\n",
      "x_eff  = [11.53094545  7.33065662],\n",
      "\n",
      "iteration 315: f_best = 0.00000000\n",
      "x_eff  = [-24.78406382  -2.42096583],\n",
      "\n",
      "iteration 316: f_best = 0.00000000\n",
      "x_eff  = [ 1.40717049 -9.07792109],\n",
      "\n",
      "iteration 317: f_best = 0.00000000\n",
      "x_eff  = [  4.02093654 -23.18142664],\n",
      "\n",
      "iteration 318: f_best = 0.00000000\n",
      "x_eff  = [  9.16937731 -16.48508349],\n",
      "\n",
      "iteration 319: f_best = 0.00000000\n",
      "x_eff  = [-15.50540272 -16.31762965],\n",
      "\n",
      "iteration 320: f_best = 0.00000000\n",
      "x_eff  = [ 8.21119694 -1.6534975 ],\n",
      "\n",
      "iteration 321: f_best = 0.00000000\n",
      "x_eff  = [ 8.5983437  15.38203719],\n",
      "\n",
      "iteration 322: f_best = 0.00000000\n",
      "x_eff  = [14.94530082 10.71918979],\n",
      "\n",
      "iteration 323: f_best = 0.00000000\n",
      "x_eff  = [23.15174589 -4.84794832],\n",
      "\n",
      "iteration 324: f_best = 0.00000000\n",
      "x_eff  = [-16.76191809  22.46020981],\n",
      "\n",
      "iteration 325: f_best = 0.00000000\n",
      "x_eff  = [ 4.13466661 11.80753443],\n",
      "\n",
      "iteration 326: f_best = 0.00000000\n",
      "x_eff  = [-14.97097772  20.00977878],\n",
      "\n",
      "iteration 327: f_best = 0.00000000\n",
      "x_eff  = [-19.70503243  21.30037416],\n",
      "\n",
      "iteration 328: f_best = 0.00000000\n",
      "x_eff  = [-17.49142024 -15.39478316],\n",
      "\n",
      "iteration 329: f_best = 0.00000000\n",
      "x_eff  = [-23.52293891  -7.91895871],\n",
      "\n",
      "iteration 330: f_best = 0.00000000\n",
      "x_eff  = [-18.0829494    6.68658965],\n",
      "\n",
      "iteration 331: f_best = 0.00000000\n",
      "x_eff  = [-22.91034541 -21.51139729],\n",
      "\n",
      "iteration 332: f_best = 0.00000000\n",
      "x_eff  = [6.96058755 2.86518259],\n",
      "\n",
      "iteration 333: f_best = 0.00000000\n",
      "x_eff  = [  7.05685281 -22.31700835],\n",
      "\n",
      "iteration 334: f_best = 0.00000000\n",
      "x_eff  = [ -9.15338198 -17.91729702],\n",
      "\n",
      "iteration 335: f_best = 0.00000000\n",
      "x_eff  = [ -0.69225702 -15.2701762 ],\n",
      "\n",
      "iteration 336: f_best = 0.00000000\n",
      "x_eff  = [-3.81563948 -2.35117951],\n",
      "\n",
      "iteration 337: f_best = 0.00000000\n",
      "x_eff  = [-15.03477063   7.77140815],\n",
      "\n",
      "iteration 338: f_best = 0.00000000\n",
      "x_eff  = [-8.6880573   4.36034483],\n",
      "\n",
      "iteration 339: f_best = 0.00000000\n",
      "x_eff  = [-10.22242382 -11.61259675],\n",
      "\n",
      "iteration 340: f_best = 0.00000000\n",
      "x_eff  = [ 3.17344916 12.20101535],\n",
      "\n",
      "iteration 341: f_best = 0.00000000\n",
      "x_eff  = [-9.32398291 15.52846736],\n",
      "\n",
      "iteration 342: f_best = 0.00000000\n",
      "x_eff  = [-7.28835017 19.48035789],\n",
      "\n",
      "iteration 343: f_best = 0.00000000\n",
      "x_eff  = [0.81358331 5.01597279],\n",
      "\n",
      "iteration 344: f_best = 0.00000000\n",
      "x_eff  = [-13.15360862   9.30082941],\n",
      "\n",
      "iteration 345: f_best = 0.00000000\n",
      "x_eff  = [ 13.88246699 -15.09911775],\n",
      "\n",
      "iteration 346: f_best = 0.00000000\n",
      "x_eff  = [ 1.10955393 16.89651011],\n",
      "\n",
      "iteration 347: f_best = 0.00000000\n",
      "x_eff  = [-3.67515407  2.16058699],\n",
      "\n",
      "iteration 348: f_best = 0.00000000\n",
      "x_eff  = [12.88175522 17.53688953],\n",
      "\n",
      "iteration 349: f_best = 0.00000000\n",
      "x_eff  = [-5.35595102  7.60248381],\n",
      "\n",
      "iteration 350: f_best = 0.00000000\n",
      "x_eff  = [-18.13141229  13.46148856],\n",
      "\n",
      "iteration 351: f_best = 0.00000000\n",
      "x_eff  = [11.07706584 -9.30188591],\n",
      "\n",
      "iteration 352: f_best = 0.00000000\n",
      "x_eff  = [ 16.85269443 -17.13419929],\n",
      "\n",
      "iteration 353: f_best = 0.00000000\n",
      "x_eff  = [15.31659434 15.60423343],\n",
      "\n",
      "iteration 354: f_best = 0.00000000\n",
      "x_eff  = [ 2.42821193 16.62372724],\n",
      "\n",
      "iteration 355: f_best = 0.00000000\n",
      "x_eff  = [ 15.01402239 -14.96830197],\n",
      "\n",
      "iteration 356: f_best = 0.00000000\n",
      "x_eff  = [  6.4567625  -11.60315771],\n",
      "\n",
      "iteration 357: f_best = 0.00000000\n",
      "x_eff  = [ -3.92722152 -13.24683456],\n",
      "\n",
      "iteration 358: f_best = 0.00000000\n",
      "x_eff  = [16.02648231 -2.26406278],\n",
      "\n",
      "iteration 359: f_best = 0.00000000\n",
      "x_eff  = [-15.71555326  14.32169893],\n",
      "\n",
      "iteration 360: f_best = 0.00000000\n",
      "x_eff  = [2.47736388 0.67402627],\n",
      "\n",
      "iteration 361: f_best = 0.00000000\n",
      "x_eff  = [-16.3083119 -16.6880454],\n",
      "\n",
      "iteration 362: f_best = 0.00000000\n",
      "x_eff  = [ 5.02749741 15.67628689],\n",
      "\n",
      "iteration 363: f_best = 0.00000000\n",
      "x_eff  = [-13.72337709  -0.81002799],\n",
      "\n",
      "iteration 364: f_best = 0.00000000\n",
      "x_eff  = [0.73582624 0.33437072],\n",
      "\n",
      "iteration 365: f_best = 0.00000000\n",
      "x_eff  = [ 7.48896869 -1.61621993],\n",
      "\n",
      "iteration 366: f_best = 0.00000000\n",
      "x_eff  = [16.16404571 -8.60758685],\n",
      "\n",
      "iteration 367: f_best = 0.00000000\n",
      "x_eff  = [ 1.75498354 -8.11023874],\n",
      "\n",
      "iteration 368: f_best = 0.00000000\n",
      "x_eff  = [ 3.59477004 -8.36208446],\n",
      "\n",
      "iteration 369: f_best = 0.00000000\n",
      "x_eff  = [-12.58563902  12.81901013],\n",
      "\n",
      "iteration 370: f_best = 0.00000000\n",
      "x_eff  = [-11.34615914  15.15311551],\n",
      "\n",
      "iteration 371: f_best = 0.00000000\n",
      "x_eff  = [ 8.59197406 -4.21383379],\n",
      "\n",
      "iteration 372: f_best = 0.00000000\n",
      "x_eff  = [ 10.87124761 -12.29245152],\n",
      "\n",
      "iteration 373: f_best = 0.00000000\n",
      "x_eff  = [-1.96089261 10.25610164],\n",
      "\n",
      "iteration 374: f_best = 0.00000000\n",
      "x_eff  = [ 0.27503737 -7.80353894],\n",
      "\n",
      "iteration 375: f_best = 0.00000000\n",
      "x_eff  = [12.57155173 -6.87709714],\n",
      "\n",
      "iteration 376: f_best = 0.00000000\n",
      "x_eff  = [11.74600262 12.4881562 ],\n",
      "\n",
      "iteration 377: f_best = 0.00000000\n",
      "x_eff  = [ 2.30690328 -8.96270416],\n",
      "\n",
      "iteration 378: f_best = 0.00000000\n",
      "x_eff  = [ 0.46306456 -3.74838324],\n",
      "\n",
      "iteration 379: f_best = 0.00000000\n",
      "x_eff  = [-6.68946836  7.69112462],\n",
      "\n",
      "iteration 380: f_best = 0.00000000\n",
      "x_eff  = [  2.59274844 -14.45284746],\n",
      "\n",
      "iteration 381: f_best = 0.00000000\n",
      "x_eff  = [8.04864287 5.90992352],\n",
      "\n",
      "iteration 382: f_best = 0.00000000\n",
      "x_eff  = [ 3.52729412 -9.42996912],\n",
      "\n",
      "iteration 383: f_best = 0.00000000\n",
      "x_eff  = [-6.57526134  6.64395322],\n",
      "\n",
      "iteration 384: f_best = 0.00000000\n",
      "x_eff  = [-11.24195767  -2.98793228],\n",
      "\n",
      "iteration 385: f_best = 0.00000000\n",
      "x_eff  = [9.76030268 6.90632583],\n",
      "\n",
      "iteration 386: f_best = 0.00000000\n",
      "x_eff  = [0.34062604 2.58541316],\n",
      "\n",
      "iteration 387: f_best = 0.00000000\n",
      "x_eff  = [ 2.64370622 12.55461433],\n",
      "\n",
      "iteration 388: f_best = 0.00000000\n",
      "x_eff  = [-7.12970239 -4.41141408],\n",
      "\n",
      "iteration 389: f_best = 0.00000000\n",
      "x_eff  = [10.256707    0.22003892],\n",
      "\n",
      "iteration 390: f_best = 0.00000000\n",
      "x_eff  = [ 8.01675039 10.59734125],\n",
      "\n",
      "iteration 391: f_best = 0.00000000\n",
      "x_eff  = [11.39799581 -3.74812527],\n",
      "\n",
      "iteration 392: f_best = 0.00000000\n",
      "x_eff  = [-7.64021343 11.51343816],\n",
      "\n",
      "iteration 393: f_best = 0.00000000\n",
      "x_eff  = [  9.41709179 -10.01015409],\n",
      "\n",
      "iteration 394: f_best = 0.00000000\n",
      "x_eff  = [-11.50042308   8.58182274],\n",
      "\n",
      "iteration 395: f_best = 0.00000000\n",
      "x_eff  = [ -6.9851119  -11.13946041],\n",
      "\n",
      "iteration 396: f_best = 0.00000000\n",
      "x_eff  = [ -4.35585527 -10.36696973],\n",
      "\n",
      "iteration 397: f_best = 0.00000000\n",
      "x_eff  = [-6.8203582   0.73516126],\n",
      "\n",
      "iteration 398: f_best = 0.00000000\n",
      "x_eff  = [-5.2380448  -1.61916483],\n",
      "\n",
      "iteration 399: f_best = 0.00000000\n",
      "x_eff  = [-7.55836405  1.93345979],\n",
      "\n",
      "iteration 400: f_best = 0.00000000\n",
      "x_eff  = [-2.7856721   3.52679735],\n",
      "\n",
      "iteration 401: f_best = 0.00000000\n",
      "x_eff  = [8.76508239 9.86773559],\n",
      "\n",
      "iteration 402: f_best = 0.00000000\n",
      "x_eff  = [ 9.16332696 -2.32005736],\n",
      "\n",
      "iteration 403: f_best = 0.00000000\n",
      "x_eff  = [ -4.04979794 -10.26936504],\n",
      "\n",
      "iteration 404: f_best = 0.00000000\n",
      "x_eff  = [-3.68246746 -5.72875   ],\n",
      "\n",
      "iteration 405: f_best = 0.00000000\n",
      "x_eff  = [10.51049365  9.92375737],\n",
      "\n",
      "iteration 406: f_best = 0.00000000\n",
      "x_eff  = [8.88667648 1.97212725],\n",
      "\n",
      "iteration 407: f_best = 0.00000000\n",
      "x_eff  = [ 4.50141839 -6.29784607],\n",
      "\n",
      "iteration 408: f_best = 0.00000000\n",
      "x_eff  = [ -1.12226626 -10.40402727],\n",
      "\n",
      "iteration 409: f_best = 0.00000000\n",
      "x_eff  = [-8.85291816  1.76479647],\n",
      "\n",
      "iteration 410: f_best = 0.00000000\n",
      "x_eff  = [ 3.48711484 -6.86231547],\n",
      "\n",
      "iteration 411: f_best = 0.00000000\n",
      "x_eff  = [-0.61079214  1.31376029],\n",
      "\n",
      "iteration 412: f_best = 0.00000000\n",
      "x_eff  = [9.10157462 3.40975202],\n",
      "\n",
      "iteration 413: f_best = 0.00000000\n",
      "x_eff  = [10.28419329  6.49744592],\n",
      "\n",
      "iteration 414: f_best = 0.00000000\n",
      "x_eff  = [10.33623874 -5.65296029],\n",
      "\n",
      "iteration 415: f_best = 0.00000000\n",
      "x_eff  = [  5.70203433 -10.17043876],\n",
      "\n",
      "iteration 416: f_best = 0.00000000\n",
      "x_eff  = [ 7.91443973 -1.93678768],\n",
      "\n",
      "iteration 417: f_best = 0.00000000\n",
      "x_eff  = [-5.1918263  -6.73822927],\n",
      "\n",
      "iteration 418: f_best = 0.00000000\n",
      "x_eff  = [-0.16515422  7.79827281],\n",
      "\n",
      "iteration 419: f_best = 0.00000000\n",
      "x_eff  = [ 6.8719304  -4.70419112],\n",
      "\n",
      "iteration 420: f_best = 0.00000000\n",
      "x_eff  = [5.22606289 6.74490056],\n",
      "\n",
      "iteration 421: f_best = 0.00000000\n",
      "x_eff  = [ 8.49439619 -6.04385896],\n",
      "\n",
      "iteration 422: f_best = 0.00000000\n",
      "x_eff  = [6.77178145 0.78917959],\n",
      "\n",
      "iteration 423: f_best = 0.00000000\n",
      "x_eff  = [7.04475627 6.10108954],\n",
      "\n",
      "iteration 424: f_best = 0.00000000\n",
      "x_eff  = [-4.32256198  8.69729708],\n",
      "\n",
      "iteration 425: f_best = 0.00000000\n",
      "x_eff  = [ 6.46505116 -9.24151819],\n",
      "\n",
      "iteration 426: f_best = 0.00000000\n",
      "x_eff  = [ 8.34331086 -8.28095026],\n",
      "\n",
      "iteration 427: f_best = 0.00000000\n",
      "x_eff  = [-3.67956588  6.73552653],\n",
      "\n",
      "iteration 428: f_best = 0.00000000\n",
      "x_eff  = [6.58316687 2.7900267 ],\n",
      "\n",
      "iteration 429: f_best = 0.00000000\n",
      "x_eff  = [-4.45729562  0.28307485],\n",
      "\n",
      "iteration 430: f_best = 0.00000000\n",
      "x_eff  = [-7.95446805  2.93630513],\n",
      "\n",
      "iteration 431: f_best = 0.00000000\n",
      "x_eff  = [-8.27738163  6.12221224],\n",
      "\n",
      "iteration 432: f_best = 0.00000000\n",
      "x_eff  = [6.51717991 2.40411741],\n",
      "\n",
      "iteration 433: f_best = 0.00000000\n",
      "x_eff  = [-7.45985782  5.6709465 ],\n",
      "\n",
      "iteration 434: f_best = 0.00000000\n",
      "x_eff  = [ 6.76295917 -6.57174382],\n",
      "\n",
      "iteration 435: f_best = 0.00000000\n",
      "x_eff  = [1.66684648 4.17432938],\n",
      "\n",
      "iteration 436: f_best = 0.00000000\n",
      "x_eff  = [ 2.53684439 -1.77382592],\n",
      "\n",
      "iteration 437: f_best = 0.00000000\n",
      "x_eff  = [ 1.51007329 -5.60603811],\n",
      "\n",
      "iteration 438: f_best = 0.00000000\n",
      "x_eff  = [3.99119215 4.27259205],\n",
      "\n",
      "iteration 439: f_best = 0.00000000\n",
      "x_eff  = [-5.92813534  2.55036485],\n",
      "\n",
      "iteration 440: f_best = 0.00000000\n",
      "x_eff  = [1.84085862 5.4817777 ],\n",
      "\n",
      "iteration 441: f_best = 0.00000000\n",
      "x_eff  = [ 0.07283163 -4.98052123],\n",
      "\n",
      "iteration 442: f_best = 0.00000000\n",
      "x_eff  = [-1.88311351  2.30009841],\n",
      "\n",
      "iteration 443: f_best = 0.00000000\n",
      "x_eff  = [ 3.32218703 -7.0895762 ],\n",
      "\n",
      "iteration 444: f_best = 0.00000000\n",
      "x_eff  = [-7.42728375 -1.1447623 ],\n",
      "\n",
      "iteration 445: f_best = 0.00000000\n",
      "x_eff  = [ 5.83390906 -3.89053533],\n",
      "\n",
      "iteration 446: f_best = 0.00000000\n",
      "x_eff  = [ 0.12687379 -1.15921864],\n",
      "\n",
      "iteration 447: f_best = 0.00000000\n",
      "x_eff  = [1.11601954 1.0323407 ],\n",
      "\n",
      "iteration 448: f_best = 0.00000000\n",
      "x_eff  = [-7.35198567  1.34172578],\n",
      "\n",
      "iteration 449: f_best = 0.00000000\n",
      "x_eff  = [-3.75343817 -0.43581566],\n",
      "\n",
      "iteration 450: f_best = 0.00000000\n",
      "x_eff  = [ 1.82261757 -6.45071459],\n",
      "\n",
      "iteration 451: f_best = 0.00000000\n",
      "x_eff  = [ 0.71907864 -4.85760626],\n",
      "\n",
      "iteration 452: f_best = 0.00000000\n",
      "x_eff  = [5.71071589 6.00851439],\n",
      "\n",
      "iteration 453: f_best = 0.00000000\n",
      "x_eff  = [-0.96593774  1.14093194],\n",
      "\n",
      "iteration 454: f_best = 0.00000000\n",
      "x_eff  = [-0.15308596 -5.07586412],\n",
      "\n",
      "iteration 455: f_best = 0.00000000\n",
      "x_eff  = [4.86768194 2.94664998],\n",
      "\n",
      "iteration 456: f_best = 0.00000000\n",
      "x_eff  = [ 2.62542458 -1.96789188],\n",
      "\n",
      "iteration 457: f_best = 0.00000000\n",
      "x_eff  = [ 2.6831287 -2.541034 ],\n",
      "\n",
      "iteration 458: f_best = 0.00000000\n",
      "x_eff  = [2.68964577 6.45783624],\n",
      "\n",
      "iteration 459: f_best = 0.00000000\n",
      "x_eff  = [ 5.15345391 -5.37157788],\n",
      "\n",
      "iteration 460: f_best = 0.00000000\n",
      "x_eff  = [-5.51541685  3.83037262],\n",
      "\n",
      "iteration 461: f_best = 0.00000000\n",
      "x_eff  = [5.57977137 2.03061247],\n",
      "\n",
      "iteration 462: f_best = 0.00000000\n",
      "x_eff  = [ 2.09091065 -3.06176195],\n",
      "\n",
      "iteration 463: f_best = 0.00000000\n",
      "x_eff  = [-2.89563387  0.36119625],\n",
      "\n",
      "iteration 464: f_best = 0.00000000\n",
      "x_eff  = [-5.27263802  2.64509216],\n",
      "\n",
      "iteration 465: f_best = 0.00000000\n",
      "x_eff  = [1.8422509  1.24992821],\n",
      "\n",
      "iteration 466: f_best = 0.00000000\n",
      "x_eff  = [3.52359815 1.23527342],\n",
      "\n",
      "iteration 467: f_best = 0.00000000\n",
      "x_eff  = [5.80575378 2.70350219],\n",
      "\n",
      "iteration 468: f_best = 0.00000000\n",
      "x_eff  = [-0.78356955 -0.05791871],\n",
      "\n",
      "iteration 469: f_best = 0.00000000\n",
      "x_eff  = [ 0.5526898 -0.7011872],\n",
      "\n",
      "iteration 470: f_best = 0.00000000\n",
      "x_eff  = [4.83102625 4.63451045],\n",
      "\n",
      "iteration 471: f_best = 0.00000000\n",
      "x_eff  = [-4.45998975  4.672699  ],\n",
      "\n",
      "iteration 472: f_best = 0.00000000\n",
      "x_eff  = [4.14281304 5.30496792],\n",
      "\n",
      "iteration 473: f_best = 0.00000000\n",
      "x_eff  = [ 1.3486649 -4.1400261],\n",
      "\n",
      "iteration 474: f_best = 0.00000000\n",
      "x_eff  = [2.58446734 1.14156246],\n",
      "\n",
      "iteration 475: f_best = 0.00000000\n",
      "x_eff  = [-1.69914649 -1.47848668],\n",
      "\n",
      "iteration 476: f_best = 0.00000000\n",
      "x_eff  = [0.8995959  3.46485804],\n",
      "\n",
      "iteration 477: f_best = 0.00000000\n",
      "x_eff  = [ 1.72238881 -2.41871996],\n",
      "\n",
      "iteration 478: f_best = 0.00000000\n",
      "x_eff  = [5.34052446 4.982889  ],\n",
      "\n",
      "iteration 479: f_best = 0.00000000\n",
      "x_eff  = [-1.95417831  2.70066037],\n",
      "\n",
      "iteration 480: f_best = 0.00000000\n",
      "x_eff  = [0.94117624 4.27463088],\n",
      "\n",
      "iteration 481: f_best = 0.00000000\n",
      "x_eff  = [ 1.3034409  -1.54646992],\n",
      "\n",
      "iteration 482: f_best = 0.00000000\n",
      "x_eff  = [0.07562086 2.45395892],\n",
      "\n",
      "iteration 483: f_best = 0.00000000\n",
      "x_eff  = [ 3.4092873  -1.45226012],\n",
      "\n",
      "iteration 484: f_best = 0.00000000\n",
      "x_eff  = [-3.62798537 -3.79951167],\n",
      "\n",
      "iteration 485: f_best = 0.00000000\n",
      "x_eff  = [-0.08558306 -3.23310551],\n",
      "\n",
      "iteration 486: f_best = 0.00000000\n",
      "x_eff  = [-1.03219012 -2.24284081],\n",
      "\n",
      "iteration 487: f_best = 0.00000000\n",
      "x_eff  = [-2.0582012  -0.47558996],\n",
      "\n",
      "iteration 488: f_best = 0.00000000\n",
      "x_eff  = [-1.17806745 -3.37935002],\n",
      "\n",
      "iteration 489: f_best = 0.00000000\n",
      "x_eff  = [-2.46120726  1.09664592],\n",
      "\n",
      "iteration 490: f_best = 0.00000000\n",
      "x_eff  = [-1.85554384 -0.78464253],\n",
      "\n",
      "iteration 491: f_best = 0.00000000\n",
      "x_eff  = [ 2.11256462 -0.96215792],\n",
      "\n",
      "iteration 492: f_best = 0.00000000\n",
      "x_eff  = [-3.04262038  2.39223285],\n",
      "\n",
      "iteration 493: f_best = 0.00000000\n",
      "x_eff  = [-0.72369252 -1.86486136],\n",
      "\n",
      "iteration 494: f_best = 0.00000000\n",
      "x_eff  = [3.0012379  2.97673726],\n",
      "\n",
      "iteration 495: f_best = 0.00000000\n",
      "x_eff  = [0.66318676 3.90873526],\n",
      "\n",
      "iteration 496: f_best = 0.00000000\n",
      "x_eff  = [ 4.04399595 -4.13048735],\n",
      "\n",
      "iteration 497: f_best = 0.00000000\n",
      "x_eff  = [3.96263892 0.42443622],\n",
      "\n",
      "iteration 498: f_best = 0.00000000\n",
      "x_eff  = [2.33964928 3.51194127],\n",
      "\n",
      "iteration 499: f_best = 0.00000000\n",
      "x_eff  = [2.54564406 1.53718186],\n",
      "\n",
      "iteration 500: f_best = 0.00000000\n",
      "x_eff  = [-1.78595893 -3.58165313],\n",
      "\n",
      "iteration 501: f_best = 0.00000000\n",
      "x_eff  = [ 3.58445225 -2.04920503],\n",
      "\n",
      "iteration 502: f_best = 0.00000000\n",
      "x_eff  = [-1.56712402  0.83557871],\n",
      "\n",
      "iteration 503: f_best = 0.00000000\n",
      "x_eff  = [-2.40086205 -3.12239194],\n",
      "\n",
      "iteration 504: f_best = 0.00000000\n",
      "x_eff  = [-1.54226014  0.67166202],\n",
      "\n",
      "iteration 505: f_best = 0.00000000\n",
      "x_eff  = [-4.09267541 -3.81544122],\n",
      "\n",
      "iteration 506: f_best = 0.00000000\n",
      "x_eff  = [-4.10458032 -0.4549002 ],\n",
      "\n",
      "iteration 507: f_best = 0.00000000\n",
      "x_eff  = [2.56362162 2.38154068],\n",
      "\n",
      "iteration 508: f_best = 0.00000000\n",
      "x_eff  = [1.66529673 1.84579103],\n",
      "\n",
      "iteration 509: f_best = 0.00000000\n",
      "x_eff  = [ 0.43304663 -3.49458676],\n",
      "\n",
      "iteration 510: f_best = 0.00000000\n",
      "x_eff  = [0.58412585 1.23982221],\n",
      "\n",
      "iteration 511: f_best = 0.00000000\n",
      "x_eff  = [2.09124061 2.93663116],\n",
      "\n",
      "iteration 512: f_best = 0.00000000\n",
      "x_eff  = [-3.68978563  3.02472406],\n",
      "\n",
      "iteration 513: f_best = 0.00000000\n",
      "x_eff  = [-1.61547877 -1.0553129 ],\n",
      "\n",
      "iteration 514: f_best = 0.00000000\n",
      "x_eff  = [-2.23047039 -3.44127202],\n",
      "\n",
      "iteration 515: f_best = 0.00000000\n",
      "x_eff  = [-1.02867933  2.40327771],\n",
      "\n",
      "iteration 516: f_best = 0.00000000\n",
      "x_eff  = [-2.74174034 -0.9622411 ],\n",
      "\n",
      "iteration 517: f_best = 0.00000000\n",
      "x_eff  = [-2.02464601  3.67021242],\n",
      "\n",
      "iteration 518: f_best = 0.00000000\n",
      "x_eff  = [-2.36532697 -3.23524853],\n",
      "\n",
      "iteration 519: f_best = 0.00000000\n",
      "x_eff  = [2.24661758 0.11809284],\n",
      "\n",
      "iteration 520: f_best = 0.00000000\n",
      "x_eff  = [-2.77475297  0.68354088],\n",
      "\n",
      "iteration 521: f_best = 0.00000000\n",
      "x_eff  = [3.26999821 2.4209965 ],\n",
      "\n",
      "iteration 522: f_best = 0.00000000\n",
      "x_eff  = [2.8266161  1.56251329],\n",
      "\n",
      "iteration 523: f_best = 0.00000000\n",
      "x_eff  = [0.62087321 3.40827952],\n",
      "\n",
      "iteration 524: f_best = 0.00000000\n",
      "x_eff  = [2.74499393 1.61551148],\n",
      "\n",
      "iteration 525: f_best = 0.00000000\n",
      "x_eff  = [-0.98845031 -0.07468286],\n",
      "\n",
      "iteration 526: f_best = 0.00000000\n",
      "x_eff  = [ 2.60486707 -0.03307597],\n",
      "\n",
      "iteration 527: f_best = 0.00000000\n",
      "x_eff  = [1.47675422 2.94590364],\n",
      "\n",
      "iteration 528: f_best = 0.00000000\n",
      "x_eff  = [3.19509543 1.02401812],\n",
      "\n",
      "iteration 529: f_best = 0.00000000\n",
      "x_eff  = [ 2.06260264 -2.5510978 ],\n",
      "\n",
      "iteration 530: f_best = 0.00000000\n",
      "x_eff  = [ 1.24285257 -0.10603111],\n",
      "\n",
      "iteration 531: f_best = 0.00000000\n",
      "x_eff  = [-0.00473394 -2.40135909],\n",
      "\n",
      "iteration 532: f_best = 0.00000000\n",
      "x_eff  = [1.90973998 2.58345437],\n",
      "\n",
      "iteration 533: f_best = 0.00000000\n",
      "x_eff  = [1.66514936 1.17766338],\n",
      "\n",
      "iteration 534: f_best = 0.00000000\n",
      "x_eff  = [-2.68739927 -2.36633287],\n",
      "\n",
      "iteration 535: f_best = 0.00000000\n",
      "x_eff  = [ 0.85918263 -0.23497017],\n",
      "\n",
      "iteration 536: f_best = 0.00000000\n",
      "x_eff  = [0.745713   2.42995337],\n",
      "\n",
      "iteration 537: f_best = 0.00000000\n",
      "x_eff  = [-0.26963745  2.20300396],\n",
      "\n",
      "iteration 538: f_best = 0.00000000\n",
      "x_eff  = [-0.34463912  2.06503601],\n",
      "\n",
      "iteration 539: f_best = 0.00000000\n",
      "x_eff  = [ 1.65399155 -2.2536528 ],\n",
      "\n",
      "iteration 540: f_best = 0.00000000\n",
      "x_eff  = [0.64791826 0.83130444],\n",
      "\n",
      "iteration 541: f_best = 0.00000000\n",
      "x_eff  = [-1.47849489  2.09018804],\n",
      "\n",
      "iteration 542: f_best = 0.00000000\n",
      "x_eff  = [ 0.02036437 -0.11904283],\n",
      "\n",
      "iteration 543: f_best = 0.00000000\n",
      "x_eff  = [1.54224081 0.81341618],\n",
      "\n",
      "iteration 544: f_best = 0.00000000\n",
      "x_eff  = [ 2.18061739 -1.64387303],\n",
      "\n",
      "iteration 545: f_best = 0.00000000\n",
      "x_eff  = [-1.13142175 -0.77872044],\n",
      "\n",
      "iteration 546: f_best = 0.00000000\n",
      "x_eff  = [ 0.40291909 -1.01246335],\n",
      "\n",
      "iteration 547: f_best = 0.00000000\n",
      "x_eff  = [-0.4635074   2.16109893],\n",
      "\n",
      "iteration 548: f_best = 0.00000000\n",
      "x_eff  = [-2.0822597  -0.08395369],\n",
      "\n",
      "iteration 549: f_best = 0.00000000\n",
      "x_eff  = [-2.45788789 -1.81608921],\n",
      "\n",
      "iteration 550: f_best = 0.00000000\n",
      "x_eff  = [-0.48300827 -2.58135818],\n",
      "\n",
      "iteration 551: f_best = 0.00000000\n",
      "x_eff  = [ 0.94281302 -1.44450011],\n",
      "\n",
      "iteration 552: f_best = 0.00000000\n",
      "x_eff  = [-1.53086851  1.47918633],\n",
      "\n",
      "iteration 553: f_best = 0.00000000\n",
      "x_eff  = [-1.18931099  0.58750697],\n",
      "\n",
      "iteration 554: f_best = 0.00000000\n",
      "x_eff  = [-1.04207428 -2.02061723],\n",
      "\n",
      "iteration 555: f_best = 0.00000000\n",
      "x_eff  = [ 0.64495931 -0.90284826],\n",
      "\n",
      "iteration 556: f_best = 0.00000000\n",
      "x_eff  = [1.01170924 2.40470234],\n",
      "\n",
      "iteration 557: f_best = 0.00000000\n",
      "x_eff  = [-2.24047991 -2.26750585],\n",
      "\n",
      "iteration 558: f_best = 0.00000000\n",
      "x_eff  = [-1.52228131  0.35711234],\n",
      "\n",
      "iteration 559: f_best = 0.00000000\n",
      "x_eff  = [ 0.16139329 -0.86962549],\n",
      "\n",
      "iteration 560: f_best = 0.00000000\n",
      "x_eff  = [-2.19266493  1.59570157],\n",
      "\n",
      "iteration 561: f_best = 0.00000000\n",
      "x_eff  = [-1.73205324  2.22299341],\n",
      "\n",
      "iteration 562: f_best = 0.00000000\n",
      "x_eff  = [ 0.1146571  -1.53382771],\n",
      "\n",
      "iteration 563: f_best = 0.00000000\n",
      "x_eff  = [-1.09713339 -0.62968363],\n",
      "\n",
      "iteration 564: f_best = 0.00000000\n",
      "x_eff  = [-0.99899861  0.26263998],\n",
      "\n",
      "iteration 565: f_best = 0.00000000\n",
      "x_eff  = [-0.81583755  0.64873656],\n",
      "\n",
      "iteration 566: f_best = 0.00000000\n",
      "x_eff  = [ 0.14389506 -0.37093913],\n",
      "\n",
      "iteration 567: f_best = 0.00000000\n",
      "x_eff  = [0.92284129 1.34314899],\n",
      "\n",
      "iteration 568: f_best = 0.00000000\n",
      "x_eff  = [-1.37917888  2.20464892],\n",
      "\n",
      "iteration 569: f_best = 0.00000000\n",
      "x_eff  = [-0.85889431 -1.23788641],\n",
      "\n",
      "iteration 570: f_best = 0.00000000\n",
      "x_eff  = [-0.64880999 -1.53234952],\n",
      "\n",
      "iteration 571: f_best = 0.00000000\n",
      "x_eff  = [1.12165017 0.62204942],\n",
      "\n",
      "iteration 572: f_best = 0.00000000\n",
      "x_eff  = [-0.25733574  0.68732799],\n",
      "\n",
      "iteration 573: f_best = 0.00000000\n",
      "x_eff  = [-1.08862989  0.57326435],\n",
      "\n",
      "iteration 574: f_best = 0.00000000\n",
      "x_eff  = [-1.92072987  1.31848651],\n",
      "\n",
      "iteration 575: f_best = 0.00000000\n",
      "x_eff  = [0.68895535 1.52965783],\n",
      "\n",
      "iteration 576: f_best = 0.00000000\n",
      "x_eff  = [ 0.65764346 -0.30376133],\n",
      "\n",
      "iteration 577: f_best = 0.00000000\n",
      "x_eff  = [1.96343969 1.73423977],\n",
      "\n",
      "iteration 578: f_best = 0.00000000\n",
      "x_eff  = [-0.63463664  1.34561791],\n",
      "\n",
      "iteration 579: f_best = 0.00000000\n",
      "x_eff  = [-1.18055472  0.08466124],\n",
      "\n",
      "iteration 580: f_best = 0.00000000\n",
      "x_eff  = [1.24398477 1.84788319],\n",
      "\n",
      "iteration 581: f_best = 0.00000000\n",
      "x_eff  = [-1.95987244 -0.99109933],\n",
      "\n",
      "iteration 582: f_best = 0.00000000\n",
      "x_eff  = [-1.57678743  0.78650312],\n",
      "\n",
      "iteration 583: f_best = 0.00000000\n",
      "x_eff  = [1.04719196 1.66496194],\n",
      "\n",
      "iteration 584: f_best = 0.00000000\n",
      "x_eff  = [-1.59382667 -0.00293632],\n",
      "\n",
      "iteration 585: f_best = 0.00000000\n",
      "x_eff  = [-0.17814316  1.7042459 ],\n",
      "\n",
      "iteration 586: f_best = 0.00000000\n",
      "x_eff  = [-1.13559277 -0.26809945],\n",
      "\n",
      "iteration 587: f_best = 0.00000000\n",
      "x_eff  = [ 1.06948678 -1.57506036],\n",
      "\n",
      "iteration 588: f_best = 0.00000000\n",
      "x_eff  = [-1.53977277  0.70805676],\n",
      "\n",
      "iteration 589: f_best = 0.00000000\n",
      "x_eff  = [-0.74727479  0.99335897],\n",
      "\n",
      "iteration 590: f_best = 0.00000000\n",
      "x_eff  = [0.85038713 1.62667095],\n",
      "\n",
      "iteration 591: f_best = 0.00000000\n",
      "x_eff  = [-0.2223114   0.32600609],\n",
      "\n",
      "iteration 592: f_best = 0.00000000\n",
      "x_eff  = [-1.25444994  0.19829842],\n",
      "\n",
      "iteration 593: f_best = 0.00000000\n",
      "x_eff  = [ 0.46863486 -1.06437355],\n",
      "\n",
      "iteration 594: f_best = 0.00000000\n",
      "x_eff  = [1.50599544 0.24382069],\n",
      "\n",
      "iteration 595: f_best = 0.00000000\n",
      "x_eff  = [0.74121952 0.98544574],\n",
      "\n",
      "iteration 596: f_best = 0.00000000\n",
      "x_eff  = [ 0.10552565 -0.6501631 ],\n",
      "\n",
      "iteration 597: f_best = 0.00000000\n",
      "x_eff  = [0.22969102 1.0567999 ],\n",
      "\n",
      "iteration 598: f_best = 0.00000000\n",
      "x_eff  = [ 0.20602863 -1.57594056],\n",
      "\n",
      "iteration 599: f_best = 0.00000000\n",
      "x_eff  = [-0.29496026  1.03496018],\n",
      "\n",
      "iteration 600: f_best = 0.00000000\n",
      "x_eff  = [-1.08876724  0.44099253],\n",
      "\n",
      "iteration 601: f_best = 0.00000000\n",
      "x_eff  = [ 0.69787259 -0.12914443],\n",
      "\n",
      "iteration 602: f_best = 0.00000000\n",
      "x_eff  = [-1.02844986  0.03455828],\n",
      "\n",
      "iteration 603: f_best = 0.00000000\n",
      "x_eff  = [-0.69912514 -0.77720732],\n",
      "\n",
      "iteration 604: f_best = 0.00000000\n",
      "x_eff  = [ 0.09577274 -0.47802567],\n",
      "\n",
      "iteration 605: f_best = 0.00000000\n",
      "x_eff  = [0.18799616 0.52660701],\n",
      "\n",
      "iteration 606: f_best = 0.00000000\n",
      "x_eff  = [-1.508419    0.14484829],\n",
      "\n",
      "iteration 607: f_best = 0.00000000\n",
      "x_eff  = [ 1.25751346 -1.04697131],\n",
      "\n",
      "iteration 608: f_best = 0.00000000\n",
      "x_eff  = [-0.62002271 -0.84111683],\n",
      "\n",
      "iteration 609: f_best = 0.00000000\n",
      "x_eff  = [ 0.63938478 -1.13577389],\n",
      "\n",
      "iteration 610: f_best = 0.00000000\n",
      "x_eff  = [-0.14464947  0.3202937 ],\n",
      "\n",
      "iteration 611: f_best = 0.00000000\n",
      "x_eff  = [-0.70291297  0.61950373],\n",
      "\n",
      "iteration 612: f_best = 0.00000000\n",
      "x_eff  = [-0.61353903  0.16990505],\n",
      "\n",
      "iteration 613: f_best = 0.00000000\n",
      "x_eff  = [-0.92562795 -0.56714684],\n",
      "\n",
      "iteration 614: f_best = 0.00000000\n",
      "x_eff  = [0.18628575 1.23067078],\n",
      "\n",
      "iteration 615: f_best = 0.00000000\n",
      "x_eff  = [0.00811433 0.10538185],\n",
      "\n",
      "iteration 616: f_best = 0.00000000\n",
      "x_eff  = [ 0.11428763 -0.93026404],\n",
      "\n",
      "iteration 617: f_best = 0.00000000\n",
      "x_eff  = [0.95391742 0.97357322],\n",
      "\n",
      "iteration 618: f_best = 0.00000000\n",
      "x_eff  = [ 1.09115952 -0.58229852],\n",
      "\n",
      "iteration 619: f_best = 0.00000000\n",
      "x_eff  = [0.45945007 0.88131609],\n",
      "\n",
      "iteration 620: f_best = 0.00000000\n",
      "x_eff  = [1.26455829 1.25974929],\n",
      "\n",
      "iteration 621: f_best = 0.00000000\n",
      "x_eff  = [-0.27898437 -1.18477134],\n",
      "\n",
      "iteration 622: f_best = 0.00000000\n",
      "x_eff  = [-0.21728122  0.39791466],\n",
      "\n",
      "iteration 623: f_best = 0.00000000\n",
      "x_eff  = [-0.99488718  0.09336438],\n",
      "\n",
      "iteration 624: f_best = 0.00000000\n",
      "x_eff  = [ 0.07234045 -0.5323857 ],\n",
      "\n",
      "iteration 625: f_best = 0.00000000\n",
      "x_eff  = [-1.2499765   0.80732115],\n",
      "\n",
      "iteration 626: f_best = 0.00000000\n",
      "x_eff  = [ 1.08498844 -0.06460243],\n",
      "\n",
      "iteration 627: f_best = 0.00000000\n",
      "x_eff  = [0.11028839 0.05554901],\n",
      "\n",
      "iteration 628: f_best = 0.00000000\n",
      "x_eff  = [ 1.07988059 -0.84125467],\n",
      "\n",
      "iteration 629: f_best = 0.00000000\n",
      "x_eff  = [-0.87372361  0.18243346],\n",
      "\n",
      "iteration 630: f_best = 0.00000000\n",
      "x_eff  = [-0.84787803  1.00878277],\n",
      "\n",
      "iteration 631: f_best = 0.00000000\n",
      "x_eff  = [-0.61372755 -0.81144365],\n",
      "\n",
      "iteration 632: f_best = 0.00000000\n",
      "x_eff  = [-0.71032023 -0.32234627],\n",
      "\n",
      "iteration 633: f_best = 0.00000000\n",
      "x_eff  = [1.00811331 1.08179419],\n",
      "\n",
      "iteration 634: f_best = 0.00000000\n",
      "x_eff  = [-0.9436582  -0.51364363],\n",
      "\n",
      "iteration 635: f_best = 0.00000000\n",
      "x_eff  = [-0.58986384 -0.72788685],\n",
      "\n",
      "iteration 636: f_best = 0.00000000\n",
      "x_eff  = [0.27180685 0.84245438],\n",
      "\n",
      "iteration 637: f_best = 0.00000000\n",
      "x_eff  = [-0.87403716  0.95998167],\n",
      "\n",
      "iteration 638: f_best = 0.00000000\n",
      "x_eff  = [ 0.37222176 -0.01068413],\n",
      "\n",
      "iteration 639: f_best = 0.00000000\n",
      "x_eff  = [0.88829576 0.29010147],\n",
      "\n",
      "iteration 640: f_best = 0.00000000\n",
      "x_eff  = [ 0.85098462 -0.98561839],\n",
      "\n",
      "iteration 641: f_best = 0.00000000\n",
      "x_eff  = [-0.02655928 -0.35540154],\n",
      "\n",
      "iteration 642: f_best = 0.00000000\n",
      "x_eff  = [ 0.32598378 -0.30919097],\n",
      "\n",
      "iteration 643: f_best = 0.00000000\n",
      "x_eff  = [0.22134601 0.09786751],\n",
      "\n",
      "iteration 644: f_best = 0.00000000\n",
      "x_eff  = [-0.21790606 -0.76610233],\n",
      "\n",
      "iteration 645: f_best = 0.00000000\n",
      "x_eff  = [-0.20054624 -0.1527957 ],\n",
      "\n",
      "iteration 646: f_best = 0.00000000\n",
      "x_eff  = [ 0.81990901 -0.76652092],\n",
      "\n",
      "iteration 647: f_best = 0.00000000\n",
      "x_eff  = [-0.66712782  0.88538276],\n",
      "\n",
      "iteration 648: f_best = 0.00000000\n",
      "x_eff  = [-0.49012506  0.37063928],\n",
      "\n",
      "iteration 649: f_best = 0.00000000\n",
      "x_eff  = [-0.63595214 -0.36834819],\n",
      "\n",
      "iteration 650: f_best = 0.00000000\n",
      "x_eff  = [0.39474071 0.1576546 ],\n",
      "\n",
      "iteration 651: f_best = 0.00000000\n",
      "x_eff  = [ 0.36680924 -0.82985059],\n",
      "\n",
      "iteration 652: f_best = 0.00000000\n",
      "x_eff  = [0.14836377 0.53313942],\n",
      "\n",
      "iteration 653: f_best = 0.00000000\n",
      "x_eff  = [ 0.59684349 -0.96014504],\n",
      "\n",
      "iteration 654: f_best = 0.00000000\n",
      "x_eff  = [ 0.18763017 -0.68985945],\n",
      "\n",
      "iteration 655: f_best = 0.00000000\n",
      "x_eff  = [-0.59415917 -0.60528992],\n",
      "\n",
      "iteration 656: f_best = 0.00000000\n",
      "x_eff  = [ 0.51574802 -0.1803859 ],\n",
      "\n",
      "iteration 657: f_best = 0.00000000\n",
      "x_eff  = [ 0.47355123 -0.25646288],\n",
      "\n",
      "iteration 658: f_best = 0.00000000\n",
      "x_eff  = [0.04553    0.59342592],\n",
      "\n",
      "iteration 659: f_best = 0.00000000\n",
      "x_eff  = [0.06187573 0.50527672],\n",
      "\n",
      "iteration 660: f_best = 0.00000000\n",
      "x_eff  = [-0.73410187 -0.30914694],\n",
      "\n",
      "iteration 661: f_best = 0.00000000\n",
      "x_eff  = [-0.35315841 -0.6975217 ],\n",
      "\n",
      "iteration 662: f_best = 0.00000000\n",
      "x_eff  = [ 0.09565496 -0.37228938],\n",
      "\n",
      "iteration 663: f_best = 0.00000000\n",
      "x_eff  = [-0.0244713   0.53814581],\n",
      "\n",
      "iteration 664: f_best = 0.00000000\n",
      "x_eff  = [-0.43015708 -0.05089147],\n",
      "\n",
      "iteration 665: f_best = 0.00000000\n",
      "x_eff  = [-0.12840264  0.08177887],\n",
      "\n",
      "iteration 666: f_best = 0.00000000\n",
      "x_eff  = [-0.84494998  0.386803  ],\n",
      "\n",
      "iteration 667: f_best = 0.00000000\n",
      "x_eff  = [ 0.44785714 -0.39747774],\n",
      "\n",
      "iteration 668: f_best = 0.00000000\n",
      "x_eff  = [-0.77105907 -0.66079144],\n",
      "\n",
      "iteration 669: f_best = 0.00000000\n",
      "x_eff  = [ 0.35969107 -0.22377935],\n",
      "\n",
      "iteration 670: f_best = 0.00000000\n",
      "x_eff  = [0.69189461 0.11846964],\n",
      "\n",
      "iteration 671: f_best = 0.00000000\n",
      "x_eff  = [ 0.30069773 -0.43442259],\n",
      "\n",
      "iteration 672: f_best = 0.00000000\n",
      "x_eff  = [-0.62709991  0.11122849],\n",
      "\n",
      "iteration 673: f_best = 0.00000000\n",
      "x_eff  = [0.18178396 0.34290353],\n",
      "\n",
      "iteration 674: f_best = 0.00000000\n",
      "x_eff  = [-0.51613312 -0.42475882],\n",
      "\n",
      "iteration 675: f_best = 0.00000000\n",
      "x_eff  = [0.20256916 0.29307953],\n",
      "\n",
      "iteration 676: f_best = 0.00000000\n",
      "x_eff  = [ 0.5833919  -0.52174845],\n",
      "\n",
      "iteration 677: f_best = 0.00000000\n",
      "x_eff  = [-0.70128799  0.44276467],\n",
      "\n",
      "iteration 678: f_best = 0.00000000\n",
      "x_eff  = [-0.58337923  0.60851024],\n",
      "\n",
      "iteration 679: f_best = 0.00000000\n",
      "x_eff  = [ 0.13297491 -0.45551075],\n",
      "\n",
      "iteration 680: f_best = 0.00000000\n",
      "x_eff  = [-0.54852822 -0.1847923 ],\n",
      "\n",
      "iteration 681: f_best = 0.00000000\n",
      "x_eff  = [0.70539621 0.63600991],\n",
      "\n",
      "iteration 682: f_best = 0.00000000\n",
      "x_eff  = [-0.5602224  -0.61585079],\n",
      "\n",
      "iteration 683: f_best = 0.00000000\n",
      "x_eff  = [ 0.31405523 -0.44807841],\n",
      "\n",
      "iteration 684: f_best = 0.00000000\n",
      "x_eff  = [-0.29362106  0.66582308],\n",
      "\n",
      "iteration 685: f_best = 0.00000000\n",
      "x_eff  = [0.16921993 0.25121041],\n",
      "\n",
      "iteration 686: f_best = 0.00000000\n",
      "x_eff  = [0.17970665 0.07907645],\n",
      "\n",
      "iteration 687: f_best = 0.00000000\n",
      "x_eff  = [ 0.14264308 -0.42430602],\n",
      "\n",
      "iteration 688: f_best = 0.00000000\n",
      "x_eff  = [-0.14657723  0.09279025],\n",
      "\n",
      "iteration 689: f_best = 0.00000000\n",
      "x_eff  = [ 0.58223913 -0.21047084],\n",
      "\n",
      "iteration 690: f_best = 0.00000000\n",
      "x_eff  = [-0.04006772 -0.3320865 ],\n",
      "\n",
      "iteration 691: f_best = 0.00000000\n",
      "x_eff  = [-0.5813345   0.27256153],\n",
      "\n",
      "iteration 692: f_best = 0.00000000\n",
      "x_eff  = [0.18610602 0.08497431],\n",
      "\n",
      "iteration 693: f_best = 0.00000000\n",
      "x_eff  = [-0.63421953 -0.40473193],\n",
      "\n",
      "iteration 694: f_best = 0.00000000\n",
      "x_eff  = [-0.31166407  0.63332245],\n",
      "\n",
      "iteration 695: f_best = 0.00000000\n",
      "x_eff  = [ 0.05528404 -0.3123933 ],\n",
      "\n",
      "iteration 696: f_best = 0.00000000\n",
      "x_eff  = [ 0.45242017 -0.28970119],\n",
      "\n",
      "iteration 697: f_best = 0.00000000\n",
      "x_eff  = [ 0.01280428 -0.00139296],\n",
      "\n",
      "iteration 698: f_best = 0.00000000\n",
      "x_eff  = [0.5964219  0.27013474],\n",
      "\n",
      "iteration 699: f_best = 0.00000000\n",
      "x_eff  = [ 0.443844   -0.13066872],\n",
      "\n",
      "iteration 700: f_best = 0.00000000\n",
      "x_eff  = [ 0.59126067 -0.34987379],\n",
      "\n",
      "iteration 701: f_best = 0.00000000\n",
      "x_eff  = [-0.33329609  0.33786521],\n",
      "\n",
      "iteration 702: f_best = 0.00000000\n",
      "x_eff  = [0.15599826 0.12953279],\n",
      "\n",
      "iteration 703: f_best = 0.00000000\n",
      "x_eff  = [ 0.02706127 -0.51616189],\n",
      "\n",
      "iteration 704: f_best = 0.00000000\n",
      "x_eff  = [-0.21475823 -0.27925624],\n",
      "\n",
      "iteration 705: f_best = 0.00000000\n",
      "x_eff  = [-0.27150526 -0.06612584],\n",
      "\n",
      "iteration 706: f_best = 0.00000000\n",
      "x_eff  = [ 0.33617057 -0.08714465],\n",
      "\n",
      "iteration 707: f_best = 0.00000000\n",
      "x_eff  = [-0.12227239  0.19437033],\n",
      "\n",
      "iteration 708: f_best = 0.00000000\n",
      "x_eff  = [ 0.2726636 -0.3968316],\n",
      "\n",
      "iteration 709: f_best = 0.00000000\n",
      "x_eff  = [0.13977337 0.36902603],\n",
      "\n",
      "iteration 710: f_best = 0.00000000\n",
      "x_eff  = [ 0.14345126 -0.33748342],\n",
      "\n",
      "iteration 711: f_best = 0.00000000\n",
      "x_eff  = [-0.12106846  0.40467129],\n",
      "\n",
      "iteration 712: f_best = 0.00000000\n",
      "x_eff  = [-0.28333748 -0.38330712],\n",
      "\n",
      "iteration 713: f_best = 0.00000000\n",
      "x_eff  = [0.16147464 0.38389824],\n",
      "\n",
      "iteration 714: f_best = 0.00000000\n",
      "x_eff  = [-0.47522552  0.41399987],\n",
      "\n",
      "iteration 715: f_best = 0.00000000\n",
      "x_eff  = [ 0.48323163 -0.31924916],\n",
      "\n",
      "iteration 716: f_best = 0.00000000\n",
      "x_eff  = [ 0.19400116 -0.1175546 ],\n",
      "\n",
      "iteration 717: f_best = 0.00000000\n",
      "x_eff  = [ 0.40079267 -0.24053091],\n",
      "\n",
      "iteration 718: f_best = 0.00000000\n",
      "x_eff  = [-0.21269066 -0.42919713],\n",
      "\n",
      "iteration 719: f_best = 0.00000000\n",
      "x_eff  = [-0.12073464  0.20849806],\n",
      "\n",
      "iteration 720: f_best = 0.00000000\n",
      "x_eff  = [0.489344   0.12585893],\n",
      "\n",
      "iteration 721: f_best = 0.00000000\n",
      "x_eff  = [0.21794966 0.34098005],\n",
      "\n",
      "iteration 722: f_best = 0.00000000\n",
      "x_eff  = [-0.21152881 -0.45685084],\n",
      "\n",
      "iteration 723: f_best = 0.00000000\n",
      "x_eff  = [ 0.14077211 -0.15677852],\n",
      "\n",
      "iteration 724: f_best = 0.00000000\n",
      "x_eff  = [ 0.42803451 -0.44592702],\n",
      "\n",
      "iteration 725: f_best = 0.00000000\n",
      "x_eff  = [-0.39031243 -0.30500326],\n",
      "\n",
      "iteration 726: f_best = 0.00000000\n",
      "x_eff  = [-0.25475174  0.4489068 ],\n",
      "\n",
      "iteration 727: f_best = 0.00000000\n",
      "x_eff  = [ 0.27374965 -0.42389477],\n",
      "\n",
      "iteration 728: f_best = 0.00000000\n",
      "x_eff  = [-0.19942854  0.20646409],\n",
      "\n",
      "iteration 729: f_best = 0.00000000\n",
      "x_eff  = [-0.05466018 -0.44906987],\n",
      "\n",
      "iteration 730: f_best = 0.00000000\n",
      "x_eff  = [0.11777168 0.28230075],\n",
      "\n",
      "iteration 731: f_best = 0.00000000\n",
      "x_eff  = [-0.4201596  -0.40025571],\n",
      "\n",
      "iteration 732: f_best = 0.00000000\n",
      "x_eff  = [ 0.02032824 -0.33744878],\n",
      "\n",
      "iteration 733: f_best = 0.00000000\n",
      "x_eff  = [-0.32078084 -0.37222063],\n",
      "\n",
      "iteration 734: f_best = 0.00000000\n",
      "x_eff  = [0.03222149 0.13768803],\n",
      "\n",
      "iteration 735: f_best = 0.00000000\n",
      "x_eff  = [-0.31436506  0.20665023],\n",
      "\n",
      "iteration 736: f_best = 0.00000000\n",
      "x_eff  = [0.26573667 0.35693617],\n",
      "\n",
      "iteration 737: f_best = 0.00000000\n",
      "x_eff  = [ 0.00837503 -0.09266112],\n",
      "\n",
      "iteration 738: f_best = 0.00000000\n",
      "x_eff  = [0.18202572 0.13121037],\n",
      "\n",
      "iteration 739: f_best = 0.00000000\n",
      "x_eff  = [-0.266608    0.34269529],\n",
      "\n",
      "iteration 740: f_best = 0.00000000\n",
      "x_eff  = [-0.2314562   0.14883435],\n",
      "\n",
      "iteration 741: f_best = 0.00000000\n",
      "x_eff  = [-0.15370554 -0.03351965],\n",
      "\n",
      "iteration 742: f_best = 0.00000000\n",
      "x_eff  = [-0.16690692  0.00862569],\n",
      "\n",
      "iteration 743: f_best = 0.00000000\n",
      "x_eff  = [-0.34986871 -0.16567622],\n",
      "\n",
      "iteration 744: f_best = 0.00000000\n",
      "x_eff  = [-0.07631317 -0.36457357],\n",
      "\n",
      "iteration 745: f_best = 0.00000000\n",
      "x_eff  = [-0.21683891  0.02496968],\n",
      "\n",
      "iteration 746: f_best = 0.00000000\n",
      "x_eff  = [0.08827017 0.09477505],\n",
      "\n",
      "iteration 747: f_best = 0.00000000\n",
      "x_eff  = [0.12989085 0.01750629],\n",
      "\n",
      "iteration 748: f_best = 0.00000000\n",
      "x_eff  = [-0.00735074 -0.34117167],\n",
      "\n",
      "iteration 749: f_best = 0.00000000\n",
      "x_eff  = [ 0.31261508 -0.22013223],\n",
      "\n",
      "iteration 750: f_best = 0.00000000\n",
      "x_eff  = [0.32761349 0.35893489],\n",
      "\n",
      "iteration 751: f_best = 0.00000000\n",
      "x_eff  = [0.30330889 0.00391081],\n",
      "\n",
      "iteration 752: f_best = 0.00000000\n",
      "x_eff  = [-0.28691916 -0.28059532],\n",
      "\n",
      "iteration 753: f_best = 0.00000000\n",
      "x_eff  = [0.21028828 0.08166832],\n",
      "\n",
      "iteration 754: f_best = 0.00000000\n",
      "x_eff  = [-0.03115154 -0.14312615],\n",
      "\n",
      "iteration 755: f_best = 0.00000000\n",
      "x_eff  = [-0.3086603   0.02534815],\n",
      "\n",
      "iteration 756: f_best = 0.00000000\n",
      "x_eff  = [-0.02126282  0.10529408],\n",
      "\n",
      "iteration 757: f_best = 0.00000000\n",
      "x_eff  = [ 0.33986868 -0.2318669 ],\n",
      "\n",
      "iteration 758: f_best = 0.00000000\n",
      "x_eff  = [-0.07592022 -0.09504966],\n",
      "\n",
      "iteration 759: f_best = 0.00000000\n",
      "x_eff  = [0.02054064 0.19142879],\n",
      "\n",
      "iteration 760: f_best = 0.00000000\n",
      "x_eff  = [0.0343233  0.17023865],\n",
      "\n",
      "iteration 761: f_best = 0.00000000\n",
      "x_eff  = [0.06406545 0.02980569],\n",
      "\n",
      "iteration 762: f_best = 0.00000000\n",
      "x_eff  = [ 0.21595146 -0.29796243],\n",
      "\n",
      "iteration 763: f_best = 0.00000000\n",
      "x_eff  = [ 0.10270676 -0.31089762],\n",
      "\n",
      "iteration 764: f_best = 0.00000000\n",
      "x_eff  = [0.17702127 0.01788146],\n",
      "\n",
      "iteration 765: f_best = 0.00000000\n",
      "x_eff  = [0.04648873 0.10505522],\n",
      "\n",
      "iteration 766: f_best = 0.00000000\n",
      "x_eff  = [-0.12543748  0.19422073],\n",
      "\n",
      "iteration 767: f_best = 0.00000000\n",
      "x_eff  = [-0.22993075 -0.01475592],\n",
      "\n",
      "iteration 768: f_best = 0.00000000\n",
      "x_eff  = [-0.30280669 -0.04307138],\n",
      "\n",
      "iteration 769: f_best = 0.00000000\n",
      "x_eff  = [-0.03983398  0.2782096 ],\n",
      "\n",
      "iteration 770: f_best = 0.00000000\n",
      "x_eff  = [0.25609988 0.10815993],\n",
      "\n",
      "iteration 771: f_best = 0.00000000\n",
      "x_eff  = [0.14027708 0.0037147 ],\n",
      "\n",
      "iteration 772: f_best = 0.00000000\n",
      "x_eff  = [-0.26214518  0.1769922 ],\n",
      "\n",
      "iteration 773: f_best = 0.00000000\n",
      "x_eff  = [ 0.15996268 -0.16709104],\n",
      "\n",
      "iteration 774: f_best = 0.00000000\n",
      "x_eff  = [0.2404992  0.23310443],\n",
      "\n",
      "iteration 775: f_best = 0.00000000\n",
      "x_eff  = [ 0.22685092 -0.22791617],\n",
      "\n",
      "iteration 776: f_best = 0.00000000\n",
      "x_eff  = [-0.0548762  -0.26338739],\n",
      "\n",
      "iteration 777: f_best = 0.00000000\n",
      "x_eff  = [-0.09820613 -0.2716198 ],\n",
      "\n",
      "iteration 778: f_best = 0.00000000\n",
      "x_eff  = [0.11023858 0.19547552],\n",
      "\n",
      "iteration 779: f_best = 0.00000000\n",
      "x_eff  = [0.00986871 0.01356635],\n",
      "\n",
      "iteration 780: f_best = 0.00000000\n",
      "x_eff  = [-0.05081855  0.13870606],\n",
      "\n",
      "iteration 781: f_best = 0.00000000\n",
      "x_eff  = [ 0.08001879 -0.23984718],\n",
      "\n",
      "iteration 782: f_best = 0.00000000\n",
      "x_eff  = [-0.11361948  0.0668793 ],\n",
      "\n",
      "iteration 783: f_best = 0.00000000\n",
      "x_eff  = [0.15918039 0.04975062],\n",
      "\n",
      "iteration 784: f_best = 0.00000000\n",
      "x_eff  = [0.10378436 0.00341895],\n",
      "\n",
      "iteration 785: f_best = 0.00000000\n",
      "x_eff  = [-0.02576857 -0.05489584],\n",
      "\n",
      "iteration 786: f_best = 0.00000000\n",
      "x_eff  = [0.18361704 0.08374983],\n",
      "\n",
      "iteration 787: f_best = 0.00000000\n",
      "x_eff  = [0.25206268 0.15163985],\n",
      "\n",
      "iteration 788: f_best = 0.00000000\n",
      "x_eff  = [0.23958759 0.13916971],\n",
      "\n",
      "iteration 789: f_best = 0.00000000\n",
      "x_eff  = [ 0.06215074 -0.15897255],\n",
      "\n",
      "iteration 790: f_best = 0.00000000\n",
      "x_eff  = [0.19468384 0.01831584],\n",
      "\n",
      "iteration 791: f_best = 0.00000000\n",
      "x_eff  = [-0.05566071  0.09541029],\n",
      "\n",
      "iteration 792: f_best = 0.00000000\n",
      "x_eff  = [0.05880866 0.2042922 ],\n",
      "\n",
      "iteration 793: f_best = 0.00000000\n",
      "x_eff  = [-0.02267776  0.0730308 ],\n",
      "\n",
      "iteration 794: f_best = 0.00000000\n",
      "x_eff  = [ 0.2320952  -0.07092721],\n",
      "\n",
      "iteration 795: f_best = 0.00000000\n",
      "x_eff  = [-0.23228775  0.04350565],\n",
      "\n",
      "iteration 796: f_best = 0.00000000\n",
      "x_eff  = [-0.00904709  0.21454642],\n",
      "\n",
      "iteration 797: f_best = 0.00000000\n",
      "x_eff  = [-0.03961597  0.07438781],\n",
      "\n",
      "iteration 798: f_best = 0.00000000\n",
      "x_eff  = [-0.20939089 -0.16320036],\n",
      "\n",
      "iteration 799: f_best = 0.00000000\n",
      "x_eff  = [ 0.12636185 -0.18549281],\n",
      "\n",
      "iteration 800: f_best = 0.00000000\n",
      "x_eff  = [-0.07926446  0.03169365],\n",
      "\n",
      "iteration 801: f_best = 0.00000000\n",
      "x_eff  = [-0.13918619 -0.20646378],\n",
      "\n",
      "iteration 802: f_best = 0.00000000\n",
      "x_eff  = [0.16315712 0.00755445],\n",
      "\n",
      "iteration 803: f_best = 0.00000000\n",
      "x_eff  = [-0.11743169 -0.11860875],\n",
      "\n",
      "iteration 804: f_best = 0.00000000\n",
      "x_eff  = [ 0.1268133 -0.0340792],\n",
      "\n",
      "iteration 805: f_best = 0.00000000\n",
      "x_eff  = [0.0571032  0.16959033],\n",
      "\n",
      "iteration 806: f_best = 0.00000000\n",
      "x_eff  = [-0.19156418 -0.20938955],\n",
      "\n",
      "iteration 807: f_best = 0.00000000\n",
      "x_eff  = [-0.04645955 -0.20175089],\n",
      "\n",
      "iteration 808: f_best = 0.00000000\n",
      "x_eff  = [ 0.03804424 -0.07333717],\n",
      "\n",
      "iteration 809: f_best = 0.00000000\n",
      "x_eff  = [-0.15193161  0.05736484],\n",
      "\n",
      "iteration 810: f_best = 0.00000000\n",
      "x_eff  = [-0.04523241  0.12990919],\n",
      "\n",
      "iteration 811: f_best = 0.00000000\n",
      "x_eff  = [ 0.00206605 -0.07201194],\n",
      "\n",
      "iteration 812: f_best = 0.00000000\n",
      "x_eff  = [-0.12264212  0.15152801],\n",
      "\n",
      "iteration 813: f_best = 0.00000000\n",
      "x_eff  = [ 0.16271463 -0.15866461],\n",
      "\n",
      "iteration 814: f_best = 0.00000000\n",
      "x_eff  = [0.04087166 0.16008177],\n",
      "\n",
      "iteration 815: f_best = 0.00000000\n",
      "x_eff  = [-0.08302354 -0.03059408],\n",
      "\n",
      "iteration 816: f_best = 0.00000000\n",
      "x_eff  = [0.12749582 0.04396228],\n",
      "\n",
      "iteration 817: f_best = 0.00000000\n",
      "x_eff  = [-0.11864697  0.03732838],\n",
      "\n",
      "iteration 818: f_best = 0.00000000\n",
      "x_eff  = [-0.13647528 -0.02981245],\n",
      "\n",
      "iteration 819: f_best = 0.00000000\n",
      "x_eff  = [0.14188505 0.12852957],\n",
      "\n",
      "iteration 820: f_best = 0.00000000\n",
      "x_eff  = [0.12383047 0.17569569],\n",
      "\n",
      "iteration 821: f_best = 0.00000000\n",
      "x_eff  = [-0.08364449 -0.00637634],\n",
      "\n",
      "iteration 822: f_best = 0.00000000\n",
      "x_eff  = [-0.17575449  0.00721364],\n",
      "\n",
      "iteration 823: f_best = 0.00000000\n",
      "x_eff  = [-0.1270958   0.10927771],\n",
      "\n",
      "iteration 824: f_best = 0.00000000\n",
      "x_eff  = [ 0.10293354 -0.1653666 ],\n",
      "\n",
      "iteration 825: f_best = 0.00000000\n",
      "x_eff  = [-0.04736095 -0.0031829 ],\n",
      "\n",
      "iteration 826: f_best = 0.00000000\n",
      "x_eff  = [ 0.01405284 -0.00545562],\n",
      "\n",
      "iteration 827: f_best = 0.00000000\n",
      "x_eff  = [-0.10908194  0.00700646],\n",
      "\n",
      "iteration 828: f_best = 0.00000000\n",
      "x_eff  = [0.11882955 0.03915029],\n",
      "\n",
      "iteration 829: f_best = 0.00000000\n",
      "x_eff  = [0.15930016 0.10985463],\n",
      "\n",
      "iteration 830: f_best = 0.00000000\n",
      "x_eff  = [-0.06505495 -0.00418394],\n",
      "\n",
      "iteration 831: f_best = 0.00000000\n",
      "x_eff  = [-0.03554581  0.10505218],\n",
      "\n",
      "iteration 832: f_best = 0.00000000\n",
      "x_eff  = [-0.00352738 -0.07185117],\n",
      "\n",
      "iteration 833: f_best = 0.00000000\n",
      "x_eff  = [-0.05661264  0.15097824],\n",
      "\n",
      "iteration 834: f_best = 0.00000000\n",
      "x_eff  = [0.03992768 0.10373867],\n",
      "\n",
      "iteration 835: f_best = 0.00000000\n",
      "x_eff  = [-0.06039504  0.03059979],\n",
      "\n",
      "iteration 836: f_best = 0.00000000\n",
      "x_eff  = [-0.14975897 -0.02853496],\n",
      "\n",
      "iteration 837: f_best = 0.00000000\n",
      "x_eff  = [-0.00379724 -0.05674525],\n",
      "\n",
      "iteration 838: f_best = 0.00000000\n",
      "x_eff  = [0.09297545 0.01854936],\n",
      "\n",
      "iteration 839: f_best = 0.00000000\n",
      "x_eff  = [-0.12285393 -0.02166712],\n",
      "\n",
      "iteration 840: f_best = 0.00000000\n",
      "x_eff  = [0.11775297 0.09554498],\n",
      "\n",
      "iteration 841: f_best = 0.00000000\n",
      "x_eff  = [ 0.07413131 -0.00093845],\n",
      "\n",
      "iteration 842: f_best = 0.00000000\n",
      "x_eff  = [-0.07474999  0.04970421],\n",
      "\n",
      "iteration 843: f_best = 0.00000000\n",
      "x_eff  = [ 0.05443629 -0.09312079],\n",
      "\n",
      "iteration 844: f_best = 0.00000000\n",
      "x_eff  = [-0.12441764 -0.07711091],\n",
      "\n",
      "iteration 845: f_best = 0.00000000\n",
      "x_eff  = [-0.02149322  0.02471071],\n",
      "\n",
      "iteration 846: f_best = 0.00000000\n",
      "x_eff  = [0.09000789 0.11011705],\n",
      "\n",
      "iteration 847: f_best = 0.00000000\n",
      "x_eff  = [-0.01448363 -0.06660261],\n",
      "\n",
      "iteration 848: f_best = 0.00000000\n",
      "x_eff  = [0.00874855 0.12286602],\n",
      "\n",
      "iteration 849: f_best = 0.00000000\n",
      "x_eff  = [0.07322224 0.04135093],\n",
      "\n",
      "iteration 850: f_best = 0.00000000\n",
      "x_eff  = [-0.02796942  0.03648628],\n",
      "\n",
      "iteration 851: f_best = 0.00000000\n",
      "x_eff  = [ 0.1301082  -0.01963011],\n",
      "\n",
      "iteration 852: f_best = 0.00000000\n",
      "x_eff  = [-0.13002365  0.02361127],\n",
      "\n",
      "iteration 853: f_best = 0.00000000\n",
      "x_eff  = [0.06801424 0.04631216],\n",
      "\n",
      "iteration 854: f_best = 0.00000000\n",
      "x_eff  = [0.04133285 0.03876447],\n",
      "\n",
      "iteration 855: f_best = 0.00000000\n",
      "x_eff  = [ 0.11597607 -0.06154554],\n",
      "\n",
      "iteration 856: f_best = 0.00000000\n",
      "x_eff  = [0.08720455 0.02235574],\n",
      "\n",
      "iteration 857: f_best = 0.00000000\n",
      "x_eff  = [-0.04532462  0.06316087],\n",
      "\n",
      "iteration 858: f_best = 0.00000000\n",
      "x_eff  = [-0.01284968  0.01694622],\n",
      "\n",
      "iteration 859: f_best = 0.00000000\n",
      "x_eff  = [0.02621298 0.01535866],\n",
      "\n",
      "iteration 860: f_best = 0.00000000\n",
      "x_eff  = [-4.90867931e-05  1.20082892e-01],\n",
      "\n",
      "iteration 861: f_best = 0.00000000\n",
      "x_eff  = [0.06848973 0.03655439],\n",
      "\n",
      "iteration 862: f_best = 0.00000000\n",
      "x_eff  = [ 0.03634461 -0.00582053],\n",
      "\n",
      "iteration 863: f_best = 0.00000000\n",
      "x_eff  = [ 0.01538259 -0.02149981],\n",
      "\n",
      "iteration 864: f_best = 0.00000000\n",
      "x_eff  = [0.03832986 0.03869094],\n",
      "\n",
      "iteration 865: f_best = 0.00000000\n",
      "x_eff  = [-0.07485387 -0.01700495],\n",
      "\n",
      "iteration 866: f_best = 0.00000000\n",
      "x_eff  = [-0.09260618 -0.05853525],\n",
      "\n",
      "iteration 867: f_best = 0.00000000\n",
      "x_eff  = [-0.06352476 -0.10476825],\n",
      "\n",
      "iteration 868: f_best = 0.00000000\n",
      "x_eff  = [-0.11246867 -0.02402135],\n",
      "\n",
      "iteration 869: f_best = 0.00000000\n",
      "x_eff  = [-0.03585973 -0.03632342],\n",
      "\n",
      "iteration 870: f_best = 0.00000000\n",
      "x_eff  = [0.10816692 0.00690936],\n",
      "\n",
      "iteration 871: f_best = 0.00000000\n",
      "x_eff  = [-0.06842267  0.035519  ],\n",
      "\n",
      "iteration 872: f_best = 0.00000000\n",
      "x_eff  = [0.0640976  0.09759322],\n",
      "\n",
      "iteration 873: f_best = 0.00000000\n",
      "x_eff  = [-0.0722389  0.0184528],\n",
      "\n",
      "iteration 874: f_best = 0.00000000\n",
      "x_eff  = [-0.09880295  0.05282359],\n",
      "\n",
      "iteration 875: f_best = 0.00000000\n",
      "x_eff  = [0.05756156 0.02815422],\n",
      "\n",
      "iteration 876: f_best = 0.00000000\n",
      "x_eff  = [-0.09293669  0.01579261],\n",
      "\n",
      "iteration 877: f_best = 0.00000000\n",
      "x_eff  = [0.00172977 0.04800483],\n",
      "\n",
      "iteration 878: f_best = 0.00000000\n",
      "x_eff  = [-0.04177308  0.08263944],\n",
      "\n",
      "iteration 879: f_best = 0.00000000\n",
      "x_eff  = [0.07103436 0.0250725 ],\n",
      "\n",
      "iteration 880: f_best = 0.00000000\n",
      "x_eff  = [-0.05337363  0.04165887],\n",
      "\n",
      "iteration 881: f_best = 0.00000000\n",
      "x_eff  = [0.06282531 0.0295669 ],\n",
      "\n",
      "iteration 882: f_best = 0.00000000\n",
      "x_eff  = [-0.0289705   0.09654681],\n",
      "\n",
      "iteration 883: f_best = 0.00000000\n",
      "x_eff  = [ 0.05061994 -0.03106475],\n",
      "\n",
      "iteration 884: f_best = 0.00000000\n",
      "x_eff  = [0.04510055 0.04574849],\n",
      "\n",
      "iteration 885: f_best = 0.00000000\n",
      "x_eff  = [-0.06701471 -0.04666897],\n",
      "\n",
      "iteration 886: f_best = 0.00000000\n",
      "x_eff  = [ 0.01921472 -0.04331345],\n",
      "\n",
      "iteration 887: f_best = 0.00000000\n",
      "x_eff  = [-0.0661783  -0.06447104],\n",
      "\n",
      "iteration 888: f_best = 0.00000000\n",
      "x_eff  = [-0.07891309  0.02463583],\n",
      "\n",
      "iteration 889: f_best = 0.00000000\n",
      "x_eff  = [ 0.08329572 -0.08021611],\n",
      "\n",
      "iteration 890: f_best = 0.00000000\n",
      "x_eff  = [-0.07321005 -0.0898065 ],\n",
      "\n",
      "iteration 891: f_best = 0.00000000\n",
      "x_eff  = [0.0601652  0.03050178],\n",
      "\n",
      "iteration 892: f_best = 0.00000000\n",
      "x_eff  = [-0.03911556 -0.04426691],\n",
      "\n",
      "iteration 893: f_best = 0.00000000\n",
      "x_eff  = [0.04922622 0.05461067],\n",
      "\n",
      "iteration 894: f_best = 0.00000000\n",
      "x_eff  = [-0.04359008  0.07246872],\n",
      "\n",
      "iteration 895: f_best = 0.00000000\n",
      "x_eff  = [0.00582335 0.01751678],\n",
      "\n",
      "iteration 896: f_best = 0.00000000\n",
      "x_eff  = [-0.00205292  0.01809745],\n",
      "\n",
      "iteration 897: f_best = 0.00000000\n",
      "x_eff  = [-0.07806496  0.03456853],\n",
      "\n",
      "iteration 898: f_best = 0.00000000\n",
      "x_eff  = [0.08147232 0.01488547],\n",
      "\n",
      "iteration 899: f_best = 0.00000000\n",
      "x_eff  = [-0.07248551 -0.03011336],\n",
      "\n",
      "iteration 900: f_best = 0.00000000\n",
      "x_eff  = [0.00766292 0.0684039 ],\n",
      "\n",
      "iteration 901: f_best = 0.00000000\n",
      "x_eff  = [0.02151227 0.05273003],\n",
      "\n",
      "iteration 902: f_best = 0.00000000\n",
      "x_eff  = [0.04709596 0.04880916],\n",
      "\n",
      "iteration 903: f_best = 0.00000000\n",
      "x_eff  = [-0.00424378  0.05124223],\n",
      "\n",
      "iteration 904: f_best = 0.00000000\n",
      "x_eff  = [ 0.07541101 -0.05578716],\n",
      "\n",
      "iteration 905: f_best = 0.00000000\n",
      "x_eff  = [-0.06279381  0.06465827],\n",
      "\n",
      "iteration 906: f_best = 0.00000000\n",
      "x_eff  = [-0.0406271   0.05387045],\n",
      "\n",
      "iteration 907: f_best = 0.00000000\n",
      "x_eff  = [-0.01009735  0.014597  ],\n",
      "\n",
      "iteration 908: f_best = 0.00000000\n",
      "x_eff  = [-0.01764956 -0.04652944],\n",
      "\n",
      "iteration 909: f_best = 0.00000000\n",
      "x_eff  = [-0.02471209 -0.02288831],\n",
      "\n",
      "iteration 910: f_best = 0.00000000\n",
      "x_eff  = [-0.06982418  0.05891706],\n",
      "\n",
      "iteration 911: f_best = 0.00000000\n",
      "x_eff  = [ 0.06185896 -0.00025254],\n",
      "\n",
      "iteration 912: f_best = 0.00000000\n",
      "x_eff  = [-0.06941659 -0.06544579],\n",
      "\n",
      "iteration 913: f_best = 0.00000000\n",
      "x_eff  = [-0.0578694  -0.02828687],\n",
      "\n",
      "iteration 914: f_best = 0.00000000\n",
      "x_eff  = [-0.00613392 -0.00196887],\n",
      "\n",
      "iteration 915: f_best = 0.00000000\n",
      "x_eff  = [-0.03891689  0.05647762],\n",
      "\n",
      "iteration 916: f_best = 0.00000000\n",
      "x_eff  = [-0.04358001  0.03204187],\n",
      "\n",
      "iteration 917: f_best = 0.00000000\n",
      "x_eff  = [-0.03077723 -0.00666825],\n",
      "\n",
      "iteration 918: f_best = 0.00000000\n",
      "x_eff  = [-0.05455299  0.04719209],\n",
      "\n",
      "iteration 919: f_best = 0.00000000\n",
      "x_eff  = [ 0.0666767  -0.05283897],\n",
      "\n",
      "iteration 920: f_best = 0.00000000\n",
      "x_eff  = [-0.04317281 -0.01133098],\n",
      "\n",
      "iteration 921: f_best = 0.00000000\n",
      "x_eff  = [-0.04343603  0.03623844],\n",
      "\n",
      "iteration 922: f_best = 0.00000000\n",
      "x_eff  = [-0.00485853 -0.01853377],\n",
      "\n",
      "iteration 923: f_best = 0.00000000\n",
      "x_eff  = [-0.00385138 -0.05967468],\n",
      "\n",
      "iteration 924: f_best = 0.00000000\n",
      "x_eff  = [-0.00602064 -0.00240143],\n",
      "\n",
      "iteration 925: f_best = 0.00000000\n",
      "x_eff  = [-0.03015054 -0.03775736],\n",
      "\n",
      "iteration 926: f_best = 0.00000000\n",
      "x_eff  = [ 0.03342232 -0.06292286],\n",
      "\n",
      "iteration 927: f_best = 0.00000000\n",
      "x_eff  = [0.02549397 0.02687968],\n",
      "\n",
      "iteration 928: f_best = 0.00000000\n",
      "x_eff  = [-0.04823919 -0.0184482 ],\n",
      "\n",
      "iteration 929: f_best = 0.00000000\n",
      "x_eff  = [-0.0450393   0.03342494],\n",
      "\n",
      "iteration 930: f_best = 0.00000000\n",
      "x_eff  = [-0.02918034  0.05942945],\n",
      "\n",
      "iteration 931: f_best = 0.00000000\n",
      "x_eff  = [-0.03211743 -0.04944474],\n",
      "\n",
      "iteration 932: f_best = 0.00000000\n",
      "x_eff  = [-0.0535991   0.04360129],\n",
      "\n",
      "iteration 933: f_best = 0.00000000\n",
      "x_eff  = [-0.00584552  0.03100626],\n",
      "\n",
      "iteration 934: f_best = 0.00000000\n",
      "x_eff  = [ 0.0466998  -0.00822597],\n",
      "\n",
      "iteration 935: f_best = 0.00000000\n",
      "x_eff  = [0.0226571 0.0295393],\n",
      "\n",
      "iteration 936: f_best = 0.00000000\n",
      "x_eff  = [ 0.00837207 -0.01016957],\n",
      "\n",
      "iteration 937: f_best = 0.00000000\n",
      "x_eff  = [ 0.00921453 -0.02906487],\n",
      "\n",
      "iteration 938: f_best = 0.00000000\n",
      "x_eff  = [-0.02496445  0.05423913],\n",
      "\n",
      "iteration 939: f_best = 0.00000000\n",
      "x_eff  = [-0.00053049 -0.048845  ],\n",
      "\n",
      "iteration 940: f_best = 0.00000000\n",
      "x_eff  = [-0.05316348  0.00157605],\n",
      "\n",
      "iteration 941: f_best = 0.00000000\n",
      "x_eff  = [ 0.04666043 -0.03952191],\n",
      "\n",
      "iteration 942: f_best = 0.00000000\n",
      "x_eff  = [ 0.05282672 -0.01279159],\n",
      "\n",
      "iteration 943: f_best = 0.00000000\n",
      "x_eff  = [0.04286669 0.00061956],\n",
      "\n",
      "iteration 944: f_best = 0.00000000\n",
      "x_eff  = [0.0299968  0.04579531],\n",
      "\n",
      "iteration 945: f_best = 0.00000000\n",
      "x_eff  = [-0.03849838 -0.01021621],\n",
      "\n",
      "iteration 946: f_best = 0.00000000\n",
      "x_eff  = [-0.00346662  0.00536423],\n",
      "\n",
      "iteration 947: f_best = 0.00000000\n",
      "x_eff  = [0.00133199 0.00870598],\n",
      "\n",
      "iteration 948: f_best = 0.00000000\n",
      "x_eff  = [ 0.04976903 -0.02550661],\n",
      "\n",
      "iteration 949: f_best = 0.00000000\n",
      "x_eff  = [-0.04600084 -0.04476336],\n",
      "\n",
      "iteration 950: f_best = 0.00000000\n",
      "x_eff  = [ 0.02538813 -0.01077643],\n",
      "\n",
      "iteration 951: f_best = 0.00000000\n",
      "x_eff  = [0.02116292 0.02677853],\n",
      "\n",
      "iteration 952: f_best = 0.00000000\n",
      "x_eff  = [-0.01717677  0.04779878],\n",
      "\n",
      "iteration 953: f_best = 0.00000000\n",
      "x_eff  = [-0.01517501 -0.04157042],\n",
      "\n",
      "iteration 954: f_best = 0.00000000\n",
      "x_eff  = [ 0.02505773 -0.0114519 ],\n",
      "\n",
      "iteration 955: f_best = 0.00000000\n",
      "x_eff  = [-0.00653827  0.03838397],\n",
      "\n",
      "iteration 956: f_best = 0.00000000\n",
      "x_eff  = [ 0.02524528 -0.02974495],\n",
      "\n",
      "iteration 957: f_best = 0.00000000\n",
      "x_eff  = [0.00274437 0.00982419],\n",
      "\n",
      "iteration 958: f_best = 0.00000000\n",
      "x_eff  = [-0.03564561 -0.01638414],\n",
      "\n",
      "iteration 959: f_best = 0.00000000\n",
      "x_eff  = [0.02541407 0.01610184],\n",
      "\n",
      "iteration 960: f_best = 0.00000000\n",
      "x_eff  = [-0.00245103  0.00262062],\n",
      "\n",
      "iteration 961: f_best = 0.00000000\n",
      "x_eff  = [ 0.01544562 -0.0118729 ],\n",
      "\n",
      "iteration 962: f_best = 0.00000000\n",
      "x_eff  = [ 0.03071885 -0.0237694 ],\n",
      "\n",
      "iteration 963: f_best = 0.00000000\n",
      "x_eff  = [0.03040213 0.02997119],\n",
      "\n",
      "iteration 964: f_best = 0.00000000\n",
      "x_eff  = [0.03641161 0.04200686],\n",
      "\n",
      "iteration 965: f_best = 0.00000000\n",
      "x_eff  = [-0.03656149  0.02897098],\n",
      "\n",
      "iteration 966: f_best = 0.00000000\n",
      "x_eff  = [0.03510567 0.01151781],\n",
      "\n",
      "iteration 967: f_best = 0.00000000\n",
      "x_eff  = [ 0.00383508 -0.01883451],\n",
      "\n",
      "iteration 968: f_best = 0.00000000\n",
      "x_eff  = [-0.00304146  0.00617968],\n",
      "\n",
      "iteration 969: f_best = 0.00000000\n",
      "x_eff  = [ 0.01101313 -0.02534371],\n",
      "\n",
      "iteration 970: f_best = 0.00000000\n",
      "x_eff  = [0.03419415 0.01714046],\n",
      "\n",
      "iteration 971: f_best = 0.00000000\n",
      "x_eff  = [ 0.01345591 -0.00353027],\n",
      "\n",
      "iteration 972: f_best = 0.00000000\n",
      "x_eff  = [-0.03974631  0.00851176],\n",
      "\n",
      "iteration 973: f_best = 0.00000000\n",
      "x_eff  = [0.03073294 0.03536297],\n",
      "\n",
      "iteration 974: f_best = 0.00000000\n",
      "x_eff  = [0.02503449 0.02132189],\n",
      "\n",
      "iteration 975: f_best = 0.00000000\n",
      "x_eff  = [ 2.83946058e-04 -7.60164400e-05],\n",
      "\n",
      "iteration 976: f_best = 0.00000000\n",
      "x_eff  = [-0.01088022 -0.02249565],\n",
      "\n",
      "iteration 977: f_best = 0.00000000\n",
      "x_eff  = [-0.01634078  0.0241639 ],\n",
      "\n",
      "iteration 978: f_best = 0.00000000\n",
      "x_eff  = [0.01959515 0.00619138],\n",
      "\n",
      "iteration 979: f_best = 0.00000000\n",
      "x_eff  = [-0.02318506 -0.0245347 ],\n",
      "\n",
      "iteration 980: f_best = 0.00000000\n",
      "x_eff  = [-0.02570345  0.01621651],\n",
      "\n",
      "iteration 981: f_best = 0.00000000\n",
      "x_eff  = [0.01887533 0.02411848],\n",
      "\n",
      "iteration 982: f_best = 0.00000000\n",
      "x_eff  = [0.01679722 0.03528798],\n",
      "\n",
      "iteration 983: f_best = 0.00000000\n",
      "x_eff  = [-0.01273854  0.02796186],\n",
      "\n",
      "iteration 984: f_best = 0.00000000\n",
      "x_eff  = [0.00425058 0.01941222],\n",
      "\n",
      "iteration 985: f_best = 0.00000000\n",
      "x_eff  = [-0.02620403  0.00578462],\n",
      "\n",
      "iteration 986: f_best = 0.00000000\n",
      "x_eff  = [-0.02877883  0.01225565],\n",
      "\n",
      "iteration 987: f_best = 0.00000000\n",
      "x_eff  = [-0.01063191 -0.00392559],\n",
      "\n",
      "iteration 988: f_best = 0.00000000\n",
      "x_eff  = [0.01146997 0.0326021 ],\n",
      "\n",
      "iteration 989: f_best = 0.00000000\n",
      "x_eff  = [0.00207916 0.024748  ],\n",
      "\n",
      "iteration 990: f_best = 0.00000000\n",
      "x_eff  = [-0.00948572 -0.01836402],\n",
      "\n",
      "iteration 991: f_best = 0.00000000\n",
      "x_eff  = [-0.01491687  0.02318254],\n",
      "\n",
      "iteration 992: f_best = 0.00000000\n",
      "x_eff  = [ 0.02080388 -0.03093496],\n",
      "\n",
      "iteration 993: f_best = 0.00000000\n",
      "x_eff  = [-0.03193685  0.00409443],\n",
      "\n",
      "iteration 994: f_best = 0.00000000\n",
      "x_eff  = [-0.02486865  0.02616124],\n",
      "\n",
      "iteration 995: f_best = 0.00000000\n",
      "x_eff  = [-0.01870822  0.01521993],\n",
      "\n",
      "iteration 996: f_best = 0.00000000\n",
      "x_eff  = [-0.00335365  0.0114421 ],\n",
      "\n",
      "iteration 997: f_best = 0.00000000\n",
      "x_eff  = [-0.02726555  0.02434994],\n",
      "\n",
      "iteration 998: f_best = 0.00000000\n",
      "x_eff  = [0.00049075 0.02691449],\n",
      "\n",
      "iteration 999: f_best = 0.00000000\n",
      "x_eff  = [-0.00731396  0.02352931],\n",
      "\n",
      "Best value for K_warmup=10: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "bounds = np.array([[-600, 600], [-600, 600]])\n",
    "tau = 1e-8\n",
    "K_warmup1 = 10\n",
    "K_warmup2 = 100\n",
    "K = 1000\n",
    "\n",
    "x_best1, f_best1 = global_opt(bounds, tau, K, K_warmup1)\n",
    "print(f\"Best value for K_warmup={K_warmup1}: {f_best1:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100: f_best = 0.71021693\n",
      "x_eff  = [-50.24035766  17.75377191],\n",
      "\n",
      "iteration 101: f_best = 0.71021693\n",
      "x_eff  = [-294.96718612  110.63720224],\n",
      "\n",
      "iteration 102: f_best = 0.71021693\n",
      "x_eff  = [-234.46419348    6.37165209],\n",
      "\n",
      "iteration 103: f_best = 0.71021693\n",
      "x_eff  = [ -90.13750101 -237.52393345],\n",
      "\n",
      "iteration 104: f_best = 0.71021693\n",
      "x_eff  = [-173.77061697   28.98041599],\n",
      "\n",
      "iteration 105: f_best = 0.71021693\n",
      "x_eff  = [-234.91612992  288.51979504],\n",
      "\n",
      "iteration 106: f_best = 0.71021693\n",
      "x_eff  = [-181.28112276  102.88538437],\n",
      "\n",
      "iteration 107: f_best = 0.71021693\n",
      "x_eff  = [-157.48678389 -216.75135787],\n",
      "\n",
      "iteration 108: f_best = 0.71021693\n",
      "x_eff  = [114.18769039  26.24321044],\n",
      "\n",
      "iteration 109: f_best = 0.71021693\n",
      "x_eff  = [225.84629994 205.23607504],\n",
      "\n",
      "iteration 110: f_best = 0.71021693\n",
      "x_eff  = [-111.6846107   -77.63912103],\n",
      "\n",
      "iteration 111: f_best = 0.71021693\n",
      "x_eff  = [   2.87635178 -240.94501188],\n",
      "\n",
      "iteration 112: f_best = 0.71021693\n",
      "x_eff  = [ 181.75411104 -234.24003808],\n",
      "\n",
      "iteration 113: f_best = 0.71021693\n",
      "x_eff  = [-102.71080081 -161.33104389],\n",
      "\n",
      "iteration 114: f_best = 0.71021693\n",
      "x_eff  = [ 99.53782073 129.26118977],\n",
      "\n",
      "iteration 115: f_best = 0.71021693\n",
      "x_eff  = [-145.56905836   30.834525  ],\n",
      "\n",
      "iteration 116: f_best = 0.71021693\n",
      "x_eff  = [178.81015838 252.50290495],\n",
      "\n",
      "iteration 117: f_best = 0.71021693\n",
      "x_eff  = [-103.48414574 -125.39511378],\n",
      "\n",
      "iteration 118: f_best = 0.71021693\n",
      "x_eff  = [-39.96541137  85.49337369],\n",
      "\n",
      "iteration 119: f_best = 0.71021693\n",
      "x_eff  = [-82.03339718 -26.96772577],\n",
      "\n",
      "iteration 120: f_best = 0.71021693\n",
      "x_eff  = [ 90.78401976 -12.85804508],\n",
      "\n",
      "iteration 121: f_best = 0.71021693\n",
      "x_eff  = [138.74089673 226.04896088],\n",
      "\n",
      "iteration 122: f_best = 0.71021693\n",
      "x_eff  = [101.82117361 127.54127241],\n",
      "\n",
      "iteration 123: f_best = 0.71021693\n",
      "x_eff  = [130.75151698 236.78601306],\n",
      "\n",
      "iteration 124: f_best = 0.71021693\n",
      "x_eff  = [116.26570531 236.21167318],\n",
      "\n",
      "iteration 125: f_best = 0.71021693\n",
      "x_eff  = [-263.52928186    6.62318034],\n",
      "\n",
      "iteration 126: f_best = 0.71021693\n",
      "x_eff  = [ -30.01883428 -112.51498295],\n",
      "\n",
      "iteration 127: f_best = 0.71021693\n",
      "x_eff  = [-225.11266613  133.69547492],\n",
      "\n",
      "iteration 128: f_best = 0.71021693\n",
      "x_eff  = [-141.52688335 -232.17561983],\n",
      "\n",
      "iteration 129: f_best = 0.71021693\n",
      "x_eff  = [150.33110541 187.94522056],\n",
      "\n",
      "iteration 130: f_best = 0.71021693\n",
      "x_eff  = [  20.5002889  -180.91980078],\n",
      "\n",
      "iteration 131: f_best = 0.71021693\n",
      "x_eff  = [160.96433583 -81.76023234],\n",
      "\n",
      "iteration 132: f_best = 0.71021693\n",
      "x_eff  = [-146.57143185   75.48894584],\n",
      "\n",
      "iteration 133: f_best = 0.71021693\n",
      "x_eff  = [ 221.00395765 -171.62451842],\n",
      "\n",
      "iteration 134: f_best = 0.71021693\n",
      "x_eff  = [ 83.12030813 195.30984653],\n",
      "\n",
      "iteration 135: f_best = 0.71021693\n",
      "x_eff  = [-111.98138683  105.04435686],\n",
      "\n",
      "iteration 136: f_best = 0.71021693\n",
      "x_eff  = [171.85364297 101.15789691],\n",
      "\n",
      "iteration 137: f_best = 0.71021693\n",
      "x_eff  = [ 27.72579853 134.03531805],\n",
      "\n",
      "iteration 138: f_best = 0.71021693\n",
      "x_eff  = [-235.55177812  -56.87163674],\n",
      "\n",
      "iteration 139: f_best = 0.71021693\n",
      "x_eff  = [-37.98184502 -70.16961368],\n",
      "\n",
      "iteration 140: f_best = 0.71021693\n",
      "x_eff  = [ 94.60928136 208.82585526],\n",
      "\n",
      "iteration 141: f_best = 0.71021693\n",
      "x_eff  = [-59.8069905   94.86451801],\n",
      "\n",
      "iteration 142: f_best = 0.71021693\n",
      "x_eff  = [ 17.14319281 -83.1081183 ],\n",
      "\n",
      "iteration 143: f_best = 0.71021693\n",
      "x_eff  = [67.12879837 -8.96215731],\n",
      "\n",
      "iteration 144: f_best = 0.71021693\n",
      "x_eff  = [184.43308539  91.45897357],\n",
      "\n",
      "iteration 145: f_best = 0.71021693\n",
      "x_eff  = [ 73.28570391 168.39446508],\n",
      "\n",
      "iteration 146: f_best = 0.71021693\n",
      "x_eff  = [165.00286462 200.04471476],\n",
      "\n",
      "iteration 147: f_best = 0.71021693\n",
      "x_eff  = [  79.78134799 -132.53732195],\n",
      "\n",
      "iteration 148: f_best = 0.71021693\n",
      "x_eff  = [-48.96162384  50.27788341],\n",
      "\n",
      "iteration 149: f_best = 0.71021693\n",
      "x_eff  = [-257.77541285 -107.50256586],\n",
      "\n",
      "iteration 150: f_best = 0.71021693\n",
      "x_eff  = [-253.46376629  189.57580656],\n",
      "\n",
      "iteration 151: f_best = 0.71021693\n",
      "x_eff  = [-223.72219205   83.85733871],\n",
      "\n",
      "iteration 152: f_best = 0.71021693\n",
      "x_eff  = [-171.96647332   44.85743473],\n",
      "\n",
      "iteration 153: f_best = 0.71021693\n",
      "x_eff  = [ 130.3941714 -190.4441533],\n",
      "\n",
      "iteration 154: f_best = 0.71021693\n",
      "x_eff  = [160.50603084  32.34262562],\n",
      "\n",
      "iteration 155: f_best = 0.71021693\n",
      "x_eff  = [-45.85588447 137.4899245 ],\n",
      "\n",
      "iteration 156: f_best = 0.71021693\n",
      "x_eff  = [-65.90423284 -81.26484421],\n",
      "\n",
      "iteration 157: f_best = 0.71021693\n",
      "x_eff  = [ 66.70369343 -26.171277  ],\n",
      "\n",
      "iteration 158: f_best = 0.71021693\n",
      "x_eff  = [-17.15414441 148.20129782],\n",
      "\n",
      "iteration 159: f_best = 0.71021693\n",
      "x_eff  = [-200.44571039  -47.72176577],\n",
      "\n",
      "iteration 160: f_best = 0.71021693\n",
      "x_eff  = [123.03851344 -17.6612595 ],\n",
      "\n",
      "iteration 161: f_best = 0.71021693\n",
      "x_eff  = [ 175.86339228 -117.93613841],\n",
      "\n",
      "iteration 162: f_best = 0.71021693\n",
      "x_eff  = [-201.26432345  130.00674452],\n",
      "\n",
      "iteration 163: f_best = 0.71021693\n",
      "x_eff  = [  38.04676409 -135.22832256],\n",
      "\n",
      "iteration 164: f_best = 0.71021693\n",
      "x_eff  = [140.66291972 -49.52091951],\n",
      "\n",
      "iteration 165: f_best = 0.71021693\n",
      "x_eff  = [-188.76628764  -80.51636183],\n",
      "\n",
      "iteration 166: f_best = 0.71021693\n",
      "x_eff  = [-237.34462217   83.0549739 ],\n",
      "\n",
      "iteration 167: f_best = 0.71021693\n",
      "x_eff  = [ 70.92398009 196.88658262],\n",
      "\n",
      "iteration 168: f_best = 0.71021693\n",
      "x_eff  = [-230.68174425  -48.45348905],\n",
      "\n",
      "iteration 169: f_best = 0.71021693\n",
      "x_eff  = [146.23057626 176.85430593],\n",
      "\n",
      "iteration 170: f_best = 0.71021693\n",
      "x_eff  = [-164.42622099  106.2275373 ],\n",
      "\n",
      "iteration 171: f_best = 0.71021693\n",
      "x_eff  = [-67.13908679 -14.09276976],\n",
      "\n",
      "iteration 172: f_best = 0.71021693\n",
      "x_eff  = [79.74333016 30.53048973],\n",
      "\n",
      "iteration 173: f_best = 0.71021693\n",
      "x_eff  = [ 12.18655994 183.93036798],\n",
      "\n",
      "iteration 174: f_best = 0.71021693\n",
      "x_eff  = [ 87.26960254 196.19776733],\n",
      "\n",
      "iteration 175: f_best = 0.71021693\n",
      "x_eff  = [113.25749147  33.53699848],\n",
      "\n",
      "iteration 176: f_best = 0.08874263\n",
      "x_eff  = [  4.68242261 -18.30365129],\n",
      "\n",
      "iteration 177: f_best = 0.08874263\n",
      "x_eff  = [-111.57469684   -9.18997704],\n",
      "\n",
      "iteration 178: f_best = 0.08874263\n",
      "x_eff  = [-25.99097026 162.38524888],\n",
      "\n",
      "iteration 179: f_best = 0.08874263\n",
      "x_eff  = [ -32.34523186 -103.75590545],\n",
      "\n",
      "iteration 180: f_best = 0.08874263\n",
      "x_eff  = [ -26.66360962 -163.690808  ],\n",
      "\n",
      "iteration 181: f_best = 0.08874263\n",
      "x_eff  = [  -8.65079105 -184.97402558],\n",
      "\n",
      "iteration 182: f_best = 0.08874263\n",
      "x_eff  = [-168.83654092  -94.67401205],\n",
      "\n",
      "iteration 183: f_best = 0.08874263\n",
      "x_eff  = [-98.77946752 155.58581715],\n",
      "\n",
      "iteration 184: f_best = 0.08874263\n",
      "x_eff  = [ 91.4531624  -23.42856692],\n",
      "\n",
      "iteration 185: f_best = 0.08874263\n",
      "x_eff  = [-116.98834838   83.46025352],\n",
      "\n",
      "iteration 186: f_best = 0.08874263\n",
      "x_eff  = [127.34399195 -49.21867315],\n",
      "\n",
      "iteration 187: f_best = 0.08874263\n",
      "x_eff  = [-127.74630873   41.79580074],\n",
      "\n",
      "iteration 188: f_best = 0.08874263\n",
      "x_eff  = [-47.22708494 132.78014013],\n",
      "\n",
      "iteration 189: f_best = 0.08874263\n",
      "x_eff  = [21.87110575 37.51143392],\n",
      "\n",
      "iteration 190: f_best = 0.08874263\n",
      "x_eff  = [173.65294557  95.79355584],\n",
      "\n",
      "iteration 191: f_best = 0.08874263\n",
      "x_eff  = [26.15924987 36.25771437],\n",
      "\n",
      "iteration 192: f_best = 0.08874263\n",
      "x_eff  = [-55.98053792  23.8951372 ],\n",
      "\n",
      "iteration 193: f_best = 0.08874263\n",
      "x_eff  = [  4.80774592 -95.61554608],\n",
      "\n",
      "iteration 194: f_best = 0.08874263\n",
      "x_eff  = [-121.01848076  -94.8103367 ],\n",
      "\n",
      "iteration 195: f_best = 0.08874263\n",
      "x_eff  = [29.90854172 63.86831234],\n",
      "\n",
      "iteration 196: f_best = 0.08874263\n",
      "x_eff  = [ 38.17377294 -54.03802659],\n",
      "\n",
      "iteration 197: f_best = 0.08874263\n",
      "x_eff  = [ -82.94436019 -173.78281824],\n",
      "\n",
      "iteration 198: f_best = 0.08874263\n",
      "x_eff  = [133.36013739 107.93189635],\n",
      "\n",
      "iteration 199: f_best = 0.08874263\n",
      "x_eff  = [117.54809242 -21.48903262],\n",
      "\n",
      "iteration 200: f_best = 0.08874263\n",
      "x_eff  = [-82.13931033 111.62495102],\n",
      "\n",
      "iteration 201: f_best = 0.08874263\n",
      "x_eff  = [ 2.3822342  65.30989894],\n",
      "\n",
      "iteration 202: f_best = 0.08874263\n",
      "x_eff  = [-66.20425105  35.61533945],\n",
      "\n",
      "iteration 203: f_best = 0.08874263\n",
      "x_eff  = [ 16.29240671 106.45397091],\n",
      "\n",
      "iteration 204: f_best = 0.08874263\n",
      "x_eff  = [-15.95987872 125.71946517],\n",
      "\n",
      "iteration 205: f_best = 0.08874263\n",
      "x_eff  = [ -38.09723654 -109.77797832],\n",
      "\n",
      "iteration 206: f_best = 0.08874263\n",
      "x_eff  = [105.81827631 -94.07617584],\n",
      "\n",
      "iteration 207: f_best = 0.08874263\n",
      "x_eff  = [22.44670719 13.17811783],\n",
      "\n",
      "iteration 208: f_best = 0.08874263\n",
      "x_eff  = [-145.40571492  -68.35122446],\n",
      "\n",
      "iteration 209: f_best = 0.08874263\n",
      "x_eff  = [-107.53424417  -37.12485368],\n",
      "\n",
      "iteration 210: f_best = 0.08874263\n",
      "x_eff  = [ 120.26226822 -155.9056469 ],\n",
      "\n",
      "iteration 211: f_best = 0.08874263\n",
      "x_eff  = [ -86.35891192 -122.66159334],\n",
      "\n",
      "iteration 212: f_best = 0.08874263\n",
      "x_eff  = [-90.39640248   9.05297376],\n",
      "\n",
      "iteration 213: f_best = 0.08874263\n",
      "x_eff  = [ 6.53222903 59.45596018],\n",
      "\n",
      "iteration 214: f_best = 0.08874263\n",
      "x_eff  = [-107.02305229  -49.10834279],\n",
      "\n",
      "iteration 215: f_best = 0.08874263\n",
      "x_eff  = [  88.1814127  -153.58014752],\n",
      "\n",
      "iteration 216: f_best = 0.08874263\n",
      "x_eff  = [141.26813254  20.31586777],\n",
      "\n",
      "iteration 217: f_best = 0.08874263\n",
      "x_eff  = [ -78.45267133 -145.5894136 ],\n",
      "\n",
      "iteration 218: f_best = 0.08874263\n",
      "x_eff  = [33.1915275  39.73166331],\n",
      "\n",
      "iteration 219: f_best = 0.08874263\n",
      "x_eff  = [-48.60289488  82.52982056],\n",
      "\n",
      "iteration 220: f_best = 0.08874263\n",
      "x_eff  = [ -44.95082974 -150.24029578],\n",
      "\n",
      "iteration 221: f_best = 0.08874263\n",
      "x_eff  = [17.43032072 69.89168451],\n",
      "\n",
      "iteration 222: f_best = 0.08874263\n",
      "x_eff  = [-122.15687499   25.79716821],\n",
      "\n",
      "iteration 223: f_best = 0.08874263\n",
      "x_eff  = [78.09994112 97.99970897],\n",
      "\n",
      "iteration 224: f_best = 0.08874263\n",
      "x_eff  = [-93.74208027 111.37668986],\n",
      "\n",
      "iteration 225: f_best = 0.08874263\n",
      "x_eff  = [-10.71925086  68.69317892],\n",
      "\n",
      "iteration 226: f_best = 0.08874263\n",
      "x_eff  = [ 62.35227218 118.37107447],\n",
      "\n",
      "iteration 227: f_best = 0.08874263\n",
      "x_eff  = [21.99436995 89.55069362],\n",
      "\n",
      "iteration 228: f_best = 0.08874263\n",
      "x_eff  = [-12.86583373 -83.10876492],\n",
      "\n",
      "iteration 229: f_best = 0.08874263\n",
      "x_eff  = [-91.07205145 -26.17584147],\n",
      "\n",
      "iteration 230: f_best = 0.08874263\n",
      "x_eff  = [ 117.66576091 -128.87441504],\n",
      "\n",
      "iteration 231: f_best = 0.08874263\n",
      "x_eff  = [  53.29167882 -139.28649236],\n",
      "\n",
      "iteration 232: f_best = 0.08874263\n",
      "x_eff  = [-82.27610355 -46.70103962],\n",
      "\n",
      "iteration 233: f_best = 0.08874263\n",
      "x_eff  = [ 123.92893932 -128.46285832],\n",
      "\n",
      "iteration 234: f_best = 0.08874263\n",
      "x_eff  = [104.34519275  73.40884883],\n",
      "\n",
      "iteration 235: f_best = 0.08874263\n",
      "x_eff  = [-77.76477298 -20.79200855],\n",
      "\n",
      "iteration 236: f_best = 0.08874263\n",
      "x_eff  = [-53.15978025 106.23961798],\n",
      "\n",
      "iteration 237: f_best = 0.08874263\n",
      "x_eff  = [-65.30869232 -33.57805731],\n",
      "\n",
      "iteration 238: f_best = 0.08874263\n",
      "x_eff  = [-102.74700815  -67.23188045],\n",
      "\n",
      "iteration 239: f_best = 0.00986467\n",
      "x_eff  = [5.9551401  1.22608927],\n",
      "\n",
      "iteration 240: f_best = 0.00986467\n",
      "x_eff  = [-93.51303847  -1.36491629],\n",
      "\n",
      "iteration 241: f_best = 0.00986467\n",
      "x_eff  = [ 13.26083298 -74.11785791],\n",
      "\n",
      "iteration 242: f_best = 0.00986467\n",
      "x_eff  = [-90.5771673  -77.45807142],\n",
      "\n",
      "iteration 243: f_best = 0.00986467\n",
      "x_eff  = [116.39833135  10.70774623],\n",
      "\n",
      "iteration 244: f_best = 0.00986467\n",
      "x_eff  = [-82.52733609  40.92222801],\n",
      "\n",
      "iteration 245: f_best = 0.00986467\n",
      "x_eff  = [-18.33903117  85.31183722],\n",
      "\n",
      "iteration 246: f_best = 0.00986467\n",
      "x_eff  = [-11.71570498 -15.94117715],\n",
      "\n",
      "iteration 247: f_best = 0.00986467\n",
      "x_eff  = [61.68971448  3.88056262],\n",
      "\n",
      "iteration 248: f_best = 0.00986467\n",
      "x_eff  = [101.11296851  95.68419432],\n",
      "\n",
      "iteration 249: f_best = 0.00986467\n",
      "x_eff  = [ -9.42874492 -25.60163705],\n",
      "\n",
      "iteration 250: f_best = 0.00986467\n",
      "x_eff  = [ 64.45301262 -83.44906182],\n",
      "\n",
      "iteration 251: f_best = 0.00986467\n",
      "x_eff  = [-100.73524958   97.5241181 ],\n",
      "\n",
      "iteration 252: f_best = 0.00986467\n",
      "x_eff  = [62.78325047 43.9741903 ],\n",
      "\n",
      "iteration 253: f_best = 0.00986467\n",
      "x_eff  = [ -72.7338855  -105.15049894],\n",
      "\n",
      "iteration 254: f_best = 0.00986467\n",
      "x_eff  = [-27.60851755 -47.70302922],\n",
      "\n",
      "iteration 255: f_best = 0.00986467\n",
      "x_eff  = [-44.00080034 -64.14765506],\n",
      "\n",
      "iteration 256: f_best = 0.00986467\n",
      "x_eff  = [-25.47080596  88.95172666],\n",
      "\n",
      "iteration 257: f_best = 0.00986467\n",
      "x_eff  = [65.11527179 20.44357993],\n",
      "\n",
      "iteration 258: f_best = 0.00986467\n",
      "x_eff  = [-60.79654601 -44.55461311],\n",
      "\n",
      "iteration 259: f_best = 0.00986467\n",
      "x_eff  = [92.37203424 -7.09485329],\n",
      "\n",
      "iteration 260: f_best = 0.00986467\n",
      "x_eff  = [ 15.22405332 -81.92602898],\n",
      "\n",
      "iteration 261: f_best = 0.00986467\n",
      "x_eff  = [-26.55031632  10.16391821],\n",
      "\n",
      "iteration 262: f_best = 0.00986467\n",
      "x_eff  = [ -2.66269677 -50.18757906],\n",
      "\n",
      "iteration 263: f_best = 0.00986467\n",
      "x_eff  = [32.332187   78.38361637],\n",
      "\n",
      "iteration 264: f_best = 0.00986467\n",
      "x_eff  = [75.52440405 29.80136096],\n",
      "\n",
      "iteration 265: f_best = 0.00986467\n",
      "x_eff  = [ 72.4583925  -40.01760839],\n",
      "\n",
      "iteration 266: f_best = 0.00986467\n",
      "x_eff  = [65.26734981 83.77612941],\n",
      "\n",
      "iteration 267: f_best = 0.00986467\n",
      "x_eff  = [  0.60853317 -28.1953002 ],\n",
      "\n",
      "iteration 268: f_best = 0.00986467\n",
      "x_eff  = [ 66.84982075 -34.55938442],\n",
      "\n",
      "iteration 269: f_best = 0.00986467\n",
      "x_eff  = [  4.73700338 -56.73982609],\n",
      "\n",
      "iteration 270: f_best = 0.00986467\n",
      "x_eff  = [-41.72386257  69.30167547],\n",
      "\n",
      "iteration 271: f_best = 0.00986467\n",
      "x_eff  = [ 25.90867104 -39.03619229],\n",
      "\n",
      "iteration 272: f_best = 0.00986467\n",
      "x_eff  = [ 45.7424213  -81.88048248],\n",
      "\n",
      "iteration 273: f_best = 0.00986467\n",
      "x_eff  = [ 61.62252497 -25.16405363],\n",
      "\n",
      "iteration 274: f_best = 0.00986467\n",
      "x_eff  = [-33.83930509  77.90727332],\n",
      "\n",
      "iteration 275: f_best = 0.00986467\n",
      "x_eff  = [ 20.00300217 -56.39170791],\n",
      "\n",
      "iteration 276: f_best = 0.00986467\n",
      "x_eff  = [ 85.20706202 -32.74765427],\n",
      "\n",
      "iteration 277: f_best = 0.00986467\n",
      "x_eff  = [ 32.18993897 -35.44379698],\n",
      "\n",
      "iteration 278: f_best = 0.00986467\n",
      "x_eff  = [ 78.62671271 -22.5319504 ],\n",
      "\n",
      "iteration 279: f_best = 0.00986467\n",
      "x_eff  = [-7.20194039 36.55008052],\n",
      "\n",
      "iteration 280: f_best = 0.00986467\n",
      "x_eff  = [-50.02070629  13.68057367],\n",
      "\n",
      "iteration 281: f_best = 0.00986467\n",
      "x_eff  = [-44.06428107  32.79198443],\n",
      "\n",
      "iteration 282: f_best = 0.00986467\n",
      "x_eff  = [ 63.46354362 -32.81735492],\n",
      "\n",
      "iteration 283: f_best = 0.00986467\n",
      "x_eff  = [24.92617768 82.18484916],\n",
      "\n",
      "iteration 284: f_best = 0.00986467\n",
      "x_eff  = [80.32535571 73.76766352],\n",
      "\n",
      "iteration 285: f_best = 0.00986467\n",
      "x_eff  = [-36.47543318  46.69446125],\n",
      "\n",
      "iteration 286: f_best = 0.00986467\n",
      "x_eff  = [-73.30507239 -45.98844388],\n",
      "\n",
      "iteration 287: f_best = 0.00986467\n",
      "x_eff  = [-24.80227679 -66.59126906],\n",
      "\n",
      "iteration 288: f_best = 0.00986467\n",
      "x_eff  = [45.80268015 24.59984644],\n",
      "\n",
      "iteration 289: f_best = 0.00986467\n",
      "x_eff  = [-2.3974029  24.60768679],\n",
      "\n",
      "iteration 290: f_best = 0.00986467\n",
      "x_eff  = [ 27.62950806 -55.27321294],\n",
      "\n",
      "iteration 291: f_best = 0.00986467\n",
      "x_eff  = [ 5.13206716 56.12853969],\n",
      "\n",
      "iteration 292: f_best = 0.00986467\n",
      "x_eff  = [ 22.39233353 -39.60504616],\n",
      "\n",
      "iteration 293: f_best = 0.00986467\n",
      "x_eff  = [ 43.23344083 -30.15885992],\n",
      "\n",
      "iteration 294: f_best = 0.00986467\n",
      "x_eff  = [-29.93723248 -49.22722143],\n",
      "\n",
      "iteration 295: f_best = 0.00986467\n",
      "x_eff  = [19.48182764 31.33017026],\n",
      "\n",
      "iteration 296: f_best = 0.00986467\n",
      "x_eff  = [-31.63899105  35.31175285],\n",
      "\n",
      "iteration 297: f_best = 0.00986467\n",
      "x_eff  = [-50.3483854  -56.37836922],\n",
      "\n",
      "iteration 298: f_best = 0.00986467\n",
      "x_eff  = [-51.96376922  33.05508079],\n",
      "\n",
      "iteration 299: f_best = 0.00986467\n",
      "x_eff  = [ 2.46155071 56.14322827],\n",
      "\n",
      "iteration 300: f_best = 0.00986467\n",
      "x_eff  = [38.9962175   3.15821974],\n",
      "\n",
      "iteration 301: f_best = 0.00986467\n",
      "x_eff  = [48.18843156 42.53539315],\n",
      "\n",
      "iteration 302: f_best = 0.00986467\n",
      "x_eff  = [-1.19196863 66.43748918],\n",
      "\n",
      "iteration 303: f_best = 0.00986467\n",
      "x_eff  = [-35.4985464  -23.23366158],\n",
      "\n",
      "iteration 304: f_best = 0.00986467\n",
      "x_eff  = [-32.54175309  -7.49032197],\n",
      "\n",
      "iteration 305: f_best = 0.00986467\n",
      "x_eff  = [-16.84263743  65.90465958],\n",
      "\n",
      "iteration 306: f_best = 0.00986467\n",
      "x_eff  = [48.04332923 59.75003328],\n",
      "\n",
      "iteration 307: f_best = 0.00986467\n",
      "x_eff  = [-26.13486045  50.72327342],\n",
      "\n",
      "iteration 308: f_best = 0.00986467\n",
      "x_eff  = [ 71.73466933 -34.39007276],\n",
      "\n",
      "iteration 309: f_best = 0.00986467\n",
      "x_eff  = [46.78140135 63.67750427],\n",
      "\n",
      "iteration 310: f_best = 0.00986467\n",
      "x_eff  = [-12.73625556  24.67018227],\n",
      "\n",
      "iteration 311: f_best = 0.00986467\n",
      "x_eff  = [19.96152178 24.45120739],\n",
      "\n",
      "iteration 312: f_best = 0.00986467\n",
      "x_eff  = [-3.83245474 18.72368233],\n",
      "\n",
      "iteration 313: f_best = 0.00986467\n",
      "x_eff  = [ 56.13591444 -50.05793774],\n",
      "\n",
      "iteration 314: f_best = 0.00986467\n",
      "x_eff  = [-29.28368431 -53.76626908],\n",
      "\n",
      "iteration 315: f_best = 0.00986467\n",
      "x_eff  = [-7.18391112 -1.42663639],\n",
      "\n",
      "iteration 316: f_best = 0.00986467\n",
      "x_eff  = [ 32.30167146 -21.33785707],\n",
      "\n",
      "iteration 317: f_best = 0.00986467\n",
      "x_eff  = [55.26129787 57.16432324],\n",
      "\n",
      "iteration 318: f_best = 0.00986467\n",
      "x_eff  = [-4.07182893 26.03930334],\n",
      "\n",
      "iteration 319: f_best = 0.00986467\n",
      "x_eff  = [-61.65177503  51.89138871],\n",
      "\n",
      "iteration 320: f_best = 0.00986467\n",
      "x_eff  = [-57.1286758  -23.53051961],\n",
      "\n",
      "iteration 321: f_best = 0.00986467\n",
      "x_eff  = [-21.58003875  54.6215366 ],\n",
      "\n",
      "iteration 322: f_best = 0.00986467\n",
      "x_eff  = [-22.31748459  -2.75095948],\n",
      "\n",
      "iteration 323: f_best = 0.00986467\n",
      "x_eff  = [-53.92269438  -5.92925362],\n",
      "\n",
      "iteration 324: f_best = 0.00986467\n",
      "x_eff  = [-14.81526826  50.27359265],\n",
      "\n",
      "iteration 325: f_best = 0.00986467\n",
      "x_eff  = [ 1.86627567 54.41591683],\n",
      "\n",
      "iteration 326: f_best = 0.00986467\n",
      "x_eff  = [-16.55599666   7.93053752],\n",
      "\n",
      "iteration 327: f_best = 0.00986467\n",
      "x_eff  = [ 1.50856299 42.6726131 ],\n",
      "\n",
      "iteration 328: f_best = 0.00986467\n",
      "x_eff  = [ -8.25606474 -27.79732653],\n",
      "\n",
      "iteration 329: f_best = 0.00986467\n",
      "x_eff  = [ 13.02514395 -18.65014408],\n",
      "\n",
      "iteration 330: f_best = 0.00986467\n",
      "x_eff  = [36.92417946 23.5770479 ],\n",
      "\n",
      "iteration 331: f_best = 0.00986467\n",
      "x_eff  = [ 7.34221131 13.53480794],\n",
      "\n",
      "iteration 332: f_best = 0.00986467\n",
      "x_eff  = [-3.85746358 31.45757947],\n",
      "\n",
      "iteration 333: f_best = 0.00986467\n",
      "x_eff  = [-49.17576935  12.85129513],\n",
      "\n",
      "iteration 334: f_best = 0.00986467\n",
      "x_eff  = [-56.32993615 -33.48988062],\n",
      "\n",
      "iteration 335: f_best = 0.00986467\n",
      "x_eff  = [34.7331493  29.94550519],\n",
      "\n",
      "iteration 336: f_best = 0.00986467\n",
      "x_eff  = [-13.60884714  -4.38392659],\n",
      "\n",
      "iteration 337: f_best = 0.00986467\n",
      "x_eff  = [ 17.06363669 -48.53903181],\n",
      "\n",
      "iteration 338: f_best = 0.00986467\n",
      "x_eff  = [-14.46100068  16.41659099],\n",
      "\n",
      "iteration 339: f_best = 0.00986467\n",
      "x_eff  = [-20.38689698  36.27380352],\n",
      "\n",
      "iteration 340: f_best = 0.00986467\n",
      "x_eff  = [10.66685094 22.13834337],\n",
      "\n",
      "iteration 341: f_best = 0.00986467\n",
      "x_eff  = [36.09507284 24.91799875],\n",
      "\n",
      "iteration 342: f_best = 0.00986467\n",
      "x_eff  = [-31.6124353   -7.12142404],\n",
      "\n",
      "iteration 343: f_best = 0.00986467\n",
      "x_eff  = [-54.26721969 -17.04252109],\n",
      "\n",
      "iteration 344: f_best = 0.00986467\n",
      "x_eff  = [-40.72688982  -8.20455288],\n",
      "\n",
      "iteration 345: f_best = 0.00986467\n",
      "x_eff  = [-19.63464045  -9.91535092],\n",
      "\n",
      "iteration 346: f_best = 0.00986467\n",
      "x_eff  = [38.37294966 42.10192027],\n",
      "\n",
      "iteration 347: f_best = 0.00986467\n",
      "x_eff  = [-24.28990476   4.64198587],\n",
      "\n",
      "iteration 348: f_best = 0.00986467\n",
      "x_eff  = [39.07691573  5.41802868],\n",
      "\n",
      "iteration 349: f_best = 0.00986467\n",
      "x_eff  = [-37.37371746 -23.37998416],\n",
      "\n",
      "iteration 350: f_best = 0.00986467\n",
      "x_eff  = [23.86679022 33.28472535],\n",
      "\n",
      "iteration 351: f_best = 0.00986467\n",
      "x_eff  = [-28.61514678  25.56343676],\n",
      "\n",
      "iteration 352: f_best = 0.00986467\n",
      "x_eff  = [ 24.68133813 -31.5466407 ],\n",
      "\n",
      "iteration 353: f_best = 0.00986467\n",
      "x_eff  = [35.12594573  7.06548755],\n",
      "\n",
      "iteration 354: f_best = 0.00986467\n",
      "x_eff  = [-22.6440504   12.50840802],\n",
      "\n",
      "iteration 355: f_best = 0.00986467\n",
      "x_eff  = [ 12.17369225 -21.63410404],\n",
      "\n",
      "iteration 356: f_best = 0.00986467\n",
      "x_eff  = [23.53485822 27.68127236],\n",
      "\n",
      "iteration 357: f_best = 0.00986467\n",
      "x_eff  = [ 22.94880888 -34.16242381],\n",
      "\n",
      "iteration 358: f_best = 0.00986467\n",
      "x_eff  = [ -6.86892065 -37.30006566],\n",
      "\n",
      "iteration 359: f_best = 0.00986467\n",
      "x_eff  = [ 25.93019673 -34.72730856],\n",
      "\n",
      "iteration 360: f_best = 0.00986467\n",
      "x_eff  = [12.63762616 -7.35170651],\n",
      "\n",
      "iteration 361: f_best = 0.00986467\n",
      "x_eff  = [-25.14924911   6.22147035],\n",
      "\n",
      "iteration 362: f_best = 0.00986467\n",
      "x_eff  = [-18.50022868  34.43248031],\n",
      "\n",
      "iteration 363: f_best = 0.00986467\n",
      "x_eff  = [-6.37905601 10.51659067],\n",
      "\n",
      "iteration 364: f_best = 0.00986467\n",
      "x_eff  = [ -9.7734741 -29.6738696],\n",
      "\n",
      "iteration 365: f_best = 0.00986467\n",
      "x_eff  = [ 15.95626716 -20.75796532],\n",
      "\n",
      "iteration 366: f_best = 0.00986467\n",
      "x_eff  = [-39.40918189  28.57288213],\n",
      "\n",
      "iteration 367: f_best = 0.00986467\n",
      "x_eff  = [-18.9105511  -19.20338984],\n",
      "\n",
      "iteration 368: f_best = 0.00986467\n",
      "x_eff  = [-2.79967364 36.60392211],\n",
      "\n",
      "iteration 369: f_best = 0.00986467\n",
      "x_eff  = [15.86914653 34.07811554],\n",
      "\n",
      "iteration 370: f_best = 0.00986467\n",
      "x_eff  = [11.61257481 14.05003459],\n",
      "\n",
      "iteration 371: f_best = 0.00986467\n",
      "x_eff  = [-12.15187765  -3.83176725],\n",
      "\n",
      "iteration 372: f_best = 0.00986467\n",
      "x_eff  = [-17.84042061   3.95904905],\n",
      "\n",
      "iteration 373: f_best = 0.00986467\n",
      "x_eff  = [11.69197513 -3.95617439],\n",
      "\n",
      "iteration 374: f_best = 0.00986467\n",
      "x_eff  = [20.16447381 -1.56627539],\n",
      "\n",
      "iteration 375: f_best = 0.00739604\n",
      "x_eff  = [-4.43469335  5.69394249],\n",
      "\n",
      "iteration 376: f_best = 0.00739604\n",
      "x_eff  = [-32.14519259 -31.19363964],\n",
      "\n",
      "iteration 377: f_best = 0.00739604\n",
      "x_eff  = [16.16114135  1.10278855],\n",
      "\n",
      "iteration 378: f_best = 0.00739604\n",
      "x_eff  = [-35.79462972  18.54570854],\n",
      "\n",
      "iteration 379: f_best = 0.00739604\n",
      "x_eff  = [-28.62597236 -29.79932937],\n",
      "\n",
      "iteration 380: f_best = 0.00739604\n",
      "x_eff  = [15.12438252  1.7814969 ],\n",
      "\n",
      "iteration 381: f_best = 0.00739604\n",
      "x_eff  = [-30.20468813  15.38323381],\n",
      "\n",
      "iteration 382: f_best = 0.00739604\n",
      "x_eff  = [19.58659456 25.81796495],\n",
      "\n",
      "iteration 383: f_best = 0.00739604\n",
      "x_eff  = [29.55060964  1.36264375],\n",
      "\n",
      "iteration 384: f_best = 0.00739604\n",
      "x_eff  = [ 3.27443147 16.9519131 ],\n",
      "\n",
      "iteration 385: f_best = 0.00739604\n",
      "x_eff  = [-15.63976329  12.69939635],\n",
      "\n",
      "iteration 386: f_best = 0.00739604\n",
      "x_eff  = [-25.18186132  -8.59514947],\n",
      "\n",
      "iteration 387: f_best = 0.00739604\n",
      "x_eff  = [  9.50115414 -25.20872747],\n",
      "\n",
      "iteration 388: f_best = 0.00739604\n",
      "x_eff  = [-19.00303245 -23.14923468],\n",
      "\n",
      "iteration 389: f_best = 0.00739604\n",
      "x_eff  = [ 22.74076242 -18.04845755],\n",
      "\n",
      "iteration 390: f_best = 0.00739604\n",
      "x_eff  = [ 13.08824764 -16.45859414],\n",
      "\n",
      "iteration 391: f_best = 0.00739604\n",
      "x_eff  = [13.78225799 29.47501658],\n",
      "\n",
      "iteration 392: f_best = 0.00739604\n",
      "x_eff  = [-1.86934621  4.06616948],\n",
      "\n",
      "iteration 393: f_best = 0.00739604\n",
      "x_eff  = [14.1018723  23.72846505],\n",
      "\n",
      "iteration 394: f_best = 0.00739604\n",
      "x_eff  = [-10.88858191 -17.82156901],\n",
      "\n",
      "iteration 395: f_best = 0.00739604\n",
      "x_eff  = [  5.20132873 -11.27191728],\n",
      "\n",
      "iteration 396: f_best = 0.00739604\n",
      "x_eff  = [14.3900166   8.17242712],\n",
      "\n",
      "iteration 397: f_best = 0.00739604\n",
      "x_eff  = [ 3.48507461 18.58523293],\n",
      "\n",
      "iteration 398: f_best = 0.00739604\n",
      "x_eff  = [-13.74991277  -5.9407614 ],\n",
      "\n",
      "iteration 399: f_best = 0.00739604\n",
      "x_eff  = [-15.75901321  -6.38272198],\n",
      "\n",
      "iteration 400: f_best = 0.00739604\n",
      "x_eff  = [-11.84993206  24.30832865],\n",
      "\n",
      "iteration 401: f_best = 0.00739604\n",
      "x_eff  = [-28.07458939 -20.63311089],\n",
      "\n",
      "iteration 402: f_best = 0.00739604\n",
      "x_eff  = [-16.48141658 -17.61445328],\n",
      "\n",
      "iteration 403: f_best = 0.00739604\n",
      "x_eff  = [ -2.17685326 -19.07782086],\n",
      "\n",
      "iteration 404: f_best = 0.00739604\n",
      "x_eff  = [-20.35059033  -8.51661305],\n",
      "\n",
      "iteration 405: f_best = 0.00739604\n",
      "x_eff  = [-10.37324329   9.74799192],\n",
      "\n",
      "iteration 406: f_best = 0.00739604\n",
      "x_eff  = [-28.03780498  -1.29240332],\n",
      "\n",
      "iteration 407: f_best = 0.00739604\n",
      "x_eff  = [  1.11924346 -19.84684122],\n",
      "\n",
      "iteration 408: f_best = 0.00739604\n",
      "x_eff  = [-12.38554988  30.43604748],\n",
      "\n",
      "iteration 409: f_best = 0.00739604\n",
      "x_eff  = [-16.32945876  -9.51462515],\n",
      "\n",
      "iteration 410: f_best = 0.00739604\n",
      "x_eff  = [-8.56275046 18.84335861],\n",
      "\n",
      "iteration 411: f_best = 0.00739604\n",
      "x_eff  = [-11.07365856 -18.84980825],\n",
      "\n",
      "iteration 412: f_best = 0.00739604\n",
      "x_eff  = [-17.12894677  -8.46998321],\n",
      "\n",
      "iteration 413: f_best = 0.00739604\n",
      "x_eff  = [ 8.69247215 -5.73673981],\n",
      "\n",
      "iteration 414: f_best = 0.00739604\n",
      "x_eff  = [ 11.16364522 -19.68724127],\n",
      "\n",
      "iteration 415: f_best = 0.00739604\n",
      "x_eff  = [  0.93642524 -20.03399643],\n",
      "\n",
      "iteration 416: f_best = 0.00739604\n",
      "x_eff  = [-18.13428551   6.04289483],\n",
      "\n",
      "iteration 417: f_best = 0.00739604\n",
      "x_eff  = [ 1.11646021 15.79526475],\n",
      "\n",
      "iteration 418: f_best = 0.00739604\n",
      "x_eff  = [ 12.47339465 -16.97033725],\n",
      "\n",
      "iteration 419: f_best = 0.00739604\n",
      "x_eff  = [-19.93062589  -7.85156346],\n",
      "\n",
      "iteration 420: f_best = 0.00739604\n",
      "x_eff  = [ 18.03436521 -19.14106276],\n",
      "\n",
      "iteration 421: f_best = 0.00739604\n",
      "x_eff  = [-23.64682487  12.94032791],\n",
      "\n",
      "iteration 422: f_best = 0.00739604\n",
      "x_eff  = [18.52528892  3.70157423],\n",
      "\n",
      "iteration 423: f_best = 0.00739604\n",
      "x_eff  = [ 4.05983492 -6.70655143],\n",
      "\n",
      "iteration 424: f_best = 0.00739604\n",
      "x_eff  = [-16.39905731 -17.04907331],\n",
      "\n",
      "iteration 425: f_best = 0.00739604\n",
      "x_eff  = [17.06795707 14.24053107],\n",
      "\n",
      "iteration 426: f_best = 0.00739604\n",
      "x_eff  = [ -4.62832723 -15.4415861 ],\n",
      "\n",
      "iteration 427: f_best = 0.00739604\n",
      "x_eff  = [18.72040829  5.94020087],\n",
      "\n",
      "iteration 428: f_best = 0.00739604\n",
      "x_eff  = [13.91977052 10.4107424 ],\n",
      "\n",
      "iteration 429: f_best = 0.00739604\n",
      "x_eff  = [-11.26374492   0.4090143 ],\n",
      "\n",
      "iteration 430: f_best = 0.00739604\n",
      "x_eff  = [1.07822216 3.97968178],\n",
      "\n",
      "iteration 431: f_best = 0.00739604\n",
      "x_eff  = [ -5.42773315 -15.07531947],\n",
      "\n",
      "iteration 432: f_best = 0.00739604\n",
      "x_eff  = [ 7.62108734 -7.4498435 ],\n",
      "\n",
      "iteration 433: f_best = 0.00739604\n",
      "x_eff  = [ 12.350141   -12.58870779],\n",
      "\n",
      "iteration 434: f_best = 0.00739604\n",
      "x_eff  = [ 3.35859611 -7.08287104],\n",
      "\n",
      "iteration 435: f_best = 0.00739604\n",
      "x_eff  = [0.34568703 9.55476322],\n",
      "\n",
      "iteration 436: f_best = 0.00739604\n",
      "x_eff  = [ 9.29600885 14.59195389],\n",
      "\n",
      "iteration 437: f_best = 0.00739604\n",
      "x_eff  = [-15.55646707   1.39498259],\n",
      "\n",
      "iteration 438: f_best = 0.00739604\n",
      "x_eff  = [-9.48655504 20.28929091],\n",
      "\n",
      "iteration 439: f_best = 0.00739604\n",
      "x_eff  = [22.22772914  9.39284574],\n",
      "\n",
      "iteration 440: f_best = 0.00739604\n",
      "x_eff  = [ -0.54238382 -11.39715572],\n",
      "\n",
      "iteration 441: f_best = 0.00739604\n",
      "x_eff  = [8.18752112 8.9584316 ],\n",
      "\n",
      "iteration 442: f_best = 0.00739604\n",
      "x_eff  = [ 9.81228394 12.62325646],\n",
      "\n",
      "iteration 443: f_best = 0.00739604\n",
      "x_eff  = [-12.56779199  -0.08760255],\n",
      "\n",
      "iteration 444: f_best = 0.00739604\n",
      "x_eff  = [-8.99626364 19.77443788],\n",
      "\n",
      "iteration 445: f_best = 0.00739604\n",
      "x_eff  = [4.25918    3.00073584],\n",
      "\n",
      "iteration 446: f_best = 0.00739604\n",
      "x_eff  = [15.15249106 -6.01712089],\n",
      "\n",
      "iteration 447: f_best = 0.00739604\n",
      "x_eff  = [-2.13752517  4.67538172],\n",
      "\n",
      "iteration 448: f_best = 0.00739604\n",
      "x_eff  = [-0.62305194  7.94487373],\n",
      "\n",
      "iteration 449: f_best = 0.00000000\n",
      "x_eff  = [ 0.95608025 -1.85383353],\n",
      "\n",
      "iteration 450: f_best = 0.00000000\n",
      "x_eff  = [-5.69986533  1.59543841],\n",
      "\n",
      "iteration 451: f_best = 0.00000000\n",
      "x_eff  = [-2.6640163  -3.08825215],\n",
      "\n",
      "iteration 452: f_best = 0.00000000\n",
      "x_eff  = [-14.43798313   2.31405531],\n",
      "\n",
      "iteration 453: f_best = 0.00000000\n",
      "x_eff  = [0.74927241 3.85759188],\n",
      "\n",
      "iteration 454: f_best = 0.00000000\n",
      "x_eff  = [-4.29184104  4.8549976 ],\n",
      "\n",
      "iteration 455: f_best = 0.00000000\n",
      "x_eff  = [-6.55342522  9.17397337],\n",
      "\n",
      "iteration 456: f_best = 0.00000000\n",
      "x_eff  = [ 1.94158925 14.73812148],\n",
      "\n",
      "iteration 457: f_best = 0.00000000\n",
      "x_eff  = [ -0.89468676 -14.61728635],\n",
      "\n",
      "iteration 458: f_best = 0.00000000\n",
      "x_eff  = [ -8.31228228 -16.04829923],\n",
      "\n",
      "iteration 459: f_best = 0.00000000\n",
      "x_eff  = [13.51611547  0.18828657],\n",
      "\n",
      "iteration 460: f_best = 0.00000000\n",
      "x_eff  = [ 1.09860413 -2.78458438],\n",
      "\n",
      "iteration 461: f_best = 0.00000000\n",
      "x_eff  = [9.66854165 8.59164799],\n",
      "\n",
      "iteration 462: f_best = 0.00000000\n",
      "x_eff  = [-5.27388521 -7.75485159],\n",
      "\n",
      "iteration 463: f_best = 0.00000000\n",
      "x_eff  = [-2.08422398 -2.15678685],\n",
      "\n",
      "iteration 464: f_best = 0.00000000\n",
      "x_eff  = [  2.6546044  -12.96953097],\n",
      "\n",
      "iteration 465: f_best = 0.00000000\n",
      "x_eff  = [ -3.6564531 -14.7482407],\n",
      "\n",
      "iteration 466: f_best = 0.00000000\n",
      "x_eff  = [-10.03110969  14.55558451],\n",
      "\n",
      "iteration 467: f_best = 0.00000000\n",
      "x_eff  = [-1.4257828  -4.17016303],\n",
      "\n",
      "iteration 468: f_best = 0.00000000\n",
      "x_eff  = [-4.69678959 -8.38982676],\n",
      "\n",
      "iteration 469: f_best = 0.00000000\n",
      "x_eff  = [  3.31900267 -11.55115351],\n",
      "\n",
      "iteration 470: f_best = 0.00000000\n",
      "x_eff  = [ 4.9018053  -2.87114675],\n",
      "\n",
      "iteration 471: f_best = 0.00000000\n",
      "x_eff  = [ 7.9989617  10.54649421],\n",
      "\n",
      "iteration 472: f_best = 0.00000000\n",
      "x_eff  = [11.63943616 13.9395741 ],\n",
      "\n",
      "iteration 473: f_best = 0.00000000\n",
      "x_eff  = [ 8.89634715 -4.8666654 ],\n",
      "\n",
      "iteration 474: f_best = 0.00000000\n",
      "x_eff  = [7.07173261 9.60306222],\n",
      "\n",
      "iteration 475: f_best = 0.00000000\n",
      "x_eff  = [-10.57753265  -6.37296583],\n",
      "\n",
      "iteration 476: f_best = 0.00000000\n",
      "x_eff  = [ -5.14815434 -12.71178181],\n",
      "\n",
      "iteration 477: f_best = 0.00000000\n",
      "x_eff  = [ -4.24175286 -11.14313766],\n",
      "\n",
      "iteration 478: f_best = 0.00000000\n",
      "x_eff  = [ 0.74782877 -5.53347948],\n",
      "\n",
      "iteration 479: f_best = 0.00000000\n",
      "x_eff  = [12.46289877  1.059208  ],\n",
      "\n",
      "iteration 480: f_best = 0.00000000\n",
      "x_eff  = [-0.06436011 12.9753832 ],\n",
      "\n",
      "iteration 481: f_best = 0.00000000\n",
      "x_eff  = [6.35745001 3.03629507],\n",
      "\n",
      "iteration 482: f_best = 0.00000000\n",
      "x_eff  = [ 2.80925566 -0.85912235],\n",
      "\n",
      "iteration 483: f_best = 0.00000000\n",
      "x_eff  = [-9.45805464 -5.24904317],\n",
      "\n",
      "iteration 484: f_best = 0.00000000\n",
      "x_eff  = [7.22444175 9.24134786],\n",
      "\n",
      "iteration 485: f_best = 0.00000000\n",
      "x_eff  = [-0.69130944 -1.6134344 ],\n",
      "\n",
      "iteration 486: f_best = 0.00000000\n",
      "x_eff  = [ 7.2535562  -2.13024685],\n",
      "\n",
      "iteration 487: f_best = 0.00000000\n",
      "x_eff  = [-0.17376253  5.94261384],\n",
      "\n",
      "iteration 488: f_best = 0.00000000\n",
      "x_eff  = [5.29695317 7.83893388],\n",
      "\n",
      "iteration 489: f_best = 0.00000000\n",
      "x_eff  = [  0.25345201 -11.89639928],\n",
      "\n",
      "iteration 490: f_best = 0.00000000\n",
      "x_eff  = [10.95649112 -0.7823189 ],\n",
      "\n",
      "iteration 491: f_best = 0.00000000\n",
      "x_eff  = [ -7.82925541 -10.39120085],\n",
      "\n",
      "iteration 492: f_best = 0.00000000\n",
      "x_eff  = [-6.99089599  1.94194719],\n",
      "\n",
      "iteration 493: f_best = 0.00000000\n",
      "x_eff  = [-4.46987542 -8.33663832],\n",
      "\n",
      "iteration 494: f_best = 0.00000000\n",
      "x_eff  = [-10.43024493   6.01574138],\n",
      "\n",
      "iteration 495: f_best = 0.00000000\n",
      "x_eff  = [ 7.51032274 -9.84137884],\n",
      "\n",
      "iteration 496: f_best = 0.00000000\n",
      "x_eff  = [9.00909869 3.87461195],\n",
      "\n",
      "iteration 497: f_best = 0.00000000\n",
      "x_eff  = [6.56620799 1.26969744],\n",
      "\n",
      "iteration 498: f_best = 0.00000000\n",
      "x_eff  = [ 4.41247161 -6.98453823],\n",
      "\n",
      "iteration 499: f_best = 0.00000000\n",
      "x_eff  = [-6.27243753 -3.93099193],\n",
      "\n",
      "iteration 500: f_best = 0.00000000\n",
      "x_eff  = [ 8.72365272 -5.06360391],\n",
      "\n",
      "iteration 501: f_best = 0.00000000\n",
      "x_eff  = [-5.17763125  0.61828832],\n",
      "\n",
      "iteration 502: f_best = 0.00000000\n",
      "x_eff  = [4.79573298 5.18607251],\n",
      "\n",
      "iteration 503: f_best = 0.00000000\n",
      "x_eff  = [-9.94318781  5.33827091],\n",
      "\n",
      "iteration 504: f_best = 0.00000000\n",
      "x_eff  = [-8.44594622  6.26575257],\n",
      "\n",
      "iteration 505: f_best = 0.00000000\n",
      "x_eff  = [ 6.14643046 10.09704533],\n",
      "\n",
      "iteration 506: f_best = 0.00000000\n",
      "x_eff  = [ 1.63509023 -2.39076122],\n",
      "\n",
      "iteration 507: f_best = 0.00000000\n",
      "x_eff  = [-6.07414071 -0.20311493],\n",
      "\n",
      "iteration 508: f_best = 0.00000000\n",
      "x_eff  = [ 7.42202335 -3.32057148],\n",
      "\n",
      "iteration 509: f_best = 0.00000000\n",
      "x_eff  = [-2.8741158  -6.55687124],\n",
      "\n",
      "iteration 510: f_best = 0.00000000\n",
      "x_eff  = [6.32062465 7.59087143],\n",
      "\n",
      "iteration 511: f_best = 0.00000000\n",
      "x_eff  = [0.99096704 7.64154294],\n",
      "\n",
      "iteration 512: f_best = 0.00000000\n",
      "x_eff  = [ 4.97863575 -3.20953313],\n",
      "\n",
      "iteration 513: f_best = 0.00000000\n",
      "x_eff  = [-9.16952583 -6.77086463],\n",
      "\n",
      "iteration 514: f_best = 0.00000000\n",
      "x_eff  = [ 5.58484567 -0.29517056],\n",
      "\n",
      "iteration 515: f_best = 0.00000000\n",
      "x_eff  = [0.26275488 1.28763511],\n",
      "\n",
      "iteration 516: f_best = 0.00000000\n",
      "x_eff  = [-3.94862058 -4.43823424],\n",
      "\n",
      "iteration 517: f_best = 0.00000000\n",
      "x_eff  = [-1.11008554  3.19452328],\n",
      "\n",
      "iteration 518: f_best = 0.00000000\n",
      "x_eff  = [-6.84998133  1.35124308],\n",
      "\n",
      "iteration 519: f_best = 0.00000000\n",
      "x_eff  = [-5.97283971 -7.42739815],\n",
      "\n",
      "iteration 520: f_best = 0.00000000\n",
      "x_eff  = [ 0.4709703  -6.29892222],\n",
      "\n",
      "iteration 521: f_best = 0.00000000\n",
      "x_eff  = [5.6602615  6.22846324],\n",
      "\n",
      "iteration 522: f_best = 0.00000000\n",
      "x_eff  = [-0.84174276  0.22186936],\n",
      "\n",
      "iteration 523: f_best = 0.00000000\n",
      "x_eff  = [5.32697487e+00 4.13032700e-03],\n",
      "\n",
      "iteration 524: f_best = 0.00000000\n",
      "x_eff  = [4.75246225 6.79057139],\n",
      "\n",
      "iteration 525: f_best = 0.00000000\n",
      "x_eff  = [-7.25503191  1.9533502 ],\n",
      "\n",
      "iteration 526: f_best = 0.00000000\n",
      "x_eff  = [-1.51481039 -2.46786053],\n",
      "\n",
      "iteration 527: f_best = 0.00000000\n",
      "x_eff  = [ 6.75431343 -6.26277064],\n",
      "\n",
      "iteration 528: f_best = 0.00000000\n",
      "x_eff  = [-2.17881904 -3.45742021],\n",
      "\n",
      "iteration 529: f_best = 0.00000000\n",
      "x_eff  = [-7.79294022  0.77762228],\n",
      "\n",
      "iteration 530: f_best = 0.00000000\n",
      "x_eff  = [1.33789446 4.13202687],\n",
      "\n",
      "iteration 531: f_best = 0.00000000\n",
      "x_eff  = [-5.71683112 -0.45163823],\n",
      "\n",
      "iteration 532: f_best = 0.00000000\n",
      "x_eff  = [-3.44885358 -7.1333842 ],\n",
      "\n",
      "iteration 533: f_best = 0.00000000\n",
      "x_eff  = [2.20494195 3.48553195],\n",
      "\n",
      "iteration 534: f_best = 0.00000000\n",
      "x_eff  = [-2.61833275 -4.86312106],\n",
      "\n",
      "iteration 535: f_best = 0.00000000\n",
      "x_eff  = [3.91944482 3.00694041],\n",
      "\n",
      "iteration 536: f_best = 0.00000000\n",
      "x_eff  = [7.15128258 6.59986222],\n",
      "\n",
      "iteration 537: f_best = 0.00000000\n",
      "x_eff  = [-1.92928149  4.44935381],\n",
      "\n",
      "iteration 538: f_best = 0.00000000\n",
      "x_eff  = [2.37154156 3.14026668],\n",
      "\n",
      "iteration 539: f_best = 0.00000000\n",
      "x_eff  = [-6.22720837  6.57627293],\n",
      "\n",
      "iteration 540: f_best = 0.00000000\n",
      "x_eff  = [3.22358566 0.389674  ],\n",
      "\n",
      "iteration 541: f_best = 0.00000000\n",
      "x_eff  = [ 3.39599389 -5.58351363],\n",
      "\n",
      "iteration 542: f_best = 0.00000000\n",
      "x_eff  = [ 3.65355434 -3.26376461],\n",
      "\n",
      "iteration 543: f_best = 0.00000000\n",
      "x_eff  = [ 1.40496659 -1.40836193],\n",
      "\n",
      "iteration 544: f_best = 0.00000000\n",
      "x_eff  = [2.2103681 1.9540364],\n",
      "\n",
      "iteration 545: f_best = 0.00000000\n",
      "x_eff  = [-5.00053695  1.83782677],\n",
      "\n",
      "iteration 546: f_best = 0.00000000\n",
      "x_eff  = [-5.32347507 -5.57661049],\n",
      "\n",
      "iteration 547: f_best = 0.00000000\n",
      "x_eff  = [-1.27977325  0.53445351],\n",
      "\n",
      "iteration 548: f_best = 0.00000000\n",
      "x_eff  = [ 1.15164966 -0.72347014],\n",
      "\n",
      "iteration 549: f_best = 0.00000000\n",
      "x_eff  = [ 4.94283867 -2.82968423],\n",
      "\n",
      "iteration 550: f_best = 0.00000000\n",
      "x_eff  = [2.98888834 2.36883981],\n",
      "\n",
      "iteration 551: f_best = 0.00000000\n",
      "x_eff  = [ 1.03126848 -3.27726912],\n",
      "\n",
      "iteration 552: f_best = 0.00000000\n",
      "x_eff  = [ 2.1212578  -3.27391104],\n",
      "\n",
      "iteration 553: f_best = 0.00000000\n",
      "x_eff  = [-2.4765081   5.47146107],\n",
      "\n",
      "iteration 554: f_best = 0.00000000\n",
      "x_eff  = [ 2.95907685 -1.4833609 ],\n",
      "\n",
      "iteration 555: f_best = 0.00000000\n",
      "x_eff  = [-5.15619282 -3.30386744],\n",
      "\n",
      "iteration 556: f_best = 0.00000000\n",
      "x_eff  = [-0.88371132  2.13529397],\n",
      "\n",
      "iteration 557: f_best = 0.00000000\n",
      "x_eff  = [0.06088222 4.73731939],\n",
      "\n",
      "iteration 558: f_best = 0.00000000\n",
      "x_eff  = [-0.33426423  2.71397042],\n",
      "\n",
      "iteration 559: f_best = 0.00000000\n",
      "x_eff  = [-3.03839925  5.09488214],\n",
      "\n",
      "iteration 560: f_best = 0.00000000\n",
      "x_eff  = [-2.90292573 -1.42358708],\n",
      "\n",
      "iteration 561: f_best = 0.00000000\n",
      "x_eff  = [0.04192451 2.16976643],\n",
      "\n",
      "iteration 562: f_best = 0.00000000\n",
      "x_eff  = [3.0780802  4.88552074],\n",
      "\n",
      "iteration 563: f_best = 0.00000000\n",
      "x_eff  = [ 4.69914717 -3.62436736],\n",
      "\n",
      "iteration 564: f_best = 0.00000000\n",
      "x_eff  = [ 5.35755951 -2.15331396],\n",
      "\n",
      "iteration 565: f_best = 0.00000000\n",
      "x_eff  = [ 4.67362425 -1.12848052],\n",
      "\n",
      "iteration 566: f_best = 0.00000000\n",
      "x_eff  = [-3.04025489 -3.08574354],\n",
      "\n",
      "iteration 567: f_best = 0.00000000\n",
      "x_eff  = [-5.53773092  3.47860695],\n",
      "\n",
      "iteration 568: f_best = 0.00000000\n",
      "x_eff  = [-0.60079991 -0.65325713],\n",
      "\n",
      "iteration 569: f_best = 0.00000000\n",
      "x_eff  = [-1.02292126  2.53959668],\n",
      "\n",
      "iteration 570: f_best = 0.00000000\n",
      "x_eff  = [-1.3275912   0.55401139],\n",
      "\n",
      "iteration 571: f_best = 0.00000000\n",
      "x_eff  = [ 3.66820247 -0.58926954],\n",
      "\n",
      "iteration 572: f_best = 0.00000000\n",
      "x_eff  = [-4.40586634  5.20692861],\n",
      "\n",
      "iteration 573: f_best = 0.00000000\n",
      "x_eff  = [ 1.47918943 -4.44403087],\n",
      "\n",
      "iteration 574: f_best = 0.00000000\n",
      "x_eff  = [ 0.59802265 -0.39546918],\n",
      "\n",
      "iteration 575: f_best = 0.00000000\n",
      "x_eff  = [-1.85878291  4.22876975],\n",
      "\n",
      "iteration 576: f_best = 0.00000000\n",
      "x_eff  = [ 3.18510896 -1.08063576],\n",
      "\n",
      "iteration 577: f_best = 0.00000000\n",
      "x_eff  = [4.38277851 0.4273163 ],\n",
      "\n",
      "iteration 578: f_best = 0.00000000\n",
      "x_eff  = [-0.22149504 -0.2050186 ],\n",
      "\n",
      "iteration 579: f_best = 0.00000000\n",
      "x_eff  = [ 1.91779017 -2.27467231],\n",
      "\n",
      "iteration 580: f_best = 0.00000000\n",
      "x_eff  = [2.13133223 2.12328453],\n",
      "\n",
      "iteration 581: f_best = 0.00000000\n",
      "x_eff  = [4.1298086  4.64766794],\n",
      "\n",
      "iteration 582: f_best = 0.00000000\n",
      "x_eff  = [-0.79086066  3.93136979],\n",
      "\n",
      "iteration 583: f_best = 0.00000000\n",
      "x_eff  = [ 1.95068503 -3.98817052],\n",
      "\n",
      "iteration 584: f_best = 0.00000000\n",
      "x_eff  = [-4.12289937  3.69705615],\n",
      "\n",
      "iteration 585: f_best = 0.00000000\n",
      "x_eff  = [-0.98811282  2.98303701],\n",
      "\n",
      "iteration 586: f_best = 0.00000000\n",
      "x_eff  = [-1.15472168  1.63829146],\n",
      "\n",
      "iteration 587: f_best = 0.00000000\n",
      "x_eff  = [2.26939284 4.56513337],\n",
      "\n",
      "iteration 588: f_best = 0.00000000\n",
      "x_eff  = [ 3.85415494 -1.37498719],\n",
      "\n",
      "iteration 589: f_best = 0.00000000\n",
      "x_eff  = [ 4.47132156 -2.19310356],\n",
      "\n",
      "iteration 590: f_best = 0.00000000\n",
      "x_eff  = [-1.25244252  3.43623927],\n",
      "\n",
      "iteration 591: f_best = 0.00000000\n",
      "x_eff  = [-1.01615793  3.68358954],\n",
      "\n",
      "iteration 592: f_best = 0.00000000\n",
      "x_eff  = [-2.54262426 -0.88420973],\n",
      "\n",
      "iteration 593: f_best = 0.00000000\n",
      "x_eff  = [-1.48155953 -1.14963984],\n",
      "\n",
      "iteration 594: f_best = 0.00000000\n",
      "x_eff  = [-2.78773484  2.60470857],\n",
      "\n",
      "iteration 595: f_best = 0.00000000\n",
      "x_eff  = [0.77512772 0.8431766 ],\n",
      "\n",
      "iteration 596: f_best = 0.00000000\n",
      "x_eff  = [-1.89674359 -4.08916616],\n",
      "\n",
      "iteration 597: f_best = 0.00000000\n",
      "x_eff  = [0.08786677 3.63654379],\n",
      "\n",
      "iteration 598: f_best = 0.00000000\n",
      "x_eff  = [-1.55574372  0.46932213],\n",
      "\n",
      "iteration 599: f_best = 0.00000000\n",
      "x_eff  = [0.14744674 3.91706351],\n",
      "\n",
      "iteration 600: f_best = 0.00000000\n",
      "x_eff  = [-1.35341588 -0.91592196],\n",
      "\n",
      "iteration 601: f_best = 0.00000000\n",
      "x_eff  = [ 2.60582211 -0.23788396],\n",
      "\n",
      "iteration 602: f_best = 0.00000000\n",
      "x_eff  = [1.07499368 0.50427631],\n",
      "\n",
      "iteration 603: f_best = 0.00000000\n",
      "x_eff  = [-3.53141451 -1.61860023],\n",
      "\n",
      "iteration 604: f_best = 0.00000000\n",
      "x_eff  = [-1.38942636  0.91999679],\n",
      "\n",
      "iteration 605: f_best = 0.00000000\n",
      "x_eff  = [-1.71651472  2.07322939],\n",
      "\n",
      "iteration 606: f_best = 0.00000000\n",
      "x_eff  = [2.8405308 1.4428462],\n",
      "\n",
      "iteration 607: f_best = 0.00000000\n",
      "x_eff  = [ 0.46462076 -3.35715512],\n",
      "\n",
      "iteration 608: f_best = 0.00000000\n",
      "x_eff  = [2.94677152 1.56452189],\n",
      "\n",
      "iteration 609: f_best = 0.00000000\n",
      "x_eff  = [ 3.33442575 -2.97840764],\n",
      "\n",
      "iteration 610: f_best = 0.00000000\n",
      "x_eff  = [-1.30875856 -3.28384718],\n",
      "\n",
      "iteration 611: f_best = 0.00000000\n",
      "x_eff  = [-2.12076429 -0.47194118],\n",
      "\n",
      "iteration 612: f_best = 0.00000000\n",
      "x_eff  = [ 2.49716536 -0.10086825],\n",
      "\n",
      "iteration 613: f_best = 0.00000000\n",
      "x_eff  = [-2.07870955 -0.33420437],\n",
      "\n",
      "iteration 614: f_best = 0.00000000\n",
      "x_eff  = [0.8595565  2.53160665],\n",
      "\n",
      "iteration 615: f_best = 0.00000000\n",
      "x_eff  = [2.00928406 0.86521019],\n",
      "\n",
      "iteration 616: f_best = 0.00000000\n",
      "x_eff  = [-0.62495941  1.46940319],\n",
      "\n",
      "iteration 617: f_best = 0.00000000\n",
      "x_eff  = [ 2.59466902 -1.82948843],\n",
      "\n",
      "iteration 618: f_best = 0.00000000\n",
      "x_eff  = [ 0.41596304 -0.97209774],\n",
      "\n",
      "iteration 619: f_best = 0.00000000\n",
      "x_eff  = [-1.14477305  1.85467102],\n",
      "\n",
      "iteration 620: f_best = 0.00000000\n",
      "x_eff  = [ 0.21229652 -2.10556544],\n",
      "\n",
      "iteration 621: f_best = 0.00000000\n",
      "x_eff  = [-1.72256965 -2.15234026],\n",
      "\n",
      "iteration 622: f_best = 0.00000000\n",
      "x_eff  = [-1.14161454  2.65092783],\n",
      "\n",
      "iteration 623: f_best = 0.00000000\n",
      "x_eff  = [-0.20173509  1.55913239],\n",
      "\n",
      "iteration 624: f_best = 0.00000000\n",
      "x_eff  = [-1.51667794  0.14456522],\n",
      "\n",
      "iteration 625: f_best = 0.00000000\n",
      "x_eff  = [-0.32445554 -2.91586587],\n",
      "\n",
      "iteration 626: f_best = 0.00000000\n",
      "x_eff  = [0.26848697 2.6863631 ],\n",
      "\n",
      "iteration 627: f_best = 0.00000000\n",
      "x_eff  = [0.19693319 0.40770691],\n",
      "\n",
      "iteration 628: f_best = 0.00000000\n",
      "x_eff  = [-2.45951899  1.0476462 ],\n",
      "\n",
      "iteration 629: f_best = 0.00000000\n",
      "x_eff  = [2.03475768 0.03818915],\n",
      "\n",
      "iteration 630: f_best = 0.00000000\n",
      "x_eff  = [-1.25085005 -1.41623303],\n",
      "\n",
      "iteration 631: f_best = 0.00000000\n",
      "x_eff  = [-0.54287217  2.89354969],\n",
      "\n",
      "iteration 632: f_best = 0.00000000\n",
      "x_eff  = [-0.67019205  0.09544426],\n",
      "\n",
      "iteration 633: f_best = 0.00000000\n",
      "x_eff  = [-2.85030177 -0.59851494],\n",
      "\n",
      "iteration 634: f_best = 0.00000000\n",
      "x_eff  = [-0.24727939 -1.47414337],\n",
      "\n",
      "iteration 635: f_best = 0.00000000\n",
      "x_eff  = [1.53306782 2.27455247],\n",
      "\n",
      "iteration 636: f_best = 0.00000000\n",
      "x_eff  = [ 0.62522275 -2.36579377],\n",
      "\n",
      "iteration 637: f_best = 0.00000000\n",
      "x_eff  = [ 2.5488071  -2.28396284],\n",
      "\n",
      "iteration 638: f_best = 0.00000000\n",
      "x_eff  = [-1.36078965  2.15220307],\n",
      "\n",
      "iteration 639: f_best = 0.00000000\n",
      "x_eff  = [-0.99758178  1.27436009],\n",
      "\n",
      "iteration 640: f_best = 0.00000000\n",
      "x_eff  = [2.30777369 2.56340962],\n",
      "\n",
      "iteration 641: f_best = 0.00000000\n",
      "x_eff  = [-1.3676312   0.43474868],\n",
      "\n",
      "iteration 642: f_best = 0.00000000\n",
      "x_eff  = [-0.58456728  1.33023166],\n",
      "\n",
      "iteration 643: f_best = 0.00000000\n",
      "x_eff  = [-0.71983093 -1.83149349],\n",
      "\n",
      "iteration 644: f_best = 0.00000000\n",
      "x_eff  = [-0.23644606 -0.09287607],\n",
      "\n",
      "iteration 645: f_best = 0.00000000\n",
      "x_eff  = [-1.90190273  0.20883289],\n",
      "\n",
      "iteration 646: f_best = 0.00000000\n",
      "x_eff  = [-2.11343476  1.93110994],\n",
      "\n",
      "iteration 647: f_best = 0.00000000\n",
      "x_eff  = [1.66384204 0.07985552],\n",
      "\n",
      "iteration 648: f_best = 0.00000000\n",
      "x_eff  = [-0.25022041  0.31968776],\n",
      "\n",
      "iteration 649: f_best = 0.00000000\n",
      "x_eff  = [ 2.27817679 -0.1867419 ],\n",
      "\n",
      "iteration 650: f_best = 0.00000000\n",
      "x_eff  = [ 0.11138443 -1.69370215],\n",
      "\n",
      "iteration 651: f_best = 0.00000000\n",
      "x_eff  = [-1.13283929 -0.98558789],\n",
      "\n",
      "iteration 652: f_best = 0.00000000\n",
      "x_eff  = [-1.20294287 -1.23324258],\n",
      "\n",
      "iteration 653: f_best = 0.00000000\n",
      "x_eff  = [-0.61814916  1.33327431],\n",
      "\n",
      "iteration 654: f_best = 0.00000000\n",
      "x_eff  = [-0.48997461 -0.05054281],\n",
      "\n",
      "iteration 655: f_best = 0.00000000\n",
      "x_eff  = [-1.52497265  1.78471392],\n",
      "\n",
      "iteration 656: f_best = 0.00000000\n",
      "x_eff  = [-0.57775149  1.58955059],\n",
      "\n",
      "iteration 657: f_best = 0.00000000\n",
      "x_eff  = [-0.52607293  0.85816618],\n",
      "\n",
      "iteration 658: f_best = 0.00000000\n",
      "x_eff  = [-1.01401104  0.64046722],\n",
      "\n",
      "iteration 659: f_best = 0.00000000\n",
      "x_eff  = [-1.63374906 -1.02656057],\n",
      "\n",
      "iteration 660: f_best = 0.00000000\n",
      "x_eff  = [-0.08523341  1.75012304],\n",
      "\n",
      "iteration 661: f_best = 0.00000000\n",
      "x_eff  = [-0.23539195 -1.99926553],\n",
      "\n",
      "iteration 662: f_best = 0.00000000\n",
      "x_eff  = [1.43245055 1.09254997],\n",
      "\n",
      "iteration 663: f_best = 0.00000000\n",
      "x_eff  = [-2.02128933  0.51793435],\n",
      "\n",
      "iteration 664: f_best = 0.00000000\n",
      "x_eff  = [-1.48162648  0.21683995],\n",
      "\n",
      "iteration 665: f_best = 0.00000000\n",
      "x_eff  = [1.75526969 1.29250211],\n",
      "\n",
      "iteration 666: f_best = 0.00000000\n",
      "x_eff  = [-1.57407252  1.17738602],\n",
      "\n",
      "iteration 667: f_best = 0.00000000\n",
      "x_eff  = [1.84417881 1.19806351],\n",
      "\n",
      "iteration 668: f_best = 0.00000000\n",
      "x_eff  = [ 0.53486518 -0.31508697],\n",
      "\n",
      "iteration 669: f_best = 0.00000000\n",
      "x_eff  = [0.77768696 1.37796621],\n",
      "\n",
      "iteration 670: f_best = 0.00000000\n",
      "x_eff  = [-1.21112186  1.4955745 ],\n",
      "\n",
      "iteration 671: f_best = 0.00000000\n",
      "x_eff  = [ 1.70718882 -1.40481203],\n",
      "\n",
      "iteration 672: f_best = 0.00000000\n",
      "x_eff  = [-0.15485469  1.80381619],\n",
      "\n",
      "iteration 673: f_best = 0.00000000\n",
      "x_eff  = [-0.86328866 -0.39997513],\n",
      "\n",
      "iteration 674: f_best = 0.00000000\n",
      "x_eff  = [0.31767658 1.62277418],\n",
      "\n",
      "iteration 675: f_best = 0.00000000\n",
      "x_eff  = [1.67634007 0.88195043],\n",
      "\n",
      "iteration 676: f_best = 0.00000000\n",
      "x_eff  = [-0.47792978 -1.31361999],\n",
      "\n",
      "iteration 677: f_best = 0.00000000\n",
      "x_eff  = [0.8136692  1.79937456],\n",
      "\n",
      "iteration 678: f_best = 0.00000000\n",
      "x_eff  = [-0.35145425 -1.12834324],\n",
      "\n",
      "iteration 679: f_best = 0.00000000\n",
      "x_eff  = [-1.66113746 -0.61430778],\n",
      "\n",
      "iteration 680: f_best = 0.00000000\n",
      "x_eff  = [-0.37448253  1.38189026],\n",
      "\n",
      "iteration 681: f_best = 0.00000000\n",
      "x_eff  = [-1.18400806 -0.78834217],\n",
      "\n",
      "iteration 682: f_best = 0.00000000\n",
      "x_eff  = [ 1.6597825  -1.58020534],\n",
      "\n",
      "iteration 683: f_best = 0.00000000\n",
      "x_eff  = [ 0.86657536 -0.47166266],\n",
      "\n",
      "iteration 684: f_best = 0.00000000\n",
      "x_eff  = [ 1.33094105 -1.2394507 ],\n",
      "\n",
      "iteration 685: f_best = 0.00000000\n",
      "x_eff  = [ 0.90502699 -1.57690841],\n",
      "\n",
      "iteration 686: f_best = 0.00000000\n",
      "x_eff  = [-0.70746456 -0.78141834],\n",
      "\n",
      "iteration 687: f_best = 0.00000000\n",
      "x_eff  = [ 0.56190557 -0.96635748],\n",
      "\n",
      "iteration 688: f_best = 0.00000000\n",
      "x_eff  = [-0.12221709  0.45803383],\n",
      "\n",
      "iteration 689: f_best = 0.00000000\n",
      "x_eff  = [-1.25500478  0.01810946],\n",
      "\n",
      "iteration 690: f_best = 0.00000000\n",
      "x_eff  = [0.43722966 0.56039949],\n",
      "\n",
      "iteration 691: f_best = 0.00000000\n",
      "x_eff  = [ 0.17077245 -0.83526759],\n",
      "\n",
      "iteration 692: f_best = 0.00000000\n",
      "x_eff  = [0.97143627 1.40756717],\n",
      "\n",
      "iteration 693: f_best = 0.00000000\n",
      "x_eff  = [-0.44898096 -0.22512873],\n",
      "\n",
      "iteration 694: f_best = 0.00000000\n",
      "x_eff  = [-0.172393  -1.2725963],\n",
      "\n",
      "iteration 695: f_best = 0.00000000\n",
      "x_eff  = [ 1.41954032 -0.19594489],\n",
      "\n",
      "iteration 696: f_best = 0.00000000\n",
      "x_eff  = [-0.90906265 -0.14906921],\n",
      "\n",
      "iteration 697: f_best = 0.00000000\n",
      "x_eff  = [-0.41234089 -0.18954227],\n",
      "\n",
      "iteration 698: f_best = 0.00000000\n",
      "x_eff  = [-0.60467982 -0.462766  ],\n",
      "\n",
      "iteration 699: f_best = 0.00000000\n",
      "x_eff  = [-0.86155511  1.06735762],\n",
      "\n",
      "iteration 700: f_best = 0.00000000\n",
      "x_eff  = [1.43424207 0.25484497],\n",
      "\n",
      "iteration 701: f_best = 0.00000000\n",
      "x_eff  = [ 0.26154027 -1.28139738],\n",
      "\n",
      "iteration 702: f_best = 0.00000000\n",
      "x_eff  = [ 1.37342508 -1.18368186],\n",
      "\n",
      "iteration 703: f_best = 0.00000000\n",
      "x_eff  = [ 0.14134491 -0.035159  ],\n",
      "\n",
      "iteration 704: f_best = 0.00000000\n",
      "x_eff  = [0.55519872 1.33153022],\n",
      "\n",
      "iteration 705: f_best = 0.00000000\n",
      "x_eff  = [0.8036282  0.75400274],\n",
      "\n",
      "iteration 706: f_best = 0.00000000\n",
      "x_eff  = [0.1700846  0.83068385],\n",
      "\n",
      "iteration 707: f_best = 0.00000000\n",
      "x_eff  = [0.76733844 0.26639045],\n",
      "\n",
      "iteration 708: f_best = 0.00000000\n",
      "x_eff  = [0.1092155 0.1968324],\n",
      "\n",
      "iteration 709: f_best = 0.00000000\n",
      "x_eff  = [ 0.28771554 -1.29765187],\n",
      "\n",
      "iteration 710: f_best = 0.00000000\n",
      "x_eff  = [0.65098651 1.32085965],\n",
      "\n",
      "iteration 711: f_best = 0.00000000\n",
      "x_eff  = [0.71076597 0.01660024],\n",
      "\n",
      "iteration 712: f_best = 0.00000000\n",
      "x_eff  = [-1.22948793 -0.05661886],\n",
      "\n",
      "iteration 713: f_best = 0.00000000\n",
      "x_eff  = [-0.45895101 -1.2409836 ],\n",
      "\n",
      "iteration 714: f_best = 0.00000000\n",
      "x_eff  = [-0.42414815 -0.12673374],\n",
      "\n",
      "iteration 715: f_best = 0.00000000\n",
      "x_eff  = [ 0.79175625 -0.75547807],\n",
      "\n",
      "iteration 716: f_best = 0.00000000\n",
      "x_eff  = [ 1.19675101 -0.86691669],\n",
      "\n",
      "iteration 717: f_best = 0.00000000\n",
      "x_eff  = [-1.21617219 -0.87783598],\n",
      "\n",
      "iteration 718: f_best = 0.00000000\n",
      "x_eff  = [ 1.20042942 -0.53867706],\n",
      "\n",
      "iteration 719: f_best = 0.00000000\n",
      "x_eff  = [-0.80526363 -0.39445831],\n",
      "\n",
      "iteration 720: f_best = 0.00000000\n",
      "x_eff  = [0.35249841 0.83093537],\n",
      "\n",
      "iteration 721: f_best = 0.00000000\n",
      "x_eff  = [ 0.87760269 -0.77244475],\n",
      "\n",
      "iteration 722: f_best = 0.00000000\n",
      "x_eff  = [-0.03838057  0.76625243],\n",
      "\n",
      "iteration 723: f_best = 0.00000000\n",
      "x_eff  = [-0.79662225  0.85014397],\n",
      "\n",
      "iteration 724: f_best = 0.00000000\n",
      "x_eff  = [-0.10319527 -0.58369772],\n",
      "\n",
      "iteration 725: f_best = 0.00000000\n",
      "x_eff  = [-0.32790196  0.65709881],\n",
      "\n",
      "iteration 726: f_best = 0.00000000\n",
      "x_eff  = [-0.07184046  0.93710466],\n",
      "\n",
      "iteration 727: f_best = 0.00000000\n",
      "x_eff  = [-0.7517597   0.82333782],\n",
      "\n",
      "iteration 728: f_best = 0.00000000\n",
      "x_eff  = [0.77029931 0.65405727],\n",
      "\n",
      "iteration 729: f_best = 0.00000000\n",
      "x_eff  = [ 0.80614864 -0.21594251],\n",
      "\n",
      "iteration 730: f_best = 0.00000000\n",
      "x_eff  = [-0.07609843  0.48099348],\n",
      "\n",
      "iteration 731: f_best = 0.00000000\n",
      "x_eff  = [-1.0340021   0.17921816],\n",
      "\n",
      "iteration 732: f_best = 0.00000000\n",
      "x_eff  = [-0.80107012 -0.49161585],\n",
      "\n",
      "iteration 733: f_best = 0.00000000\n",
      "x_eff  = [ 1.06627645 -0.98714377],\n",
      "\n",
      "iteration 734: f_best = 0.00000000\n",
      "x_eff  = [ 0.49426275 -0.63591009],\n",
      "\n",
      "iteration 735: f_best = 0.00000000\n",
      "x_eff  = [0.87018991 0.20058728],\n",
      "\n",
      "iteration 736: f_best = 0.00000000\n",
      "x_eff  = [0.24069168 0.38128467],\n",
      "\n",
      "iteration 737: f_best = 0.00000000\n",
      "x_eff  = [-0.36799232  0.53383703],\n",
      "\n",
      "iteration 738: f_best = 0.00000000\n",
      "x_eff  = [ 0.87307137 -0.61022816],\n",
      "\n",
      "iteration 739: f_best = 0.00000000\n",
      "x_eff  = [-1.00444544 -0.56158006],\n",
      "\n",
      "iteration 740: f_best = 0.00000000\n",
      "x_eff  = [ 0.85058983 -0.721568  ],\n",
      "\n",
      "iteration 741: f_best = 0.00000000\n",
      "x_eff  = [-0.20622541 -0.83247244],\n",
      "\n",
      "iteration 742: f_best = 0.00000000\n",
      "x_eff  = [-0.94445657  0.36278505],\n",
      "\n",
      "iteration 743: f_best = 0.00000000\n",
      "x_eff  = [0.11152009 0.17877855],\n",
      "\n",
      "iteration 744: f_best = 0.00000000\n",
      "x_eff  = [ 0.48262247 -0.35675634],\n",
      "\n",
      "iteration 745: f_best = 0.00000000\n",
      "x_eff  = [-0.44790016 -0.41677559],\n",
      "\n",
      "iteration 746: f_best = 0.00000000\n",
      "x_eff  = [-0.73008692  0.4798689 ],\n",
      "\n",
      "iteration 747: f_best = 0.00000000\n",
      "x_eff  = [0.28546435 0.65688432],\n",
      "\n",
      "iteration 748: f_best = 0.00000000\n",
      "x_eff  = [0.32117728 0.02117541],\n",
      "\n",
      "iteration 749: f_best = 0.00000000\n",
      "x_eff  = [ 0.53507682 -0.49237939],\n",
      "\n",
      "iteration 750: f_best = 0.00000000\n",
      "x_eff  = [ 0.6966172  -0.40783415],\n",
      "\n",
      "iteration 751: f_best = 0.00000000\n",
      "x_eff  = [ 0.51956858 -0.58019686],\n",
      "\n",
      "iteration 752: f_best = 0.00000000\n",
      "x_eff  = [-0.4655896   0.00408853],\n",
      "\n",
      "iteration 753: f_best = 0.00000000\n",
      "x_eff  = [-0.86296484 -0.06435006],\n",
      "\n",
      "iteration 754: f_best = 0.00000000\n",
      "x_eff  = [ 0.44148778 -0.82734507],\n",
      "\n",
      "iteration 755: f_best = 0.00000000\n",
      "x_eff  = [0.09362431 0.22550263],\n",
      "\n",
      "iteration 756: f_best = 0.00000000\n",
      "x_eff  = [0.0022404  0.07234928],\n",
      "\n",
      "iteration 757: f_best = 0.00000000\n",
      "x_eff  = [ 0.5318411  -0.15841207],\n",
      "\n",
      "iteration 758: f_best = 0.00000000\n",
      "x_eff  = [-0.78525475  0.68346558],\n",
      "\n",
      "iteration 759: f_best = 0.00000000\n",
      "x_eff  = [-0.03132531 -0.52567201],\n",
      "\n",
      "iteration 760: f_best = 0.00000000\n",
      "x_eff  = [0.28140532 0.18153965],\n",
      "\n",
      "iteration 761: f_best = 0.00000000\n",
      "x_eff  = [0.73717924 0.77993523],\n",
      "\n",
      "iteration 762: f_best = 0.00000000\n",
      "x_eff  = [0.21417831 0.52053172],\n",
      "\n",
      "iteration 763: f_best = 0.00000000\n",
      "x_eff  = [-0.4360908  -0.65358497],\n",
      "\n",
      "iteration 764: f_best = 0.00000000\n",
      "x_eff  = [-0.41751125  0.23431221],\n",
      "\n",
      "iteration 765: f_best = 0.00000000\n",
      "x_eff  = [ 0.51577637 -0.5584229 ],\n",
      "\n",
      "iteration 766: f_best = 0.00000000\n",
      "x_eff  = [ 0.15290858 -0.74815048],\n",
      "\n",
      "iteration 767: f_best = 0.00000000\n",
      "x_eff  = [-0.39089429 -0.43763954],\n",
      "\n",
      "iteration 768: f_best = 0.00000000\n",
      "x_eff  = [ 0.31057839 -0.73437181],\n",
      "\n",
      "iteration 769: f_best = 0.00000000\n",
      "x_eff  = [-0.31275269 -0.6889924 ],\n",
      "\n",
      "iteration 770: f_best = 0.00000000\n",
      "x_eff  = [-0.68518188 -0.66757193],\n",
      "\n",
      "iteration 771: f_best = 0.00000000\n",
      "x_eff  = [-0.4806357  -0.12380616],\n",
      "\n",
      "iteration 772: f_best = 0.00000000\n",
      "x_eff  = [-0.6933752   0.70615981],\n",
      "\n",
      "iteration 773: f_best = 0.00000000\n",
      "x_eff  = [-0.46008676  0.12825624],\n",
      "\n",
      "iteration 774: f_best = 0.00000000\n",
      "x_eff  = [-0.29603446  0.16250144],\n",
      "\n",
      "iteration 775: f_best = 0.00000000\n",
      "x_eff  = [-0.50168775 -0.14542694],\n",
      "\n",
      "iteration 776: f_best = 0.00000000\n",
      "x_eff  = [-0.22508118  0.08433229],\n",
      "\n",
      "iteration 777: f_best = 0.00000000\n",
      "x_eff  = [-0.3545219  -0.06176031],\n",
      "\n",
      "iteration 778: f_best = 0.00000000\n",
      "x_eff  = [0.09234861 0.15239057],\n",
      "\n",
      "iteration 779: f_best = 0.00000000\n",
      "x_eff  = [ 0.38537974 -0.66353239],\n",
      "\n",
      "iteration 780: f_best = 0.00000000\n",
      "x_eff  = [-0.42907808  0.12552019],\n",
      "\n",
      "iteration 781: f_best = 0.00000000\n",
      "x_eff  = [0.63649014 0.61220639],\n",
      "\n",
      "iteration 782: f_best = 0.00000000\n",
      "x_eff  = [ 0.00169088 -0.07911647],\n",
      "\n",
      "iteration 783: f_best = 0.00000000\n",
      "x_eff  = [-0.415286  -0.0833774],\n",
      "\n",
      "iteration 784: f_best = 0.00000000\n",
      "x_eff  = [-0.56247965  0.53553428],\n",
      "\n",
      "iteration 785: f_best = 0.00000000\n",
      "x_eff  = [-0.4852475   0.08998347],\n",
      "\n",
      "iteration 786: f_best = 0.00000000\n",
      "x_eff  = [-0.22968153 -0.42599778],\n",
      "\n",
      "iteration 787: f_best = 0.00000000\n",
      "x_eff  = [0.60599814 0.30371019],\n",
      "\n",
      "iteration 788: f_best = 0.00000000\n",
      "x_eff  = [-0.28900237 -0.2955412 ],\n",
      "\n",
      "iteration 789: f_best = 0.00000000\n",
      "x_eff  = [0.11292157 0.1491572 ],\n",
      "\n",
      "iteration 790: f_best = 0.00000000\n",
      "x_eff  = [ 0.60107323 -0.46787711],\n",
      "\n",
      "iteration 791: f_best = 0.00000000\n",
      "x_eff  = [-0.09337057  0.4463572 ],\n",
      "\n",
      "iteration 792: f_best = 0.00000000\n",
      "x_eff  = [-0.56260115 -0.50002924],\n",
      "\n",
      "iteration 793: f_best = 0.00000000\n",
      "x_eff  = [0.09617805 0.52785842],\n",
      "\n",
      "iteration 794: f_best = 0.00000000\n",
      "x_eff  = [ 0.36536017 -0.11969847],\n",
      "\n",
      "iteration 795: f_best = 0.00000000\n",
      "x_eff  = [0.43701117 0.24526668],\n",
      "\n",
      "iteration 796: f_best = 0.00000000\n",
      "x_eff  = [-0.48934382  0.3408045 ],\n",
      "\n",
      "iteration 797: f_best = 0.00000000\n",
      "x_eff  = [ 0.26504454 -0.04430661],\n",
      "\n",
      "iteration 798: f_best = 0.00000000\n",
      "x_eff  = [0.05709125 0.53151715],\n",
      "\n",
      "iteration 799: f_best = 0.00000000\n",
      "x_eff  = [ 0.27874316 -0.46786268],\n",
      "\n",
      "iteration 800: f_best = 0.00000000\n",
      "x_eff  = [0.49409453 0.52197547],\n",
      "\n",
      "iteration 801: f_best = 0.00000000\n",
      "x_eff  = [-0.04963718  0.49468709],\n",
      "\n",
      "iteration 802: f_best = 0.00000000\n",
      "x_eff  = [0.10259879 0.19989535],\n",
      "\n",
      "iteration 803: f_best = 0.00000000\n",
      "x_eff  = [ 0.49833388 -0.02573865],\n",
      "\n",
      "iteration 804: f_best = 0.00000000\n",
      "x_eff  = [ 0.16479502 -0.3400832 ],\n",
      "\n",
      "iteration 805: f_best = 0.00000000\n",
      "x_eff  = [0.20053313 0.34812892],\n",
      "\n",
      "iteration 806: f_best = 0.00000000\n",
      "x_eff  = [ 0.3834838 -0.3203776],\n",
      "\n",
      "iteration 807: f_best = 0.00000000\n",
      "x_eff  = [-0.28876352 -0.50299224],\n",
      "\n",
      "iteration 808: f_best = 0.00000000\n",
      "x_eff  = [-0.02315441 -0.25728966],\n",
      "\n",
      "iteration 809: f_best = 0.00000000\n",
      "x_eff  = [-0.33417457 -0.36262363],\n",
      "\n",
      "iteration 810: f_best = 0.00000000\n",
      "x_eff  = [ 0.23252281 -0.36335855],\n",
      "\n",
      "iteration 811: f_best = 0.00000000\n",
      "x_eff  = [-0.39284308 -0.29715254],\n",
      "\n",
      "iteration 812: f_best = 0.00000000\n",
      "x_eff  = [ 0.13829583 -0.09213986],\n",
      "\n",
      "iteration 813: f_best = 0.00000000\n",
      "x_eff  = [-0.24034998 -0.43015142],\n",
      "\n",
      "iteration 814: f_best = 0.00000000\n",
      "x_eff  = [0.30654493 0.06143902],\n",
      "\n",
      "iteration 815: f_best = 0.00000000\n",
      "x_eff  = [-0.27759773  0.0989742 ],\n",
      "\n",
      "iteration 816: f_best = 0.00000000\n",
      "x_eff  = [ 0.30022101 -0.27659905],\n",
      "\n",
      "iteration 817: f_best = 0.00000000\n",
      "x_eff  = [-0.01702668 -0.07731942],\n",
      "\n",
      "iteration 818: f_best = 0.00000000\n",
      "x_eff  = [0.42964149 0.14193235],\n",
      "\n",
      "iteration 819: f_best = 0.00000000\n",
      "x_eff  = [-0.03714393 -0.1940461 ],\n",
      "\n",
      "iteration 820: f_best = 0.00000000\n",
      "x_eff  = [-0.01629721 -0.15697976],\n",
      "\n",
      "iteration 821: f_best = 0.00000000\n",
      "x_eff  = [ 0.30295835 -0.30664366],\n",
      "\n",
      "iteration 822: f_best = 0.00000000\n",
      "x_eff  = [-0.21611216 -0.13989334],\n",
      "\n",
      "iteration 823: f_best = 0.00000000\n",
      "x_eff  = [0.34739518 0.12723889],\n",
      "\n",
      "iteration 824: f_best = 0.00000000\n",
      "x_eff  = [-0.05041117  0.21036148],\n",
      "\n",
      "iteration 825: f_best = 0.00000000\n",
      "x_eff  = [0.28628278 0.12080882],\n",
      "\n",
      "iteration 826: f_best = 0.00000000\n",
      "x_eff  = [-0.26787762 -0.34290605],\n",
      "\n",
      "iteration 827: f_best = 0.00000000\n",
      "x_eff  = [-0.19449891  0.19553774],\n",
      "\n",
      "iteration 828: f_best = 0.00000000\n",
      "x_eff  = [0.07196184 0.16850361],\n",
      "\n",
      "iteration 829: f_best = 0.00000000\n",
      "x_eff  = [-0.18992934 -0.29759126],\n",
      "\n",
      "iteration 830: f_best = 0.00000000\n",
      "x_eff  = [0.12608813 0.29351122],\n",
      "\n",
      "iteration 831: f_best = 0.00000000\n",
      "x_eff  = [0.34919228 0.03632071],\n",
      "\n",
      "iteration 832: f_best = 0.00000000\n",
      "x_eff  = [0.27632285 0.34556557],\n",
      "\n",
      "iteration 833: f_best = 0.00000000\n",
      "x_eff  = [0.36602541 0.08752458],\n",
      "\n",
      "iteration 834: f_best = 0.00000000\n",
      "x_eff  = [ 0.11896863 -0.0571148 ],\n",
      "\n",
      "iteration 835: f_best = 0.00000000\n",
      "x_eff  = [-0.09752876  0.19287192],\n",
      "\n",
      "iteration 836: f_best = 0.00000000\n",
      "x_eff  = [-0.00911314  0.29354542],\n",
      "\n",
      "iteration 837: f_best = 0.00000000\n",
      "x_eff  = [ 0.1771715  -0.30960267],\n",
      "\n",
      "iteration 838: f_best = 0.00000000\n",
      "x_eff  = [-0.15163013  0.06922111],\n",
      "\n",
      "iteration 839: f_best = 0.00000000\n",
      "x_eff  = [-0.03127138 -0.23780744],\n",
      "\n",
      "iteration 840: f_best = 0.00000000\n",
      "x_eff  = [ 0.04271554 -0.3255264 ],\n",
      "\n",
      "iteration 841: f_best = 0.00000000\n",
      "x_eff  = [-0.08661838  0.25923633],\n",
      "\n",
      "iteration 842: f_best = 0.00000000\n",
      "x_eff  = [-0.29880495  0.025959  ],\n",
      "\n",
      "iteration 843: f_best = 0.00000000\n",
      "x_eff  = [-0.24396652  0.17826408],\n",
      "\n",
      "iteration 844: f_best = 0.00000000\n",
      "x_eff  = [-0.05693097  0.12536406],\n",
      "\n",
      "iteration 845: f_best = 0.00000000\n",
      "x_eff  = [ 0.26034007 -0.12215376],\n",
      "\n",
      "iteration 846: f_best = 0.00000000\n",
      "x_eff  = [ 0.1071694  -0.11737813],\n",
      "\n",
      "iteration 847: f_best = 0.00000000\n",
      "x_eff  = [-0.22392117  0.11328245],\n",
      "\n",
      "iteration 848: f_best = 0.00000000\n",
      "x_eff  = [-0.28202557  0.07236378],\n",
      "\n",
      "iteration 849: f_best = 0.00000000\n",
      "x_eff  = [-0.26028851 -0.13501488],\n",
      "\n",
      "iteration 850: f_best = 0.00000000\n",
      "x_eff  = [0.13340596 0.13757903],\n",
      "\n",
      "iteration 851: f_best = 0.00000000\n",
      "x_eff  = [-0.1527997   0.01144769],\n",
      "\n",
      "iteration 852: f_best = 0.00000000\n",
      "x_eff  = [ 0.21614831 -0.19868065],\n",
      "\n",
      "iteration 853: f_best = 0.00000000\n",
      "x_eff  = [-0.23055981 -0.18238539],\n",
      "\n",
      "iteration 854: f_best = 0.00000000\n",
      "x_eff  = [ 0.24083477 -0.22599424],\n",
      "\n",
      "iteration 855: f_best = 0.00000000\n",
      "x_eff  = [0.2071033  0.26796576],\n",
      "\n",
      "iteration 856: f_best = 0.00000000\n",
      "x_eff  = [ 0.18219615 -0.08705511],\n",
      "\n",
      "iteration 857: f_best = 0.00000000\n",
      "x_eff  = [ 0.03348069 -0.29717636],\n",
      "\n",
      "iteration 858: f_best = 0.00000000\n",
      "x_eff  = [-0.28795456  0.15829042],\n",
      "\n",
      "iteration 859: f_best = 0.00000000\n",
      "x_eff  = [ 0.0265771  -0.02350738],\n",
      "\n",
      "iteration 860: f_best = 0.00000000\n",
      "x_eff  = [-0.2429658  -0.25444683],\n",
      "\n",
      "iteration 861: f_best = 0.00000000\n",
      "x_eff  = [0.14009628 0.00949145],\n",
      "\n",
      "iteration 862: f_best = 0.00000000\n",
      "x_eff  = [0.04403635 0.19210249],\n",
      "\n",
      "iteration 863: f_best = 0.00000000\n",
      "x_eff  = [ 0.26532179 -0.25107194],\n",
      "\n",
      "iteration 864: f_best = 0.00000000\n",
      "x_eff  = [0.04076695 0.22199518],\n",
      "\n",
      "iteration 865: f_best = 0.00000000\n",
      "x_eff  = [ 0.23404579 -0.14285426],\n",
      "\n",
      "iteration 866: f_best = 0.00000000\n",
      "x_eff  = [-0.2088188  -0.28043285],\n",
      "\n",
      "iteration 867: f_best = 0.00000000\n",
      "x_eff  = [ 0.25254532 -0.06805024],\n",
      "\n",
      "iteration 868: f_best = 0.00000000\n",
      "x_eff  = [-0.2237075   0.10754242],\n",
      "\n",
      "iteration 869: f_best = 0.00000000\n",
      "x_eff  = [ 0.14812714 -0.11821127],\n",
      "\n",
      "iteration 870: f_best = 0.00000000\n",
      "x_eff  = [-0.15482889 -0.20140771],\n",
      "\n",
      "iteration 871: f_best = 0.00000000\n",
      "x_eff  = [-0.13092227  0.211236  ],\n",
      "\n",
      "iteration 872: f_best = 0.00000000\n",
      "x_eff  = [0.22516354 0.16570257],\n",
      "\n",
      "iteration 873: f_best = 0.00000000\n",
      "x_eff  = [-0.24074053  0.08767198],\n",
      "\n",
      "iteration 874: f_best = 0.00000000\n",
      "x_eff  = [-0.212938    0.03012773],\n",
      "\n",
      "iteration 875: f_best = 0.00000000\n",
      "x_eff  = [0.1567517 0.1811919],\n",
      "\n",
      "iteration 876: f_best = 0.00000000\n",
      "x_eff  = [ 0.19171546 -0.00930379],\n",
      "\n",
      "iteration 877: f_best = 0.00000000\n",
      "x_eff  = [-0.04706101  0.08875345],\n",
      "\n",
      "iteration 878: f_best = 0.00000000\n",
      "x_eff  = [-0.00048961 -0.1830701 ],\n",
      "\n",
      "iteration 879: f_best = 0.00000000\n",
      "x_eff  = [0.16499198 0.08905274],\n",
      "\n",
      "iteration 880: f_best = 0.00000000\n",
      "x_eff  = [-0.2390635   0.21528162],\n",
      "\n",
      "iteration 881: f_best = 0.00000000\n",
      "x_eff  = [ 0.12631456 -0.07978357],\n",
      "\n",
      "iteration 882: f_best = 0.00000000\n",
      "x_eff  = [-0.1473337  -0.07163846],\n",
      "\n",
      "iteration 883: f_best = 0.00000000\n",
      "x_eff  = [-0.04058654 -0.17228534],\n",
      "\n",
      "iteration 884: f_best = 0.00000000\n",
      "x_eff  = [-0.20896155  0.05070311],\n",
      "\n",
      "iteration 885: f_best = 0.00000000\n",
      "x_eff  = [0.01947257 0.06440003],\n",
      "\n",
      "iteration 886: f_best = 0.00000000\n",
      "x_eff  = [-0.20178997  0.10547166],\n",
      "\n",
      "iteration 887: f_best = 0.00000000\n",
      "x_eff  = [0.02987731 0.01478296],\n",
      "\n",
      "iteration 888: f_best = 0.00000000\n",
      "x_eff  = [ 0.08353129 -0.10517308],\n",
      "\n",
      "iteration 889: f_best = 0.00000000\n",
      "x_eff  = [ 0.06444308 -0.1515226 ],\n",
      "\n",
      "iteration 890: f_best = 0.00000000\n",
      "x_eff  = [0.20947805 0.21056101],\n",
      "\n",
      "iteration 891: f_best = 0.00000000\n",
      "x_eff  = [ 0.04461493 -0.09395454],\n",
      "\n",
      "iteration 892: f_best = 0.00000000\n",
      "x_eff  = [-0.16168381  0.16175233],\n",
      "\n",
      "iteration 893: f_best = 0.00000000\n",
      "x_eff  = [-0.00749911  0.17171699],\n",
      "\n",
      "iteration 894: f_best = 0.00000000\n",
      "x_eff  = [-0.03312501  0.03056191],\n",
      "\n",
      "iteration 895: f_best = 0.00000000\n",
      "x_eff  = [-0.15923647  0.09860234],\n",
      "\n",
      "iteration 896: f_best = 0.00000000\n",
      "x_eff  = [0.19878912 0.1620881 ],\n",
      "\n",
      "iteration 897: f_best = 0.00000000\n",
      "x_eff  = [-0.1669894   0.06322593],\n",
      "\n",
      "iteration 898: f_best = 0.00000000\n",
      "x_eff  = [-0.04905195 -0.12561772],\n",
      "\n",
      "iteration 899: f_best = 0.00000000\n",
      "x_eff  = [ 0.11830013 -0.1616018 ],\n",
      "\n",
      "iteration 900: f_best = 0.00000000\n",
      "x_eff  = [ 0.11114716 -0.16267728],\n",
      "\n",
      "iteration 901: f_best = 0.00000000\n",
      "x_eff  = [-0.02157402 -0.15230199],\n",
      "\n",
      "iteration 902: f_best = 0.00000000\n",
      "x_eff  = [-0.17683967 -0.15007017],\n",
      "\n",
      "iteration 903: f_best = 0.00000000\n",
      "x_eff  = [-0.1327302   0.10960669],\n",
      "\n",
      "iteration 904: f_best = 0.00000000\n",
      "x_eff  = [ 0.11216639 -0.03246825],\n",
      "\n",
      "iteration 905: f_best = 0.00000000\n",
      "x_eff  = [-0.10164929  0.00261426],\n",
      "\n",
      "iteration 906: f_best = 0.00000000\n",
      "x_eff  = [-0.1305979  -0.07540644],\n",
      "\n",
      "iteration 907: f_best = 0.00000000\n",
      "x_eff  = [-0.02822853  0.13416452],\n",
      "\n",
      "iteration 908: f_best = 0.00000000\n",
      "x_eff  = [-0.13731755 -0.0375679 ],\n",
      "\n",
      "iteration 909: f_best = 0.00000000\n",
      "x_eff  = [-0.0859274  -0.17430016],\n",
      "\n",
      "iteration 910: f_best = 0.00000000\n",
      "x_eff  = [-0.13303986 -0.08776632],\n",
      "\n",
      "iteration 911: f_best = 0.00000000\n",
      "x_eff  = [-0.13921721  0.09985706],\n",
      "\n",
      "iteration 912: f_best = 0.00000000\n",
      "x_eff  = [ 0.00743372 -0.11103298],\n",
      "\n",
      "iteration 913: f_best = 0.00000000\n",
      "x_eff  = [-0.15137065  0.13909107],\n",
      "\n",
      "iteration 914: f_best = 0.00000000\n",
      "x_eff  = [ 0.01310376 -0.14786243],\n",
      "\n",
      "iteration 915: f_best = 0.00000000\n",
      "x_eff  = [-0.07559425 -0.01359798],\n",
      "\n",
      "iteration 916: f_best = 0.00000000\n",
      "x_eff  = [ 0.10054668 -0.14342282],\n",
      "\n",
      "iteration 917: f_best = 0.00000000\n",
      "x_eff  = [0.08130323 0.05368919],\n",
      "\n",
      "iteration 918: f_best = 0.00000000\n",
      "x_eff  = [ 0.15096595 -0.07440715],\n",
      "\n",
      "iteration 919: f_best = 0.00000000\n",
      "x_eff  = [0.01156487 0.08904591],\n",
      "\n",
      "iteration 920: f_best = 0.00000000\n",
      "x_eff  = [0.06503429 0.08006571],\n",
      "\n",
      "iteration 921: f_best = 0.00000000\n",
      "x_eff  = [-0.07370008  0.14208303],\n",
      "\n",
      "iteration 922: f_best = 0.00000000\n",
      "x_eff  = [-0.08470658  0.1459406 ],\n",
      "\n",
      "iteration 923: f_best = 0.00000000\n",
      "x_eff  = [ 0.13504174 -0.07826666],\n",
      "\n",
      "iteration 924: f_best = 0.00000000\n",
      "x_eff  = [-0.1137573   0.13016801],\n",
      "\n",
      "iteration 925: f_best = 0.00000000\n",
      "x_eff  = [-0.10366582 -0.09756674],\n",
      "\n",
      "iteration 926: f_best = 0.00000000\n",
      "x_eff  = [0.04713642 0.109141  ],\n",
      "\n",
      "iteration 927: f_best = 0.00000000\n",
      "x_eff  = [-0.03102538 -0.12661035],\n",
      "\n",
      "iteration 928: f_best = 0.00000000\n",
      "x_eff  = [-0.02357312 -0.14821   ],\n",
      "\n",
      "iteration 929: f_best = 0.00000000\n",
      "x_eff  = [-0.09013046 -0.14604356],\n",
      "\n",
      "iteration 930: f_best = 0.00000000\n",
      "x_eff  = [-0.04499586 -0.01992687],\n",
      "\n",
      "iteration 931: f_best = 0.00000000\n",
      "x_eff  = [-0.00026305 -0.049048  ],\n",
      "\n",
      "iteration 932: f_best = 0.00000000\n",
      "x_eff  = [ 0.10551994 -0.0160861 ],\n",
      "\n",
      "iteration 933: f_best = 0.00000000\n",
      "x_eff  = [ 0.03518762 -0.12375602],\n",
      "\n",
      "iteration 934: f_best = 0.00000000\n",
      "x_eff  = [0.09539891 0.04603434],\n",
      "\n",
      "iteration 935: f_best = 0.00000000\n",
      "x_eff  = [-0.04909022 -0.07514078],\n",
      "\n",
      "iteration 936: f_best = 0.00000000\n",
      "x_eff  = [ 0.02440172 -0.12061645],\n",
      "\n",
      "iteration 937: f_best = 0.00000000\n",
      "x_eff  = [-0.03042807  0.02546075],\n",
      "\n",
      "iteration 938: f_best = 0.00000000\n",
      "x_eff  = [ 0.10838677 -0.10778777],\n",
      "\n",
      "iteration 939: f_best = 0.00000000\n",
      "x_eff  = [-0.07903395  0.00395186],\n",
      "\n",
      "iteration 940: f_best = 0.00000000\n",
      "x_eff  = [0.01599108 0.0491614 ],\n",
      "\n",
      "iteration 941: f_best = 0.00000000\n",
      "x_eff  = [ 0.0734743 -0.0148502],\n",
      "\n",
      "iteration 942: f_best = 0.00000000\n",
      "x_eff  = [0.10158617 0.07638703],\n",
      "\n",
      "iteration 943: f_best = 0.00000000\n",
      "x_eff  = [ 0.07952265 -0.11740144],\n",
      "\n",
      "iteration 944: f_best = 0.00000000\n",
      "x_eff  = [ 0.10283784 -0.03011618],\n",
      "\n",
      "iteration 945: f_best = 0.00000000\n",
      "x_eff  = [-0.06736174 -0.10680645],\n",
      "\n",
      "iteration 946: f_best = 0.00000000\n",
      "x_eff  = [ 0.03338758 -0.08748633],\n",
      "\n",
      "iteration 947: f_best = 0.00000000\n",
      "x_eff  = [ 0.07862061 -0.03465607],\n",
      "\n",
      "iteration 948: f_best = 0.00000000\n",
      "x_eff  = [-0.08553162 -0.00348097],\n",
      "\n",
      "iteration 949: f_best = 0.00000000\n",
      "x_eff  = [0.02699563 0.08285517],\n",
      "\n",
      "iteration 950: f_best = 0.00000000\n",
      "x_eff  = [ 0.10177699 -0.01264262],\n",
      "\n",
      "iteration 951: f_best = 0.00000000\n",
      "x_eff  = [ 0.06352597 -0.06849073],\n",
      "\n",
      "iteration 952: f_best = 0.00000000\n",
      "x_eff  = [-0.0907147   0.11904523],\n",
      "\n",
      "iteration 953: f_best = 0.00000000\n",
      "x_eff  = [-0.09355757 -0.01326443],\n",
      "\n",
      "iteration 954: f_best = 0.00000000\n",
      "x_eff  = [0.06028366 0.08047179],\n",
      "\n",
      "iteration 955: f_best = 0.00000000\n",
      "x_eff  = [-0.10362976  0.06268985],\n",
      "\n",
      "iteration 956: f_best = 0.00000000\n",
      "x_eff  = [0.01442761 0.11450865],\n",
      "\n",
      "iteration 957: f_best = 0.00000000\n",
      "x_eff  = [0.00952417 0.06010442],\n",
      "\n",
      "iteration 958: f_best = 0.00000000\n",
      "x_eff  = [ 0.08352962 -0.07495779],\n",
      "\n",
      "iteration 959: f_best = 0.00000000\n",
      "x_eff  = [ 0.01285354 -0.03281006],\n",
      "\n",
      "iteration 960: f_best = 0.00000000\n",
      "x_eff  = [0.0001795  0.07216667],\n",
      "\n",
      "iteration 961: f_best = 0.00000000\n",
      "x_eff  = [0.05293337 0.0971835 ],\n",
      "\n",
      "iteration 962: f_best = 0.00000000\n",
      "x_eff  = [-0.05299689  0.00882408],\n",
      "\n",
      "iteration 963: f_best = 0.00000000\n",
      "x_eff  = [-0.06060969 -0.08789214],\n",
      "\n",
      "iteration 964: f_best = 0.00000000\n",
      "x_eff  = [ 0.03770225 -0.0597292 ],\n",
      "\n",
      "iteration 965: f_best = 0.00000000\n",
      "x_eff  = [ 0.02749546 -0.06906111],\n",
      "\n",
      "iteration 966: f_best = 0.00000000\n",
      "x_eff  = [0.10375071 0.03291929],\n",
      "\n",
      "iteration 967: f_best = 0.00000000\n",
      "x_eff  = [-0.0648112   0.06917935],\n",
      "\n",
      "iteration 968: f_best = 0.00000000\n",
      "x_eff  = [-0.07170356  0.09316473],\n",
      "\n",
      "iteration 969: f_best = 0.00000000\n",
      "x_eff  = [-0.06415839 -0.07687492],\n",
      "\n",
      "iteration 970: f_best = 0.00000000\n",
      "x_eff  = [ 0.07437718 -0.04414947],\n",
      "\n",
      "iteration 971: f_best = 0.00000000\n",
      "x_eff  = [-0.06604617 -0.0135604 ],\n",
      "\n",
      "iteration 972: f_best = 0.00000000\n",
      "x_eff  = [0.00018657 0.08307687],\n",
      "\n",
      "iteration 973: f_best = 0.00000000\n",
      "x_eff  = [-0.0382427  -0.06411757],\n",
      "\n",
      "iteration 974: f_best = 0.00000000\n",
      "x_eff  = [ 0.02578197 -0.00842986],\n",
      "\n",
      "iteration 975: f_best = 0.00000000\n",
      "x_eff  = [0.07146251 0.00553886],\n",
      "\n",
      "iteration 976: f_best = 0.00000000\n",
      "x_eff  = [-0.04701017 -0.08652926],\n",
      "\n",
      "iteration 977: f_best = 0.00000000\n",
      "x_eff  = [-0.01584519  0.06359075],\n",
      "\n",
      "iteration 978: f_best = 0.00000000\n",
      "x_eff  = [-0.07869534  0.03462787],\n",
      "\n",
      "iteration 979: f_best = 0.00000000\n",
      "x_eff  = [-0.0540254   0.00582836],\n",
      "\n",
      "iteration 980: f_best = 0.00000000\n",
      "x_eff  = [-0.00350788  0.00534812],\n",
      "\n",
      "iteration 981: f_best = 0.00000000\n",
      "x_eff  = [-0.03799365 -0.0655561 ],\n",
      "\n",
      "iteration 982: f_best = 0.00000000\n",
      "x_eff  = [0.0684896  0.05583551],\n",
      "\n",
      "iteration 983: f_best = 0.00000000\n",
      "x_eff  = [-0.08027095 -0.05732643],\n",
      "\n",
      "iteration 984: f_best = 0.00000000\n",
      "x_eff  = [ 0.03042969 -0.06526836],\n",
      "\n",
      "iteration 985: f_best = 0.00000000\n",
      "x_eff  = [-0.07068024  0.06515662],\n",
      "\n",
      "iteration 986: f_best = 0.00000000\n",
      "x_eff  = [ 0.07007348 -0.05247847],\n",
      "\n",
      "iteration 987: f_best = 0.00000000\n",
      "x_eff  = [-0.07222211 -0.04986125],\n",
      "\n",
      "iteration 988: f_best = 0.00000000\n",
      "x_eff  = [-0.04124375  0.06376641],\n",
      "\n",
      "iteration 989: f_best = 0.00000000\n",
      "x_eff  = [ 0.07867987 -0.05093166],\n",
      "\n",
      "iteration 990: f_best = 0.00000000\n",
      "x_eff  = [0.0069553  0.04049439],\n",
      "\n",
      "iteration 991: f_best = 0.00000000\n",
      "x_eff  = [ 0.03747696 -0.00560921],\n",
      "\n",
      "iteration 992: f_best = 0.00000000\n",
      "x_eff  = [0.07281257 0.0716729 ],\n",
      "\n",
      "iteration 993: f_best = 0.00000000\n",
      "x_eff  = [ 0.06179915 -0.01358404],\n",
      "\n",
      "iteration 994: f_best = 0.00000000\n",
      "x_eff  = [0.02957862 0.04557011],\n",
      "\n",
      "iteration 995: f_best = 0.00000000\n",
      "x_eff  = [-0.03622718 -0.07522308],\n",
      "\n",
      "iteration 996: f_best = 0.00000000\n",
      "x_eff  = [-0.03013257 -0.05695384],\n",
      "\n",
      "iteration 997: f_best = 0.00000000\n",
      "x_eff  = [-0.05584751  0.04212501],\n",
      "\n",
      "iteration 998: f_best = 0.00000000\n",
      "x_eff  = [0.03263205 0.04111395],\n",
      "\n",
      "iteration 999: f_best = 0.00000000\n",
      "x_eff  = [-0.01461849 -0.05180927],\n",
      "\n",
      "Best value for K_warmup=100: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "x_best2, f_best2 = global_opt(bounds, tau, K, K_warmup2)\n",
    "print(f\"Best value for K_warmup={K_warmup2}: {f_best2:.8f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run the code three times and look through the iterations each time, we find that:\n",
    "  \n",
    "$\\underline{K}=10$ converges at iteration 215, iteration 297 and iteration 188 \n",
    " \n",
    "and\n",
    " \n",
    "$\\underline{K}=100$ converges at iteration 477, iteration 385 and iteration 407"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our observations, we find that $\\underline{K}=10$ converges faster compared to $\\underline{K}=100$, but they both converge to 0 well before the last iteration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
