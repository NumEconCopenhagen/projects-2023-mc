{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Problem 1: Optimal taxation with government consumption](#toc1_)    \n",
    "- 2. [Problem 2: Labor adjustment costs](#toc2_)    \n",
    "- 3. [Problem 3: Global optimizer with refined multi-start](#toc3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "import sympy as sm\n",
    "from sympy import Symbol\n",
    "from sympy.solvers import solve\n",
    "from scipy.optimize import root_scalar\n",
    "\n",
    "#from scipy import optimize\n",
    "#import pandas as pd \n",
    "\n",
    "sm.init_printing(use_unicode=True) # for pretty printing\n",
    "#from IPython.display import display\n",
    "#import ipywidgets as widgets\n",
    "#from types import SimpleNamespace\n",
    "#from copy import deepcopy\n",
    "\n",
    "# Autoreload modules when code is run. Otherwise, python will not see recent changes. \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Problem 1: Optimal taxation with government consumption](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consider a worker choosing hours of labor, $L\\in[0,24]$, to maximize utility: \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "V(w,\\tau,G)&=\\max_{L\\in[0,24]}\\ln\\left(C^{\\alpha}G^{1-\\alpha}\\right)-\\nu\\frac{L^{2}}{2}\\\\&\\text{s.t.}\\\\&C=\\kappa+(1-\\tau)wL\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $C$ is *private* consumption with weight $\\alpha\\in(0,1)$.\n",
    "* $\\kappa > 0$ is the *free private* consumption component.\n",
    "* $(1-\\tau)wL$ is the *costly private* consumption component.\n",
    "* $w > 0 $ is the real wage.\n",
    "* $\\tau \\in (0,1)$ is the labor-income tax rate.\n",
    "* $G > 0 $ is *government* consumption with weight $1-\\alpha$.\n",
    "* $\\nu > 0$ is the disutility of labor scaling factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The baseline parameters are:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\alpha &= 0.5\\\\\n",
    "\\kappa &= 1.0\\\\\n",
    "\\nu &= \\frac{1}{2\\cdot16^2} \\\\\n",
    "w &= 1.0 \\\\ \n",
    "\\tau &= 0.30 \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining baseline parameters:\n",
    "alpha = 0.5\n",
    "kappa = 1.0\n",
    "nu = 1/(2*16**2)\n",
    "w = 1.0\n",
    "tau = 0.30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Verify that the optimal labor supply choice is $L^{\\star}(\\tilde{w}) =\\frac{-\\kappa+\\sqrt{\\kappa^{2}+4\\frac{\\alpha}{\\nu}\\tilde{w}^2}}{2\\tilde{w}}$, where $\\tilde{w} = (1-\\tau)w$, for $G\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify this by using the Lagrangian method. We begin by defining the Lagrangian function:\n",
    "$$\\mathcal{L}(C,G,L,\\lambda)=\\ln(C^{\\alpha}G^{1-\\alpha})-\\nu\\frac{L^{2}}{2}+\\lambda\\left[\\kappa+(1-\\tau)wL-C\\right]$$\n",
    "We find the FOC wrt. $L$ by setting the derivative of the function equal to $0$:\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial L} = 0$$\n",
    "$$\\Rightarrow \\lambda(1-\\tau)w - \\nu L = 0$$\n",
    "$$\\Rightarrow \\lambda(1-\\tau)w  = \\nu L$$\n",
    "$$\\Rightarrow L = \\frac{\\lambda(1-\\tau)w}{\\nu}$$\n",
    "Then, we find the expression for $C$:\n",
    "$$C=\\kappa+(1-\\tau)wL = \\kappa+(1-\\tau)w\\frac{\\lambda(1-\\tau)w}{\\nu} $$\n",
    "As $\\tilde{w} = (1-\\tau)w$, we get:\n",
    "$$C=\\kappa+\\tilde{w}L = \\kappa+\\tilde{w}\\frac{\\lambda(\\tilde{w})}{\\nu} $$\n",
    "\n",
    "$$\\Rightarrow \\lambda = \\frac{\\sqrt{\\kappa^{2}+4\\frac{\\alpha G}{\\nu}\\tilde{w}^2}-\\kappa}{2\\tilde{w}}$$\n",
    "\n",
    "Which result in:\n",
    "$$L^{\\star}(\\tilde{w}) =\\frac{-\\kappa+\\sqrt{\\kappa^{2}+4\\frac{\\alpha G}{\\nu}\\tilde{w}^2}}{2\\tilde{w}}$$\n",
    "Hereby, it is vertified that the optimal labor supply choice is $L^{\\star}(\\tilde{w}) =\\frac{-\\kappa+\\sqrt{\\kappa^{2}+4\\frac{\\alpha G}{\\nu}\\tilde{w}^2}}{2\\tilde{w}}$, where $\\tilde{w} = (1-\\tau)w$, for $G\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Illustrate how $L^{\\star}(\\tilde{w})$ depends on $w$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the expression for $L^{\\star}(\\tilde{w})$ to illustrate how the optimal labor supply choice depends on $w$ for different values of $G$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining function for optimal labor supply\n",
    "def L_star(w, G):\n",
    "    return (-kappa + np.sqrt(kappa**2 + 4*alpha*G/(nu)*((1-tau)*w)**2))/(2*((1-tau)*w))\n",
    "\n",
    "# Defining a range of values for tilde_w\n",
    "w_values = np.linspace(0.000001, 1, 1000)\n",
    "\n",
    "# Defining values for G\n",
    "G_values = [1.0, 1.25, 1.5, 1.75, 2.0]\n",
    "\n",
    "# Plotting L_star as a function of tilde_w for different values of G\n",
    "for G in G_values:\n",
    "    L_values = L_star(w_values, G)\n",
    "    plt.plot(w_values, L_values, label='G = {}'.format(G))\n",
    "\n",
    "# Adding axis labels and legend\n",
    "plt.xlabel('$w$')\n",
    "plt.ylabel('$L^*$')\n",
    "plt.title('Illustration of how $L^*(\\\\tilde{w})$ depends on $w$')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now consider a government, who chooses $\\tau$ and spend all of the taxes on government consumption so:\n",
    "\n",
    "$$\n",
    "G = \\tau w L^{\\star}((1-\\tau)w)\n",
    "$$\n",
    "\n",
    "**Question 3:** Plot the implied $L$, $G$ and worker utility for a grid of $\\tau$-values.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the labor supply $L^{\\star}$, government consumption $G$, and worker utility $V(w,\\tau,G)$ for different values of $\\tau$. Afterwards, we plot all three variables against $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining function for optimal labor supply\n",
    "def L_star(tau, w):\n",
    "    return (-kappa+np.sqrt(kappa**2+4*alpha*tau*w**2/nu))/(2*tau*w)\n",
    "\n",
    "# Defining function for government consumption\n",
    "def G(tau, w):\n",
    "    return tau*w*L_star(tau, w)\n",
    "\n",
    "# Defining function for worker utility\n",
    "def utility(tau, w):\n",
    "    L = L_star(tau, w)\n",
    "    C = kappa+(1-tau)*w*L\n",
    "    return np.log(C**alpha*G(tau, w)**(1-alpha))-nu*L**2/2\n",
    "\n",
    "# Defining a range of values for tau\n",
    "tau_values = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Calculating optimal labor supply, government consumption, and worker utility for different values of tau\n",
    "L_values = L_star(tau_values, w)\n",
    "G_values = G(tau_values, w)\n",
    "utility_values = utility(tau_values, w)\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(3, 1, sharex=True, figsize=(10,12))\n",
    "fig.suptitle('The implied labor supply, government consumption, and worker utility for different values of $\\\\tau$', fontsize=14)\n",
    "ax[0].plot(tau_values, L_values, color='red')\n",
    "ax[0].set_ylabel('$L$')\n",
    "ax[0].set_xlabel('$\\\\tau$')\n",
    "ax[0].set_title('Labor supply')\n",
    "ax[1].plot(tau_values, G_values, color='orange')\n",
    "ax[1].set_ylabel('$G$')\n",
    "ax[1].set_xlabel('$\\\\tau$')\n",
    "ax[1].set_title('Government consumption')\n",
    "ax[2].plot(tau_values, utility_values, color='green')\n",
    "ax[2].set_ylabel('$V$')\n",
    "ax[2].set_xlabel('$\\\\tau$')\n",
    "ax[2].set_title('Worker utility')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that when labor-income tax rate is close to 0, labor supply is high, government consumption is low and worker utility is low. This is because there is incentive to work as the workers keep a bigger part of their wage, but as the tax rate is low, government does not have an income and cannot consume. Worker utility is low, which can be explained by government not being able to provide public goods for the workers. As the labor-income taxe rate increases, labor supply decreases, government consumption increases, and worker utility increases to a certain point, but if the tax rate is too high, worker utility begins to decrease as a too high income-tax reduces incentive to work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Find the socially optimal tax rate $\\tau^{\\star}\\in(0,1)$ maximizing worker utility. Illustrate your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The socially optimal tax rate is 0.521\n"
     ]
    }
   ],
   "source": [
    "# Define the utility function\n",
    "def utility(L, tau):\n",
    "    C = kappa+(1-tau)*w*L\n",
    "    G = tau*w*L**2\n",
    "    return np.log(C**alpha*G**(1-alpha))-nu*(L**2)/2\n",
    "\n",
    "# Define the objective function to maximize utility subject to the government budget constraint\n",
    "def objective(tau):\n",
    "    def gov_constraint(L):\n",
    "        return tau*w*L**2-utility(L, tau)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, tau),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return -1*utility(L_star, tau)\n",
    "\n",
    "# Find the optimal tax rate that maximizes utility\n",
    "res = minimize_scalar(objective, bounds=(0, 1), method='bounded', options={'disp': 0})\n",
    "tau_star = res.x\n",
    "print(f\"The socially optimal tax rate is {tau_star:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more general preference formulation for the worker is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{V}(w,\\tau,G)&=\\max_{L\\in[0,24]}\\frac{\\left[ \\left( \\alpha C^{\\frac{\\sigma-1}{\\sigma}}+(1-\\alpha) G^{\\frac{\\sigma-1}{\\sigma}} \\right)^{\\frac{\\sigma}{\\sigma - 1} }\\right]^{1-\\rho}-1}{1-\\rho}- \\nu\\frac{L^{1+\\varepsilon}}{1+\\varepsilon},\\,\\,\\,\\varepsilon,\\rho,\\sigma>0,\\,\\,\\,\\rho,\\sigma\\neq1\\\\&\\text{s.t.}\\\\&C=\\kappa+(1-\\tau)wL\n",
    "\\end{align*}    \n",
    "$$\n",
    "\n",
    "Optimal labor supply is now $L^{\\star}(\\tilde{w},G)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions 5 and 6 must be answered with the general formulation, and for 2 different set of parameters:\n",
    "\n",
    "- Set 1:  $\\sigma = 1.001$, $\\rho = 1.001$ and $\\varepsilon = 1.0$.\n",
    "- Set 2:  $\\sigma = 1.5$, $\\rho = 1.5$ and $\\varepsilon = 1.0 $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Find the $G$ that solves $G = \\tau w L^{\\star}((1-\\tau)w,G)$ using the $\\tau$ found in question 4.\n",
    "\n",
    "*Hint: First write code that solves the worker problem for given values of $G$ and $\\tau$. Then find the correct G based on this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to G = tau*w*L_star*((1-tau)*w) for tau = 0.52, sigma = 1.001, rho = 1.001, epsilon = 1.0 is G = 1.5486\n"
     ]
    }
   ],
   "source": [
    "# Define the utility function with general formulation\n",
    "def utility(L, C, G, sigma, rho, epsilon):\n",
    "    return (((alpha*C**( (sigma-1)/sigma ) + (1-alpha)*G**( (sigma-1)/sigma ))**(sigma/(sigma-1)))**(1-rho)-1)/(1-rho) - nu*L**(1+epsilon)/(1+epsilon)\n",
    "\n",
    "# Define the objective function to solve for labor supply\n",
    "def objective(L, tau, G, sigma, rho, epsilon):\n",
    "    C = kappa + (1-tau)*w*L\n",
    "    return -utility(L, C, G, sigma, rho, epsilon)\n",
    "\n",
    "# Define the constraint function to solve for G\n",
    "def constraint(G, tau, sigma, rho, epsilon):\n",
    "    def objective_internal(L):\n",
    "        return -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return G - tau*w*L_star*((1-tau)*w)\n",
    "\n",
    "# Set 1 parameters\n",
    "sigma = 1.001\n",
    "rho = 1.001\n",
    "epsilon = 1.0\n",
    "\n",
    "\n",
    "\n",
    "# Find the G that solves the equation G = tau*w*L_star*((1-tau)*w) for a given tau\n",
    "def get_G(tau, sigma, rho, epsilon):\n",
    "    res = minimize(lambda G: constraint(G, tau, sigma, rho, epsilon), 0.5, method='SLSQP', bounds=[(0, None)])\n",
    "    return res.x[0]\n",
    "\n",
    "\n",
    "tau = 0.521\n",
    "G = get_G(tau, sigma, rho, epsilon)\n",
    "print(f\"The solution to G = tau*w*L_star*((1-tau)*w) for tau = {tau:.2f}, sigma = {sigma:.3f}, rho = {rho:.3f}, epsilon = {epsilon:.1f} is G = {G:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to G = tau*w*L_star*((1-tau)*w) for tau = 0.52, sigma = 1.500, rho = 1.500, epsilon = 1.0 is G = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Define the utility function with general formulation\n",
    "def utility(L, C, G, sigma, rho, epsilon):\n",
    "    return (((alpha*C**( (sigma-1)/sigma ) + (1-alpha)*G**( (sigma-1)/sigma ))**(sigma/(sigma-1)))**(1-rho)-1)/(1-rho) - nu*L**(1+epsilon)/(1+epsilon)\n",
    "\n",
    "# Define the objective function to solve for labor supply\n",
    "def objective(L, tau, G, sigma, rho, epsilon):\n",
    "    C = kappa + (1-tau)*w*L\n",
    "    return -utility(L, C, G, sigma, rho, epsilon)\n",
    "\n",
    "# Define the constraint function to solve for G\n",
    "def constraint(G, tau, sigma, rho, epsilon):\n",
    "    def objective_internal(L):\n",
    "        return -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return G - tau*w*L_star*((1-tau)*w)\n",
    "\n",
    "# Set 2 parameters\n",
    "sigma = 1.5\n",
    "rho = 1.5\n",
    "epsilon = 1.0\n",
    "\n",
    "\n",
    "\n",
    "# Find the G that solves the equation G = tau*w*L_star*((1-tau)*w) for a given tau\n",
    "def get_G(tau, sigma, rho, epsilon):\n",
    "    res = minimize(lambda G: constraint(G, tau, sigma, rho, epsilon), 0.5, method='SLSQP', bounds=[(0, None)])\n",
    "    return res.x[0]\n",
    "\n",
    "\n",
    "tau = 0.521\n",
    "G = get_G(tau, sigma, rho, epsilon)\n",
    "print(f\"The solution to G = tau*w*L_star*((1-tau)*w) for tau = {tau:.2f}, sigma = {sigma:.3f}, rho = {rho:.3f}, epsilon = {epsilon:.1f} is G = {G:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** Find the socially optimal tax rate, $\\tau^{\\star}$, maximizing worker utility, while keeping $G = \\tau w L^{\\star}((1-\\tau)w,G)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The socially optimal tax rate for sigma = 1.010, rho = 1.010, epsilon = 1.0 is tau = 0.3955\n"
     ]
    }
   ],
   "source": [
    "# Define the utility function with general formulation\n",
    "def utility(L, C, G, sigma, rho, epsilon):\n",
    "    return (((alpha*C**( (sigma-1)/sigma ) + (1-alpha)*G**( (sigma-1)/sigma ))**(sigma/(sigma-1)))**(1-rho)-1)/(1-rho) - nu*L**(1+epsilon)/(1+epsilon)\n",
    "\n",
    "# Define the objective function to solve for labor supply\n",
    "def objective(L, tau, G, sigma, rho, epsilon):\n",
    "    C = kappa + (1-tau)*w*L\n",
    "    return -utility(L, C, G, sigma, rho, epsilon)\n",
    "\n",
    "# Define the constraint function to solve for G\n",
    "def constraint(G, tau, sigma, rho, epsilon):\n",
    "    def objective_internal(L):\n",
    "        return -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return G - tau*w*L_star*((1-tau)*w)\n",
    "\n",
    "# Find the G that solves the equation G = tau*w*L_star*((1-tau)*w) for a given tau\n",
    "def get_G(tau, sigma, rho, epsilon):\n",
    "    res = minimize(lambda G: constraint(G, tau, sigma, rho, epsilon), 0.5, method='SLSQP', bounds=[(0, None)])\n",
    "    return res.x[0]\n",
    "\n",
    "# Define the objective function to maximize utility subject to the government budget constraint\n",
    "def objective_social(tau, G, sigma, rho, epsilon):\n",
    "    def gov_constraint(L):\n",
    "        C = kappa + (1-tau) * w * L\n",
    "        return G - tau * w * L * ((1 - tau) * w)\n",
    "    res = minimize_scalar(lambda L: -1*utility(L, kappa+(1-tau)*w*L, G, sigma, rho, epsilon),\n",
    "                          bounds=(0, 24), method='bounded', options={'disp': 0})\n",
    "    L_star = res.x\n",
    "    return -1*utility(L_star, kappa+(1-tau)*w*L_star, G, sigma, rho, epsilon)\n",
    "\n",
    "# Set 1 parameters\n",
    "sigma = 1.01\n",
    "rho = 1.01\n",
    "epsilon = 1.0\n",
    "\n",
    "# Find the socially optimal tax rate that maximizes utility subject to the government budget constraint\n",
    "res = minimize_scalar(lambda tau: -1*objective_social(tau, get_G(tau, sigma, rho, epsilon), sigma, rho, epsilon),\n",
    "                      bounds=(0, 1), method='bounded', options={'disp': 0})\n",
    "tau_star = res.x\n",
    "\n",
    "print(f\"The socially optimal tax rate for sigma = {sigma:.3f}, rho = {rho:.3f}, epsilon = {epsilon:.1f} is tau = {tau_star:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Problem 2: Labor adjustment costs](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You own a hair salon. You employ hairdressers, $\\ell_t$, to produce haircuts, $y_t = \\ell_t$.\n",
    "\n",
    "The wage for each haridresser is $w$.\n",
    "\n",
    "The demand for haircuts implies that the price of haircuts you can charge is $p_t = \\kappa_t y_t^{-\\eta}$, where $\\kappa_t$ is a demand-shock and $\\eta \\in (0,1)$ measures the elasticity of demand.\n",
    "\n",
    "Profits are:\n",
    "\n",
    "$$\n",
    "\\Pi_t = p_t y_t - w \\ell_t = \\kappa_t \\ell_t^{1-\\eta} - w \\ell_t\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline parameters are:\n",
    "- $\\eta = 0.5$\n",
    "- $w = 1.0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Verify numerically that $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ maximises profits, for $\\kappa\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vertify numerically that $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ maximises profits, for $\\kappa\\in\\left\\{1.0 , 2.0\\right\\}$ by using sympy. First we find the derivative of profit wrt. $\\ell$. Hereafter we find the equation that maximises profits by putting this equation equal to zero and solve for $\\ell$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = sm.symbols('eta')\n",
    "w = sm.symbols('w')\n",
    "kappa = sm.symbols('kappa')\n",
    "ell = sm.symbols('ell')\n",
    "p=sm.symbols('p')\n",
    "y=sm.symbols('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/latex": [
       "$\\displaystyle - w + \\frac{\\ell^{1 - \\eta} \\kappa \\left(1 - \\eta\\right)}{\\ell}$"
      ],
      "text/plain": [
       "        1 - η          \n",
       "     ell     ⋅κ⋅(1 - η)\n",
       "-w + ──────────────────\n",
       "            ell        "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit=kappa*ell**(1-eta)-w*ell\n",
    "diffprofit=profit.diff(ell)\n",
    "diffprofit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b7/xr_h9h1s35l0rntn_yj3w_9h0000gn/T/ipykernel_96096/3107884399.py:1: SymPyDeprecationWarning: \n",
      "\n",
      "Eq(expr) with a single argument with the right-hand side\n",
      "defaulting to 0 is deprecated. Use Eq(expr, 0) instead.\n",
      "\n",
      "See https://docs.sympy.org/latest/explanation/active-deprecations.html#deprecated-eq-expr\n",
      "for details.\n",
      "\n",
      "This has been deprecated since SymPy version 1.5. It\n",
      "will be removed in a future version of SymPy.\n",
      "\n",
      "  profit=sm.Eq(kappa*(1-eta)*ell**(-eta)-w)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/latex": [
       "$\\displaystyle \\left[ \\left(\\frac{\\kappa \\left(1 - \\eta\\right)}{w}\\right)^{\\frac{1}{\\eta}}\\right]$"
      ],
      "text/plain": [
       "⎡    ___________⎤\n",
       "⎢   ╱ κ⋅(1 - η) ⎥\n",
       "⎢η ╱  ───────── ⎥\n",
       "⎣╲╱       w     ⎦"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit=sm.Eq(kappa*(1-eta)*ell**(-eta)-w)\n",
    "result = sm.solve(profit, ell)\n",
    "result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vertifies that $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ maximises profits, for $\\kappa\\in\\left\\{1.0 , 2.0\\right\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given values of $\\eta$ and $w$, and the two values of $\\kappa_t$, we can calculate profit-maximizing value of $\\ell_t$ for each $\\kappa_t$ to be:\n",
    "\n",
    "For $\\kappa_t = 1.0$:\n",
    "\n",
    "$$\\ell_t=\\left(\\frac{(1-0.5)\\times 1.0}{1.0}\\right)^{\\frac{1}{0.5}}\\approx 0.709$$\n",
    "\n",
    "For $\\kappa_t = 2.0$:\n",
    "\n",
    "$$\\ell_t=\\left(\\frac{(1-0.5)\\times 2.0}{1.0}\\right)^{\\frac{1}{0.5}}\\approx 1.140$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider a *dynamic* version of the model.\n",
    "\n",
    "* The demand-shock is a so-called AR(1) in logs, \n",
    "\n",
    "$$\n",
    "\\log \\kappa_{t} = \\rho \\log \\kappa_{t-1} + \\epsilon_{t},\\,\\,\\, \\epsilon_{t+1} \\sim \\mathcal{N}(-0.5\\sigma_{\\epsilon}^2,\\sigma_{\\epsilon})\n",
    "$$\n",
    "\n",
    "* Any hiring or firing implies a fixed adjustment cost, $\\iota > 0 $.\n",
    "* Future profits are discounted with a monthly factor of $R \\in (0,1)$.\n",
    "\n",
    "The initial demand shock is $\\kappa_{-1} = 1$ and the planning horizon is 10 years, i.e. 120 months so $t \\in \\{0,1,2,\\dots,119\\}$. Initially you don't have any employees, $\\ell_{-1}=0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The *ex post* value of the salon is *conditional* on the shock series is:\n",
    "\n",
    "$$\n",
    "h(\\epsilon_0,\\epsilon_1,\\dots,\\epsilon_{119}) = \\left[\\sum_{t=0}^{119}R^{-t}\\left[\\kappa_{t}\\ell_{t}^{1-\\eta}-w\\ell_{t}-\\boldsymbol{1}_{\\ell_{t}\\neq\\ell_{t-1}}\\iota\\right]\\right]\n",
    "$$\n",
    "\n",
    "The *ex ante* expected value of the salon can be approximated by\n",
    "\n",
    "$$\n",
    "H = \\mathbb{E}[h(\\epsilon_0,\\epsilon_1,\\dots,\\epsilon_{119})] \\approx \\frac{1}{K}\\sum_{k=0}^{K} h(\\epsilon_0^k,\\epsilon_1^k,\\dots,\\epsilon_{119}^k)\n",
    "$$\n",
    "\n",
    "where each $k\\in\\{0,1,\\dots,K-1\\}$ is a random shock series. Maximizing profitability means maximizing $H$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline parameters are: \n",
    "\n",
    "- $\\rho = 0.90$\n",
    "- $\\iota = 0.01$\n",
    "- $\\sigma_{\\epsilon} = 0.10$\n",
    "- $R = \\left(1+0.01\\right)^{1/12}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Calculate $H$ if the policy  $\\ell_{t}=\\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}}$ from question 1 is followed. Choose $K$ so the approximation is good enough to not affect your results substantially."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate $H$, we choose $K=100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters\n",
    "eta = 0.5\n",
    "w = 1.0\n",
    "rho = 0.8\n",
    "sigma_eps = 0.1\n",
    "iota = 0.1\n",
    "R = 0.9\n",
    "T = 120\n",
    "\n",
    "# Choosing K\n",
    "K = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 2.513\n"
     ]
    }
   ],
   "source": [
    "# Set initial values\n",
    "kappa = np.ones(T+1)\n",
    "ell = np.zeros(T+1)\n",
    "h_vals = np.zeros(K)\n",
    "\n",
    "\n",
    "# Simulate shock series and calculate h for each\n",
    "for k in range(K):\n",
    "    eps = np.random.normal(loc=-0.5*sigma_eps**2, scale=sigma_eps, size=T+1)\n",
    "    for t in range(1, T+1):\n",
    "        kappa[t] = np.exp(rho*np.log(kappa[t-1]) + eps[t])\n",
    "    for t in range(T+1):\n",
    "        ell_new = ((1-eta)*kappa[t]/w)**(1/eta)\n",
    "        if t == 0:\n",
    "            adj_cost = 0\n",
    "        else:\n",
    "            adj_cost = np.abs(ell_new - ell[t-1])*iota\n",
    "        pi = kappa[t]*ell_new**(1-eta) - w*ell_new - adj_cost\n",
    "        h_vals[k] += R**t * pi\n",
    "        ell[t] = ell_new\n",
    "\n",
    "H = np.mean(h_vals)\n",
    "print(f\"H = {H:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the *ex ante* expected value of the salon is approximately 2.488"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we consider policies on the form:\n",
    "\n",
    "$$\n",
    "\n",
    "\\ell_{t}=\\begin{cases}\n",
    "\\ell_t^{\\ast}  & \\text{if }\\left|\\ell_{t-1}-\\ell_t^{\\ast} \\right|>\\Delta\\\\\n",
    "\\ell_{t-1} & \\text{else }\n",
    "\\end{cases}\n",
    "\\\\\n",
    "\\text{where}\\,\\,\\ell_t^{\\ast} = \\left(\\frac{(1-\\eta)\\kappa_{t}}{w}\\right)^{\\frac{1}{\\eta}} \\\\\n",
    "\n",
    "$$\n",
    "With $\\Delta \\geq 0$ and $\\Delta = 0$ being the previous policy.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 3:** Calculate $H$ if the policy above was followed with $\\Delta = 0.05$. Does it improve profitability?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calcualte $H$, where $\\Delta = 0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H = 2.172\n"
     ]
    }
   ],
   "source": [
    "# Defining parameters\n",
    "Delta = 0.05\n",
    "\n",
    "# Set initial values\n",
    "kappa = np.ones(T+1)\n",
    "ell = np.zeros(T+1)\n",
    "h_vals = np.zeros(K)\n",
    "\n",
    "# Simulate shock series and calculate h for each\n",
    "for k in range(K):\n",
    "    eps = np.random.normal(loc=-0.5*sigma_eps**2, scale=sigma_eps, size=T+1)\n",
    "    for t in range(1, T+1):\n",
    "        kappa[t] = np.exp(rho*np.log(kappa[t-1]) + eps[t])\n",
    "    for t in range(T+1):\n",
    "        ell_new = ((1-eta)*kappa[t]/w)**(1/eta)\n",
    "        if t == 0:\n",
    "            adj_cost = 0\n",
    "        else:\n",
    "            if np.abs(ell_new - ell[t-1]) > Delta:\n",
    "                ell_new = np.round(ell_new, 2)\n",
    "                adj_cost = iota\n",
    "            else:\n",
    "                adj_cost = 0\n",
    "        pi = kappa[t]*ell_new**(1-eta) - w*ell_new - adj_cost\n",
    "        h_vals[k] += R**t * pi\n",
    "        ell[t] = ell_new\n",
    "\n",
    "H = np.mean(h_vals)\n",
    "print(f\"H = {H:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H$ is now a smaller value, which means that if the policy above was followed with $\\Delta = 0.05$, the profitability is not improved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Find the optimal $\\Delta$ maximizing $H$. Illustrate your result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the optimal $\\Delta$ that maximizes $H$, we try 100 different values of $\\Delta$ between 0 and 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Delta = 0.21\n",
      "H = 258.74\n"
     ]
    }
   ],
   "source": [
    "# Set initial values\n",
    "kappa = np.ones(T+1)\n",
    "ell = np.zeros(T+1)\n",
    "h_vals = np.zeros(K)\n",
    "\n",
    "for j, Delta in enumerate(np.linspace(0, 0.3, 100)):\n",
    "    for k in range(K):\n",
    "        eps = np.random.normal(loc=-0.5*sigma_eps**2, scale=sigma_eps, size=T+1)\n",
    "        for t in range(1, T+1):\n",
    "            kappa[t] = np.exp(rho*np.log(kappa[t-1]) + eps[t])\n",
    "        for t in range(T+1):\n",
    "            ell_new = ((1-eta)*kappa[t]/w)**(1/eta)\n",
    "            if t == 0:\n",
    "                adj_cost = 0\n",
    "            else:\n",
    "                if np.abs(ell_new - ell[t-1]) > Delta:\n",
    "                    ell_new = np.round(ell_new, 2)\n",
    "                    adj_cost = iota\n",
    "                else:\n",
    "                    adj_cost = 0\n",
    "            pi = kappa[t]*ell_new**(1-eta) - w*ell_new - adj_cost\n",
    "            h_vals[j] += R**t * pi\n",
    "            ell[t] = ell_new\n",
    "\n",
    "optimal_Delta = np.linspace(0, 0.3, 100)[np.argmax(h_vals)]\n",
    "H_optimal = np.max(h_vals)\n",
    "print(f\"Optimal Delta = {optimal_Delta:.2f}\")\n",
    "print(f\"H = {H_optimal:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value of $H$ is a lot higher than the values we have previously found, but the optimal value of $\\Delta$ is also a lot higher than the $\\Delta$ values used in the two previous questions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 5:** Suggest an alternative policy you believe might improve profitability. Implement and test your policy.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative policy that might improve profitability is to adjust the \n",
    "the number of hairdressers employed $\\ell_t$ based on the expected demand shock (forecast).\n",
    "\n",
    "We use a forecast of $\\log \\kappa_{t+1}$ based on $\\log \\kappa_t$ and the estimated parameters for AR(1). Then, we use the forecast to calculate the optimal number of hairdressers employed $\\ell_t^{\\ast}$, subject to the adjustment cost $\\iota$.\n",
    "\n",
    "This policy uses a 'noisy' forecast of future demand, so it might not always perform better than the other policies, but it has the potential to be more adaptive to changing demand conditions as it takes expected future shocks into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Delta = 0.26\n",
      "H = 229.56\n"
     ]
    }
   ],
   "source": [
    "kappa = np.ones(T+1)\n",
    "ell = np.zeros(T+1)\n",
    "h_vals = np.zeros(K)\n",
    "\n",
    "def forecast_kappa(log_kappa_t, eps_t):\n",
    "    return rho*log_kappa_t - 0.5*sigma_eps**2 + eps_t\n",
    "\n",
    "for j, Delta in enumerate(np.linspace(0, 0.3, 100)):\n",
    "    for k in range(K):\n",
    "        eps = np.random.normal(loc=-0.5*sigma_eps**2, scale=sigma_eps, size=T+1)\n",
    "        for t in range(1, T+1):\n",
    "            kappa[t] = np.exp(forecast_kappa(np.log(kappa[t-1]), eps[t]))\n",
    "            ell_new = ((1-eta)*kappa[t]/w)**(1/eta)\n",
    "            if t == 0:\n",
    "                adj_cost = 0\n",
    "            else:\n",
    "                if np.abs(ell_new - ell[t-1]) > Delta:\n",
    "                    ell_new = np.round(ell_new, 2)\n",
    "                    adj_cost = iota\n",
    "                else:\n",
    "                    adj_cost = 0\n",
    "            pi = kappa[t]*ell_new**(1-eta) - w*ell_new - adj_cost\n",
    "            h_vals[j] += R**t * pi\n",
    "            ell[t] = ell_new\n",
    "\n",
    "optimal_Delta = np.linspace(0, 0.3, 100)[np.argmax(h_vals)]\n",
    "H_optimal = np.max(h_vals)\n",
    "print(f\"Optimal Delta = {optimal_Delta:.2f}\")\n",
    "print(f\"H = {H_optimal:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that this alternative policy leads to a lower $H$ than in question 4 with the original policy. Therefore, we can conclude that adjusting the number of hairdressers employed based on the expected demand shock does not lead to higher profitability."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a id='toc3_'></a>[Problem 3: Global optimizer with refined multi-start](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the Griewank function:\n",
    "\n",
    "$$ f(\\boldsymbol{x}) = \\sum^n_{i=1} \\frac{x^2_i}{4000}-\\prod^n_{i=1}\\cos\\left(\\frac{x_i}{\\sqrt{i}}\\right)+1$$\n",
    "\n",
    "The **global minimum** of this function is $f(0,0) = 0$ (remember: $\\cos(0)=1$).<br>\n",
    "But the function also have a lot of **local minima**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def griewank(x):\n",
    "    return griewank_(x[0],x[1])\n",
    "    \n",
    "def griewank_(x1,x2):\n",
    "    A = x1**2/4000 + x2**2/4000\n",
    "    B = np.cos(x1/np.sqrt(1))*np.cos(x2/np.sqrt(2))\n",
    "    return A-B+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **refined global optimizer with multi-start** is:\n",
    "\n",
    "1. Choose *bounds* for $\\mathbf{x}$ and *tolerance* $\\tau > 0$.\n",
    "2. Choose number of *warm-up iterations*, $\\underline{K} > 0$ and *maximum number of iterations*, $K > \\underline{K}$.\n",
    "3. In each iteration for $k \\in \\{0,1,\\dots,K-1\\}$:\n",
    "\n",
    "    A. Draw random $\\mathbf{x}^k$ uniformly within chosen bounds.\n",
    "\n",
    "    B. If $k < \\underline{K}$ go to step E.\n",
    "\n",
    "    C. Calculate $\\chi^k = 0.50\\cdot\\frac{2}{1+\\exp((k-\\underline{K})/100)}$  \n",
    "\n",
    "    D. Set $\\mathbf{x}^{k0} = \\chi^k \\mathbf{x}^k + (1-\\chi^k)\\mathbf{x}^{\\ast} $\n",
    "\n",
    "    E. Run optimizer with $\\mathbf{x}^{k0}$ as initial guess and $\\mathbf{x}^{k\\ast}$ as result.\n",
    "\n",
    "    F. Set $\\mathbf{x}^{\\ast} = \\mathbf{x}^{k\\ast}$ if $k = 0$ or $f(\\mathbf{x}^{k\\ast}) < f(\\mathbf{x}^{\\ast})$\n",
    "\n",
    "    G. If $f(\\mathbf{x}^{\\ast}) < \\tau$ go to step 4.\n",
    "\n",
    "4. Return the result $\\mathbf{x}^{\\ast}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As settings we choose:\n",
    "\n",
    "* $x_1,x_2 \\in  [-600,600]$\n",
    "* $\\tau = 10^{-8}$\n",
    "* $\\underline{K}=10$\n",
    "* $K=1000$\n",
    "\n",
    "The optimizer in Step 3.E is `BFGS` with a tolerance of $\\tau$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Implement the refined global optimizer with multi-start. Illustrate how the effective initial guesses $\\mathbf{x}^{k0}$ vary with the iteration counter $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def griewank(x):\n",
    "    return (x[0]**2/4000 + x[1]**2/4000\n",
    "            - np.cos(x[0]/np.sqrt(1)) * np.cos(x[1]/np.sqrt(2)) + 1)\n",
    "\n",
    "def global_opt(bounds, tau, K, K_warmup):\n",
    "    # Initialize best solution and value\n",
    "    x_best = None\n",
    "    f_best = np.inf\n",
    "\n",
    "    # Warm-up iterations without refinement step\n",
    "    for k in range(K_warmup):\n",
    "        # Draw random guess within bounds\n",
    "        x0 = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "        # Minimize function with BFGS\n",
    "        res = minimize(griewank, x0, method=\"BFGS\", tol=tau)\n",
    "\n",
    "        # Update best solution and value\n",
    "        if res.fun < f_best:\n",
    "            x_best = res.x\n",
    "            f_best = res.fun\n",
    "\n",
    "    # Refinement iterations with adjusted guess\n",
    "    for k in range(K_warmup, K):\n",
    "        # Draw random guess within bounds\n",
    "        xk = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "\n",
    "        if k == K_warmup:\n",
    "            # First refinement step\n",
    "            x_ref = x_best\n",
    "        else:\n",
    "            # Calculate chi_k\n",
    "            chi_k = 0.5*2/(1+np.exp((k - K_warmup)/100))\n",
    "\n",
    "            # Adjust initial guess\n",
    "            x_ref = chi_k * xk + (1 - chi_k) * x_best\n",
    "\n",
    "        # Minimize function with BFGS\n",
    "        res = minimize(griewank, x_ref, method=\"BFGS\", tol=tau)\n",
    "\n",
    "        # Update best solution if improvement\n",
    "        if res.fun < f_best:\n",
    "            x_best = res.x\n",
    "            f_best = res.fun\n",
    "\n",
    "        # Print current best value and effective initial guess\n",
    "        print(f\"iteration {k}: f_best = {f_best:.8f}\")\n",
    "        print(f\"           x_eff  = {x_ref},\\n\")\n",
    "\n",
    "    return x_best, f_best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function global_opt takes three arguments: bounds is a 2-by-2 array containing the lower and upper bounds for the variables $x_1$ and $x_2$, tau is the tolerance for the optimization, and K is the maximum number of iterations (including warm-up iterations) and K_warmup is the number of warm-up iterations before refinements start.\n",
    "The function first performs K_warmup iterations without the refinement step described in Step 3.D of the algorithm. This is done to collect some starting points that are then used for the refinement iterations. The best solution found during the warm-up iterations is stored in x_best and f_best .\n",
    "Then, the refinement iterations are done from iteration K_warmup up to K . In each iteration, a new point xk is drawn uniformly within the bounds. If this is the first refinement step (k==K_warmup ), then x_best is used as the reference point x_ref . Otherwise, a parameter chi_k is calculated and used to adjust a linear combination of the new point and the previous best point. The adjusted point x_ref is then used as the initial guess for a new optimization with BFGS. The best solution found during the refinement iterations is again stored in x_best and f_best , but only if it improves upon the previous best solution.\n",
    "Finally, the function prints the current best value and the effective initial guess used for the most recent optimization. The effective initial guess is either the best point found during the warm-up iterations, or an adjusted point that is a linear combination of the new point and the best point found so far.\n",
    "To illustrate how the effective initial guesses vary with the iteration counter k , we can call the function global_opt with some arbitrary parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10: f_best = 1.30923682\n",
      "           x_eff  = [-53.38036582  48.8228623 ],\n",
      "\n",
      "iteration 11: f_best = 1.30923682\n",
      "           x_eff  = [-20.54120643 322.8715655 ],\n",
      "\n",
      "iteration 12: f_best = 1.30923682\n",
      "           x_eff  = [-109.93554494 -191.52079119],\n",
      "\n",
      "iteration 13: f_best = 1.30923682\n",
      "           x_eff  = [ 100.04450164 -237.7290499 ],\n",
      "\n",
      "iteration 14: f_best = 1.30923682\n",
      "           x_eff  = [-279.885912    172.18535277],\n",
      "\n",
      "iteration 15: f_best = 1.30923682\n",
      "           x_eff  = [-159.90189351 -261.71874695],\n",
      "\n",
      "iteration 16: f_best = 1.30923682\n",
      "           x_eff  = [-264.25270802  222.59523681],\n",
      "\n",
      "iteration 17: f_best = 1.30923682\n",
      "           x_eff  = [-184.9910484    13.93621059],\n",
      "\n",
      "iteration 18: f_best = 1.30923682\n",
      "           x_eff  = [ 252.97016342 -173.24076466],\n",
      "\n",
      "iteration 19: f_best = 1.30923682\n",
      "           x_eff  = [234.14520112  97.14606654],\n",
      "\n",
      "iteration 20: f_best = 1.30923682\n",
      "           x_eff  = [-208.91366978  257.11683649],\n",
      "\n",
      "iteration 21: f_best = 0.35497049\n",
      "           x_eff  = [ 10.28341165 -35.50473635],\n",
      "\n",
      "iteration 22: f_best = 0.35497049\n",
      "           x_eff  = [-116.75073038  -67.95059875],\n",
      "\n",
      "iteration 23: f_best = 0.35497049\n",
      "           x_eff  = [-60.53145169 -67.78842617],\n",
      "\n",
      "iteration 24: f_best = 0.35497049\n",
      "           x_eff  = [-72.04342925  94.16267862],\n",
      "\n",
      "iteration 25: f_best = 0.35497049\n",
      "           x_eff  = [239.27539377  28.06528592],\n",
      "\n",
      "iteration 26: f_best = 0.35497049\n",
      "           x_eff  = [-117.02167258  225.50544264],\n",
      "\n",
      "iteration 27: f_best = 0.35497049\n",
      "           x_eff  = [-193.22697891   56.17539775],\n",
      "\n",
      "iteration 28: f_best = 0.35497049\n",
      "           x_eff  = [-200.49523609 -220.38528034],\n",
      "\n",
      "iteration 29: f_best = 0.35497049\n",
      "           x_eff  = [ 172.08208619 -143.0808104 ],\n",
      "\n",
      "iteration 30: f_best = 0.35497049\n",
      "           x_eff  = [-238.63687989  -71.96780926],\n",
      "\n",
      "iteration 31: f_best = 0.35497049\n",
      "           x_eff  = [-201.10789402  155.94618524],\n",
      "\n",
      "iteration 32: f_best = 0.35497049\n",
      "           x_eff  = [  14.24684502 -253.30967637],\n",
      "\n",
      "iteration 33: f_best = 0.35497049\n",
      "           x_eff  = [-229.65403602  -32.91389065],\n",
      "\n",
      "iteration 34: f_best = 0.35497049\n",
      "           x_eff  = [ -99.04786194 -198.92563352],\n",
      "\n",
      "iteration 35: f_best = 0.35497049\n",
      "           x_eff  = [-2.13001771 87.6657139 ],\n",
      "\n",
      "iteration 36: f_best = 0.35497049\n",
      "           x_eff  = [-114.63480214  -69.6245068 ],\n",
      "\n",
      "iteration 37: f_best = 0.35497049\n",
      "           x_eff  = [122.69239972 -62.2512465 ],\n",
      "\n",
      "iteration 38: f_best = 0.35497049\n",
      "           x_eff  = [ -64.01239459 -128.68559004],\n",
      "\n",
      "iteration 39: f_best = 0.35497049\n",
      "           x_eff  = [-60.18784932 -79.08407074],\n",
      "\n",
      "iteration 40: f_best = 0.35497049\n",
      "           x_eff  = [223.96734792 -33.75306086],\n",
      "\n",
      "iteration 41: f_best = 0.35497049\n",
      "           x_eff  = [216.72803769  67.99960203],\n",
      "\n",
      "iteration 42: f_best = 0.35497049\n",
      "           x_eff  = [184.39167921   2.32474065],\n",
      "\n",
      "iteration 43: f_best = 0.35497049\n",
      "           x_eff  = [-45.84118724 207.6075054 ],\n",
      "\n",
      "iteration 44: f_best = 0.35497049\n",
      "           x_eff  = [  -0.69094235 -102.57530631],\n",
      "\n",
      "iteration 45: f_best = 0.35497049\n",
      "           x_eff  = [-83.23774188  84.98819152],\n",
      "\n",
      "iteration 46: f_best = 0.35497049\n",
      "           x_eff  = [-124.84690689 -111.74483511],\n",
      "\n",
      "iteration 47: f_best = 0.35497049\n",
      "           x_eff  = [-65.52595229 -32.10489662],\n",
      "\n",
      "iteration 48: f_best = 0.35497049\n",
      "           x_eff  = [-222.17430031 -136.68766133],\n",
      "\n",
      "iteration 49: f_best = 0.35497049\n",
      "           x_eff  = [-47.35808244  86.81104986],\n",
      "\n",
      "iteration 50: f_best = 0.35497049\n",
      "           x_eff  = [-164.63433922   52.4502016 ],\n",
      "\n",
      "iteration 51: f_best = 0.35497049\n",
      "           x_eff  = [183.79669922 -36.99221924],\n",
      "\n",
      "iteration 52: f_best = 0.35497049\n",
      "           x_eff  = [157.29778462 144.11476208],\n",
      "\n",
      "iteration 53: f_best = 0.35497049\n",
      "           x_eff  = [ 115.69256573 -137.14893825],\n",
      "\n",
      "iteration 54: f_best = 0.35497049\n",
      "           x_eff  = [ 59.8665224  -52.91762799],\n",
      "\n",
      "iteration 55: f_best = 0.35497049\n",
      "           x_eff  = [ 25.931124 124.025605],\n",
      "\n",
      "iteration 56: f_best = 0.35497049\n",
      "           x_eff  = [ 72.63108606 156.32800425],\n",
      "\n",
      "iteration 57: f_best = 0.35497049\n",
      "           x_eff  = [ 178.16807746 -229.8592742 ],\n",
      "\n",
      "iteration 58: f_best = 0.35497049\n",
      "           x_eff  = [ -54.90748614 -184.50829648],\n",
      "\n",
      "iteration 59: f_best = 0.35497049\n",
      "           x_eff  = [-36.01325745 -32.00707788],\n",
      "\n",
      "iteration 60: f_best = 0.35497049\n",
      "           x_eff  = [-169.14804386   12.16125689],\n",
      "\n",
      "iteration 61: f_best = 0.35497049\n",
      "           x_eff  = [-152.13840823 -227.26344579],\n",
      "\n",
      "iteration 62: f_best = 0.35497049\n",
      "           x_eff  = [208.47890631 -43.05418663],\n",
      "\n",
      "iteration 63: f_best = 0.35497049\n",
      "           x_eff  = [-193.37387735 -241.55752601],\n",
      "\n",
      "iteration 64: f_best = 0.35497049\n",
      "           x_eff  = [-76.72405131 138.4197547 ],\n",
      "\n",
      "iteration 65: f_best = 0.35497049\n",
      "           x_eff  = [-129.88488553  -88.18480538],\n",
      "\n",
      "iteration 66: f_best = 0.35497049\n",
      "           x_eff  = [216.98144652  82.57897072],\n",
      "\n",
      "iteration 67: f_best = 0.35497049\n",
      "           x_eff  = [141.2840163 -97.7004896],\n",
      "\n",
      "iteration 68: f_best = 0.35497049\n",
      "           x_eff  = [156.98747456 -33.5184108 ],\n",
      "\n",
      "iteration 69: f_best = 0.35497049\n",
      "           x_eff  = [-83.3452925   -2.51855305],\n",
      "\n",
      "iteration 70: f_best = 0.35497049\n",
      "           x_eff  = [ 152.84538769 -199.20804174],\n",
      "\n",
      "iteration 71: f_best = 0.35497049\n",
      "           x_eff  = [217.39466192  27.82649475],\n",
      "\n",
      "iteration 72: f_best = 0.35497049\n",
      "           x_eff  = [-149.62802365  -54.14238461],\n",
      "\n",
      "iteration 73: f_best = 0.35497049\n",
      "           x_eff  = [-47.40644309  -2.51994454],\n",
      "\n",
      "iteration 74: f_best = 0.35497049\n",
      "           x_eff  = [-60.94794484 -23.12784922],\n",
      "\n",
      "iteration 75: f_best = 0.35497049\n",
      "           x_eff  = [-56.23136374  45.89911007],\n",
      "\n",
      "iteration 76: f_best = 0.35497049\n",
      "           x_eff  = [ 37.02661665 -70.46370312],\n",
      "\n",
      "iteration 77: f_best = 0.35497049\n",
      "           x_eff  = [58.06145089 22.28156316],\n",
      "\n",
      "iteration 78: f_best = 0.35497049\n",
      "           x_eff  = [-183.15741865  -89.94025753],\n",
      "\n",
      "iteration 79: f_best = 0.35497049\n",
      "           x_eff  = [-77.67613954  69.58205016],\n",
      "\n",
      "iteration 80: f_best = 0.35497049\n",
      "           x_eff  = [-108.93282589  -72.12426871],\n",
      "\n",
      "iteration 81: f_best = 0.35497049\n",
      "           x_eff  = [  29.5210964  -109.26010523],\n",
      "\n",
      "iteration 82: f_best = 0.35497049\n",
      "           x_eff  = [ 185.81542576 -219.1314528 ],\n",
      "\n",
      "iteration 83: f_best = 0.35497049\n",
      "           x_eff  = [202.59151825 -12.84385627],\n",
      "\n",
      "iteration 84: f_best = 0.35497049\n",
      "           x_eff  = [161.13366914  57.93500205],\n",
      "\n",
      "iteration 85: f_best = 0.35497049\n",
      "           x_eff  = [-18.17543313 154.49244292],\n",
      "\n",
      "iteration 86: f_best = 0.16521108\n",
      "           x_eff  = [-24.09303681 -14.91948609],\n",
      "\n",
      "iteration 87: f_best = 0.16521108\n",
      "           x_eff  = [ 109.57711658 -150.37943826],\n",
      "\n",
      "iteration 88: f_best = 0.16521108\n",
      "           x_eff  = [-77.95367189 126.90011708],\n",
      "\n",
      "iteration 89: f_best = 0.16521108\n",
      "           x_eff  = [-193.92095043   92.30796374],\n",
      "\n",
      "iteration 90: f_best = 0.16521108\n",
      "           x_eff  = [-42.53408886  44.89174292],\n",
      "\n",
      "iteration 91: f_best = 0.16521108\n",
      "           x_eff  = [-112.62463737 -172.17614128],\n",
      "\n",
      "iteration 92: f_best = 0.16521108\n",
      "           x_eff  = [-35.11287689  49.79066167],\n",
      "\n",
      "iteration 93: f_best = 0.16521108\n",
      "           x_eff  = [-135.59832185   40.34160029],\n",
      "\n",
      "iteration 94: f_best = 0.16521108\n",
      "           x_eff  = [-34.85403019 -16.77282087],\n",
      "\n",
      "iteration 95: f_best = 0.16521108\n",
      "           x_eff  = [  68.18558666 -188.39950773],\n",
      "\n",
      "iteration 96: f_best = 0.16521108\n",
      "           x_eff  = [ -54.89526467 -159.78387808],\n",
      "\n",
      "iteration 97: f_best = 0.16521108\n",
      "           x_eff  = [124.56883421 146.95940329],\n",
      "\n",
      "iteration 98: f_best = 0.16521108\n",
      "           x_eff  = [-161.91150303   -1.56212756],\n",
      "\n",
      "iteration 99: f_best = 0.16521108\n",
      "           x_eff  = [124.18781539 -81.59503953],\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bounds = np.array([[-600, 600], [-600, 600]])\n",
    "tau = 1e-8\n",
    "K_warmup = 10\n",
    "K = 100\n",
    "\n",
    "x_best, f_best = global_opt(bounds, tau, K, K_warmup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will perform 10 warm-up iterations and 90 refinement iterations with adjusted initial guesses. We can plot the effective initial guesses for these iterations as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot effective initial guesses\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x_best[0], x_best[1], color=\"orange\", s=50, label=\"Final solution\")\n",
    "plt.scatter(bounds[:, 0], bounds[:, 0], color=\"red\", s=50, label=\"Bounds\")\n",
    "plt.scatter(bounds[:, 1], bounds[:, 1], color=\"red\", s=50)\n",
    "for k in range(K):\n",
    "    if k < K_warmup:\n",
    "        # Use best point from warm-up iterations as reference\n",
    "        x_ref = x_best\n",
    "    else:\n",
    "        # Calculate chi_k\n",
    "        chi_k = 0.5*2/(1+np.exp((k - K_warmup)/100))\n",
    "\n",
    "        # Adjust initial guess\n",
    "        xk = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "        x_ref = chi_k * xk + (1 - chi_k) * x_best\n",
    "\n",
    "    plt.scatter(x_ref[0], x_ref[1], color=\"green\", \n",
    "                alpha=0.2, s=5)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(bounds[0])\n",
    "plt.ylim(bounds[1])\n",
    "plt.xlabel(r\"$x_1$\")\n",
    "plt.ylabel(r\"$x_2$\")\n",
    "plt.title(\"Effective initial guesses\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will produce a plot that shows the bounds, the final solution, and all the effective initial guesses used during the optimization. The color of each point indicates the iteration number, with green for refinement steps and orange for the final solution from the last iteration:\n",
    "Effective initial guesses\n",
    "As we can see, the effective initial guesses are clustered around the final solution towards the end of the optimization. In the beginning of the optimization, they are spread out more, but still tend to center around the best point found during the warm-up iterations. The adjustment parameter chi_k controls the degree of diffusion away from the previous best point. It starts at 0.5 in the first refinement iteration, which means that the new point and the previous best point are given equal weight in the adjusted initial guess. As k increases, chi_k decreases and the adjusted initial guess becomes more dependent on the previous best point. The effect of this can be seen in the plot, as the green points become more concentrated around the final solution towards the end of the optimization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Is it a better idea to set $\\underline{K} = 100$? Is the convergence faster?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer question 2, we can compare the performance of the refined global optimizer with K_warmup=10 and K=1000 to the version with K_warmup=100 and K=1000 on the Griewank function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10: f_best = 1.66712946\n",
      "           x_eff  = [-8.16405774e+01 -2.72833912e-08],\n",
      "\n",
      "iteration 11: f_best = 1.66712946\n",
      "           x_eff  = [  52.71365833 -222.35430568],\n",
      "\n",
      "iteration 12: f_best = 1.66712946\n",
      "           x_eff  = [-322.86879638  153.25467149],\n",
      "\n",
      "iteration 13: f_best = 1.66712946\n",
      "           x_eff  = [-232.71841665   -1.60372989],\n",
      "\n",
      "iteration 14: f_best = 1.66712946\n",
      "           x_eff  = [163.21540682 -37.53304566],\n",
      "\n",
      "iteration 15: f_best = 1.66712946\n",
      "           x_eff  = [-161.70401755  140.74225226],\n",
      "\n",
      "iteration 16: f_best = 1.66712946\n",
      "           x_eff  = [ 11.65736169 176.24661822],\n",
      "\n",
      "iteration 17: f_best = 1.66712946\n",
      "           x_eff  = [ 201.4279059  -216.69185328],\n",
      "\n",
      "iteration 18: f_best = 1.66712946\n",
      "           x_eff  = [163.77008041  17.77896112],\n",
      "\n",
      "iteration 19: f_best = 1.59727821\n",
      "           x_eff  = [-0.10653869 81.32162   ],\n",
      "\n",
      "iteration 20: f_best = 1.59727821\n",
      "           x_eff  = [233.76738566  68.41354379],\n",
      "\n",
      "iteration 21: f_best = 1.59727821\n",
      "           x_eff  = [ 185.77355939 -212.51141414],\n",
      "\n",
      "iteration 22: f_best = 1.59727821\n",
      "           x_eff  = [-66.24043577 -89.8577771 ],\n",
      "\n",
      "iteration 23: f_best = 1.59727821\n",
      "           x_eff  = [220.19770936 -83.28571598],\n",
      "\n",
      "iteration 24: f_best = 1.59727821\n",
      "           x_eff  = [ -2.91473998 198.02344473],\n",
      "\n",
      "iteration 25: f_best = 1.59727821\n",
      "           x_eff  = [ -98.18142456 -206.97238535],\n",
      "\n",
      "iteration 26: f_best = 1.59727821\n",
      "           x_eff  = [-52.14958696 152.36987365],\n",
      "\n",
      "iteration 27: f_best = 1.59727821\n",
      "           x_eff  = [216.42438111 -60.25123422],\n",
      "\n",
      "iteration 28: f_best = 1.59727821\n",
      "           x_eff  = [249.86639616  81.83939376],\n",
      "\n",
      "iteration 29: f_best = 1.59727821\n",
      "           x_eff  = [-108.63170552 -202.16594016],\n",
      "\n",
      "iteration 30: f_best = 1.59727821\n",
      "           x_eff  = [146.68603851  28.03388628],\n",
      "\n",
      "iteration 31: f_best = 1.59727821\n",
      "           x_eff  = [-167.26034233  226.6469313 ],\n",
      "\n",
      "iteration 32: f_best = 1.59727821\n",
      "           x_eff  = [-253.02814392  243.45977446],\n",
      "\n",
      "iteration 33: f_best = 1.59727821\n",
      "           x_eff  = [-137.29990685 -197.93285942],\n",
      "\n",
      "iteration 34: f_best = 1.59727821\n",
      "           x_eff  = [-132.84934826  -37.29776692],\n",
      "\n",
      "iteration 35: f_best = 1.59727821\n",
      "           x_eff  = [-124.94306768 -142.81163136],\n",
      "\n",
      "iteration 36: f_best = 1.59727821\n",
      "           x_eff  = [201.22236266  87.20777795],\n",
      "\n",
      "iteration 37: f_best = 1.59727821\n",
      "           x_eff  = [ 141.76552044 -100.81580839],\n",
      "\n",
      "iteration 38: f_best = 1.59727821\n",
      "           x_eff  = [-39.9910113  110.20794885],\n",
      "\n",
      "iteration 39: f_best = 1.59727821\n",
      "           x_eff  = [ 29.12041573 100.32873702],\n",
      "\n",
      "iteration 40: f_best = 1.59727821\n",
      "           x_eff  = [ 218.88869792 -200.056546  ],\n",
      "\n",
      "iteration 41: f_best = 1.59727821\n",
      "           x_eff  = [ 188.5516305  -137.67265281],\n",
      "\n",
      "iteration 42: f_best = 1.59727821\n",
      "           x_eff  = [74.05884154 79.73770264],\n",
      "\n",
      "iteration 43: f_best = 1.59727821\n",
      "           x_eff  = [181.43845073 -82.77282918],\n",
      "\n",
      "iteration 44: f_best = 0.10850154\n",
      "           x_eff  = [-18.25599552   7.62770301],\n",
      "\n",
      "iteration 45: f_best = 0.10850154\n",
      "           x_eff  = [-104.82822251  199.61627551],\n",
      "\n",
      "iteration 46: f_best = 0.10850154\n",
      "           x_eff  = [196.63109112 101.37452791],\n",
      "\n",
      "iteration 47: f_best = 0.10850154\n",
      "           x_eff  = [  3.83648152 181.69872889],\n",
      "\n",
      "iteration 48: f_best = 0.10850154\n",
      "           x_eff  = [ -40.96774725 -115.61102337],\n",
      "\n",
      "iteration 49: f_best = 0.10850154\n",
      "           x_eff  = [-96.9119313   84.86521054],\n",
      "\n",
      "iteration 50: f_best = 0.10850154\n",
      "           x_eff  = [140.8104416  -36.26361998],\n",
      "\n",
      "iteration 51: f_best = 0.10850154\n",
      "           x_eff  = [173.17096843 226.60040268],\n",
      "\n",
      "iteration 52: f_best = 0.10850154\n",
      "           x_eff  = [  43.57078192 -204.89225456],\n",
      "\n",
      "iteration 53: f_best = 0.10850154\n",
      "           x_eff  = [181.60776425  89.88604755],\n",
      "\n",
      "iteration 54: f_best = 0.10850154\n",
      "           x_eff  = [-173.7210154   -17.24574529],\n",
      "\n",
      "iteration 55: f_best = 0.10850154\n",
      "           x_eff  = [-179.77280774 -199.92583153],\n",
      "\n",
      "iteration 56: f_best = 0.10850154\n",
      "           x_eff  = [ 99.96585569 198.61568913],\n",
      "\n",
      "iteration 57: f_best = 0.10850154\n",
      "           x_eff  = [119.11840718 -22.37536397],\n",
      "\n",
      "iteration 58: f_best = 0.10850154\n",
      "           x_eff  = [28.09892436 19.12356832],\n",
      "\n",
      "iteration 59: f_best = 0.10850154\n",
      "           x_eff  = [104.44208236  37.28040041],\n",
      "\n",
      "iteration 60: f_best = 0.10850154\n",
      "           x_eff  = [ 62.93052973 -33.78497218],\n",
      "\n",
      "iteration 61: f_best = 0.10850154\n",
      "           x_eff  = [-25.94632365 108.55560533],\n",
      "\n",
      "iteration 62: f_best = 0.10850154\n",
      "           x_eff  = [ 61.05444956 136.00016673],\n",
      "\n",
      "iteration 63: f_best = 0.10850154\n",
      "           x_eff  = [  13.17546806 -169.74762944],\n",
      "\n",
      "iteration 64: f_best = 0.10850154\n",
      "           x_eff  = [69.14353799 74.75936668],\n",
      "\n",
      "iteration 65: f_best = 0.10850154\n",
      "           x_eff  = [-40.45376251 137.42575198],\n",
      "\n",
      "iteration 66: f_best = 0.10850154\n",
      "           x_eff  = [-133.90321282  192.81568411],\n",
      "\n",
      "iteration 67: f_best = 0.10850154\n",
      "           x_eff  = [125.23046984  -8.96198482],\n",
      "\n",
      "iteration 68: f_best = 0.10850154\n",
      "           x_eff  = [ -11.81081287 -130.68364743],\n",
      "\n",
      "iteration 69: f_best = 0.10850154\n",
      "           x_eff  = [-17.21809842 116.97972828],\n",
      "\n",
      "iteration 70: f_best = 0.10850154\n",
      "           x_eff  = [196.61502039  84.24025043],\n",
      "\n",
      "iteration 71: f_best = 0.10850154\n",
      "           x_eff  = [ 23.6729081  -39.08345379],\n",
      "\n",
      "iteration 72: f_best = 0.10850154\n",
      "           x_eff  = [-82.78355231 212.753556  ],\n",
      "\n",
      "iteration 73: f_best = 0.10850154\n",
      "           x_eff  = [  10.03591777 -117.73469091],\n",
      "\n",
      "iteration 74: f_best = 0.10850154\n",
      "           x_eff  = [71.97371573 88.92166746],\n",
      "\n",
      "iteration 75: f_best = 0.10850154\n",
      "           x_eff  = [-90.68105479 180.55003257],\n",
      "\n",
      "iteration 76: f_best = 0.10850154\n",
      "           x_eff  = [149.06853646 -95.74288333],\n",
      "\n",
      "iteration 77: f_best = 0.10850154\n",
      "           x_eff  = [-158.97441269  178.23975839],\n",
      "\n",
      "iteration 78: f_best = 0.10850154\n",
      "           x_eff  = [-133.70471319  -46.31831749],\n",
      "\n",
      "iteration 79: f_best = 0.10850154\n",
      "           x_eff  = [-14.66937602  57.09834044],\n",
      "\n",
      "iteration 80: f_best = 0.10850154\n",
      "           x_eff  = [-109.21254995  153.87048161],\n",
      "\n",
      "iteration 81: f_best = 0.10850154\n",
      "           x_eff  = [14.84415409 41.42936209],\n",
      "\n",
      "iteration 82: f_best = 0.10850154\n",
      "           x_eff  = [-76.7606715   99.57945197],\n",
      "\n",
      "iteration 83: f_best = 0.10850154\n",
      "           x_eff  = [-188.32519327  -82.21143906],\n",
      "\n",
      "iteration 84: f_best = 0.10850154\n",
      "           x_eff  = [-139.83940386  -16.86312137],\n",
      "\n",
      "iteration 85: f_best = 0.10850154\n",
      "           x_eff  = [-201.62365857   71.60543671],\n",
      "\n",
      "iteration 86: f_best = 0.10850154\n",
      "           x_eff  = [  89.31310147 -171.43907014],\n",
      "\n",
      "iteration 87: f_best = 0.10850154\n",
      "           x_eff  = [-157.09249823  153.28484163],\n",
      "\n",
      "iteration 88: f_best = 0.10850154\n",
      "           x_eff  = [ 160.50261146 -127.01830114],\n",
      "\n",
      "iteration 89: f_best = 0.10850154\n",
      "           x_eff  = [ -50.47271568 -139.4269849 ],\n",
      "\n",
      "iteration 90: f_best = 0.10850154\n",
      "           x_eff  = [-196.10007274   17.14718691],\n",
      "\n",
      "iteration 91: f_best = 0.10850154\n",
      "           x_eff  = [ 30.32985404 -54.14124159],\n",
      "\n",
      "iteration 92: f_best = 0.10850154\n",
      "           x_eff  = [-68.88349443  19.49176242],\n",
      "\n",
      "iteration 93: f_best = 0.10850154\n",
      "           x_eff  = [ 59.9008114  -98.50447759],\n",
      "\n",
      "iteration 94: f_best = 0.10850154\n",
      "           x_eff  = [-152.1262585    35.59622762],\n",
      "\n",
      "iteration 95: f_best = 0.10850154\n",
      "           x_eff  = [-76.39543064  24.64459953],\n",
      "\n",
      "iteration 96: f_best = 0.10850154\n",
      "           x_eff  = [-154.25448483 -163.05747861],\n",
      "\n",
      "iteration 97: f_best = 0.10850154\n",
      "           x_eff  = [-6.09151076 76.90032424],\n",
      "\n",
      "iteration 98: f_best = 0.10850154\n",
      "           x_eff  = [ 141.95111605 -169.0180523 ],\n",
      "\n",
      "iteration 99: f_best = 0.10850154\n",
      "           x_eff  = [-124.66575864  164.09022131],\n",
      "\n",
      "iteration 100: f_best = 0.10850154\n",
      "           x_eff  = [-99.50267109  40.50278352],\n",
      "\n",
      "iteration 101: f_best = 0.10850154\n",
      "           x_eff  = [-74.14248507  89.33047821],\n",
      "\n",
      "iteration 102: f_best = 0.10850154\n",
      "           x_eff  = [22.1013589  -4.10948541],\n",
      "\n",
      "iteration 103: f_best = 0.10850154\n",
      "           x_eff  = [-60.38128883  39.87406522],\n",
      "\n",
      "iteration 104: f_best = 0.10850154\n",
      "           x_eff  = [-31.83192218 144.77315366],\n",
      "\n",
      "iteration 105: f_best = 0.10850154\n",
      "           x_eff  = [-99.18431879 -11.39613781],\n",
      "\n",
      "iteration 106: f_best = 0.10850154\n",
      "           x_eff  = [ 36.79382066 -14.43275212],\n",
      "\n",
      "iteration 107: f_best = 0.10850154\n",
      "           x_eff  = [-50.57422253 135.35521921],\n",
      "\n",
      "iteration 108: f_best = 0.10850154\n",
      "           x_eff  = [119.84602375 137.8715411 ],\n",
      "\n",
      "iteration 109: f_best = 0.10850154\n",
      "           x_eff  = [  33.99286968 -129.37239143],\n",
      "\n",
      "iteration 110: f_best = 0.10850154\n",
      "           x_eff  = [81.41754603 65.46150757],\n",
      "\n",
      "iteration 111: f_best = 0.10850154\n",
      "           x_eff  = [  67.21654304 -125.08105261],\n",
      "\n",
      "iteration 112: f_best = 0.10850154\n",
      "           x_eff  = [-164.57578436   86.73803216],\n",
      "\n",
      "iteration 113: f_best = 0.10850154\n",
      "           x_eff  = [ -67.41540185 -130.42032787],\n",
      "\n",
      "iteration 114: f_best = 0.10850154\n",
      "           x_eff  = [-85.58291611 111.04160366],\n",
      "\n",
      "iteration 115: f_best = 0.10850154\n",
      "           x_eff  = [134.60838806  32.36900234],\n",
      "\n",
      "iteration 116: f_best = 0.10850154\n",
      "           x_eff  = [-126.80846101 -131.54213081],\n",
      "\n",
      "iteration 117: f_best = 0.10850154\n",
      "           x_eff  = [-151.18723652  -99.09959824],\n",
      "\n",
      "iteration 118: f_best = 0.10850154\n",
      "           x_eff  = [131.73896949 -22.28423346],\n",
      "\n",
      "iteration 119: f_best = 0.10850154\n",
      "           x_eff  = [  0.62307844 -72.37525756],\n",
      "\n",
      "iteration 120: f_best = 0.10850154\n",
      "           x_eff  = [104.34630039 -29.07741791],\n",
      "\n",
      "iteration 121: f_best = 0.10850154\n",
      "           x_eff  = [-45.95422302  56.26790284],\n",
      "\n",
      "iteration 122: f_best = 0.10850154\n",
      "           x_eff  = [-96.13872221 -12.58691774],\n",
      "\n",
      "iteration 123: f_best = 0.10850154\n",
      "           x_eff  = [-149.52262391  139.80714948],\n",
      "\n",
      "iteration 124: f_best = 0.10850154\n",
      "           x_eff  = [  47.01884319 -117.62746509],\n",
      "\n",
      "iteration 125: f_best = 0.10850154\n",
      "           x_eff  = [-42.77686738  18.40853083],\n",
      "\n",
      "iteration 126: f_best = 0.10850154\n",
      "           x_eff  = [-156.02104333   -9.01520165],\n",
      "\n",
      "iteration 127: f_best = 0.10850154\n",
      "           x_eff  = [-111.35347871   88.9620029 ],\n",
      "\n",
      "iteration 128: f_best = 0.10850154\n",
      "           x_eff  = [110.55461779 -95.99509127],\n",
      "\n",
      "iteration 129: f_best = 0.10850154\n",
      "           x_eff  = [ -96.14378299 -117.33226477],\n",
      "\n",
      "iteration 130: f_best = 0.10850154\n",
      "           x_eff  = [35.22881641 69.76656391],\n",
      "\n",
      "iteration 131: f_best = 0.10850154\n",
      "           x_eff  = [-112.81777994 -126.05182825],\n",
      "\n",
      "iteration 132: f_best = 0.10850154\n",
      "           x_eff  = [-149.43412819  101.40613364],\n",
      "\n",
      "iteration 133: f_best = 0.10850154\n",
      "           x_eff  = [30.05372909 79.00480772],\n",
      "\n",
      "iteration 134: f_best = 0.10850154\n",
      "           x_eff  = [39.86730165 38.3000536 ],\n",
      "\n",
      "iteration 135: f_best = 0.10850154\n",
      "           x_eff  = [-113.19690606  -86.33552997],\n",
      "\n",
      "iteration 136: f_best = 0.10850154\n",
      "           x_eff  = [90.82915185  9.97515089],\n",
      "\n",
      "iteration 137: f_best = 0.10850154\n",
      "           x_eff  = [ 39.45400883 -19.31347273],\n",
      "\n",
      "iteration 138: f_best = 0.10850154\n",
      "           x_eff  = [-73.81191462 -87.96243775],\n",
      "\n",
      "iteration 139: f_best = 0.10850154\n",
      "           x_eff  = [ 69.29877541 -59.69386256],\n",
      "\n",
      "iteration 140: f_best = 0.10850154\n",
      "           x_eff  = [ -44.72503223 -110.70343812],\n",
      "\n",
      "iteration 141: f_best = 0.10850154\n",
      "           x_eff  = [58.88083578 -4.65812746],\n",
      "\n",
      "iteration 142: f_best = 0.10850154\n",
      "           x_eff  = [-111.60982545  -45.47533207],\n",
      "\n",
      "iteration 143: f_best = 0.10850154\n",
      "           x_eff  = [ 58.15413331 -93.97854194],\n",
      "\n",
      "iteration 144: f_best = 0.10850154\n",
      "           x_eff  = [-122.91074499   81.23053039],\n",
      "\n",
      "iteration 145: f_best = 0.10850154\n",
      "           x_eff  = [-52.36576969  98.19653523],\n",
      "\n",
      "iteration 146: f_best = 0.10850154\n",
      "           x_eff  = [ 7.66438322 78.30006827],\n",
      "\n",
      "iteration 147: f_best = 0.10850154\n",
      "           x_eff  = [-81.72655464  26.90465052],\n",
      "\n",
      "iteration 148: f_best = 0.10850154\n",
      "           x_eff  = [-64.89608341 -11.55705106],\n",
      "\n",
      "iteration 149: f_best = 0.10850154\n",
      "           x_eff  = [ 14.14260186 -46.46379037],\n",
      "\n",
      "iteration 150: f_best = 0.10850154\n",
      "           x_eff  = [-74.39591432 -44.10052789],\n",
      "\n",
      "iteration 151: f_best = 0.10850154\n",
      "           x_eff  = [-122.86800141  -57.23760111],\n",
      "\n",
      "iteration 152: f_best = 0.10850154\n",
      "           x_eff  = [76.8842234  84.23169822],\n",
      "\n",
      "iteration 153: f_best = 0.10850154\n",
      "           x_eff  = [ 92.97766751 -40.50410593],\n",
      "\n",
      "iteration 154: f_best = 0.10850154\n",
      "           x_eff  = [-37.68790725 119.61462213],\n",
      "\n",
      "iteration 155: f_best = 0.10850154\n",
      "           x_eff  = [-104.56044537   30.76707931],\n",
      "\n",
      "iteration 156: f_best = 0.10850154\n",
      "           x_eff  = [ 81.07956063 -10.26349121],\n",
      "\n",
      "iteration 157: f_best = 0.10850154\n",
      "           x_eff  = [ 38.7969693  -64.97683569],\n",
      "\n",
      "iteration 158: f_best = 0.10850154\n",
      "           x_eff  = [25.98900035 84.63459013],\n",
      "\n",
      "iteration 159: f_best = 0.10850154\n",
      "           x_eff  = [64.75861152 41.64098739],\n",
      "\n",
      "iteration 160: f_best = 0.10850154\n",
      "           x_eff  = [-112.57752989  -25.62934   ],\n",
      "\n",
      "iteration 161: f_best = 0.10850154\n",
      "           x_eff  = [ 13.19763329 -52.13771108],\n",
      "\n",
      "iteration 162: f_best = 0.10850154\n",
      "           x_eff  = [-107.9262024   70.441644 ],\n",
      "\n",
      "iteration 163: f_best = 0.10850154\n",
      "           x_eff  = [43.85643418 79.86629559],\n",
      "\n",
      "iteration 164: f_best = 0.10850154\n",
      "           x_eff  = [ 83.56767803 -44.13675901],\n",
      "\n",
      "iteration 165: f_best = 0.10850154\n",
      "           x_eff  = [14.7703754  69.97576213],\n",
      "\n",
      "iteration 166: f_best = 0.10850154\n",
      "           x_eff  = [-12.03177345 -72.84199582],\n",
      "\n",
      "iteration 167: f_best = 0.10850154\n",
      "           x_eff  = [ 69.89713779 -70.24810112],\n",
      "\n",
      "iteration 168: f_best = 0.10850154\n",
      "           x_eff  = [  0.81434962 -49.71238273],\n",
      "\n",
      "iteration 169: f_best = 0.10850154\n",
      "           x_eff  = [59.79387564 62.20348525],\n",
      "\n",
      "iteration 170: f_best = 0.10850154\n",
      "           x_eff  = [42.2557159  26.57327159],\n",
      "\n",
      "iteration 171: f_best = 0.10850154\n",
      "           x_eff  = [30.40713139  9.20445362],\n",
      "\n",
      "iteration 172: f_best = 0.10850154\n",
      "           x_eff  = [-50.64268871  78.68476799],\n",
      "\n",
      "iteration 173: f_best = 0.10850154\n",
      "           x_eff  = [20.05146704 78.59385046],\n",
      "\n",
      "iteration 174: f_best = 0.10850154\n",
      "           x_eff  = [30.13732214 66.69537596],\n",
      "\n",
      "iteration 175: f_best = 0.10850154\n",
      "           x_eff  = [ 41.01990679 -35.19425029],\n",
      "\n",
      "iteration 176: f_best = 0.10850154\n",
      "           x_eff  = [39.82403187 24.26914324],\n",
      "\n",
      "iteration 177: f_best = 0.10850154\n",
      "           x_eff  = [-86.23682493  40.26799917],\n",
      "\n",
      "iteration 178: f_best = 0.10850154\n",
      "           x_eff  = [-100.81448801  -57.88183136],\n",
      "\n",
      "iteration 179: f_best = 0.10850154\n",
      "           x_eff  = [52.90452778 57.51334379],\n",
      "\n",
      "iteration 180: f_best = 0.10850154\n",
      "           x_eff  = [ 31.55943258 -49.9353548 ],\n",
      "\n",
      "iteration 181: f_best = 0.10850154\n",
      "           x_eff  = [-75.27618738  59.06552627],\n",
      "\n",
      "iteration 182: f_best = 0.10850154\n",
      "           x_eff  = [-87.1998359   -8.90051962],\n",
      "\n",
      "iteration 183: f_best = 0.10850154\n",
      "           x_eff  = [36.38441344 66.44626531],\n",
      "\n",
      "iteration 184: f_best = 0.10850154\n",
      "           x_eff  = [-92.9999068   80.35381949],\n",
      "\n",
      "iteration 185: f_best = 0.10850154\n",
      "           x_eff  = [-74.16253668 -59.82943569],\n",
      "\n",
      "iteration 186: f_best = 0.10850154\n",
      "           x_eff  = [-79.71164925 -70.43163942],\n",
      "\n",
      "iteration 187: f_best = 0.10850154\n",
      "           x_eff  = [ 49.48820237 -10.89427942],\n",
      "\n",
      "iteration 188: f_best = 0.10850154\n",
      "           x_eff  = [-59.06520411 -78.09575819],\n",
      "\n",
      "iteration 189: f_best = 0.10850154\n",
      "           x_eff  = [43.21752051  9.67123675],\n",
      "\n",
      "iteration 190: f_best = 0.10850154\n",
      "           x_eff  = [-40.31280805  -6.43302327],\n",
      "\n",
      "iteration 191: f_best = 0.10850154\n",
      "           x_eff  = [51.68392657  1.83003713],\n",
      "\n",
      "iteration 192: f_best = 0.10850154\n",
      "           x_eff  = [ 65.82958709 -19.30423531],\n",
      "\n",
      "iteration 193: f_best = 0.10850154\n",
      "           x_eff  = [41.05330495  7.45422447],\n",
      "\n",
      "iteration 194: f_best = 0.10850154\n",
      "           x_eff  = [-32.6662547  -47.35919776],\n",
      "\n",
      "iteration 195: f_best = 0.10850154\n",
      "           x_eff  = [ 22.65117689 -49.49990253],\n",
      "\n",
      "iteration 196: f_best = 0.10850154\n",
      "           x_eff  = [-20.67458072  55.05261099],\n",
      "\n",
      "iteration 197: f_best = 0.10850154\n",
      "           x_eff  = [-86.94386068  77.76595498],\n",
      "\n",
      "iteration 198: f_best = 0.10850154\n",
      "           x_eff  = [-8.70612373 41.31819379],\n",
      "\n",
      "iteration 199: f_best = 0.10850154\n",
      "           x_eff  = [ 15.87682341 -60.69892137],\n",
      "\n",
      "iteration 200: f_best = 0.10850154\n",
      "           x_eff  = [-90.73952263 -45.17007684],\n",
      "\n",
      "iteration 201: f_best = 0.10850154\n",
      "           x_eff  = [-56.26493324  45.59078405],\n",
      "\n",
      "iteration 202: f_best = 0.10850154\n",
      "           x_eff  = [-82.6731273  -20.08041993],\n",
      "\n",
      "iteration 203: f_best = 0.10850154\n",
      "           x_eff  = [-45.0957352   20.50499668],\n",
      "\n",
      "iteration 204: f_best = 0.10850154\n",
      "           x_eff  = [-35.27555792  69.43117113],\n",
      "\n",
      "iteration 205: f_best = 0.10850154\n",
      "           x_eff  = [ 17.88233993 -19.25764233],\n",
      "\n",
      "iteration 206: f_best = 0.10850154\n",
      "           x_eff  = [-83.22858924 -55.32508129],\n",
      "\n",
      "iteration 207: f_best = 0.10850154\n",
      "           x_eff  = [-60.56543649  -9.19310437],\n",
      "\n",
      "iteration 208: f_best = 0.10850154\n",
      "           x_eff  = [-79.89117056  -8.35140901],\n",
      "\n",
      "iteration 209: f_best = 0.10850154\n",
      "           x_eff  = [-52.2716275  -39.27569034],\n",
      "\n",
      "iteration 210: f_best = 0.10850154\n",
      "           x_eff  = [ 46.29487522 -10.51736325],\n",
      "\n",
      "iteration 211: f_best = 0.10850154\n",
      "           x_eff  = [-38.70367548 -54.42222793],\n",
      "\n",
      "iteration 212: f_best = 0.10850154\n",
      "           x_eff  = [32.4135554   4.44408649],\n",
      "\n",
      "iteration 213: f_best = 0.10850154\n",
      "           x_eff  = [31.55354411 72.08075398],\n",
      "\n",
      "iteration 214: f_best = 0.10850154\n",
      "           x_eff  = [ 11.14235562 -42.15685107],\n",
      "\n",
      "iteration 215: f_best = 0.10850154\n",
      "           x_eff  = [-48.97864987  16.06913869],\n",
      "\n",
      "iteration 216: f_best = 0.10850154\n",
      "           x_eff  = [42.49685344 75.35989198],\n",
      "\n",
      "iteration 217: f_best = 0.10850154\n",
      "           x_eff  = [ 6.98111185 61.94025697],\n",
      "\n",
      "iteration 218: f_best = 0.10850154\n",
      "           x_eff  = [-57.72798089  55.0446807 ],\n",
      "\n",
      "iteration 219: f_best = 0.10850154\n",
      "           x_eff  = [-62.03241479 -29.17809052],\n",
      "\n",
      "iteration 220: f_best = 0.10850154\n",
      "           x_eff  = [-64.50280872 -12.44483585],\n",
      "\n",
      "iteration 221: f_best = 0.10850154\n",
      "           x_eff  = [-78.06103923 -11.76866793],\n",
      "\n",
      "iteration 222: f_best = 0.10850154\n",
      "           x_eff  = [23.22386652  6.8428598 ],\n",
      "\n",
      "iteration 223: f_best = 0.10850154\n",
      "           x_eff  = [-44.00705977 -34.58455381],\n",
      "\n",
      "iteration 224: f_best = 0.10850154\n",
      "           x_eff  = [ 12.23540387 -18.65171711],\n",
      "\n",
      "iteration 225: f_best = 0.06656436\n",
      "           x_eff  = [ 7.45479294 11.86065894],\n",
      "\n",
      "iteration 226: f_best = 0.06656436\n",
      "           x_eff  = [46.73933895 67.56432659],\n",
      "\n",
      "iteration 227: f_best = 0.06656436\n",
      "           x_eff  = [ 61.85417689 -20.33336993],\n",
      "\n",
      "iteration 228: f_best = 0.06656436\n",
      "           x_eff  = [53.79628993 72.82961423],\n",
      "\n",
      "iteration 229: f_best = 0.06656436\n",
      "           x_eff  = [ 62.54938779 -16.30224933],\n",
      "\n",
      "iteration 230: f_best = 0.06656436\n",
      "           x_eff  = [-38.67547675  -5.31865367],\n",
      "\n",
      "iteration 231: f_best = 0.06656436\n",
      "           x_eff  = [47.09058514 40.65964733],\n",
      "\n",
      "iteration 232: f_best = 0.06656436\n",
      "           x_eff  = [20.8774241   3.61904407],\n",
      "\n",
      "iteration 233: f_best = 0.06656436\n",
      "           x_eff  = [-13.46184533  26.20670203],\n",
      "\n",
      "iteration 234: f_best = 0.06656436\n",
      "           x_eff  = [66.06043535 56.4384304 ],\n",
      "\n",
      "iteration 235: f_best = 0.02712538\n",
      "           x_eff  = [-8.98137938 -1.20637467],\n",
      "\n",
      "iteration 236: f_best = 0.02712538\n",
      "           x_eff  = [ 27.29082421 -21.42239033],\n",
      "\n",
      "iteration 237: f_best = 0.02712538\n",
      "           x_eff  = [-61.13573883 -29.30130861],\n",
      "\n",
      "iteration 238: f_best = 0.02712538\n",
      "           x_eff  = [-48.46467753 -59.38052106],\n",
      "\n",
      "iteration 239: f_best = 0.02712538\n",
      "           x_eff  = [-48.19123971 -25.57899916],\n",
      "\n",
      "iteration 240: f_best = 0.02712538\n",
      "           x_eff  = [ -9.74359108 -50.70975724],\n",
      "\n",
      "iteration 241: f_best = 0.02712538\n",
      "           x_eff  = [ 10.17583661 -27.22988668],\n",
      "\n",
      "iteration 242: f_best = 0.02712538\n",
      "           x_eff  = [-15.5101169   18.58298556],\n",
      "\n",
      "iteration 243: f_best = 0.02712538\n",
      "           x_eff  = [ 17.75549994 -26.63679664],\n",
      "\n",
      "iteration 244: f_best = 0.00739604\n",
      "           x_eff  = [-4.79954121  4.84042888],\n",
      "\n",
      "iteration 245: f_best = 0.00739604\n",
      "           x_eff  = [ 33.84785995 -42.0844162 ],\n",
      "\n",
      "iteration 246: f_best = 0.00739604\n",
      "           x_eff  = [-5.4345454  26.17252048],\n",
      "\n",
      "iteration 247: f_best = 0.00739604\n",
      "           x_eff  = [-18.17211359 -32.34509955],\n",
      "\n",
      "iteration 248: f_best = 0.00739604\n",
      "           x_eff  = [ 27.79031421 -13.20339749],\n",
      "\n",
      "iteration 249: f_best = 0.00739604\n",
      "           x_eff  = [46.41025701  7.3840949 ],\n",
      "\n",
      "iteration 250: f_best = 0.00739604\n",
      "           x_eff  = [-31.52764787  24.11524919],\n",
      "\n",
      "iteration 251: f_best = 0.00739604\n",
      "           x_eff  = [19.21671838 37.05998595],\n",
      "\n",
      "iteration 252: f_best = 0.00739604\n",
      "           x_eff  = [45.49226117 12.98009776],\n",
      "\n",
      "iteration 253: f_best = 0.00739604\n",
      "           x_eff  = [-32.69420148 -12.80273987],\n",
      "\n",
      "iteration 254: f_best = 0.00739604\n",
      "           x_eff  = [ 14.73522003 -16.28822715],\n",
      "\n",
      "iteration 255: f_best = 0.00739604\n",
      "           x_eff  = [43.92375189 -8.97901683],\n",
      "\n",
      "iteration 256: f_best = 0.00739604\n",
      "           x_eff  = [-41.98706115  40.27390206],\n",
      "\n",
      "iteration 257: f_best = 0.00739604\n",
      "           x_eff  = [ 5.94894428 12.33907231],\n",
      "\n",
      "iteration 258: f_best = 0.00739604\n",
      "           x_eff  = [-30.74862226 -22.76129669],\n",
      "\n",
      "iteration 259: f_best = 0.00739604\n",
      "           x_eff  = [ 12.1514797  -31.68063961],\n",
      "\n",
      "iteration 260: f_best = 0.00739604\n",
      "           x_eff  = [-19.57298151 -31.28254522],\n",
      "\n",
      "iteration 261: f_best = 0.00739604\n",
      "           x_eff  = [-8.95446081 11.0274303 ],\n",
      "\n",
      "iteration 262: f_best = 0.00739604\n",
      "           x_eff  = [-40.57017662  35.44196647],\n",
      "\n",
      "iteration 263: f_best = 0.00739604\n",
      "           x_eff  = [35.2452112  7.8834823],\n",
      "\n",
      "iteration 264: f_best = 0.00739604\n",
      "           x_eff  = [  6.25474263 -22.00222476],\n",
      "\n",
      "iteration 265: f_best = 0.00739604\n",
      "           x_eff  = [-25.54265743  26.29367535],\n",
      "\n",
      "iteration 266: f_best = 0.00739604\n",
      "           x_eff  = [36.77509188  6.21043788],\n",
      "\n",
      "iteration 267: f_best = 0.00739604\n",
      "           x_eff  = [-33.53030722  -8.14979412],\n",
      "\n",
      "iteration 268: f_best = 0.00739604\n",
      "           x_eff  = [32.98319181 23.79986687],\n",
      "\n",
      "iteration 269: f_best = 0.00739604\n",
      "           x_eff  = [-24.92614311 -27.57506329],\n",
      "\n",
      "iteration 270: f_best = 0.00739604\n",
      "           x_eff  = [14.81519264 35.35855117],\n",
      "\n",
      "iteration 271: f_best = 0.00739604\n",
      "           x_eff  = [-18.9763543 -13.6028428],\n",
      "\n",
      "iteration 272: f_best = 0.00739604\n",
      "           x_eff  = [33.00225402 44.38589402],\n",
      "\n",
      "iteration 273: f_best = 0.00739604\n",
      "           x_eff  = [-17.19696797 -15.41699384],\n",
      "\n",
      "iteration 274: f_best = 0.00000000\n",
      "           x_eff  = [-3.37008462e-04 -3.13427144e+00],\n",
      "\n",
      "iteration 275: f_best = 0.00000000\n",
      "           x_eff  = [-26.10769278  -3.64437626],\n",
      "\n",
      "iteration 276: f_best = 0.00000000\n",
      "           x_eff  = [10.14931903  9.40498297],\n",
      "\n",
      "iteration 277: f_best = 0.00000000\n",
      "           x_eff  = [-28.9401388   32.33876567],\n",
      "\n",
      "iteration 278: f_best = 0.00000000\n",
      "           x_eff  = [-37.16302761  35.08624137],\n",
      "\n",
      "iteration 279: f_best = 0.00000000\n",
      "           x_eff  = [ 18.14062996 -14.90503763],\n",
      "\n",
      "iteration 280: f_best = 0.00000000\n",
      "           x_eff  = [-13.76382962 -21.18108193],\n",
      "\n",
      "iteration 281: f_best = 0.00000000\n",
      "           x_eff  = [-1.74048096  1.63169673],\n",
      "\n",
      "iteration 282: f_best = 0.00000000\n",
      "           x_eff  = [30.71636395 22.92513264],\n",
      "\n",
      "iteration 283: f_best = 0.00000000\n",
      "           x_eff  = [30.29430639 30.04001647],\n",
      "\n",
      "iteration 284: f_best = 0.00000000\n",
      "           x_eff  = [-15.6442991 -18.4376079],\n",
      "\n",
      "iteration 285: f_best = 0.00000000\n",
      "           x_eff  = [13.20226012  2.72908904],\n",
      "\n",
      "iteration 286: f_best = 0.00000000\n",
      "           x_eff  = [5.11695665 2.37504977],\n",
      "\n",
      "iteration 287: f_best = 0.00000000\n",
      "           x_eff  = [ 28.41827498 -33.0266322 ],\n",
      "\n",
      "iteration 288: f_best = 0.00000000\n",
      "           x_eff  = [-17.65304596 -25.50543552],\n",
      "\n",
      "iteration 289: f_best = 0.00000000\n",
      "           x_eff  = [-12.51965712  -3.63368487],\n",
      "\n",
      "iteration 290: f_best = 0.00000000\n",
      "           x_eff  = [ 25.03832073 -21.11361567],\n",
      "\n",
      "iteration 291: f_best = 0.00000000\n",
      "           x_eff  = [ -4.25161586 -14.54569717],\n",
      "\n",
      "iteration 292: f_best = 0.00000000\n",
      "           x_eff  = [22.75903981  0.60802784],\n",
      "\n",
      "iteration 293: f_best = 0.00000000\n",
      "           x_eff  = [ -4.59636704 -29.56861176],\n",
      "\n",
      "iteration 294: f_best = 0.00000000\n",
      "           x_eff  = [-0.95639765 21.70309669],\n",
      "\n",
      "iteration 295: f_best = 0.00000000\n",
      "           x_eff  = [ 19.10035764 -27.00924241],\n",
      "\n",
      "iteration 296: f_best = 0.00000000\n",
      "           x_eff  = [ 31.69688782 -31.57141385],\n",
      "\n",
      "iteration 297: f_best = 0.00000000\n",
      "           x_eff  = [ 27.18029567 -22.87931172],\n",
      "\n",
      "iteration 298: f_best = 0.00000000\n",
      "           x_eff  = [-12.7018278   -5.85596855],\n",
      "\n",
      "iteration 299: f_best = 0.00000000\n",
      "           x_eff  = [ 30.75483734 -13.26945889],\n",
      "\n",
      "iteration 300: f_best = 0.00000000\n",
      "           x_eff  = [21.66674412 14.60995315],\n",
      "\n",
      "iteration 301: f_best = 0.00000000\n",
      "           x_eff  = [-6.77073886  7.00299568],\n",
      "\n",
      "iteration 302: f_best = 0.00000000\n",
      "           x_eff  = [-9.55796715  3.89518912],\n",
      "\n",
      "iteration 303: f_best = 0.00000000\n",
      "           x_eff  = [  8.96589229 -12.83491422],\n",
      "\n",
      "iteration 304: f_best = 0.00000000\n",
      "           x_eff  = [ -4.06627677 -15.10566584],\n",
      "\n",
      "iteration 305: f_best = 0.00000000\n",
      "           x_eff  = [-29.27128243 -19.67883756],\n",
      "\n",
      "iteration 306: f_best = 0.00000000\n",
      "           x_eff  = [  4.86047862 -14.6538029 ],\n",
      "\n",
      "iteration 307: f_best = 0.00000000\n",
      "           x_eff  = [-5.07590434 26.54081871],\n",
      "\n",
      "iteration 308: f_best = 0.00000000\n",
      "           x_eff  = [-26.17748254 -25.07964433],\n",
      "\n",
      "iteration 309: f_best = 0.00000000\n",
      "           x_eff  = [ 7.92115537 -2.22861138],\n",
      "\n",
      "iteration 310: f_best = 0.00000000\n",
      "           x_eff  = [ 17.52755337 -24.08969553],\n",
      "\n",
      "iteration 311: f_best = 0.00000000\n",
      "           x_eff  = [24.59195476 26.66022652],\n",
      "\n",
      "iteration 312: f_best = 0.00000000\n",
      "           x_eff  = [-23.34829188  25.59685254],\n",
      "\n",
      "iteration 313: f_best = 0.00000000\n",
      "           x_eff  = [-22.40632012   4.25848397],\n",
      "\n",
      "iteration 314: f_best = 0.00000000\n",
      "           x_eff  = [17.2525771 10.9125955],\n",
      "\n",
      "iteration 315: f_best = 0.00000000\n",
      "           x_eff  = [-20.54700558  -9.10144616],\n",
      "\n",
      "iteration 316: f_best = 0.00000000\n",
      "           x_eff  = [18.20919996 14.92300348],\n",
      "\n",
      "iteration 317: f_best = 0.00000000\n",
      "           x_eff  = [ 5.12559245 16.46632453],\n",
      "\n",
      "iteration 318: f_best = 0.00000000\n",
      "           x_eff  = [18.18769561  2.05021001],\n",
      "\n",
      "iteration 319: f_best = 0.00000000\n",
      "           x_eff  = [  5.26242305 -12.25419941],\n",
      "\n",
      "iteration 320: f_best = 0.00000000\n",
      "           x_eff  = [ 19.33176579 -13.42259727],\n",
      "\n",
      "iteration 321: f_best = 0.00000000\n",
      "           x_eff  = [ 8.08396328 18.3077604 ],\n",
      "\n",
      "iteration 322: f_best = 0.00000000\n",
      "           x_eff  = [-15.40552076 -18.46084134],\n",
      "\n",
      "iteration 323: f_best = 0.00000000\n",
      "           x_eff  = [ 4.79028276 -1.20363145],\n",
      "\n",
      "iteration 324: f_best = 0.00000000\n",
      "           x_eff  = [-22.867149    -4.00970271],\n",
      "\n",
      "iteration 325: f_best = 0.00000000\n",
      "           x_eff  = [23.26084854  3.78263392],\n",
      "\n",
      "iteration 326: f_best = 0.00000000\n",
      "           x_eff  = [21.81212074 -5.05252829],\n",
      "\n",
      "iteration 327: f_best = 0.00000000\n",
      "           x_eff  = [-4.39082993 -4.44004347],\n",
      "\n",
      "iteration 328: f_best = 0.00000000\n",
      "           x_eff  = [-7.88184008 15.05385246],\n",
      "\n",
      "iteration 329: f_best = 0.00000000\n",
      "           x_eff  = [ 13.31425185 -19.14535045],\n",
      "\n",
      "iteration 330: f_best = 0.00000000\n",
      "           x_eff  = [ 19.4978634 -21.2228187],\n",
      "\n",
      "iteration 331: f_best = 0.00000000\n",
      "           x_eff  = [22.80768503  1.17325714],\n",
      "\n",
      "iteration 332: f_best = 0.00000000\n",
      "           x_eff  = [-4.85844192 16.80396327],\n",
      "\n",
      "iteration 333: f_best = 0.00000000\n",
      "           x_eff  = [ 2.23095461 -4.32135909],\n",
      "\n",
      "iteration 334: f_best = 0.00000000\n",
      "           x_eff  = [-6.52232793 10.29721158],\n",
      "\n",
      "iteration 335: f_best = 0.00000000\n",
      "           x_eff  = [ -1.58166455 -19.11834045],\n",
      "\n",
      "iteration 336: f_best = 0.00000000\n",
      "           x_eff  = [-6.18144114  4.42894415],\n",
      "\n",
      "iteration 337: f_best = 0.00000000\n",
      "           x_eff  = [ 2.37466415 18.27904209],\n",
      "\n",
      "iteration 338: f_best = 0.00000000\n",
      "           x_eff  = [-18.85284777  -9.39696072],\n",
      "\n",
      "iteration 339: f_best = 0.00000000\n",
      "           x_eff  = [16.76900912 -3.60696463],\n",
      "\n",
      "iteration 340: f_best = 0.00000000\n",
      "           x_eff  = [-11.92222849  15.43208405],\n",
      "\n",
      "iteration 341: f_best = 0.00000000\n",
      "           x_eff  = [-21.02228383  -0.18684636],\n",
      "\n",
      "iteration 342: f_best = 0.00000000\n",
      "           x_eff  = [ 6.02387246 15.44794339],\n",
      "\n",
      "iteration 343: f_best = 0.00000000\n",
      "           x_eff  = [-5.02399489 14.46217578],\n",
      "\n",
      "iteration 344: f_best = 0.00000000\n",
      "           x_eff  = [ 14.01919467 -13.63397783],\n",
      "\n",
      "iteration 345: f_best = 0.00000000\n",
      "           x_eff  = [-17.05051188  11.62298874],\n",
      "\n",
      "iteration 346: f_best = 0.00000000\n",
      "           x_eff  = [ 12.0718013  -10.94061186],\n",
      "\n",
      "iteration 347: f_best = 0.00000000\n",
      "           x_eff  = [-12.92242753  -8.58919796],\n",
      "\n",
      "iteration 348: f_best = 0.00000000\n",
      "           x_eff  = [-3.04788509  8.18335752],\n",
      "\n",
      "iteration 349: f_best = 0.00000000\n",
      "           x_eff  = [ -5.52684461 -18.49140311],\n",
      "\n",
      "iteration 350: f_best = 0.00000000\n",
      "           x_eff  = [18.40019172  8.99132743],\n",
      "\n",
      "iteration 351: f_best = 0.00000000\n",
      "           x_eff  = [-6.02618512  3.09991189],\n",
      "\n",
      "iteration 352: f_best = 0.00000000\n",
      "           x_eff  = [-13.87196989  16.9280374 ],\n",
      "\n",
      "iteration 353: f_best = 0.00000000\n",
      "           x_eff  = [0.58838431 0.08927803],\n",
      "\n",
      "iteration 354: f_best = 0.00000000\n",
      "           x_eff  = [-15.55115284  11.77555209],\n",
      "\n",
      "iteration 355: f_best = 0.00000000\n",
      "           x_eff  = [-7.49965899  0.96742207],\n",
      "\n",
      "iteration 356: f_best = 0.00000000\n",
      "           x_eff  = [11.18987815 10.15977577],\n",
      "\n",
      "iteration 357: f_best = 0.00000000\n",
      "           x_eff  = [-10.3433166  -10.79093767],\n",
      "\n",
      "iteration 358: f_best = 0.00000000\n",
      "           x_eff  = [ 4.18330977 -5.61453351],\n",
      "\n",
      "iteration 359: f_best = 0.00000000\n",
      "           x_eff  = [15.16994966  1.76609444],\n",
      "\n",
      "iteration 360: f_best = 0.00000000\n",
      "           x_eff  = [16.29748007 -1.61154726],\n",
      "\n",
      "iteration 361: f_best = 0.00000000\n",
      "           x_eff  = [5.97631271 4.88800621],\n",
      "\n",
      "iteration 362: f_best = 0.00000000\n",
      "           x_eff  = [-3.88102815 11.37810308],\n",
      "\n",
      "iteration 363: f_best = 0.00000000\n",
      "           x_eff  = [-0.18649928  2.0662283 ],\n",
      "\n",
      "iteration 364: f_best = 0.00000000\n",
      "           x_eff  = [4.46459431 1.37879659],\n",
      "\n",
      "iteration 365: f_best = 0.00000000\n",
      "           x_eff  = [14.43523003 12.24910942],\n",
      "\n",
      "iteration 366: f_best = 0.00000000\n",
      "           x_eff  = [-8.35616962  8.82528142],\n",
      "\n",
      "iteration 367: f_best = 0.00000000\n",
      "           x_eff  = [ -8.01058974 -12.50004309],\n",
      "\n",
      "iteration 368: f_best = 0.00000000\n",
      "           x_eff  = [ 4.25927778 13.64530637],\n",
      "\n",
      "iteration 369: f_best = 0.00000000\n",
      "           x_eff  = [12.69076579 15.95444822],\n",
      "\n",
      "iteration 370: f_best = 0.00000000\n",
      "           x_eff  = [-7.70505062 15.2522168 ],\n",
      "\n",
      "iteration 371: f_best = 0.00000000\n",
      "           x_eff  = [-0.55817912 -1.29179406],\n",
      "\n",
      "iteration 372: f_best = 0.00000000\n",
      "           x_eff  = [ -0.32719748 -13.08449655],\n",
      "\n",
      "iteration 373: f_best = 0.00000000\n",
      "           x_eff  = [-14.96156568  -3.57057954],\n",
      "\n",
      "iteration 374: f_best = 0.00000000\n",
      "           x_eff  = [-6.64083766  0.95141784],\n",
      "\n",
      "iteration 375: f_best = 0.00000000\n",
      "           x_eff  = [-7.41999372 -6.56098801],\n",
      "\n",
      "iteration 376: f_best = 0.00000000\n",
      "           x_eff  = [-8.82882232  5.83124004],\n",
      "\n",
      "iteration 377: f_best = 0.00000000\n",
      "           x_eff  = [-6.12741099  7.92884406],\n",
      "\n",
      "iteration 378: f_best = 0.00000000\n",
      "           x_eff  = [ 7.85432326 -5.40398716],\n",
      "\n",
      "iteration 379: f_best = 0.00000000\n",
      "           x_eff  = [-13.58096425  -8.46876141],\n",
      "\n",
      "iteration 380: f_best = 0.00000000\n",
      "           x_eff  = [-7.73330422  6.24351554],\n",
      "\n",
      "iteration 381: f_best = 0.00000000\n",
      "           x_eff  = [ 8.6015497  -2.47750196],\n",
      "\n",
      "iteration 382: f_best = 0.00000000\n",
      "           x_eff  = [-8.49970216 12.48281452],\n",
      "\n",
      "iteration 383: f_best = 0.00000000\n",
      "           x_eff  = [-0.20280084 -8.21418398],\n",
      "\n",
      "iteration 384: f_best = 0.00000000\n",
      "           x_eff  = [-2.2080379  -7.30843497],\n",
      "\n",
      "iteration 385: f_best = 0.00000000\n",
      "           x_eff  = [-7.84698084 -9.54147439],\n",
      "\n",
      "iteration 386: f_best = 0.00000000\n",
      "           x_eff  = [-0.05661275 -0.41197828],\n",
      "\n",
      "iteration 387: f_best = 0.00000000\n",
      "           x_eff  = [-5.89053554  8.43162829],\n",
      "\n",
      "iteration 388: f_best = 0.00000000\n",
      "           x_eff  = [ 6.62340813 10.57622998],\n",
      "\n",
      "iteration 389: f_best = 0.00000000\n",
      "           x_eff  = [-3.70722289  0.54667466],\n",
      "\n",
      "iteration 390: f_best = 0.00000000\n",
      "           x_eff  = [ -9.57650671 -10.0070503 ],\n",
      "\n",
      "iteration 391: f_best = 0.00000000\n",
      "           x_eff  = [-7.68867101 12.83769545],\n",
      "\n",
      "iteration 392: f_best = 0.00000000\n",
      "           x_eff  = [-4.80002961 -1.18473875],\n",
      "\n",
      "iteration 393: f_best = 0.00000000\n",
      "           x_eff  = [-12.04991549  -7.42579956],\n",
      "\n",
      "iteration 394: f_best = 0.00000000\n",
      "           x_eff  = [-1.5858726  -9.52861723],\n",
      "\n",
      "iteration 395: f_best = 0.00000000\n",
      "           x_eff  = [-12.44111347   8.12073269],\n",
      "\n",
      "iteration 396: f_best = 0.00000000\n",
      "           x_eff  = [ 1.12111719 -6.20876899],\n",
      "\n",
      "iteration 397: f_best = 0.00000000\n",
      "           x_eff  = [ -3.22511755 -10.43410488],\n",
      "\n",
      "iteration 398: f_best = 0.00000000\n",
      "           x_eff  = [-6.44666199  8.54228474],\n",
      "\n",
      "iteration 399: f_best = 0.00000000\n",
      "           x_eff  = [-0.82409232 11.22726927],\n",
      "\n",
      "iteration 400: f_best = 0.00000000\n",
      "           x_eff  = [-5.1194129  -2.08174582],\n",
      "\n",
      "iteration 401: f_best = 0.00000000\n",
      "           x_eff  = [ 5.62188213 -6.61526239],\n",
      "\n",
      "iteration 402: f_best = 0.00000000\n",
      "           x_eff  = [11.30908041 -5.41716349],\n",
      "\n",
      "iteration 403: f_best = 0.00000000\n",
      "           x_eff  = [ 0.50579215 -8.44614202],\n",
      "\n",
      "iteration 404: f_best = 0.00000000\n",
      "           x_eff  = [ 2.03618712 -3.8813629 ],\n",
      "\n",
      "iteration 405: f_best = 0.00000000\n",
      "           x_eff  = [-2.59245268 -6.50735295],\n",
      "\n",
      "iteration 406: f_best = 0.00000000\n",
      "           x_eff  = [-2.63860445  7.7422325 ],\n",
      "\n",
      "iteration 407: f_best = 0.00000000\n",
      "           x_eff  = [ 7.26914465 -3.67331756],\n",
      "\n",
      "iteration 408: f_best = 0.00000000\n",
      "           x_eff  = [5.44783065 4.8294918 ],\n",
      "\n",
      "iteration 409: f_best = 0.00000000\n",
      "           x_eff  = [7.17198954 3.19895599],\n",
      "\n",
      "iteration 410: f_best = 0.00000000\n",
      "           x_eff  = [ -8.65412326 -10.33206694],\n",
      "\n",
      "iteration 411: f_best = 0.00000000\n",
      "           x_eff  = [8.55261118 4.638945  ],\n",
      "\n",
      "iteration 412: f_best = 0.00000000\n",
      "           x_eff  = [ 5.6115101  -4.84250474],\n",
      "\n",
      "iteration 413: f_best = 0.00000000\n",
      "           x_eff  = [7.13071238 1.48040745],\n",
      "\n",
      "iteration 414: f_best = 0.00000000\n",
      "           x_eff  = [ 5.97790176 -0.50730782],\n",
      "\n",
      "iteration 415: f_best = 0.00000000\n",
      "           x_eff  = [5.25460029 2.25362489],\n",
      "\n",
      "iteration 416: f_best = 0.00000000\n",
      "           x_eff  = [ 0.12971929 -8.50472271],\n",
      "\n",
      "iteration 417: f_best = 0.00000000\n",
      "           x_eff  = [ 8.7312592  -1.33652285],\n",
      "\n",
      "iteration 418: f_best = 0.00000000\n",
      "           x_eff  = [-8.32048244  2.85499489],\n",
      "\n",
      "iteration 419: f_best = 0.00000000\n",
      "           x_eff  = [-8.31561403 -2.50348736],\n",
      "\n",
      "iteration 420: f_best = 0.00000000\n",
      "           x_eff  = [9.75359517 3.0290081 ],\n",
      "\n",
      "iteration 421: f_best = 0.00000000\n",
      "           x_eff  = [3.01834827 9.09489377],\n",
      "\n",
      "iteration 422: f_best = 0.00000000\n",
      "           x_eff  = [-8.55194835  7.82042612],\n",
      "\n",
      "iteration 423: f_best = 0.00000000\n",
      "           x_eff  = [-5.33894235 -6.75150515],\n",
      "\n",
      "iteration 424: f_best = 0.00000000\n",
      "           x_eff  = [ 3.6764606  -6.85219467],\n",
      "\n",
      "iteration 425: f_best = 0.00000000\n",
      "           x_eff  = [8.85321598 0.05156553],\n",
      "\n",
      "iteration 426: f_best = 0.00000000\n",
      "           x_eff  = [-4.70817236  8.17069958],\n",
      "\n",
      "iteration 427: f_best = 0.00000000\n",
      "           x_eff  = [-5.94497292  1.01446655],\n",
      "\n",
      "iteration 428: f_best = 0.00000000\n",
      "           x_eff  = [-2.89998995  6.12505669],\n",
      "\n",
      "iteration 429: f_best = 0.00000000\n",
      "           x_eff  = [-6.60229283 -1.79861719],\n",
      "\n",
      "iteration 430: f_best = 0.00000000\n",
      "           x_eff  = [ 5.63660114 -0.30797844],\n",
      "\n",
      "iteration 431: f_best = 0.00000000\n",
      "           x_eff  = [4.15605779 4.02780679],\n",
      "\n",
      "iteration 432: f_best = 0.00000000\n",
      "           x_eff  = [ 2.44142919 -3.27196516],\n",
      "\n",
      "iteration 433: f_best = 0.00000000\n",
      "           x_eff  = [0.52618335 8.16668685],\n",
      "\n",
      "iteration 434: f_best = 0.00000000\n",
      "           x_eff  = [-7.00915169  7.51356695],\n",
      "\n",
      "iteration 435: f_best = 0.00000000\n",
      "           x_eff  = [-7.12351669 -3.51797454],\n",
      "\n",
      "iteration 436: f_best = 0.00000000\n",
      "           x_eff  = [-0.87450489  6.81274336],\n",
      "\n",
      "iteration 437: f_best = 0.00000000\n",
      "           x_eff  = [2.88242101 7.13511767],\n",
      "\n",
      "iteration 438: f_best = 0.00000000\n",
      "           x_eff  = [4.55533052 4.08568331],\n",
      "\n",
      "iteration 439: f_best = 0.00000000\n",
      "           x_eff  = [-5.35895393 -4.05541645],\n",
      "\n",
      "iteration 440: f_best = 0.00000000\n",
      "           x_eff  = [-1.18421506 -1.26549039],\n",
      "\n",
      "iteration 441: f_best = 0.00000000\n",
      "           x_eff  = [-6.966514    7.66914865],\n",
      "\n",
      "iteration 442: f_best = 0.00000000\n",
      "           x_eff  = [ 1.09009637 -5.56446856],\n",
      "\n",
      "iteration 443: f_best = 0.00000000\n",
      "           x_eff  = [-2.89905037 -0.88211907],\n",
      "\n",
      "iteration 444: f_best = 0.00000000\n",
      "           x_eff  = [-2.51204456  2.32334236],\n",
      "\n",
      "iteration 445: f_best = 0.00000000\n",
      "           x_eff  = [2.77060647 4.38308281],\n",
      "\n",
      "iteration 446: f_best = 0.00000000\n",
      "           x_eff  = [-5.93413389 -4.65398626],\n",
      "\n",
      "iteration 447: f_best = 0.00000000\n",
      "           x_eff  = [1.02350217 0.72763233],\n",
      "\n",
      "iteration 448: f_best = 0.00000000\n",
      "           x_eff  = [ 0.27524607 -3.44269046],\n",
      "\n",
      "iteration 449: f_best = 0.00000000\n",
      "           x_eff  = [-3.77095434 -3.96260353],\n",
      "\n",
      "iteration 450: f_best = 0.00000000\n",
      "           x_eff  = [4.33900086 0.62524877],\n",
      "\n",
      "iteration 451: f_best = 0.00000000\n",
      "           x_eff  = [-6.21169499  0.63240206],\n",
      "\n",
      "iteration 452: f_best = 0.00000000\n",
      "           x_eff  = [2.54911752 5.68207207],\n",
      "\n",
      "iteration 453: f_best = 0.00000000\n",
      "           x_eff  = [-5.2392071  -4.95805006],\n",
      "\n",
      "iteration 454: f_best = 0.00000000\n",
      "           x_eff  = [6.41230703 3.37585839],\n",
      "\n",
      "iteration 455: f_best = 0.00000000\n",
      "           x_eff  = [-6.12297419 -0.44241946],\n",
      "\n",
      "iteration 456: f_best = 0.00000000\n",
      "           x_eff  = [ 0.11714576 -2.73662965],\n",
      "\n",
      "iteration 457: f_best = 0.00000000\n",
      "           x_eff  = [4.31528735 4.22415335],\n",
      "\n",
      "iteration 458: f_best = 0.00000000\n",
      "           x_eff  = [ 1.81580501 -4.65684302],\n",
      "\n",
      "iteration 459: f_best = 0.00000000\n",
      "           x_eff  = [-4.65726106  0.70696807],\n",
      "\n",
      "iteration 460: f_best = 0.00000000\n",
      "           x_eff  = [-3.17377345 -6.37074323],\n",
      "\n",
      "iteration 461: f_best = 0.00000000\n",
      "           x_eff  = [ 3.96605584 -4.8827835 ],\n",
      "\n",
      "iteration 462: f_best = 0.00000000\n",
      "           x_eff  = [-4.66956359 -3.82928073],\n",
      "\n",
      "iteration 463: f_best = 0.00000000\n",
      "           x_eff  = [ 4.11010779 -3.06114163],\n",
      "\n",
      "iteration 464: f_best = 0.00000000\n",
      "           x_eff  = [1.58857666 0.00536595],\n",
      "\n",
      "iteration 465: f_best = 0.00000000\n",
      "           x_eff  = [-2.9440398  -4.10560339],\n",
      "\n",
      "iteration 466: f_best = 0.00000000\n",
      "           x_eff  = [ 0.82914035 -0.43583189],\n",
      "\n",
      "iteration 467: f_best = 0.00000000\n",
      "           x_eff  = [ 5.96697747 -4.37797568],\n",
      "\n",
      "iteration 468: f_best = 0.00000000\n",
      "           x_eff  = [-3.7030867  -0.40203243],\n",
      "\n",
      "iteration 469: f_best = 0.00000000\n",
      "           x_eff  = [ 4.93462544 -1.55306045],\n",
      "\n",
      "iteration 470: f_best = 0.00000000\n",
      "           x_eff  = [-0.21661784  0.63479434],\n",
      "\n",
      "iteration 471: f_best = 0.00000000\n",
      "           x_eff  = [ 2.89591529 -5.61697267],\n",
      "\n",
      "iteration 472: f_best = 0.00000000\n",
      "           x_eff  = [-3.89577703  4.45888428],\n",
      "\n",
      "iteration 473: f_best = 0.00000000\n",
      "           x_eff  = [-2.84948162  3.98389017],\n",
      "\n",
      "iteration 474: f_best = 0.00000000\n",
      "           x_eff  = [-1.8493266   4.27753369],\n",
      "\n",
      "iteration 475: f_best = 0.00000000\n",
      "           x_eff  = [-0.75628449  3.43390052],\n",
      "\n",
      "iteration 476: f_best = 0.00000000\n",
      "           x_eff  = [ 3.2801313  -4.25259158],\n",
      "\n",
      "iteration 477: f_best = 0.00000000\n",
      "           x_eff  = [3.30102373 1.83264041],\n",
      "\n",
      "iteration 478: f_best = 0.00000000\n",
      "           x_eff  = [0.892905   3.56677244],\n",
      "\n",
      "iteration 479: f_best = 0.00000000\n",
      "           x_eff  = [-3.58103694  5.30827832],\n",
      "\n",
      "iteration 480: f_best = 0.00000000\n",
      "           x_eff  = [-2.07061461 -3.78829415],\n",
      "\n",
      "iteration 481: f_best = 0.00000000\n",
      "           x_eff  = [-3.51474208  3.93657606],\n",
      "\n",
      "iteration 482: f_best = 0.00000000\n",
      "           x_eff  = [ 1.27111798 -1.91700361],\n",
      "\n",
      "iteration 483: f_best = 0.00000000\n",
      "           x_eff  = [-3.34402543 -5.21986348],\n",
      "\n",
      "iteration 484: f_best = 0.00000000\n",
      "           x_eff  = [-1.11440586 -4.11498698],\n",
      "\n",
      "iteration 485: f_best = 0.00000000\n",
      "           x_eff  = [-3.37894109  4.6132803 ],\n",
      "\n",
      "iteration 486: f_best = 0.00000000\n",
      "           x_eff  = [1.77890145 3.1035204 ],\n",
      "\n",
      "iteration 487: f_best = 0.00000000\n",
      "           x_eff  = [-3.82101037 -2.12535   ],\n",
      "\n",
      "iteration 488: f_best = 0.00000000\n",
      "           x_eff  = [0.6849066  3.75946099],\n",
      "\n",
      "iteration 489: f_best = 0.00000000\n",
      "           x_eff  = [-3.94486646 -2.28954739],\n",
      "\n",
      "iteration 490: f_best = 0.00000000\n",
      "           x_eff  = [ 3.7940035  -3.23727536],\n",
      "\n",
      "iteration 491: f_best = 0.00000000\n",
      "           x_eff  = [ 1.32853265 -0.19292903],\n",
      "\n",
      "iteration 492: f_best = 0.00000000\n",
      "           x_eff  = [ 0.21352816 -1.56279816],\n",
      "\n",
      "iteration 493: f_best = 0.00000000\n",
      "           x_eff  = [3.64793982 1.64218947],\n",
      "\n",
      "iteration 494: f_best = 0.00000000\n",
      "           x_eff  = [-3.33171038  3.38531606],\n",
      "\n",
      "iteration 495: f_best = 0.00000000\n",
      "           x_eff  = [ 0.91201803 -2.4435649 ],\n",
      "\n",
      "iteration 496: f_best = 0.00000000\n",
      "           x_eff  = [-2.00850072  1.03966276],\n",
      "\n",
      "iteration 497: f_best = 0.00000000\n",
      "           x_eff  = [0.24009116 4.06872806],\n",
      "\n",
      "iteration 498: f_best = 0.00000000\n",
      "           x_eff  = [3.44024455 4.38907628],\n",
      "\n",
      "iteration 499: f_best = 0.00000000\n",
      "           x_eff  = [-2.4132965   2.94139882],\n",
      "\n",
      "iteration 500: f_best = 0.00000000\n",
      "           x_eff  = [ 2.04471622 -0.62461996],\n",
      "\n",
      "iteration 501: f_best = 0.00000000\n",
      "           x_eff  = [-2.73109143  2.54270972],\n",
      "\n",
      "iteration 502: f_best = 0.00000000\n",
      "           x_eff  = [-4.04650484  1.13672801],\n",
      "\n",
      "iteration 503: f_best = 0.00000000\n",
      "           x_eff  = [-0.93421058 -3.12516288],\n",
      "\n",
      "iteration 504: f_best = 0.00000000\n",
      "           x_eff  = [-0.6186888  0.4559644],\n",
      "\n",
      "iteration 505: f_best = 0.00000000\n",
      "           x_eff  = [-4.11614754  0.63457448],\n",
      "\n",
      "iteration 506: f_best = 0.00000000\n",
      "           x_eff  = [-2.01981932 -2.07806528],\n",
      "\n",
      "iteration 507: f_best = 0.00000000\n",
      "           x_eff  = [-0.62727201 -1.7707417 ],\n",
      "\n",
      "iteration 508: f_best = 0.00000000\n",
      "           x_eff  = [ 1.7075975  -0.15965249],\n",
      "\n",
      "iteration 509: f_best = 0.00000000\n",
      "           x_eff  = [2.916527   0.26903378],\n",
      "\n",
      "iteration 510: f_best = 0.00000000\n",
      "           x_eff  = [ 3.46886979 -2.61042717],\n",
      "\n",
      "iteration 511: f_best = 0.00000000\n",
      "           x_eff  = [ 0.2506901  -0.45440876],\n",
      "\n",
      "iteration 512: f_best = 0.00000000\n",
      "           x_eff  = [3.34524574 3.52712302],\n",
      "\n",
      "iteration 513: f_best = 0.00000000\n",
      "           x_eff  = [ 1.94253666 -0.76440359],\n",
      "\n",
      "iteration 514: f_best = 0.00000000\n",
      "           x_eff  = [-3.04686419  2.95450368],\n",
      "\n",
      "iteration 515: f_best = 0.00000000\n",
      "           x_eff  = [ 1.31354909 -3.11142255],\n",
      "\n",
      "iteration 516: f_best = 0.00000000\n",
      "           x_eff  = [-3.6576138  -3.51081161],\n",
      "\n",
      "iteration 517: f_best = 0.00000000\n",
      "           x_eff  = [ 1.52038689 -1.94773358],\n",
      "\n",
      "iteration 518: f_best = 0.00000000\n",
      "           x_eff  = [-2.97186244 -3.066346  ],\n",
      "\n",
      "iteration 519: f_best = 0.00000000\n",
      "           x_eff  = [-2.28933389  1.12052665],\n",
      "\n",
      "iteration 520: f_best = 0.00000000\n",
      "           x_eff  = [-0.01115734  2.04003189],\n",
      "\n",
      "iteration 521: f_best = 0.00000000\n",
      "           x_eff  = [-1.72136385 -0.31333165],\n",
      "\n",
      "iteration 522: f_best = 0.00000000\n",
      "           x_eff  = [1.26712306 0.93875945],\n",
      "\n",
      "iteration 523: f_best = 0.00000000\n",
      "           x_eff  = [-1.4940628  -0.01074016],\n",
      "\n",
      "iteration 524: f_best = 0.00000000\n",
      "           x_eff  = [1.65136286 0.48373499],\n",
      "\n",
      "iteration 525: f_best = 0.00000000\n",
      "           x_eff  = [2.39122167 2.89955391],\n",
      "\n",
      "iteration 526: f_best = 0.00000000\n",
      "           x_eff  = [-3.41023779  0.85058696],\n",
      "\n",
      "iteration 527: f_best = 0.00000000\n",
      "           x_eff  = [1.27727941 0.7661924 ],\n",
      "\n",
      "iteration 528: f_best = 0.00000000\n",
      "           x_eff  = [-2.58720116  0.88866769],\n",
      "\n",
      "iteration 529: f_best = 0.00000000\n",
      "           x_eff  = [-2.69106195  2.98039899],\n",
      "\n",
      "iteration 530: f_best = 0.00000000\n",
      "           x_eff  = [1.98645141 0.22441482],\n",
      "\n",
      "iteration 531: f_best = 0.00000000\n",
      "           x_eff  = [-0.36762184 -2.28789812],\n",
      "\n",
      "iteration 532: f_best = 0.00000000\n",
      "           x_eff  = [ 2.32874639 -0.82519159],\n",
      "\n",
      "iteration 533: f_best = 0.00000000\n",
      "           x_eff  = [0.37832464 0.32274016],\n",
      "\n",
      "iteration 534: f_best = 0.00000000\n",
      "           x_eff  = [ 2.18148168 -0.97462014],\n",
      "\n",
      "iteration 535: f_best = 0.00000000\n",
      "           x_eff  = [-0.24174512  1.15081356],\n",
      "\n",
      "iteration 536: f_best = 0.00000000\n",
      "           x_eff  = [2.20370116 2.82395635],\n",
      "\n",
      "iteration 537: f_best = 0.00000000\n",
      "           x_eff  = [-1.45671073 -1.17542936],\n",
      "\n",
      "iteration 538: f_best = 0.00000000\n",
      "           x_eff  = [-0.0304542   0.78020006],\n",
      "\n",
      "iteration 539: f_best = 0.00000000\n",
      "           x_eff  = [-2.64578169  0.43959466],\n",
      "\n",
      "iteration 540: f_best = 0.00000000\n",
      "           x_eff  = [ 2.08102588 -2.02006298],\n",
      "\n",
      "iteration 541: f_best = 0.00000000\n",
      "           x_eff  = [-1.85085919 -0.61687013],\n",
      "\n",
      "iteration 542: f_best = 0.00000000\n",
      "           x_eff  = [-2.78226316 -2.50822202],\n",
      "\n",
      "iteration 543: f_best = 0.00000000\n",
      "           x_eff  = [-0.84329934 -1.31265724],\n",
      "\n",
      "iteration 544: f_best = 0.00000000\n",
      "           x_eff  = [ 0.33982324 -2.31658547],\n",
      "\n",
      "iteration 545: f_best = 0.00000000\n",
      "           x_eff  = [-1.67769303  1.84692962],\n",
      "\n",
      "iteration 546: f_best = 0.00000000\n",
      "           x_eff  = [-2.13565427 -1.06064088],\n",
      "\n",
      "iteration 547: f_best = 0.00000000\n",
      "           x_eff  = [-2.457902    1.68959415],\n",
      "\n",
      "iteration 548: f_best = 0.00000000\n",
      "           x_eff  = [ 1.84785313 -0.16858069],\n",
      "\n",
      "iteration 549: f_best = 0.00000000\n",
      "           x_eff  = [-1.86168861  2.45980598],\n",
      "\n",
      "iteration 550: f_best = 0.00000000\n",
      "           x_eff  = [-1.11468076  0.55884483],\n",
      "\n",
      "iteration 551: f_best = 0.00000000\n",
      "           x_eff  = [-1.64425477 -0.06682347],\n",
      "\n",
      "iteration 552: f_best = 0.00000000\n",
      "           x_eff  = [0.94149147 1.62262718],\n",
      "\n",
      "iteration 553: f_best = 0.00000000\n",
      "           x_eff  = [1.23670175 2.25698794],\n",
      "\n",
      "iteration 554: f_best = 0.00000000\n",
      "           x_eff  = [2.34091845 1.48568755],\n",
      "\n",
      "iteration 555: f_best = 0.00000000\n",
      "           x_eff  = [ 1.74083426 -1.2160628 ],\n",
      "\n",
      "iteration 556: f_best = 0.00000000\n",
      "           x_eff  = [-1.37565764  1.47600619],\n",
      "\n",
      "iteration 557: f_best = 0.00000000\n",
      "           x_eff  = [-1.87680407 -1.33213948],\n",
      "\n",
      "iteration 558: f_best = 0.00000000\n",
      "           x_eff  = [1.50685029 0.3837653 ],\n",
      "\n",
      "iteration 559: f_best = 0.00000000\n",
      "           x_eff  = [0.69180027 0.29935146],\n",
      "\n",
      "iteration 560: f_best = 0.00000000\n",
      "           x_eff  = [ 1.97751433 -1.00959154],\n",
      "\n",
      "iteration 561: f_best = 0.00000000\n",
      "           x_eff  = [ 1.9308426  -1.86821164],\n",
      "\n",
      "iteration 562: f_best = 0.00000000\n",
      "           x_eff  = [-1.16903977 -1.07579681],\n",
      "\n",
      "iteration 563: f_best = 0.00000000\n",
      "           x_eff  = [-2.34688824 -2.11263248],\n",
      "\n",
      "iteration 564: f_best = 0.00000000\n",
      "           x_eff  = [2.05664647 2.29682948],\n",
      "\n",
      "iteration 565: f_best = 0.00000000\n",
      "           x_eff  = [-1.48221409 -0.29887222],\n",
      "\n",
      "iteration 566: f_best = 0.00000000\n",
      "           x_eff  = [-1.65802297  0.61399374],\n",
      "\n",
      "iteration 567: f_best = 0.00000000\n",
      "           x_eff  = [-0.02285231 -2.0255756 ],\n",
      "\n",
      "iteration 568: f_best = 0.00000000\n",
      "           x_eff  = [1.55831481 0.34642536],\n",
      "\n",
      "iteration 569: f_best = 0.00000000\n",
      "           x_eff  = [-1.63119511 -1.48439572],\n",
      "\n",
      "iteration 570: f_best = 0.00000000\n",
      "           x_eff  = [1.96965758 1.99512397],\n",
      "\n",
      "iteration 571: f_best = 0.00000000\n",
      "           x_eff  = [ 0.99356021 -0.40292851],\n",
      "\n",
      "iteration 572: f_best = 0.00000000\n",
      "           x_eff  = [-1.63555621 -1.45383179],\n",
      "\n",
      "iteration 573: f_best = 0.00000000\n",
      "           x_eff  = [ 0.45172794 -0.56932192],\n",
      "\n",
      "iteration 574: f_best = 0.00000000\n",
      "           x_eff  = [-0.52008536  1.06650412],\n",
      "\n",
      "iteration 575: f_best = 0.00000000\n",
      "           x_eff  = [0.39422439 1.84434027],\n",
      "\n",
      "iteration 576: f_best = 0.00000000\n",
      "           x_eff  = [ 1.15251409 -1.96022473],\n",
      "\n",
      "iteration 577: f_best = 0.00000000\n",
      "           x_eff  = [0.19126033 1.74088297],\n",
      "\n",
      "iteration 578: f_best = 0.00000000\n",
      "           x_eff  = [-0.46048439  1.40823808],\n",
      "\n",
      "iteration 579: f_best = 0.00000000\n",
      "           x_eff  = [-0.64275338 -1.52808836],\n",
      "\n",
      "iteration 580: f_best = 0.00000000\n",
      "           x_eff  = [-0.47572945 -0.36421977],\n",
      "\n",
      "iteration 581: f_best = 0.00000000\n",
      "           x_eff  = [ 0.85981448 -0.88108811],\n",
      "\n",
      "iteration 582: f_best = 0.00000000\n",
      "           x_eff  = [-1.46551771 -1.81974216],\n",
      "\n",
      "iteration 583: f_best = 0.00000000\n",
      "           x_eff  = [1.87231934 0.33176672],\n",
      "\n",
      "iteration 584: f_best = 0.00000000\n",
      "           x_eff  = [-0.08821196 -0.87967493],\n",
      "\n",
      "iteration 585: f_best = 0.00000000\n",
      "           x_eff  = [ 0.89894175 -1.00762622],\n",
      "\n",
      "iteration 586: f_best = 0.00000000\n",
      "           x_eff  = [-0.33948322  0.06826615],\n",
      "\n",
      "iteration 587: f_best = 0.00000000\n",
      "           x_eff  = [ 0.67052178 -0.50411683],\n",
      "\n",
      "iteration 588: f_best = 0.00000000\n",
      "           x_eff  = [-0.7973841   1.77031167],\n",
      "\n",
      "iteration 589: f_best = 0.00000000\n",
      "           x_eff  = [ 1.0720533  -1.51951109],\n",
      "\n",
      "iteration 590: f_best = 0.00000000\n",
      "           x_eff  = [0.08141875 1.1161165 ],\n",
      "\n",
      "iteration 591: f_best = 0.00000000\n",
      "           x_eff  = [-1.7840978 -1.7481586],\n",
      "\n",
      "iteration 592: f_best = 0.00000000\n",
      "           x_eff  = [ 1.22023666 -0.12867902],\n",
      "\n",
      "iteration 593: f_best = 0.00000000\n",
      "           x_eff  = [ 0.35942708 -0.06338328],\n",
      "\n",
      "iteration 594: f_best = 0.00000000\n",
      "           x_eff  = [0.15667121 0.87782274],\n",
      "\n",
      "iteration 595: f_best = 0.00000000\n",
      "           x_eff  = [0.43379491 0.66807328],\n",
      "\n",
      "iteration 596: f_best = 0.00000000\n",
      "           x_eff  = [-0.22173263 -1.24969809],\n",
      "\n",
      "iteration 597: f_best = 0.00000000\n",
      "           x_eff  = [1.36349935 1.2417107 ],\n",
      "\n",
      "iteration 598: f_best = 0.00000000\n",
      "           x_eff  = [-0.9090594  -1.24462967],\n",
      "\n",
      "iteration 599: f_best = 0.00000000\n",
      "           x_eff  = [ 0.67989028 -0.08429037],\n",
      "\n",
      "iteration 600: f_best = 0.00000000\n",
      "           x_eff  = [ 1.56917786 -1.46469499],\n",
      "\n",
      "iteration 601: f_best = 0.00000000\n",
      "           x_eff  = [1.49925398 0.52449984],\n",
      "\n",
      "iteration 602: f_best = 0.00000000\n",
      "           x_eff  = [ 1.181155   -0.59913058],\n",
      "\n",
      "iteration 603: f_best = 0.00000000\n",
      "           x_eff  = [-0.58678671 -1.56571986],\n",
      "\n",
      "iteration 604: f_best = 0.00000000\n",
      "           x_eff  = [-0.91094556  0.4384547 ],\n",
      "\n",
      "iteration 605: f_best = 0.00000000\n",
      "           x_eff  = [0.1328967  0.39027452],\n",
      "\n",
      "iteration 606: f_best = 0.00000000\n",
      "           x_eff  = [ 0.16329896 -0.46736378],\n",
      "\n",
      "iteration 607: f_best = 0.00000000\n",
      "           x_eff  = [-1.1662367  -0.79348059],\n",
      "\n",
      "iteration 608: f_best = 0.00000000\n",
      "           x_eff  = [1.32564414 0.1756616 ],\n",
      "\n",
      "iteration 609: f_best = 0.00000000\n",
      "           x_eff  = [ 0.21517215 -1.13791346],\n",
      "\n",
      "iteration 610: f_best = 0.00000000\n",
      "           x_eff  = [0.1304878  0.79831459],\n",
      "\n",
      "iteration 611: f_best = 0.00000000\n",
      "           x_eff  = [0.40443051 1.21112154],\n",
      "\n",
      "iteration 612: f_best = 0.00000000\n",
      "           x_eff  = [ 0.68397791 -0.06171205],\n",
      "\n",
      "iteration 613: f_best = 0.00000000\n",
      "           x_eff  = [-0.72984203  0.31564813],\n",
      "\n",
      "iteration 614: f_best = 0.00000000\n",
      "           x_eff  = [-0.07574427 -1.04715215],\n",
      "\n",
      "iteration 615: f_best = 0.00000000\n",
      "           x_eff  = [ 1.02765571 -0.11476305],\n",
      "\n",
      "iteration 616: f_best = 0.00000000\n",
      "           x_eff  = [0.44745995 0.03528994],\n",
      "\n",
      "iteration 617: f_best = 0.00000000\n",
      "           x_eff  = [1.24453523 0.5768877 ],\n",
      "\n",
      "iteration 618: f_best = 0.00000000\n",
      "           x_eff  = [-0.79411664 -0.89609089],\n",
      "\n",
      "iteration 619: f_best = 0.00000000\n",
      "           x_eff  = [-0.16961504 -0.30971412],\n",
      "\n",
      "iteration 620: f_best = 0.00000000\n",
      "           x_eff  = [-0.13568791  1.18267634],\n",
      "\n",
      "iteration 621: f_best = 0.00000000\n",
      "           x_eff  = [0.80903748 0.60431738],\n",
      "\n",
      "iteration 622: f_best = 0.00000000\n",
      "           x_eff  = [-0.33389237 -0.32095416],\n",
      "\n",
      "iteration 623: f_best = 0.00000000\n",
      "           x_eff  = [-0.76417848 -0.51446502],\n",
      "\n",
      "iteration 624: f_best = 0.00000000\n",
      "           x_eff  = [0.00300005 0.80935306],\n",
      "\n",
      "iteration 625: f_best = 0.00000000\n",
      "           x_eff  = [-0.20050414 -0.15267018],\n",
      "\n",
      "iteration 626: f_best = 0.00000000\n",
      "           x_eff  = [-0.29205981  0.6903587 ],\n",
      "\n",
      "iteration 627: f_best = 0.00000000\n",
      "           x_eff  = [-0.23236373 -0.7516713 ],\n",
      "\n",
      "iteration 628: f_best = 0.00000000\n",
      "           x_eff  = [0.8034936  1.00879255],\n",
      "\n",
      "iteration 629: f_best = 0.00000000\n",
      "           x_eff  = [-0.11718139 -0.69844008],\n",
      "\n",
      "iteration 630: f_best = 0.00000000\n",
      "           x_eff  = [-0.59667073  0.30921168],\n",
      "\n",
      "iteration 631: f_best = 0.00000000\n",
      "           x_eff  = [-1.02532244 -0.17369663],\n",
      "\n",
      "iteration 632: f_best = 0.00000000\n",
      "           x_eff  = [0.04028232 0.06882699],\n",
      "\n",
      "iteration 633: f_best = 0.00000000\n",
      "           x_eff  = [ 0.25639051 -0.64799288],\n",
      "\n",
      "iteration 634: f_best = 0.00000000\n",
      "           x_eff  = [-0.81591582 -0.05637121],\n",
      "\n",
      "iteration 635: f_best = 0.00000000\n",
      "           x_eff  = [ 0.46661278 -0.97475419],\n",
      "\n",
      "iteration 636: f_best = 0.00000000\n",
      "           x_eff  = [ 1.01768681 -0.29182119],\n",
      "\n",
      "iteration 637: f_best = 0.00000000\n",
      "           x_eff  = [ 0.82389457 -0.80283308],\n",
      "\n",
      "iteration 638: f_best = 0.00000000\n",
      "           x_eff  = [ 0.36797331 -1.06303141],\n",
      "\n",
      "iteration 639: f_best = 0.00000000\n",
      "           x_eff  = [1.05834564 1.05244195],\n",
      "\n",
      "iteration 640: f_best = 0.00000000\n",
      "           x_eff  = [1.09468107 1.03869639],\n",
      "\n",
      "iteration 641: f_best = 0.00000000\n",
      "           x_eff  = [0.38600302 0.0493401 ],\n",
      "\n",
      "iteration 642: f_best = 0.00000000\n",
      "           x_eff  = [-0.55920928  0.13587793],\n",
      "\n",
      "iteration 643: f_best = 0.00000000\n",
      "           x_eff  = [0.51181758 0.2778127 ],\n",
      "\n",
      "iteration 644: f_best = 0.00000000\n",
      "           x_eff  = [-0.8913256   0.41184432],\n",
      "\n",
      "iteration 645: f_best = 0.00000000\n",
      "           x_eff  = [ 0.84571739 -0.01772128],\n",
      "\n",
      "iteration 646: f_best = 0.00000000\n",
      "           x_eff  = [0.13355741 0.2417596 ],\n",
      "\n",
      "iteration 647: f_best = 0.00000000\n",
      "           x_eff  = [-0.42443028 -0.48809008],\n",
      "\n",
      "iteration 648: f_best = 0.00000000\n",
      "           x_eff  = [-0.22468563 -0.36790087],\n",
      "\n",
      "iteration 649: f_best = 0.00000000\n",
      "           x_eff  = [-0.22843817 -0.97068348],\n",
      "\n",
      "iteration 650: f_best = 0.00000000\n",
      "           x_eff  = [-0.92189357  0.66636103],\n",
      "\n",
      "iteration 651: f_best = 0.00000000\n",
      "           x_eff  = [0.632857   0.48889886],\n",
      "\n",
      "iteration 652: f_best = 0.00000000\n",
      "           x_eff  = [0.19739782 0.34646486],\n",
      "\n",
      "iteration 653: f_best = 0.00000000\n",
      "           x_eff  = [ 0.04177044 -0.31744812],\n",
      "\n",
      "iteration 654: f_best = 0.00000000\n",
      "           x_eff  = [0.04604815 0.61498581],\n",
      "\n",
      "iteration 655: f_best = 0.00000000\n",
      "           x_eff  = [ 0.3587151  -0.09842471],\n",
      "\n",
      "iteration 656: f_best = 0.00000000\n",
      "           x_eff  = [ 0.36906109 -0.81768471],\n",
      "\n",
      "iteration 657: f_best = 0.00000000\n",
      "           x_eff  = [ 0.40082377 -0.32248281],\n",
      "\n",
      "iteration 658: f_best = 0.00000000\n",
      "           x_eff  = [ 0.69875182 -0.80343331],\n",
      "\n",
      "iteration 659: f_best = 0.00000000\n",
      "           x_eff  = [-0.28181659  0.4438292 ],\n",
      "\n",
      "iteration 660: f_best = 0.00000000\n",
      "           x_eff  = [ 0.72756192 -0.61903892],\n",
      "\n",
      "iteration 661: f_best = 0.00000000\n",
      "           x_eff  = [-0.82689508  0.79515095],\n",
      "\n",
      "iteration 662: f_best = 0.00000000\n",
      "           x_eff  = [-0.79021104  0.5972444 ],\n",
      "\n",
      "iteration 663: f_best = 0.00000000\n",
      "           x_eff  = [-0.68405088  0.58861295],\n",
      "\n",
      "iteration 664: f_best = 0.00000000\n",
      "           x_eff  = [-0.8105539  -0.27004457],\n",
      "\n",
      "iteration 665: f_best = 0.00000000\n",
      "           x_eff  = [-0.28235554 -0.18465851],\n",
      "\n",
      "iteration 666: f_best = 0.00000000\n",
      "           x_eff  = [-0.44457001 -0.40417443],\n",
      "\n",
      "iteration 667: f_best = 0.00000000\n",
      "           x_eff  = [0.3265509  0.69001194],\n",
      "\n",
      "iteration 668: f_best = 0.00000000\n",
      "           x_eff  = [ 0.00440636 -0.72669632],\n",
      "\n",
      "iteration 669: f_best = 0.00000000\n",
      "           x_eff  = [-0.43197313  0.29741733],\n",
      "\n",
      "iteration 670: f_best = 0.00000000\n",
      "           x_eff  = [0.08574362 0.52749278],\n",
      "\n",
      "iteration 671: f_best = 0.00000000\n",
      "           x_eff  = [ 0.13567959 -0.50611257],\n",
      "\n",
      "iteration 672: f_best = 0.00000000\n",
      "           x_eff  = [-0.76849029 -0.01216504],\n",
      "\n",
      "iteration 673: f_best = 0.00000000\n",
      "           x_eff  = [0.56223979 0.70063112],\n",
      "\n",
      "iteration 674: f_best = 0.00000000\n",
      "           x_eff  = [-0.17047282  0.66656654],\n",
      "\n",
      "iteration 675: f_best = 0.00000000\n",
      "           x_eff  = [ 0.37992608 -0.64862914],\n",
      "\n",
      "iteration 676: f_best = 0.00000000\n",
      "           x_eff  = [-0.03864408 -0.29135593],\n",
      "\n",
      "iteration 677: f_best = 0.00000000\n",
      "           x_eff  = [0.26449666 0.40366695],\n",
      "\n",
      "iteration 678: f_best = 0.00000000\n",
      "           x_eff  = [0.70397691 0.56807236],\n",
      "\n",
      "iteration 679: f_best = 0.00000000\n",
      "           x_eff  = [0.47548244 0.46743725],\n",
      "\n",
      "iteration 680: f_best = 0.00000000\n",
      "           x_eff  = [-0.686348   0.3794297],\n",
      "\n",
      "iteration 681: f_best = 0.00000000\n",
      "           x_eff  = [0.12911434 0.12644238],\n",
      "\n",
      "iteration 682: f_best = 0.00000000\n",
      "           x_eff  = [-0.61149598 -0.0802564 ],\n",
      "\n",
      "iteration 683: f_best = 0.00000000\n",
      "           x_eff  = [-0.26275033 -0.1129412 ],\n",
      "\n",
      "iteration 684: f_best = 0.00000000\n",
      "           x_eff  = [-0.45632373 -0.2831166 ],\n",
      "\n",
      "iteration 685: f_best = 0.00000000\n",
      "           x_eff  = [-0.00305075  0.08524888],\n",
      "\n",
      "iteration 686: f_best = 0.00000000\n",
      "           x_eff  = [ 0.37127464 -0.11618264],\n",
      "\n",
      "iteration 687: f_best = 0.00000000\n",
      "           x_eff  = [0.43437421 0.56228843],\n",
      "\n",
      "iteration 688: f_best = 0.00000000\n",
      "           x_eff  = [ 0.66600595 -0.5726769 ],\n",
      "\n",
      "iteration 689: f_best = 0.00000000\n",
      "           x_eff  = [-0.34049651  0.59189171],\n",
      "\n",
      "iteration 690: f_best = 0.00000000\n",
      "           x_eff  = [-0.59851672  0.22404192],\n",
      "\n",
      "iteration 691: f_best = 0.00000000\n",
      "           x_eff  = [-0.44519119 -0.12493417],\n",
      "\n",
      "iteration 692: f_best = 0.00000000\n",
      "           x_eff  = [0.43546333 0.12688487],\n",
      "\n",
      "iteration 693: f_best = 0.00000000\n",
      "           x_eff  = [-0.11298476 -0.18751105],\n",
      "\n",
      "iteration 694: f_best = 0.00000000\n",
      "           x_eff  = [ 0.47479473 -0.15811947],\n",
      "\n",
      "iteration 695: f_best = 0.00000000\n",
      "           x_eff  = [-0.05503235  0.60139952],\n",
      "\n",
      "iteration 696: f_best = 0.00000000\n",
      "           x_eff  = [0.34188326 0.12557153],\n",
      "\n",
      "iteration 697: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03482836 -0.3104247 ],\n",
      "\n",
      "iteration 698: f_best = 0.00000000\n",
      "           x_eff  = [-0.49936368 -0.10116788],\n",
      "\n",
      "iteration 699: f_best = 0.00000000\n",
      "           x_eff  = [-0.26347138  0.15211367],\n",
      "\n",
      "iteration 700: f_best = 0.00000000\n",
      "           x_eff  = [ 0.37053444 -0.5037624 ],\n",
      "\n",
      "iteration 701: f_best = 0.00000000\n",
      "           x_eff  = [ 0.4123596  -0.14111467],\n",
      "\n",
      "iteration 702: f_best = 0.00000000\n",
      "           x_eff  = [0.00685435 0.27797307],\n",
      "\n",
      "iteration 703: f_best = 0.00000000\n",
      "           x_eff  = [-0.5532091   0.32080788],\n",
      "\n",
      "iteration 704: f_best = 0.00000000\n",
      "           x_eff  = [-0.01035123  0.12632407],\n",
      "\n",
      "iteration 705: f_best = 0.00000000\n",
      "           x_eff  = [ 0.1780793  -0.01082826],\n",
      "\n",
      "iteration 706: f_best = 0.00000000\n",
      "           x_eff  = [0.49247696 0.00720395],\n",
      "\n",
      "iteration 707: f_best = 0.00000000\n",
      "           x_eff  = [-0.23205864 -0.24654462],\n",
      "\n",
      "iteration 708: f_best = 0.00000000\n",
      "           x_eff  = [0.1251719  0.19629385],\n",
      "\n",
      "iteration 709: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03771301 -0.02674822],\n",
      "\n",
      "iteration 710: f_best = 0.00000000\n",
      "           x_eff  = [ 0.30917306 -0.07436464],\n",
      "\n",
      "iteration 711: f_best = 0.00000000\n",
      "           x_eff  = [-0.36196969  0.19728246],\n",
      "\n",
      "iteration 712: f_best = 0.00000000\n",
      "           x_eff  = [-0.0728809  -0.09950007],\n",
      "\n",
      "iteration 713: f_best = 0.00000000\n",
      "           x_eff  = [-0.20917101 -0.34162807],\n",
      "\n",
      "iteration 714: f_best = 0.00000000\n",
      "           x_eff  = [ 0.11127753 -0.10424679],\n",
      "\n",
      "iteration 715: f_best = 0.00000000\n",
      "           x_eff  = [ 0.21111193 -0.17010395],\n",
      "\n",
      "iteration 716: f_best = 0.00000000\n",
      "           x_eff  = [-0.08968502 -0.32255479],\n",
      "\n",
      "iteration 717: f_best = 0.00000000\n",
      "           x_eff  = [-0.06181936  0.22933567],\n",
      "\n",
      "iteration 718: f_best = 0.00000000\n",
      "           x_eff  = [ 0.38996299 -0.38370954],\n",
      "\n",
      "iteration 719: f_best = 0.00000000\n",
      "           x_eff  = [-0.37468956  0.09553523],\n",
      "\n",
      "iteration 720: f_best = 0.00000000\n",
      "           x_eff  = [0.14415977 0.27584118],\n",
      "\n",
      "iteration 721: f_best = 0.00000000\n",
      "           x_eff  = [-0.28147562  0.08498618],\n",
      "\n",
      "iteration 722: f_best = 0.00000000\n",
      "           x_eff  = [0.42521503 0.22455437],\n",
      "\n",
      "iteration 723: f_best = 0.00000000\n",
      "           x_eff  = [0.44646482 0.24469168],\n",
      "\n",
      "iteration 724: f_best = 0.00000000\n",
      "           x_eff  = [-0.26338485 -0.12252482],\n",
      "\n",
      "iteration 725: f_best = 0.00000000\n",
      "           x_eff  = [0.3235677  0.02308325],\n",
      "\n",
      "iteration 726: f_best = 0.00000000\n",
      "           x_eff  = [-0.20673529  0.35810275],\n",
      "\n",
      "iteration 727: f_best = 0.00000000\n",
      "           x_eff  = [-0.34843525 -0.00946197],\n",
      "\n",
      "iteration 728: f_best = 0.00000000\n",
      "           x_eff  = [ 0.36473761 -0.26898634],\n",
      "\n",
      "iteration 729: f_best = 0.00000000\n",
      "           x_eff  = [-0.0960546  -0.18992511],\n",
      "\n",
      "iteration 730: f_best = 0.00000000\n",
      "           x_eff  = [ 0.08473647 -0.16373223],\n",
      "\n",
      "iteration 731: f_best = 0.00000000\n",
      "           x_eff  = [0.33794604 0.2345518 ],\n",
      "\n",
      "iteration 732: f_best = 0.00000000\n",
      "           x_eff  = [-0.13688674  0.03446008],\n",
      "\n",
      "iteration 733: f_best = 0.00000000\n",
      "           x_eff  = [-0.30594701  0.17685241],\n",
      "\n",
      "iteration 734: f_best = 0.00000000\n",
      "           x_eff  = [0.12533872 0.14864572],\n",
      "\n",
      "iteration 735: f_best = 0.00000000\n",
      "           x_eff  = [0.05110136 0.36987471],\n",
      "\n",
      "iteration 736: f_best = 0.00000000\n",
      "           x_eff  = [ 0.33217954 -0.35551487],\n",
      "\n",
      "iteration 737: f_best = 0.00000000\n",
      "           x_eff  = [0.39100024 0.41511222],\n",
      "\n",
      "iteration 738: f_best = 0.00000000\n",
      "           x_eff  = [-0.08723295 -0.22196087],\n",
      "\n",
      "iteration 739: f_best = 0.00000000\n",
      "           x_eff  = [-0.29528715 -0.37914152],\n",
      "\n",
      "iteration 740: f_best = 0.00000000\n",
      "           x_eff  = [-0.13028432  0.24451489],\n",
      "\n",
      "iteration 741: f_best = 0.00000000\n",
      "           x_eff  = [0.00887441 0.15229044],\n",
      "\n",
      "iteration 742: f_best = 0.00000000\n",
      "           x_eff  = [ 0.22563303 -0.19586268],\n",
      "\n",
      "iteration 743: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03358766 -0.08033495],\n",
      "\n",
      "iteration 744: f_best = 0.00000000\n",
      "           x_eff  = [ 0.33650345 -0.24783523],\n",
      "\n",
      "iteration 745: f_best = 0.00000000\n",
      "           x_eff  = [-0.30868799 -0.1556029 ],\n",
      "\n",
      "iteration 746: f_best = 0.00000000\n",
      "           x_eff  = [ 0.32896996 -0.37987352],\n",
      "\n",
      "iteration 747: f_best = 0.00000000\n",
      "           x_eff  = [ 0.25949816 -0.36596548],\n",
      "\n",
      "iteration 748: f_best = 0.00000000\n",
      "           x_eff  = [-0.11484654  0.06300939],\n",
      "\n",
      "iteration 749: f_best = 0.00000000\n",
      "           x_eff  = [-0.35930418 -0.28889835],\n",
      "\n",
      "iteration 750: f_best = 0.00000000\n",
      "           x_eff  = [ 0.3197851  -0.16875774],\n",
      "\n",
      "iteration 751: f_best = 0.00000000\n",
      "           x_eff  = [-0.2833343  -0.27662802],\n",
      "\n",
      "iteration 752: f_best = 0.00000000\n",
      "           x_eff  = [ 0.10891939 -0.28106433],\n",
      "\n",
      "iteration 753: f_best = 0.00000000\n",
      "           x_eff  = [ 0.17423089 -0.01689839],\n",
      "\n",
      "iteration 754: f_best = 0.00000000\n",
      "           x_eff  = [-0.19206387  0.00193958],\n",
      "\n",
      "iteration 755: f_best = 0.00000000\n",
      "           x_eff  = [-0.20137435  0.23123015],\n",
      "\n",
      "iteration 756: f_best = 0.00000000\n",
      "           x_eff  = [ 0.04251017 -0.33096601],\n",
      "\n",
      "iteration 757: f_best = 0.00000000\n",
      "           x_eff  = [ 0.27087192 -0.23101457],\n",
      "\n",
      "iteration 758: f_best = 0.00000000\n",
      "           x_eff  = [-0.17497384  0.19432823],\n",
      "\n",
      "iteration 759: f_best = 0.00000000\n",
      "           x_eff  = [0.01515597 0.05828145],\n",
      "\n",
      "iteration 760: f_best = 0.00000000\n",
      "           x_eff  = [0.09071994 0.19128508],\n",
      "\n",
      "iteration 761: f_best = 0.00000000\n",
      "           x_eff  = [-0.14705291 -0.31006458],\n",
      "\n",
      "iteration 762: f_best = 0.00000000\n",
      "           x_eff  = [ 0.28009861 -0.32472165],\n",
      "\n",
      "iteration 763: f_best = 0.00000000\n",
      "           x_eff  = [0.20791563 0.2051518 ],\n",
      "\n",
      "iteration 764: f_best = 0.00000000\n",
      "           x_eff  = [-0.0809515  -0.22674083],\n",
      "\n",
      "iteration 765: f_best = 0.00000000\n",
      "           x_eff  = [-0.30247565  0.02421537],\n",
      "\n",
      "iteration 766: f_best = 0.00000000\n",
      "           x_eff  = [-0.16185856 -0.19063224],\n",
      "\n",
      "iteration 767: f_best = 0.00000000\n",
      "           x_eff  = [ 0.18338731 -0.21946219],\n",
      "\n",
      "iteration 768: f_best = 0.00000000\n",
      "           x_eff  = [-0.13766385  0.28464698],\n",
      "\n",
      "iteration 769: f_best = 0.00000000\n",
      "           x_eff  = [ 0.26326403 -0.2227447 ],\n",
      "\n",
      "iteration 770: f_best = 0.00000000\n",
      "           x_eff  = [-0.12819493  0.08807534],\n",
      "\n",
      "iteration 771: f_best = 0.00000000\n",
      "           x_eff  = [-0.08887138  0.22918898],\n",
      "\n",
      "iteration 772: f_best = 0.00000000\n",
      "           x_eff  = [-0.03951144 -0.10043085],\n",
      "\n",
      "iteration 773: f_best = 0.00000000\n",
      "           x_eff  = [-0.04976478 -0.15915825],\n",
      "\n",
      "iteration 774: f_best = 0.00000000\n",
      "           x_eff  = [-0.17170225 -0.06649279],\n",
      "\n",
      "iteration 775: f_best = 0.00000000\n",
      "           x_eff  = [ 0.19677098 -0.19889423],\n",
      "\n",
      "iteration 776: f_best = 0.00000000\n",
      "           x_eff  = [0.20428779 0.13465142],\n",
      "\n",
      "iteration 777: f_best = 0.00000000\n",
      "           x_eff  = [-0.04429578 -0.24400726],\n",
      "\n",
      "iteration 778: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03630688 -0.21051176],\n",
      "\n",
      "iteration 779: f_best = 0.00000000\n",
      "           x_eff  = [-0.04888838 -0.04324056],\n",
      "\n",
      "iteration 780: f_best = 0.00000000\n",
      "           x_eff  = [-0.25595913  0.25024085],\n",
      "\n",
      "iteration 781: f_best = 0.00000000\n",
      "           x_eff  = [-0.13512873 -0.00333748],\n",
      "\n",
      "iteration 782: f_best = 0.00000000\n",
      "           x_eff  = [-0.16521249  0.01980021],\n",
      "\n",
      "iteration 783: f_best = 0.00000000\n",
      "           x_eff  = [ 0.06321643 -0.13864146],\n",
      "\n",
      "iteration 784: f_best = 0.00000000\n",
      "           x_eff  = [-0.141182   -0.06083817],\n",
      "\n",
      "iteration 785: f_best = 0.00000000\n",
      "           x_eff  = [-0.01496747 -0.10454317],\n",
      "\n",
      "iteration 786: f_best = 0.00000000\n",
      "           x_eff  = [-0.00173942 -0.17812769],\n",
      "\n",
      "iteration 787: f_best = 0.00000000\n",
      "           x_eff  = [0.09375411 0.01043488],\n",
      "\n",
      "iteration 788: f_best = 0.00000000\n",
      "           x_eff  = [-0.20900194  0.06230978],\n",
      "\n",
      "iteration 789: f_best = 0.00000000\n",
      "           x_eff  = [-0.22990963  0.16963207],\n",
      "\n",
      "iteration 790: f_best = 0.00000000\n",
      "           x_eff  = [ 0.14476914 -0.08921429],\n",
      "\n",
      "iteration 791: f_best = 0.00000000\n",
      "           x_eff  = [-0.01844172  0.16605234],\n",
      "\n",
      "iteration 792: f_best = 0.00000000\n",
      "           x_eff  = [ 0.07328099 -0.19321673],\n",
      "\n",
      "iteration 793: f_best = 0.00000000\n",
      "           x_eff  = [0.20943296 0.04567285],\n",
      "\n",
      "iteration 794: f_best = 0.00000000\n",
      "           x_eff  = [0.19678211 0.23427222],\n",
      "\n",
      "iteration 795: f_best = 0.00000000\n",
      "           x_eff  = [0.00753575 0.15028053],\n",
      "\n",
      "iteration 796: f_best = 0.00000000\n",
      "           x_eff  = [-0.19048386  0.17960357],\n",
      "\n",
      "iteration 797: f_best = 0.00000000\n",
      "           x_eff  = [0.01557835 0.03591677],\n",
      "\n",
      "iteration 798: f_best = 0.00000000\n",
      "           x_eff  = [ 0.13198049 -0.04495393],\n",
      "\n",
      "iteration 799: f_best = 0.00000000\n",
      "           x_eff  = [-0.13975905 -0.1822737 ],\n",
      "\n",
      "iteration 800: f_best = 0.00000000\n",
      "           x_eff  = [-0.06509915  0.12376296],\n",
      "\n",
      "iteration 801: f_best = 0.00000000\n",
      "           x_eff  = [0.14896828 0.00461447],\n",
      "\n",
      "iteration 802: f_best = 0.00000000\n",
      "           x_eff  = [-0.07107221  0.05131636],\n",
      "\n",
      "iteration 803: f_best = 0.00000000\n",
      "           x_eff  = [0.12685921 0.10723067],\n",
      "\n",
      "iteration 804: f_best = 0.00000000\n",
      "           x_eff  = [-0.11272323  0.18933661],\n",
      "\n",
      "iteration 805: f_best = 0.00000000\n",
      "           x_eff  = [ 0.13145534 -0.16151305],\n",
      "\n",
      "iteration 806: f_best = 0.00000000\n",
      "           x_eff  = [-0.00151584 -0.05881008],\n",
      "\n",
      "iteration 807: f_best = 0.00000000\n",
      "           x_eff  = [-0.10640958 -0.16616939],\n",
      "\n",
      "iteration 808: f_best = 0.00000000\n",
      "           x_eff  = [ 0.103836   -0.11066126],\n",
      "\n",
      "iteration 809: f_best = 0.00000000\n",
      "           x_eff  = [-0.08732304 -0.16999018],\n",
      "\n",
      "iteration 810: f_best = 0.00000000\n",
      "           x_eff  = [-0.01772669 -0.14903786],\n",
      "\n",
      "iteration 811: f_best = 0.00000000\n",
      "           x_eff  = [-0.17252149  0.09605868],\n",
      "\n",
      "iteration 812: f_best = 0.00000000\n",
      "           x_eff  = [0.15384366 0.01854292],\n",
      "\n",
      "iteration 813: f_best = 0.00000000\n",
      "           x_eff  = [-0.09580013  0.01040749],\n",
      "\n",
      "iteration 814: f_best = 0.00000000\n",
      "           x_eff  = [-0.12344517  0.07090389],\n",
      "\n",
      "iteration 815: f_best = 0.00000000\n",
      "           x_eff  = [0.01540757 0.12583955],\n",
      "\n",
      "iteration 816: f_best = 0.00000000\n",
      "           x_eff  = [-0.037009   -0.11751152],\n",
      "\n",
      "iteration 817: f_best = 0.00000000\n",
      "           x_eff  = [-0.17696404  0.06244985],\n",
      "\n",
      "iteration 818: f_best = 0.00000000\n",
      "           x_eff  = [-0.12628885  0.036718  ],\n",
      "\n",
      "iteration 819: f_best = 0.00000000\n",
      "           x_eff  = [-0.16349852  0.14265012],\n",
      "\n",
      "iteration 820: f_best = 0.00000000\n",
      "           x_eff  = [-0.04141654  0.12557018],\n",
      "\n",
      "iteration 821: f_best = 0.00000000\n",
      "           x_eff  = [0.02758049 0.13987697],\n",
      "\n",
      "iteration 822: f_best = 0.00000000\n",
      "           x_eff  = [ 0.17109759 -0.07198439],\n",
      "\n",
      "iteration 823: f_best = 0.00000000\n",
      "           x_eff  = [-0.14367688  0.03792108],\n",
      "\n",
      "iteration 824: f_best = 0.00000000\n",
      "           x_eff  = [0.10764852 0.11910775],\n",
      "\n",
      "iteration 825: f_best = 0.00000000\n",
      "           x_eff  = [-0.0239088  -0.01143971],\n",
      "\n",
      "iteration 826: f_best = 0.00000000\n",
      "           x_eff  = [0.01641421 0.10805381],\n",
      "\n",
      "iteration 827: f_best = 0.00000000\n",
      "           x_eff  = [ 0.10797645 -0.09522152],\n",
      "\n",
      "iteration 828: f_best = 0.00000000\n",
      "           x_eff  = [-0.05961392  0.10073286],\n",
      "\n",
      "iteration 829: f_best = 0.00000000\n",
      "           x_eff  = [-0.0487185   0.12397344],\n",
      "\n",
      "iteration 830: f_best = 0.00000000\n",
      "           x_eff  = [-0.05343059 -0.12812913],\n",
      "\n",
      "iteration 831: f_best = 0.00000000\n",
      "           x_eff  = [-0.07621125 -0.09892481],\n",
      "\n",
      "iteration 832: f_best = 0.00000000\n",
      "           x_eff  = [-0.06978451  0.0640495 ],\n",
      "\n",
      "iteration 833: f_best = 0.00000000\n",
      "           x_eff  = [ 0.00591742 -0.15134065],\n",
      "\n",
      "iteration 834: f_best = 0.00000000\n",
      "           x_eff  = [ 0.10803997 -0.14784917],\n",
      "\n",
      "iteration 835: f_best = 0.00000000\n",
      "           x_eff  = [-0.13616408 -0.02230226],\n",
      "\n",
      "iteration 836: f_best = 0.00000000\n",
      "           x_eff  = [ 0.01895155 -0.11313767],\n",
      "\n",
      "iteration 837: f_best = 0.00000000\n",
      "           x_eff  = [-0.07661499 -0.01822781],\n",
      "\n",
      "iteration 838: f_best = 0.00000000\n",
      "           x_eff  = [-0.06200788 -0.05358131],\n",
      "\n",
      "iteration 839: f_best = 0.00000000\n",
      "           x_eff  = [ 0.11490687 -0.02644273],\n",
      "\n",
      "iteration 840: f_best = 0.00000000\n",
      "           x_eff  = [-0.0647121  -0.07396439],\n",
      "\n",
      "iteration 841: f_best = 0.00000000\n",
      "           x_eff  = [0.12499923 0.13515184],\n",
      "\n",
      "iteration 842: f_best = 0.00000000\n",
      "           x_eff  = [0.08893519 0.05721695],\n",
      "\n",
      "iteration 843: f_best = 0.00000000\n",
      "           x_eff  = [-0.09402041  0.03945373],\n",
      "\n",
      "iteration 844: f_best = 0.00000000\n",
      "           x_eff  = [0.08970466 0.11286462],\n",
      "\n",
      "iteration 845: f_best = 0.00000000\n",
      "           x_eff  = [-0.00783563 -0.12241184],\n",
      "\n",
      "iteration 846: f_best = 0.00000000\n",
      "           x_eff  = [-0.0604509  -0.09437916],\n",
      "\n",
      "iteration 847: f_best = 0.00000000\n",
      "           x_eff  = [-0.13106673 -0.06027726],\n",
      "\n",
      "iteration 848: f_best = 0.00000000\n",
      "           x_eff  = [-0.13440092 -0.00109481],\n",
      "\n",
      "iteration 849: f_best = 0.00000000\n",
      "           x_eff  = [-0.03014694 -0.06438899],\n",
      "\n",
      "iteration 850: f_best = 0.00000000\n",
      "           x_eff  = [-0.09154012  0.03715409],\n",
      "\n",
      "iteration 851: f_best = 0.00000000\n",
      "           x_eff  = [-0.12282674 -0.12835769],\n",
      "\n",
      "iteration 852: f_best = 0.00000000\n",
      "           x_eff  = [0.08254274 0.11842595],\n",
      "\n",
      "iteration 853: f_best = 0.00000000\n",
      "           x_eff  = [-0.09455919 -0.09588336],\n",
      "\n",
      "iteration 854: f_best = 0.00000000\n",
      "           x_eff  = [-0.03720386 -0.09393724],\n",
      "\n",
      "iteration 855: f_best = 0.00000000\n",
      "           x_eff  = [0.09642357 0.02068511],\n",
      "\n",
      "iteration 856: f_best = 0.00000000\n",
      "           x_eff  = [0.11161203 0.11353625],\n",
      "\n",
      "iteration 857: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02160105 -0.0944146 ],\n",
      "\n",
      "iteration 858: f_best = 0.00000000\n",
      "           x_eff  = [-0.09488836 -0.00621146],\n",
      "\n",
      "iteration 859: f_best = 0.00000000\n",
      "           x_eff  = [ 0.06523671 -0.11584408],\n",
      "\n",
      "iteration 860: f_best = 0.00000000\n",
      "           x_eff  = [ 0.00604974 -0.00976919],\n",
      "\n",
      "iteration 861: f_best = 0.00000000\n",
      "           x_eff  = [0.10811479 0.05311471],\n",
      "\n",
      "iteration 862: f_best = 0.00000000\n",
      "           x_eff  = [-0.02680482 -0.00089221],\n",
      "\n",
      "iteration 863: f_best = 0.00000000\n",
      "           x_eff  = [-0.02157588 -0.02508703],\n",
      "\n",
      "iteration 864: f_best = 0.00000000\n",
      "           x_eff  = [-0.03944756  0.01720126],\n",
      "\n",
      "iteration 865: f_best = 0.00000000\n",
      "           x_eff  = [ 0.07149465 -0.09079172],\n",
      "\n",
      "iteration 866: f_best = 0.00000000\n",
      "           x_eff  = [-0.06924821  0.05282592],\n",
      "\n",
      "iteration 867: f_best = 0.00000000\n",
      "           x_eff  = [ 0.10814475 -0.00826622],\n",
      "\n",
      "iteration 868: f_best = 0.00000000\n",
      "           x_eff  = [-0.06603369  0.04317351],\n",
      "\n",
      "iteration 869: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03979648 -0.02389692],\n",
      "\n",
      "iteration 870: f_best = 0.00000000\n",
      "           x_eff  = [ 0.06266085 -0.04663446],\n",
      "\n",
      "iteration 871: f_best = 0.00000000\n",
      "           x_eff  = [ 0.10742117 -0.04510346],\n",
      "\n",
      "iteration 872: f_best = 0.00000000\n",
      "           x_eff  = [-0.02980611 -0.06983569],\n",
      "\n",
      "iteration 873: f_best = 0.00000000\n",
      "           x_eff  = [ 0.09725609 -0.06745727],\n",
      "\n",
      "iteration 874: f_best = 0.00000000\n",
      "           x_eff  = [-0.09755126  0.05249645],\n",
      "\n",
      "iteration 875: f_best = 0.00000000\n",
      "           x_eff  = [-0.06387963 -0.10480992],\n",
      "\n",
      "iteration 876: f_best = 0.00000000\n",
      "           x_eff  = [-0.04847813  0.00201591],\n",
      "\n",
      "iteration 877: f_best = 0.00000000\n",
      "           x_eff  = [0.0734012  0.07464802],\n",
      "\n",
      "iteration 878: f_best = 0.00000000\n",
      "           x_eff  = [0.03526669 0.02502892],\n",
      "\n",
      "iteration 879: f_best = 0.00000000\n",
      "           x_eff  = [-0.05950592 -0.06292357],\n",
      "\n",
      "iteration 880: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03275826 -0.08555882],\n",
      "\n",
      "iteration 881: f_best = 0.00000000\n",
      "           x_eff  = [-0.00470322  0.04488166],\n",
      "\n",
      "iteration 882: f_best = 0.00000000\n",
      "           x_eff  = [0.03993395 0.04418894],\n",
      "\n",
      "iteration 883: f_best = 0.00000000\n",
      "           x_eff  = [ 0.0615846  -0.09252945],\n",
      "\n",
      "iteration 884: f_best = 0.00000000\n",
      "           x_eff  = [-0.01745107  0.01700604],\n",
      "\n",
      "iteration 885: f_best = 0.00000000\n",
      "           x_eff  = [0.05039099 0.01480358],\n",
      "\n",
      "iteration 886: f_best = 0.00000000\n",
      "           x_eff  = [ 0.09152    -0.04711621],\n",
      "\n",
      "iteration 887: f_best = 0.00000000\n",
      "           x_eff  = [-0.07044574  0.05274456],\n",
      "\n",
      "iteration 888: f_best = 0.00000000\n",
      "           x_eff  = [-0.01904975 -0.05072268],\n",
      "\n",
      "iteration 889: f_best = 0.00000000\n",
      "           x_eff  = [-0.00322955  0.04172399],\n",
      "\n",
      "iteration 890: f_best = 0.00000000\n",
      "           x_eff  = [-0.07382191 -0.03595638],\n",
      "\n",
      "iteration 891: f_best = 0.00000000\n",
      "           x_eff  = [-0.08255666  0.02717795],\n",
      "\n",
      "iteration 892: f_best = 0.00000000\n",
      "           x_eff  = [ 0.0672311  -0.00383471],\n",
      "\n",
      "iteration 893: f_best = 0.00000000\n",
      "           x_eff  = [-0.00767266  0.03500516],\n",
      "\n",
      "iteration 894: f_best = 0.00000000\n",
      "           x_eff  = [0.02570179 0.06807649],\n",
      "\n",
      "iteration 895: f_best = 0.00000000\n",
      "           x_eff  = [-0.05884366 -0.01649496],\n",
      "\n",
      "iteration 896: f_best = 0.00000000\n",
      "           x_eff  = [-0.0804307  -0.06166677],\n",
      "\n",
      "iteration 897: f_best = 0.00000000\n",
      "           x_eff  = [0.07194796 0.02042255],\n",
      "\n",
      "iteration 898: f_best = 0.00000000\n",
      "           x_eff  = [-0.0641743   0.04344793],\n",
      "\n",
      "iteration 899: f_best = 0.00000000\n",
      "           x_eff  = [-0.06392383 -0.06072492],\n",
      "\n",
      "iteration 900: f_best = 0.00000000\n",
      "           x_eff  = [-0.03246593  0.02435285],\n",
      "\n",
      "iteration 901: f_best = 0.00000000\n",
      "           x_eff  = [-0.00098816 -0.03714529],\n",
      "\n",
      "iteration 902: f_best = 0.00000000\n",
      "           x_eff  = [-0.01003848  0.02074178],\n",
      "\n",
      "iteration 903: f_best = 0.00000000\n",
      "           x_eff  = [-0.03137191 -0.07092467],\n",
      "\n",
      "iteration 904: f_best = 0.00000000\n",
      "           x_eff  = [0.02270241 0.06640447],\n",
      "\n",
      "iteration 905: f_best = 0.00000000\n",
      "           x_eff  = [0.05795967 0.03734948],\n",
      "\n",
      "iteration 906: f_best = 0.00000000\n",
      "           x_eff  = [ 0.01479245 -0.03847736],\n",
      "\n",
      "iteration 907: f_best = 0.00000000\n",
      "           x_eff  = [-0.02547594 -0.06064857],\n",
      "\n",
      "iteration 908: f_best = 0.00000000\n",
      "           x_eff  = [-0.01217199  0.04223945],\n",
      "\n",
      "iteration 909: f_best = 0.00000000\n",
      "           x_eff  = [0.01906981 0.03521033],\n",
      "\n",
      "iteration 910: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03177541 -0.06334913],\n",
      "\n",
      "iteration 911: f_best = 0.00000000\n",
      "           x_eff  = [-0.06714758  0.0121401 ],\n",
      "\n",
      "iteration 912: f_best = 0.00000000\n",
      "           x_eff  = [-0.06350181 -0.06607973],\n",
      "\n",
      "iteration 913: f_best = 0.00000000\n",
      "           x_eff  = [0.05152814 0.00680669],\n",
      "\n",
      "iteration 914: f_best = 0.00000000\n",
      "           x_eff  = [0.00813528 0.04722656],\n",
      "\n",
      "iteration 915: f_best = 0.00000000\n",
      "           x_eff  = [0.01622665 0.06539173],\n",
      "\n",
      "iteration 916: f_best = 0.00000000\n",
      "           x_eff  = [0.04768191 0.05558168],\n",
      "\n",
      "iteration 917: f_best = 0.00000000\n",
      "           x_eff  = [-0.04261932 -0.01202112],\n",
      "\n",
      "iteration 918: f_best = 0.00000000\n",
      "           x_eff  = [ 0.04320809 -0.03761282],\n",
      "\n",
      "iteration 919: f_best = 0.00000000\n",
      "           x_eff  = [-0.01039798 -0.0470004 ],\n",
      "\n",
      "iteration 920: f_best = 0.00000000\n",
      "           x_eff  = [-0.06121198 -0.00866904],\n",
      "\n",
      "iteration 921: f_best = 0.00000000\n",
      "           x_eff  = [-0.02601443 -0.03465181],\n",
      "\n",
      "iteration 922: f_best = 0.00000000\n",
      "           x_eff  = [-0.05995852 -0.03490996],\n",
      "\n",
      "iteration 923: f_best = 0.00000000\n",
      "           x_eff  = [ 0.04603283 -0.05849516],\n",
      "\n",
      "iteration 924: f_best = 0.00000000\n",
      "           x_eff  = [0.03232374 0.00915283],\n",
      "\n",
      "iteration 925: f_best = 0.00000000\n",
      "           x_eff  = [0.05659417 0.05543983],\n",
      "\n",
      "iteration 926: f_best = 0.00000000\n",
      "           x_eff  = [-0.05668668  0.01245489],\n",
      "\n",
      "iteration 927: f_best = 0.00000000\n",
      "           x_eff  = [-0.04736497 -0.02738237],\n",
      "\n",
      "iteration 928: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03061049 -0.01224175],\n",
      "\n",
      "iteration 929: f_best = 0.00000000\n",
      "           x_eff  = [ 0.04069889 -0.01527446],\n",
      "\n",
      "iteration 930: f_best = 0.00000000\n",
      "           x_eff  = [-0.05835174 -0.053628  ],\n",
      "\n",
      "iteration 931: f_best = 0.00000000\n",
      "           x_eff  = [0.01139026 0.05303688],\n",
      "\n",
      "iteration 932: f_best = 0.00000000\n",
      "           x_eff  = [-0.01373196 -0.02474465],\n",
      "\n",
      "iteration 933: f_best = 0.00000000\n",
      "           x_eff  = [ 0.040924   -0.04661277],\n",
      "\n",
      "iteration 934: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03716513 -0.01788592],\n",
      "\n",
      "iteration 935: f_best = 0.00000000\n",
      "           x_eff  = [-0.02829254  0.03739948],\n",
      "\n",
      "iteration 936: f_best = 0.00000000\n",
      "           x_eff  = [-0.01291163 -0.02467897],\n",
      "\n",
      "iteration 937: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03167601 -0.0551887 ],\n",
      "\n",
      "iteration 938: f_best = 0.00000000\n",
      "           x_eff  = [ 0.01700125 -0.01072181],\n",
      "\n",
      "iteration 939: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02052806 -0.00306482],\n",
      "\n",
      "iteration 940: f_best = 0.00000000\n",
      "           x_eff  = [ 0.04473505 -0.04463467],\n",
      "\n",
      "iteration 941: f_best = 0.00000000\n",
      "           x_eff  = [-0.04092465 -0.01499842],\n",
      "\n",
      "iteration 942: f_best = 0.00000000\n",
      "           x_eff  = [-0.0312952  -0.04001463],\n",
      "\n",
      "iteration 943: f_best = 0.00000000\n",
      "           x_eff  = [0.02883527 0.01620684],\n",
      "\n",
      "iteration 944: f_best = 0.00000000\n",
      "           x_eff  = [-0.05140173  0.00167988],\n",
      "\n",
      "iteration 945: f_best = 0.00000000\n",
      "           x_eff  = [-0.02317718  0.05113868],\n",
      "\n",
      "iteration 946: f_best = 0.00000000\n",
      "           x_eff  = [0.02072098 0.04520034],\n",
      "\n",
      "iteration 947: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03454462 -0.01939454],\n",
      "\n",
      "iteration 948: f_best = 0.00000000\n",
      "           x_eff  = [0.01694617 0.01563619],\n",
      "\n",
      "iteration 949: f_best = 0.00000000\n",
      "           x_eff  = [-0.03029881  0.0314988 ],\n",
      "\n",
      "iteration 950: f_best = 0.00000000\n",
      "           x_eff  = [-0.00450068 -0.01385612],\n",
      "\n",
      "iteration 951: f_best = 0.00000000\n",
      "           x_eff  = [ 0.01303935 -0.01842517],\n",
      "\n",
      "iteration 952: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02195508 -0.01438237],\n",
      "\n",
      "iteration 953: f_best = 0.00000000\n",
      "           x_eff  = [0.01978943 0.03260131],\n",
      "\n",
      "iteration 954: f_best = 0.00000000\n",
      "           x_eff  = [-0.0027721  -0.03666864],\n",
      "\n",
      "iteration 955: f_best = 0.00000000\n",
      "           x_eff  = [-0.03034181  0.02947194],\n",
      "\n",
      "iteration 956: f_best = 0.00000000\n",
      "           x_eff  = [-0.04048035 -0.02501711],\n",
      "\n",
      "iteration 957: f_best = 0.00000000\n",
      "           x_eff  = [-0.00393166 -0.00159539],\n",
      "\n",
      "iteration 958: f_best = 0.00000000\n",
      "           x_eff  = [-0.04439963 -0.01373446],\n",
      "\n",
      "iteration 959: f_best = 0.00000000\n",
      "           x_eff  = [0.02762638 0.01579377],\n",
      "\n",
      "iteration 960: f_best = 0.00000000\n",
      "           x_eff  = [ 0.0127684  -0.03723521],\n",
      "\n",
      "iteration 961: f_best = 0.00000000\n",
      "           x_eff  = [-0.02108598  0.02295814],\n",
      "\n",
      "iteration 962: f_best = 0.00000000\n",
      "           x_eff  = [-0.02565289  0.04088923],\n",
      "\n",
      "iteration 963: f_best = 0.00000000\n",
      "           x_eff  = [-0.00667277  0.00011044],\n",
      "\n",
      "iteration 964: f_best = 0.00000000\n",
      "           x_eff  = [-2.36293872e-05 -9.10828259e-03],\n",
      "\n",
      "iteration 965: f_best = 0.00000000\n",
      "           x_eff  = [-0.02176986 -0.0400928 ],\n",
      "\n",
      "iteration 966: f_best = 0.00000000\n",
      "           x_eff  = [-0.02935744 -0.01642183],\n",
      "\n",
      "iteration 967: f_best = 0.00000000\n",
      "           x_eff  = [ 0.0125549  -0.02979071],\n",
      "\n",
      "iteration 968: f_best = 0.00000000\n",
      "           x_eff  = [-0.04069612 -0.02038755],\n",
      "\n",
      "iteration 969: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03017488 -0.02913686],\n",
      "\n",
      "iteration 970: f_best = 0.00000000\n",
      "           x_eff  = [-0.01978514  0.00282921],\n",
      "\n",
      "iteration 971: f_best = 0.00000000\n",
      "           x_eff  = [-0.00216141 -0.01846839],\n",
      "\n",
      "iteration 972: f_best = 0.00000000\n",
      "           x_eff  = [ 0.00068203 -0.03193329],\n",
      "\n",
      "iteration 973: f_best = 0.00000000\n",
      "           x_eff  = [-0.03667272 -0.00474654],\n",
      "\n",
      "iteration 974: f_best = 0.00000000\n",
      "           x_eff  = [0.00925773 0.00630822],\n",
      "\n",
      "iteration 975: f_best = 0.00000000\n",
      "           x_eff  = [-0.02006965 -0.02085849],\n",
      "\n",
      "iteration 976: f_best = 0.00000000\n",
      "           x_eff  = [ 0.0302273  -0.02524837],\n",
      "\n",
      "iteration 977: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02995612 -0.01517566],\n",
      "\n",
      "iteration 978: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02448054 -0.03744962],\n",
      "\n",
      "iteration 979: f_best = 0.00000000\n",
      "           x_eff  = [0.03271927 0.02617684],\n",
      "\n",
      "iteration 980: f_best = 0.00000000\n",
      "           x_eff  = [0.00842785 0.01081994],\n",
      "\n",
      "iteration 981: f_best = 0.00000000\n",
      "           x_eff  = [-0.02916274  0.01115919],\n",
      "\n",
      "iteration 982: f_best = 0.00000000\n",
      "           x_eff  = [-0.01890465  0.01888653],\n",
      "\n",
      "iteration 983: f_best = 0.00000000\n",
      "           x_eff  = [ 0.03435219 -0.00185372],\n",
      "\n",
      "iteration 984: f_best = 0.00000000\n",
      "           x_eff  = [ 0.01496055 -0.01686134],\n",
      "\n",
      "iteration 985: f_best = 0.00000000\n",
      "           x_eff  = [-0.00624152 -0.01704127],\n",
      "\n",
      "iteration 986: f_best = 0.00000000\n",
      "           x_eff  = [0.01518011 0.01268738],\n",
      "\n",
      "iteration 987: f_best = 0.00000000\n",
      "           x_eff  = [-0.00496222  0.03425888],\n",
      "\n",
      "iteration 988: f_best = 0.00000000\n",
      "           x_eff  = [-0.00083556 -0.01845199],\n",
      "\n",
      "iteration 989: f_best = 0.00000000\n",
      "           x_eff  = [-0.01574654 -0.01206547],\n",
      "\n",
      "iteration 990: f_best = 0.00000000\n",
      "           x_eff  = [-0.03103913  0.0151335 ],\n",
      "\n",
      "iteration 991: f_best = 0.00000000\n",
      "           x_eff  = [-0.01534824 -0.01832724],\n",
      "\n",
      "iteration 992: f_best = 0.00000000\n",
      "           x_eff  = [-0.00075921 -0.00131042],\n",
      "\n",
      "iteration 993: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02276746 -0.01393722],\n",
      "\n",
      "iteration 994: f_best = 0.00000000\n",
      "           x_eff  = [-0.0175286  0.0203114],\n",
      "\n",
      "iteration 995: f_best = 0.00000000\n",
      "           x_eff  = [ 0.00505685 -0.00558814],\n",
      "\n",
      "iteration 996: f_best = 0.00000000\n",
      "           x_eff  = [-0.00031343 -0.02079906],\n",
      "\n",
      "iteration 997: f_best = 0.00000000\n",
      "           x_eff  = [-0.01837752 -0.01163124],\n",
      "\n",
      "iteration 998: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02062479 -0.02806657],\n",
      "\n",
      "iteration 999: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02248848 -0.02707264],\n",
      "\n",
      "iteration 100: f_best = 3.16640125\n",
      "           x_eff  = [106.76072757  35.5075015 ],\n",
      "\n",
      "iteration 101: f_best = 3.16640125\n",
      "           x_eff  = [ -58.81392571 -135.56107891],\n",
      "\n",
      "iteration 102: f_best = 3.16640125\n",
      "           x_eff  = [194.29393524 204.70744156],\n",
      "\n",
      "iteration 103: f_best = 3.16640125\n",
      "           x_eff  = [238.28731432  48.74541398],\n",
      "\n",
      "iteration 104: f_best = 3.16640125\n",
      "           x_eff  = [-69.30149691 215.07551157],\n",
      "\n",
      "iteration 105: f_best = 0.59898066\n",
      "           x_eff  = [ 4.74319111 49.79117886],\n",
      "\n",
      "iteration 106: f_best = 0.59898066\n",
      "           x_eff  = [  81.73433143 -260.27976939],\n",
      "\n",
      "iteration 107: f_best = 0.59898066\n",
      "           x_eff  = [115.30043328 147.02708099],\n",
      "\n",
      "iteration 108: f_best = 0.59898066\n",
      "           x_eff  = [105.65210548 -10.09662218],\n",
      "\n",
      "iteration 109: f_best = 0.59898066\n",
      "           x_eff  = [ 204.34400493 -230.78792068],\n",
      "\n",
      "iteration 110: f_best = 0.59898066\n",
      "           x_eff  = [-121.20317616 -133.73560139],\n",
      "\n",
      "iteration 111: f_best = 0.59898066\n",
      "           x_eff  = [-125.93443915  243.52786854],\n",
      "\n",
      "iteration 112: f_best = 0.59898066\n",
      "           x_eff  = [-220.02461329 -238.46396448],\n",
      "\n",
      "iteration 113: f_best = 0.59898066\n",
      "           x_eff  = [-226.12978997 -211.25716574],\n",
      "\n",
      "iteration 114: f_best = 0.59898066\n",
      "           x_eff  = [ 92.23687525 -39.59275277],\n",
      "\n",
      "iteration 115: f_best = 0.59898066\n",
      "           x_eff  = [57.99820852 23.70120621],\n",
      "\n",
      "iteration 116: f_best = 0.59898066\n",
      "           x_eff  = [-46.91838063 -58.48252585],\n",
      "\n",
      "iteration 117: f_best = 0.59898066\n",
      "           x_eff  = [218.45073143  65.55414968],\n",
      "\n",
      "iteration 118: f_best = 0.59898066\n",
      "           x_eff  = [ 80.07250087 205.86893609],\n",
      "\n",
      "iteration 119: f_best = 0.59898066\n",
      "           x_eff  = [201.7386597 179.3848916],\n",
      "\n",
      "iteration 120: f_best = 0.59898066\n",
      "           x_eff  = [-83.61154169  -4.33523151],\n",
      "\n",
      "iteration 121: f_best = 0.59898066\n",
      "           x_eff  = [-130.5017824   -75.24601328],\n",
      "\n",
      "iteration 122: f_best = 0.59898066\n",
      "           x_eff  = [-154.67738192  227.94040691],\n",
      "\n",
      "iteration 123: f_best = 0.59898066\n",
      "           x_eff  = [ 87.49847954 255.06696714],\n",
      "\n",
      "iteration 124: f_best = 0.59898066\n",
      "           x_eff  = [ 44.36982671 202.46371922],\n",
      "\n",
      "iteration 125: f_best = 0.59898066\n",
      "           x_eff  = [254.43031178   8.51857544],\n",
      "\n",
      "iteration 126: f_best = 0.59898066\n",
      "           x_eff  = [262.01382519 124.22765187],\n",
      "\n",
      "iteration 127: f_best = 0.59898066\n",
      "           x_eff  = [239.02711151 137.68962659],\n",
      "\n",
      "iteration 128: f_best = 0.59898066\n",
      "           x_eff  = [181.22165563 115.78728931],\n",
      "\n",
      "iteration 129: f_best = 0.59898066\n",
      "           x_eff  = [95.32860894 53.20635477],\n",
      "\n",
      "iteration 130: f_best = 0.59898066\n",
      "           x_eff  = [198.65008422 116.01904466],\n",
      "\n",
      "iteration 131: f_best = 0.59898066\n",
      "           x_eff  = [223.32374805 243.37977082],\n",
      "\n",
      "iteration 132: f_best = 0.59898066\n",
      "           x_eff  = [ 195.63744658 -141.26635602],\n",
      "\n",
      "iteration 133: f_best = 0.59898066\n",
      "           x_eff  = [ 229.96123879 -187.55478282],\n",
      "\n",
      "iteration 134: f_best = 0.59898066\n",
      "           x_eff  = [-59.5309062  269.83566537],\n",
      "\n",
      "iteration 135: f_best = 0.59898066\n",
      "           x_eff  = [214.92046111 -44.77073416],\n",
      "\n",
      "iteration 136: f_best = 0.59898066\n",
      "           x_eff  = [-14.82212472 159.25761378],\n",
      "\n",
      "iteration 137: f_best = 0.59898066\n",
      "           x_eff  = [  57.53627892 -192.61393043],\n",
      "\n",
      "iteration 138: f_best = 0.59898066\n",
      "           x_eff  = [135.4384394   43.56705086],\n",
      "\n",
      "iteration 139: f_best = 0.59898066\n",
      "           x_eff  = [59.43933474 87.34082511],\n",
      "\n",
      "iteration 140: f_best = 0.59898066\n",
      "           x_eff  = [150.48590714 -83.69444698],\n",
      "\n",
      "iteration 141: f_best = 0.59898066\n",
      "           x_eff  = [-155.06391078  152.62324164],\n",
      "\n",
      "iteration 142: f_best = 0.59898066\n",
      "           x_eff  = [-93.27348993   1.2108824 ],\n",
      "\n",
      "iteration 143: f_best = 0.59898066\n",
      "           x_eff  = [207.59965089  19.33440288],\n",
      "\n",
      "iteration 144: f_best = 0.59898066\n",
      "           x_eff  = [ 11.97892113 137.04248166],\n",
      "\n",
      "iteration 145: f_best = 0.59898066\n",
      "           x_eff  = [-200.96372552  -35.10348554],\n",
      "\n",
      "iteration 146: f_best = 0.59898066\n",
      "           x_eff  = [82.50474072 49.73621774],\n",
      "\n",
      "iteration 147: f_best = 0.59898066\n",
      "           x_eff  = [-82.86590851 250.6027752 ],\n",
      "\n",
      "iteration 148: f_best = 0.59898066\n",
      "           x_eff  = [154.38260931 136.55211229],\n",
      "\n",
      "iteration 149: f_best = 0.59898066\n",
      "           x_eff  = [-142.55982667 -189.61201819],\n",
      "\n",
      "iteration 150: f_best = 0.59898066\n",
      "           x_eff  = [-63.89432032  61.55072466],\n",
      "\n",
      "iteration 151: f_best = 0.59898066\n",
      "           x_eff  = [-129.76312496 -135.6624648 ],\n",
      "\n",
      "iteration 152: f_best = 0.59898066\n",
      "           x_eff  = [134.77561419  82.77187619],\n",
      "\n",
      "iteration 153: f_best = 0.59898066\n",
      "           x_eff  = [176.57348471 -46.11635773],\n",
      "\n",
      "iteration 154: f_best = 0.59898066\n",
      "           x_eff  = [110.46701657  38.15964155],\n",
      "\n",
      "iteration 155: f_best = 0.59898066\n",
      "           x_eff  = [209.73407617 -23.47489046],\n",
      "\n",
      "iteration 156: f_best = 0.59898066\n",
      "           x_eff  = [88.83628011 55.31876354],\n",
      "\n",
      "iteration 157: f_best = 0.59898066\n",
      "           x_eff  = [ 47.01773273 116.21975186],\n",
      "\n",
      "iteration 158: f_best = 0.59898066\n",
      "           x_eff  = [-87.51412585 -17.84149043],\n",
      "\n",
      "iteration 159: f_best = 0.59898066\n",
      "           x_eff  = [  30.7600247  -120.77419165],\n",
      "\n",
      "iteration 160: f_best = 0.59898066\n",
      "           x_eff  = [ 177.79743756 -122.73808552],\n",
      "\n",
      "iteration 161: f_best = 0.59898066\n",
      "           x_eff  = [-65.05233928 118.86111651],\n",
      "\n",
      "iteration 162: f_best = 0.59898066\n",
      "           x_eff  = [170.69974051 -12.4185528 ],\n",
      "\n",
      "iteration 163: f_best = 0.59898066\n",
      "           x_eff  = [-108.45872862   95.04688286],\n",
      "\n",
      "iteration 164: f_best = 0.59898066\n",
      "           x_eff  = [-151.55984183   10.84622257],\n",
      "\n",
      "iteration 165: f_best = 0.59898066\n",
      "           x_eff  = [ 11.08110286 147.34363055],\n",
      "\n",
      "iteration 166: f_best = 0.59898066\n",
      "           x_eff  = [71.51856454 42.14573956],\n",
      "\n",
      "iteration 167: f_best = 0.59898066\n",
      "           x_eff  = [147.46710301 -59.86073741],\n",
      "\n",
      "iteration 168: f_best = 0.59898066\n",
      "           x_eff  = [  4.26189366 -70.66406083],\n",
      "\n",
      "iteration 169: f_best = 0.59898066\n",
      "           x_eff  = [-121.33443131 -155.50357989],\n",
      "\n",
      "iteration 170: f_best = 0.59898066\n",
      "           x_eff  = [  23.04356307 -142.46109073],\n",
      "\n",
      "iteration 171: f_best = 0.59898066\n",
      "           x_eff  = [184.34931661  85.39903734],\n",
      "\n",
      "iteration 172: f_best = 0.59898066\n",
      "           x_eff  = [-93.30527528 -57.39616046],\n",
      "\n",
      "iteration 173: f_best = 0.59898066\n",
      "           x_eff  = [105.65654836 -92.02803131],\n",
      "\n",
      "iteration 174: f_best = 0.59898066\n",
      "           x_eff  = [134.61207774  24.35120028],\n",
      "\n",
      "iteration 175: f_best = 0.59898066\n",
      "           x_eff  = [ 21.79506429 184.76384336],\n",
      "\n",
      "iteration 176: f_best = 0.59898066\n",
      "           x_eff  = [-120.00572054  172.89607917],\n",
      "\n",
      "iteration 177: f_best = 0.59898066\n",
      "           x_eff  = [-1.79117404e+02  1.41562584e-01],\n",
      "\n",
      "iteration 178: f_best = 0.59898066\n",
      "           x_eff  = [-23.00337405  98.28662166],\n",
      "\n",
      "iteration 179: f_best = 0.59898066\n",
      "           x_eff  = [-109.12426317   21.70964717],\n",
      "\n",
      "iteration 180: f_best = 0.59898066\n",
      "           x_eff  = [-53.38476069  68.50645808],\n",
      "\n",
      "iteration 181: f_best = 0.59898066\n",
      "           x_eff  = [ 14.79000209 -69.6453197 ],\n",
      "\n",
      "iteration 182: f_best = 0.59898066\n",
      "           x_eff  = [-86.93375988  90.6572656 ],\n",
      "\n",
      "iteration 183: f_best = 0.59898066\n",
      "           x_eff  = [-76.72450094 184.96778966],\n",
      "\n",
      "iteration 184: f_best = 0.59898066\n",
      "           x_eff  = [180.40111766  22.71017962],\n",
      "\n",
      "iteration 185: f_best = 0.59898066\n",
      "           x_eff  = [77.44643962 16.47482871],\n",
      "\n",
      "iteration 186: f_best = 0.59898066\n",
      "           x_eff  = [100.42795096 147.712134  ],\n",
      "\n",
      "iteration 187: f_best = 0.59898066\n",
      "           x_eff  = [-70.26848031  53.83614434],\n",
      "\n",
      "iteration 188: f_best = 0.59898066\n",
      "           x_eff  = [95.05914141 63.28761754],\n",
      "\n",
      "iteration 189: f_best = 0.59898066\n",
      "           x_eff  = [ 81.17769704 -55.69005577],\n",
      "\n",
      "iteration 190: f_best = 0.59898066\n",
      "           x_eff  = [-17.48706943 143.84700982],\n",
      "\n",
      "iteration 191: f_best = 0.59898066\n",
      "           x_eff  = [-75.18565964   1.10486523],\n",
      "\n",
      "iteration 192: f_best = 0.59898066\n",
      "           x_eff  = [-105.22819838  -56.07594987],\n",
      "\n",
      "iteration 193: f_best = 0.59898066\n",
      "           x_eff  = [ -4.51795263 122.9853224 ],\n",
      "\n",
      "iteration 194: f_best = 0.59898066\n",
      "           x_eff  = [-39.33070792 195.78896878],\n",
      "\n",
      "iteration 195: f_best = 0.59898066\n",
      "           x_eff  = [-136.17606155   93.96348176],\n",
      "\n",
      "iteration 196: f_best = 0.59898066\n",
      "           x_eff  = [15.68688354 48.62437748],\n",
      "\n",
      "iteration 197: f_best = 0.59898066\n",
      "           x_eff  = [-150.70876373  129.09237279],\n",
      "\n",
      "iteration 198: f_best = 0.59898066\n",
      "           x_eff  = [-37.1795548  177.27569278],\n",
      "\n",
      "iteration 199: f_best = 0.59898066\n",
      "           x_eff  = [-155.11642013   39.65076288],\n",
      "\n",
      "iteration 200: f_best = 0.59898066\n",
      "           x_eff  = [ 73.23685822 -86.37851866],\n",
      "\n",
      "iteration 201: f_best = 0.59898066\n",
      "           x_eff  = [   2.85622277 -107.01189668],\n",
      "\n",
      "iteration 202: f_best = 0.59898066\n",
      "           x_eff  = [154.60365795 175.30297677],\n",
      "\n",
      "iteration 203: f_best = 0.59898066\n",
      "           x_eff  = [ 159.33332943 -114.10103159],\n",
      "\n",
      "iteration 204: f_best = 0.59898066\n",
      "           x_eff  = [-89.54987767 177.76924748],\n",
      "\n",
      "iteration 205: f_best = 0.59898066\n",
      "           x_eff  = [ -19.52343124 -100.0213176 ],\n",
      "\n",
      "iteration 206: f_best = 0.35512819\n",
      "           x_eff  = [37.10725648  1.1399247 ],\n",
      "\n",
      "iteration 207: f_best = 0.35512819\n",
      "           x_eff  = [-112.81763949    7.68176591],\n",
      "\n",
      "iteration 208: f_best = 0.35512819\n",
      "           x_eff  = [-59.67703058 -67.74833146],\n",
      "\n",
      "iteration 209: f_best = 0.35512819\n",
      "           x_eff  = [27.81128247 49.81892418],\n",
      "\n",
      "iteration 210: f_best = 0.35512819\n",
      "           x_eff  = [ 32.15893849 -73.82990979],\n",
      "\n",
      "iteration 211: f_best = 0.35512819\n",
      "           x_eff  = [-6.00411361 62.59443662],\n",
      "\n",
      "iteration 212: f_best = 0.35512819\n",
      "           x_eff  = [102.33932244 -46.56096606],\n",
      "\n",
      "iteration 213: f_best = 0.35512819\n",
      "           x_eff  = [40.33805166 32.16438711],\n",
      "\n",
      "iteration 214: f_best = 0.35512819\n",
      "           x_eff  = [162.38205672 129.05845929],\n",
      "\n",
      "iteration 215: f_best = 0.35512819\n",
      "           x_eff  = [153.46251331  26.940066  ],\n",
      "\n",
      "iteration 216: f_best = 0.35512819\n",
      "           x_eff  = [58.98594537 14.63975962],\n",
      "\n",
      "iteration 217: f_best = 0.35512819\n",
      "           x_eff  = [121.75248016  94.706283  ],\n",
      "\n",
      "iteration 218: f_best = 0.35512819\n",
      "           x_eff  = [117.43695857 108.09346198],\n",
      "\n",
      "iteration 219: f_best = 0.35512819\n",
      "           x_eff  = [ 45.25766921 -92.84460867],\n",
      "\n",
      "iteration 220: f_best = 0.35512819\n",
      "           x_eff  = [57.36354096 80.48509228],\n",
      "\n",
      "iteration 221: f_best = 0.35512819\n",
      "           x_eff  = [ -5.57830327 118.7390558 ],\n",
      "\n",
      "iteration 222: f_best = 0.35512819\n",
      "           x_eff  = [68.85019031 18.38487861],\n",
      "\n",
      "iteration 223: f_best = 0.35512819\n",
      "           x_eff  = [ 61.56558669 -13.46068797],\n",
      "\n",
      "iteration 224: f_best = 0.35512819\n",
      "           x_eff  = [49.15394243 96.61273023],\n",
      "\n",
      "iteration 225: f_best = 0.35512819\n",
      "           x_eff  = [-29.21712082 -84.65843029],\n",
      "\n",
      "iteration 226: f_best = 0.35512819\n",
      "           x_eff  = [-68.04128045 -67.01488246],\n",
      "\n",
      "iteration 227: f_best = 0.35512819\n",
      "           x_eff  = [-95.94470959   9.26177178],\n",
      "\n",
      "iteration 228: f_best = 0.35512819\n",
      "           x_eff  = [-42.67130217 126.37705065],\n",
      "\n",
      "iteration 229: f_best = 0.00739604\n",
      "           x_eff  = [-2.32805812  6.88727452],\n",
      "\n",
      "iteration 230: f_best = 0.00739604\n",
      "           x_eff  = [-51.6631872   26.51604742],\n",
      "\n",
      "iteration 231: f_best = 0.00739604\n",
      "           x_eff  = [112.62023746 -43.62915195],\n",
      "\n",
      "iteration 232: f_best = 0.00739604\n",
      "           x_eff  = [27.5668783  33.45076775],\n",
      "\n",
      "iteration 233: f_best = 0.00739604\n",
      "           x_eff  = [18.23364837 70.84462518],\n",
      "\n",
      "iteration 234: f_best = 0.00739604\n",
      "           x_eff  = [119.20936082 111.03687218],\n",
      "\n",
      "iteration 235: f_best = 0.00739604\n",
      "           x_eff  = [-11.78809502 -66.9950534 ],\n",
      "\n",
      "iteration 236: f_best = 0.00739604\n",
      "           x_eff  = [42.3830602 92.3691296],\n",
      "\n",
      "iteration 237: f_best = 0.00739604\n",
      "           x_eff  = [33.85368325 14.92127912],\n",
      "\n",
      "iteration 238: f_best = 0.00739604\n",
      "           x_eff  = [-74.50461699  38.32263956],\n",
      "\n",
      "iteration 239: f_best = 0.00739604\n",
      "           x_eff  = [ 69.63544374 -40.92050985],\n",
      "\n",
      "iteration 240: f_best = 0.00739604\n",
      "           x_eff  = [61.21711422 -2.40874193],\n",
      "\n",
      "iteration 241: f_best = 0.00739604\n",
      "           x_eff  = [-20.82324124  65.04911056],\n",
      "\n",
      "iteration 242: f_best = 0.00739604\n",
      "           x_eff  = [-71.63900246  40.93981555],\n",
      "\n",
      "iteration 243: f_best = 0.00739604\n",
      "           x_eff  = [-59.03281172 -68.93745841],\n",
      "\n",
      "iteration 244: f_best = 0.00739604\n",
      "           x_eff  = [111.81192511 -18.76812011],\n",
      "\n",
      "iteration 245: f_best = 0.00739604\n",
      "           x_eff  = [ -16.03379777 -102.75228596],\n",
      "\n",
      "iteration 246: f_best = 0.00739604\n",
      "           x_eff  = [-58.97856349  74.677301  ],\n",
      "\n",
      "iteration 247: f_best = 0.00739604\n",
      "           x_eff  = [74.56798585 13.72084632],\n",
      "\n",
      "iteration 248: f_best = 0.00739604\n",
      "           x_eff  = [ 62.76366917 -98.52695546],\n",
      "\n",
      "iteration 249: f_best = 0.00739604\n",
      "           x_eff  = [-57.25630911 -51.54332841],\n",
      "\n",
      "iteration 250: f_best = 0.00739604\n",
      "           x_eff  = [ 26.32090778 -62.34890812],\n",
      "\n",
      "iteration 251: f_best = 0.00739604\n",
      "           x_eff  = [73.17101674 -9.09425512],\n",
      "\n",
      "iteration 252: f_best = 0.00739604\n",
      "           x_eff  = [102.98708065   1.11938495],\n",
      "\n",
      "iteration 253: f_best = 0.00739604\n",
      "           x_eff  = [96.45107306 32.30412029],\n",
      "\n",
      "iteration 254: f_best = 0.00739604\n",
      "           x_eff  = [-31.68131555 -71.4061382 ],\n",
      "\n",
      "iteration 255: f_best = 0.00739604\n",
      "           x_eff  = [66.02914545 27.20312036],\n",
      "\n",
      "iteration 256: f_best = 0.00739604\n",
      "           x_eff  = [68.04481953 31.25491077],\n",
      "\n",
      "iteration 257: f_best = 0.00739604\n",
      "           x_eff  = [ 86.04537386 -39.62409632],\n",
      "\n",
      "iteration 258: f_best = 0.00739604\n",
      "           x_eff  = [ 49.61221102 101.49960136],\n",
      "\n",
      "iteration 259: f_best = 0.00739604\n",
      "           x_eff  = [-89.47817046  13.16568824],\n",
      "\n",
      "iteration 260: f_best = 0.00739604\n",
      "           x_eff  = [20.68550807 43.39168863],\n",
      "\n",
      "iteration 261: f_best = 0.00739604\n",
      "           x_eff  = [ 72.7742544  -48.23197571],\n",
      "\n",
      "iteration 262: f_best = 0.00739604\n",
      "           x_eff  = [ 58.29687748 -15.38699821],\n",
      "\n",
      "iteration 263: f_best = 0.00739604\n",
      "           x_eff  = [-37.06760531 -81.5140803 ],\n",
      "\n",
      "iteration 264: f_best = 0.00739604\n",
      "           x_eff  = [-53.61125022 -77.44939331],\n",
      "\n",
      "iteration 265: f_best = 0.00739604\n",
      "           x_eff  = [-1.19981337 39.69536977],\n",
      "\n",
      "iteration 266: f_best = 0.00739604\n",
      "           x_eff  = [-98.17720421  64.44083322],\n",
      "\n",
      "iteration 267: f_best = 0.00739604\n",
      "           x_eff  = [-55.01691591  63.01277806],\n",
      "\n",
      "iteration 268: f_best = 0.00739604\n",
      "           x_eff  = [ 29.45194976 -44.12628512],\n",
      "\n",
      "iteration 269: f_best = 0.00739604\n",
      "           x_eff  = [ 20.88721142 -13.7651387 ],\n",
      "\n",
      "iteration 270: f_best = 0.00739604\n",
      "           x_eff  = [  0.52156519 -85.99589327],\n",
      "\n",
      "iteration 271: f_best = 0.00739604\n",
      "           x_eff  = [-43.18527041  29.19841136],\n",
      "\n",
      "iteration 272: f_best = 0.00739604\n",
      "           x_eff  = [ 8.9438563  84.46185518],\n",
      "\n",
      "iteration 273: f_best = 0.00739604\n",
      "           x_eff  = [-78.93786623 -31.23217715],\n",
      "\n",
      "iteration 274: f_best = 0.00739604\n",
      "           x_eff  = [-37.10399461  66.49314712],\n",
      "\n",
      "iteration 275: f_best = 0.00739604\n",
      "           x_eff  = [-46.6930486   62.71832644],\n",
      "\n",
      "iteration 276: f_best = 0.00739604\n",
      "           x_eff  = [-76.27263121 -69.38900644],\n",
      "\n",
      "iteration 277: f_best = 0.00739604\n",
      "           x_eff  = [ 71.24613135 -49.67058542],\n",
      "\n",
      "iteration 278: f_best = 0.00739604\n",
      "           x_eff  = [ 26.08905832 -17.95099332],\n",
      "\n",
      "iteration 279: f_best = 0.00739604\n",
      "           x_eff  = [54.60779844 -3.64916455],\n",
      "\n",
      "iteration 280: f_best = 0.00739604\n",
      "           x_eff  = [ 69.21436191 -21.94631653],\n",
      "\n",
      "iteration 281: f_best = 0.00739604\n",
      "           x_eff  = [-48.42581849 -55.3171361 ],\n",
      "\n",
      "iteration 282: f_best = 0.00739604\n",
      "           x_eff  = [16.49680551 31.71836763],\n",
      "\n",
      "iteration 283: f_best = 0.00739604\n",
      "           x_eff  = [ 47.15983367 -15.50918653],\n",
      "\n",
      "iteration 284: f_best = 0.00739604\n",
      "           x_eff  = [ 51.63743504 -30.99814788],\n",
      "\n",
      "iteration 285: f_best = 0.00739604\n",
      "           x_eff  = [73.58206225 44.98924618],\n",
      "\n",
      "iteration 286: f_best = 0.00739604\n",
      "           x_eff  = [ 27.95283186 -31.83668679],\n",
      "\n",
      "iteration 287: f_best = 0.00739604\n",
      "           x_eff  = [11.75840865 35.2096072 ],\n",
      "\n",
      "iteration 288: f_best = 0.00739604\n",
      "           x_eff  = [-13.38898057 -45.51499324],\n",
      "\n",
      "iteration 289: f_best = 0.00739604\n",
      "           x_eff  = [-70.6169611  -69.45096309],\n",
      "\n",
      "iteration 290: f_best = 0.00739604\n",
      "           x_eff  = [-20.87308262  77.78711928],\n",
      "\n",
      "iteration 291: f_best = 0.00739604\n",
      "           x_eff  = [ 34.79261914 -28.62689544],\n",
      "\n",
      "iteration 292: f_best = 0.00739604\n",
      "           x_eff  = [ 9.38662123 22.55641137],\n",
      "\n",
      "iteration 293: f_best = 0.00739604\n",
      "           x_eff  = [39.48163349 36.06680993],\n",
      "\n",
      "iteration 294: f_best = 0.00739604\n",
      "           x_eff  = [ 16.67559909 -29.62056464],\n",
      "\n",
      "iteration 295: f_best = 0.00739604\n",
      "           x_eff  = [ 47.31239664 -28.37536947],\n",
      "\n",
      "iteration 296: f_best = 0.00739604\n",
      "           x_eff  = [-69.08095033  46.06639749],\n",
      "\n",
      "iteration 297: f_best = 0.00739604\n",
      "           x_eff  = [-73.59313194  25.1651826 ],\n",
      "\n",
      "iteration 298: f_best = 0.00739604\n",
      "           x_eff  = [40.07500353 44.88188841],\n",
      "\n",
      "iteration 299: f_best = 0.00739604\n",
      "           x_eff  = [51.58637822 -1.9242314 ],\n",
      "\n",
      "iteration 300: f_best = 0.00739604\n",
      "           x_eff  = [-26.34476451  74.31579189],\n",
      "\n",
      "iteration 301: f_best = 0.00739604\n",
      "           x_eff  = [  7.32770424 -49.54961798],\n",
      "\n",
      "iteration 302: f_best = 0.00739604\n",
      "           x_eff  = [-69.53475725  66.3103447 ],\n",
      "\n",
      "iteration 303: f_best = 0.00739604\n",
      "           x_eff  = [  2.40500987 -10.83057435],\n",
      "\n",
      "iteration 304: f_best = 0.00739604\n",
      "           x_eff  = [-28.98443426  -0.88333677],\n",
      "\n",
      "iteration 305: f_best = 0.00739604\n",
      "           x_eff  = [ 44.94465539 -22.21939312],\n",
      "\n",
      "iteration 306: f_best = 0.00739604\n",
      "           x_eff  = [-17.22807431  30.53160599],\n",
      "\n",
      "iteration 307: f_best = 0.00739604\n",
      "           x_eff  = [  0.39592223 -48.43276437],\n",
      "\n",
      "iteration 308: f_best = 0.00739604\n",
      "           x_eff  = [ 45.15452201 -17.51550418],\n",
      "\n",
      "iteration 309: f_best = 0.00739604\n",
      "           x_eff  = [ 21.29719894 -31.20778441],\n",
      "\n",
      "iteration 310: f_best = 0.00739604\n",
      "           x_eff  = [55.60665797 33.83785811],\n",
      "\n",
      "iteration 311: f_best = 0.00739604\n",
      "           x_eff  = [-41.74411301  38.42504097],\n",
      "\n",
      "iteration 312: f_best = 0.00739604\n",
      "           x_eff  = [ 39.51620062 -39.79261053],\n",
      "\n",
      "iteration 313: f_best = 0.00739604\n",
      "           x_eff  = [-30.71201281 -19.85380769],\n",
      "\n",
      "iteration 314: f_best = 0.00739604\n",
      "           x_eff  = [ 23.24433314 -40.032364  ],\n",
      "\n",
      "iteration 315: f_best = 0.00739604\n",
      "           x_eff  = [ 58.46805049 -10.88235375],\n",
      "\n",
      "iteration 316: f_best = 0.00739604\n",
      "           x_eff  = [38.81732116 -5.30013133],\n",
      "\n",
      "iteration 317: f_best = 0.00739604\n",
      "           x_eff  = [-35.0529408  21.3205486],\n",
      "\n",
      "iteration 318: f_best = 0.00739604\n",
      "           x_eff  = [-14.56053297  20.1282784 ],\n",
      "\n",
      "iteration 319: f_best = 0.00739604\n",
      "           x_eff  = [50.95517666  7.55040669],\n",
      "\n",
      "iteration 320: f_best = 0.00739604\n",
      "           x_eff  = [35.86092587 30.67056738],\n",
      "\n",
      "iteration 321: f_best = 0.00739604\n",
      "           x_eff  = [-34.47120601  52.50682512],\n",
      "\n",
      "iteration 322: f_best = 0.00739604\n",
      "           x_eff  = [38.28400349 -3.91590784],\n",
      "\n",
      "iteration 323: f_best = 0.00739604\n",
      "           x_eff  = [27.98458532  2.90967511],\n",
      "\n",
      "iteration 324: f_best = 0.00739604\n",
      "           x_eff  = [  7.12978257 -34.55803811],\n",
      "\n",
      "iteration 325: f_best = 0.00739604\n",
      "           x_eff  = [-40.98458617 -30.68007141],\n",
      "\n",
      "iteration 326: f_best = 0.00739604\n",
      "           x_eff  = [-12.05468643  31.5655252 ],\n",
      "\n",
      "iteration 327: f_best = 0.00739604\n",
      "           x_eff  = [-51.12980523 -26.36752693],\n",
      "\n",
      "iteration 328: f_best = 0.00739604\n",
      "           x_eff  = [-27.14053566 -14.75358695],\n",
      "\n",
      "iteration 329: f_best = 0.00739604\n",
      "           x_eff  = [20.87818873 54.46042413],\n",
      "\n",
      "iteration 330: f_best = 0.00739604\n",
      "           x_eff  = [-25.39101437   2.05093112],\n",
      "\n",
      "iteration 331: f_best = 0.00739604\n",
      "           x_eff  = [-45.71121936  -9.36833556],\n",
      "\n",
      "iteration 332: f_best = 0.00739604\n",
      "           x_eff  = [-24.95949826  25.02678295],\n",
      "\n",
      "iteration 333: f_best = 0.00739604\n",
      "           x_eff  = [-15.72250027 -40.97959777],\n",
      "\n",
      "iteration 334: f_best = 0.00739604\n",
      "           x_eff  = [-19.91372584  51.39822656],\n",
      "\n",
      "iteration 335: f_best = 0.00739604\n",
      "           x_eff  = [49.28108168 -8.10922053],\n",
      "\n",
      "iteration 336: f_best = 0.00739604\n",
      "           x_eff  = [-17.01318296   8.71146829],\n",
      "\n",
      "iteration 337: f_best = 0.00739604\n",
      "           x_eff  = [ 33.18805141 -35.86543069],\n",
      "\n",
      "iteration 338: f_best = 0.00739604\n",
      "           x_eff  = [25.30311658 39.48260641],\n",
      "\n",
      "iteration 339: f_best = 0.00739604\n",
      "           x_eff  = [-34.08204563 -26.79027566],\n",
      "\n",
      "iteration 340: f_best = 0.00739604\n",
      "           x_eff  = [-22.23358934   9.69985769],\n",
      "\n",
      "iteration 341: f_best = 0.00739604\n",
      "           x_eff  = [-6.06869598  1.83716075],\n",
      "\n",
      "iteration 342: f_best = 0.00739604\n",
      "           x_eff  = [-40.88389072 -41.17897893],\n",
      "\n",
      "iteration 343: f_best = 0.00739604\n",
      "           x_eff  = [-36.65010925 -29.45306842],\n",
      "\n",
      "iteration 344: f_best = 0.00739604\n",
      "           x_eff  = [27.81802037 24.74310794],\n",
      "\n",
      "iteration 345: f_best = 0.00739604\n",
      "           x_eff  = [-40.20349408  -8.87705753],\n",
      "\n",
      "iteration 346: f_best = 0.00739604\n",
      "           x_eff  = [-4.66385643 18.89420134],\n",
      "\n",
      "iteration 347: f_best = 0.00739604\n",
      "           x_eff  = [-19.58971274 -31.03072992],\n",
      "\n",
      "iteration 348: f_best = 0.00739604\n",
      "           x_eff  = [-26.75205465 -20.22958601],\n",
      "\n",
      "iteration 349: f_best = 0.00739604\n",
      "           x_eff  = [ 8.35169438 19.59037755],\n",
      "\n",
      "iteration 350: f_best = 0.00739604\n",
      "           x_eff  = [27.12686028 26.85255127],\n",
      "\n",
      "iteration 351: f_best = 0.00739604\n",
      "           x_eff  = [  5.5903166  -38.82565122],\n",
      "\n",
      "iteration 352: f_best = 0.00739604\n",
      "           x_eff  = [-22.56881945  -2.35315241],\n",
      "\n",
      "iteration 353: f_best = 0.00739604\n",
      "           x_eff  = [ 19.30469633 -22.98361697],\n",
      "\n",
      "iteration 354: f_best = 0.00739604\n",
      "           x_eff  = [-28.80041507  40.73773423],\n",
      "\n",
      "iteration 355: f_best = 0.00739604\n",
      "           x_eff  = [-37.92697722 -15.64561788],\n",
      "\n",
      "iteration 356: f_best = 0.00739604\n",
      "           x_eff  = [38.51828578 10.30917416],\n",
      "\n",
      "iteration 357: f_best = 0.00739604\n",
      "           x_eff  = [17.84135834 22.64595438],\n",
      "\n",
      "iteration 358: f_best = 0.00739604\n",
      "           x_eff  = [-15.14177469  33.05671242],\n",
      "\n",
      "iteration 359: f_best = 0.00739604\n",
      "           x_eff  = [-37.71862369  41.61035764],\n",
      "\n",
      "iteration 360: f_best = 0.00739604\n",
      "           x_eff  = [25.87476293 28.47031175],\n",
      "\n",
      "iteration 361: f_best = 0.00739604\n",
      "           x_eff  = [-24.7878639  28.1305532],\n",
      "\n",
      "iteration 362: f_best = 0.00739604\n",
      "           x_eff  = [27.23583727 36.75812706],\n",
      "\n",
      "iteration 363: f_best = 0.00739604\n",
      "           x_eff  = [ 4.68501832 -9.42966181],\n",
      "\n",
      "iteration 364: f_best = 0.00739604\n",
      "           x_eff  = [-27.00020704 -21.01294937],\n",
      "\n",
      "iteration 365: f_best = 0.00739604\n",
      "           x_eff  = [ 23.37343813 -16.65744824],\n",
      "\n",
      "iteration 366: f_best = 0.00739604\n",
      "           x_eff  = [ 29.88965396 -18.87403302],\n",
      "\n",
      "iteration 367: f_best = 0.00739604\n",
      "           x_eff  = [-0.56832062  3.7344051 ],\n",
      "\n",
      "iteration 368: f_best = 0.00739604\n",
      "           x_eff  = [-18.911915    12.54148221],\n",
      "\n",
      "iteration 369: f_best = 0.00739604\n",
      "           x_eff  = [-11.64013046  40.16227898],\n",
      "\n",
      "iteration 370: f_best = 0.00739604\n",
      "           x_eff  = [-14.42107737  -1.95973447],\n",
      "\n",
      "iteration 371: f_best = 0.00739604\n",
      "           x_eff  = [-2.19875979  2.21183833],\n",
      "\n",
      "iteration 372: f_best = 0.00739604\n",
      "           x_eff  = [10.25537479 32.8458242 ],\n",
      "\n",
      "iteration 373: f_best = 0.00739604\n",
      "           x_eff  = [11.39200592  4.05684976],\n",
      "\n",
      "iteration 374: f_best = 0.00739604\n",
      "           x_eff  = [-24.38066847  15.43430307],\n",
      "\n",
      "iteration 375: f_best = 0.00739604\n",
      "           x_eff  = [-8.72142923 24.08254447],\n",
      "\n",
      "iteration 376: f_best = 0.00739604\n",
      "           x_eff  = [  3.95888331 -13.88459645],\n",
      "\n",
      "iteration 377: f_best = 0.00739604\n",
      "           x_eff  = [ 32.30645959 -25.36705427],\n",
      "\n",
      "iteration 378: f_best = 0.00739604\n",
      "           x_eff  = [-26.37597886   8.27226303],\n",
      "\n",
      "iteration 379: f_best = 0.00739604\n",
      "           x_eff  = [-24.24357907 -26.56563739],\n",
      "\n",
      "iteration 380: f_best = 0.00739604\n",
      "           x_eff  = [11.74817691 24.5079893 ],\n",
      "\n",
      "iteration 381: f_best = 0.00739604\n",
      "           x_eff  = [-27.67375968  34.32974318],\n",
      "\n",
      "iteration 382: f_best = 0.00739604\n",
      "           x_eff  = [ 8.08815135 18.06789671],\n",
      "\n",
      "iteration 383: f_best = 0.00739604\n",
      "           x_eff  = [-36.10860551  -6.36405001],\n",
      "\n",
      "iteration 384: f_best = 0.00739604\n",
      "           x_eff  = [ 8.70539554 11.28764598],\n",
      "\n",
      "iteration 385: f_best = 0.00739604\n",
      "           x_eff  = [  7.71430666 -22.29145314],\n",
      "\n",
      "iteration 386: f_best = 0.00739604\n",
      "           x_eff  = [  0.78504415 -10.92246173],\n",
      "\n",
      "iteration 387: f_best = 0.00739604\n",
      "           x_eff  = [-15.79502722  -1.6429845 ],\n",
      "\n",
      "iteration 388: f_best = 0.00739604\n",
      "           x_eff  = [20.73080606 -0.0777435 ],\n",
      "\n",
      "iteration 389: f_best = 0.00739604\n",
      "           x_eff  = [ 13.0751344  -14.14190271],\n",
      "\n",
      "iteration 390: f_best = 0.00739604\n",
      "           x_eff  = [-18.35643651  19.57357178],\n",
      "\n",
      "iteration 391: f_best = 0.00739604\n",
      "           x_eff  = [-13.38916537  -9.61383956],\n",
      "\n",
      "iteration 392: f_best = 0.00739604\n",
      "           x_eff  = [-10.30216988  14.94222776],\n",
      "\n",
      "iteration 393: f_best = 0.00739604\n",
      "           x_eff  = [-23.06190221 -13.02921195],\n",
      "\n",
      "iteration 394: f_best = 0.00739604\n",
      "           x_eff  = [-2.12054078 -4.859689  ],\n",
      "\n",
      "iteration 395: f_best = 0.00739604\n",
      "           x_eff  = [-18.38542086  -6.40689382],\n",
      "\n",
      "iteration 396: f_best = 0.00739604\n",
      "           x_eff  = [ 8.5968224  -2.00904235],\n",
      "\n",
      "iteration 397: f_best = 0.00739604\n",
      "           x_eff  = [25.74898691 23.11546422],\n",
      "\n",
      "iteration 398: f_best = 0.00739604\n",
      "           x_eff  = [ 3.4133967  -2.09282518],\n",
      "\n",
      "iteration 399: f_best = 0.00739604\n",
      "           x_eff  = [-4.74512725 25.07022292],\n",
      "\n",
      "iteration 400: f_best = 0.00739604\n",
      "           x_eff  = [-22.52963805 -13.28205167],\n",
      "\n",
      "iteration 401: f_best = 0.00739604\n",
      "           x_eff  = [ 5.23774252 19.00679265],\n",
      "\n",
      "iteration 402: f_best = 0.00739604\n",
      "           x_eff  = [-13.83084243  17.87013049],\n",
      "\n",
      "iteration 403: f_best = 0.00739604\n",
      "           x_eff  = [-30.02742102  -3.96494358],\n",
      "\n",
      "iteration 404: f_best = 0.00739604\n",
      "           x_eff  = [-29.38252615   0.6134762 ],\n",
      "\n",
      "iteration 405: f_best = 0.00739604\n",
      "           x_eff  = [-6.25672721  5.6978231 ],\n",
      "\n",
      "iteration 406: f_best = 0.00739604\n",
      "           x_eff  = [ 1.40401136 30.33944118],\n",
      "\n",
      "iteration 407: f_best = 0.00739604\n",
      "           x_eff  = [ 23.06839177 -21.94705822],\n",
      "\n",
      "iteration 408: f_best = 0.00000000\n",
      "           x_eff  = [ 0.22372656 -3.02903716],\n",
      "\n",
      "iteration 409: f_best = 0.00000000\n",
      "           x_eff  = [10.70187654  6.61749861],\n",
      "\n",
      "iteration 410: f_best = 0.00000000\n",
      "           x_eff  = [ -4.0905139  -19.17989957],\n",
      "\n",
      "iteration 411: f_best = 0.00000000\n",
      "           x_eff  = [-18.13557999  25.52589011],\n",
      "\n",
      "iteration 412: f_best = 0.00000000\n",
      "           x_eff  = [ 9.17442865 21.50502748],\n",
      "\n",
      "iteration 413: f_best = 0.00000000\n",
      "           x_eff  = [13.27406422 -5.65107788],\n",
      "\n",
      "iteration 414: f_best = 0.00000000\n",
      "           x_eff  = [-7.33033148 21.68608755],\n",
      "\n",
      "iteration 415: f_best = 0.00000000\n",
      "           x_eff  = [23.83351167 19.79800437],\n",
      "\n",
      "iteration 416: f_best = 0.00000000\n",
      "           x_eff  = [20.2927171   8.74894717],\n",
      "\n",
      "iteration 417: f_best = 0.00000000\n",
      "           x_eff  = [ 4.44476861 15.14242128],\n",
      "\n",
      "iteration 418: f_best = 0.00000000\n",
      "           x_eff  = [-16.15957258   0.92109284],\n",
      "\n",
      "iteration 419: f_best = 0.00000000\n",
      "           x_eff  = [ 2.50724734 -9.77793235],\n",
      "\n",
      "iteration 420: f_best = 0.00000000\n",
      "           x_eff  = [-9.79911592  1.18036231],\n",
      "\n",
      "iteration 421: f_best = 0.00000000\n",
      "           x_eff  = [-15.76699729  14.55695928],\n",
      "\n",
      "iteration 422: f_best = 0.00000000\n",
      "           x_eff  = [  9.88117231 -21.92319535],\n",
      "\n",
      "iteration 423: f_best = 0.00000000\n",
      "           x_eff  = [ -9.58132976 -13.42554817],\n",
      "\n",
      "iteration 424: f_best = 0.00000000\n",
      "           x_eff  = [-13.61243615  -5.94778562],\n",
      "\n",
      "iteration 425: f_best = 0.00000000\n",
      "           x_eff  = [21.23008805 19.13152827],\n",
      "\n",
      "iteration 426: f_best = 0.00000000\n",
      "           x_eff  = [ 7.90169361 19.73080506],\n",
      "\n",
      "iteration 427: f_best = 0.00000000\n",
      "           x_eff  = [ -8.20172906 -17.02833193],\n",
      "\n",
      "iteration 428: f_best = 0.00000000\n",
      "           x_eff  = [-21.63607565 -16.7666565 ],\n",
      "\n",
      "iteration 429: f_best = 0.00000000\n",
      "           x_eff  = [-19.14581024 -12.99413963],\n",
      "\n",
      "iteration 430: f_best = 0.00000000\n",
      "           x_eff  = [-8.65800181 17.28926858],\n",
      "\n",
      "iteration 431: f_best = 0.00000000\n",
      "           x_eff  = [ 2.71638635 -5.3462497 ],\n",
      "\n",
      "iteration 432: f_best = 0.00000000\n",
      "           x_eff  = [ 2.838796   12.56032613],\n",
      "\n",
      "iteration 433: f_best = 0.00000000\n",
      "           x_eff  = [15.21994902  2.94124686],\n",
      "\n",
      "iteration 434: f_best = 0.00000000\n",
      "           x_eff  = [-4.3097755 -7.6494508],\n",
      "\n",
      "iteration 435: f_best = 0.00000000\n",
      "           x_eff  = [-10.98844698  -5.00958903],\n",
      "\n",
      "iteration 436: f_best = 0.00000000\n",
      "           x_eff  = [-0.35390715 12.6918992 ],\n",
      "\n",
      "iteration 437: f_best = 0.00000000\n",
      "           x_eff  = [  7.65466775 -18.18107151],\n",
      "\n",
      "iteration 438: f_best = 0.00000000\n",
      "           x_eff  = [-18.12712386 -12.26138321],\n",
      "\n",
      "iteration 439: f_best = 0.00000000\n",
      "           x_eff  = [ 14.58895613 -13.99726734],\n",
      "\n",
      "iteration 440: f_best = 0.00000000\n",
      "           x_eff  = [ 8.31977502 -8.84721195],\n",
      "\n",
      "iteration 441: f_best = 0.00000000\n",
      "           x_eff  = [  6.48677116 -11.66802289],\n",
      "\n",
      "iteration 442: f_best = 0.00000000\n",
      "           x_eff  = [-0.93016872 17.84102867],\n",
      "\n",
      "iteration 443: f_best = 0.00000000\n",
      "           x_eff  = [-9.98968704  7.45401146],\n",
      "\n",
      "iteration 444: f_best = 0.00000000\n",
      "           x_eff  = [10.56173691  1.37778304],\n",
      "\n",
      "iteration 445: f_best = 0.00000000\n",
      "           x_eff  = [-12.94515254   9.75383723],\n",
      "\n",
      "iteration 446: f_best = 0.00000000\n",
      "           x_eff  = [  6.9387373  -18.15944797],\n",
      "\n",
      "iteration 447: f_best = 0.00000000\n",
      "           x_eff  = [16.02153616  1.2681268 ],\n",
      "\n",
      "iteration 448: f_best = 0.00000000\n",
      "           x_eff  = [5.51035325 4.32848598],\n",
      "\n",
      "iteration 449: f_best = 0.00000000\n",
      "           x_eff  = [15.96472348  3.33068735],\n",
      "\n",
      "iteration 450: f_best = 0.00000000\n",
      "           x_eff  = [-15.88507645  -8.85072024],\n",
      "\n",
      "iteration 451: f_best = 0.00000000\n",
      "           x_eff  = [ 0.83565227 -9.66090771],\n",
      "\n",
      "iteration 452: f_best = 0.00000000\n",
      "           x_eff  = [5.47021461 0.05760368],\n",
      "\n",
      "iteration 453: f_best = 0.00000000\n",
      "           x_eff  = [-1.08680896 -3.75142561],\n",
      "\n",
      "iteration 454: f_best = 0.00000000\n",
      "           x_eff  = [-0.11363529 -1.44782554],\n",
      "\n",
      "iteration 455: f_best = 0.00000000\n",
      "           x_eff  = [-16.01917967 -14.4442033 ],\n",
      "\n",
      "iteration 456: f_best = 0.00000000\n",
      "           x_eff  = [-6.64668122 16.37229927],\n",
      "\n",
      "iteration 457: f_best = 0.00000000\n",
      "           x_eff  = [-12.65895904 -12.71442978],\n",
      "\n",
      "iteration 458: f_best = 0.00000000\n",
      "           x_eff  = [-16.21427886   1.12852496],\n",
      "\n",
      "iteration 459: f_best = 0.00000000\n",
      "           x_eff  = [-6.07175453 -9.12028554],\n",
      "\n",
      "iteration 460: f_best = 0.00000000\n",
      "           x_eff  = [-13.98051029  -9.14523009],\n",
      "\n",
      "iteration 461: f_best = 0.00000000\n",
      "           x_eff  = [ 6.47739036 -5.97180495],\n",
      "\n",
      "iteration 462: f_best = 0.00000000\n",
      "           x_eff  = [-12.42702756   3.70521842],\n",
      "\n",
      "iteration 463: f_best = 0.00000000\n",
      "           x_eff  = [2.54828379 0.25405726],\n",
      "\n",
      "iteration 464: f_best = 0.00000000\n",
      "           x_eff  = [  0.15557922 -10.68883193],\n",
      "\n",
      "iteration 465: f_best = 0.00000000\n",
      "           x_eff  = [-13.58680264   9.72148279],\n",
      "\n",
      "iteration 466: f_best = 0.00000000\n",
      "           x_eff  = [-14.94688363   9.83889088],\n",
      "\n",
      "iteration 467: f_best = 0.00000000\n",
      "           x_eff  = [-4.11782134 -4.82772078],\n",
      "\n",
      "iteration 468: f_best = 0.00000000\n",
      "           x_eff  = [3.67609374 6.51273078],\n",
      "\n",
      "iteration 469: f_best = 0.00000000\n",
      "           x_eff  = [-7.13943028  9.01395949],\n",
      "\n",
      "iteration 470: f_best = 0.00000000\n",
      "           x_eff  = [11.93668027  4.94836987],\n",
      "\n",
      "iteration 471: f_best = 0.00000000\n",
      "           x_eff  = [ 0.10008054 11.73808881],\n",
      "\n",
      "iteration 472: f_best = 0.00000000\n",
      "           x_eff  = [-8.0643801   9.68389184],\n",
      "\n",
      "iteration 473: f_best = 0.00000000\n",
      "           x_eff  = [  2.89390548 -12.93093539],\n",
      "\n",
      "iteration 474: f_best = 0.00000000\n",
      "           x_eff  = [-6.15118807  4.23288633],\n",
      "\n",
      "iteration 475: f_best = 0.00000000\n",
      "           x_eff  = [-4.26229263  8.98773649],\n",
      "\n",
      "iteration 476: f_best = 0.00000000\n",
      "           x_eff  = [-4.97591014 -3.02724158],\n",
      "\n",
      "iteration 477: f_best = 0.00000000\n",
      "           x_eff  = [-7.84287232  0.49949762],\n",
      "\n",
      "iteration 478: f_best = 0.00000000\n",
      "           x_eff  = [ 9.90148277 12.66509011],\n",
      "\n",
      "iteration 479: f_best = 0.00000000\n",
      "           x_eff  = [-8.9854017  11.51970027],\n",
      "\n",
      "iteration 480: f_best = 0.00000000\n",
      "           x_eff  = [-8.23117829  5.53283293],\n",
      "\n",
      "iteration 481: f_best = 0.00000000\n",
      "           x_eff  = [-9.92774422 10.25781679],\n",
      "\n",
      "iteration 482: f_best = 0.00000000\n",
      "           x_eff  = [11.43735458 -0.94569701],\n",
      "\n",
      "iteration 483: f_best = 0.00000000\n",
      "           x_eff  = [2.39505712 5.33156582],\n",
      "\n",
      "iteration 484: f_best = 0.00000000\n",
      "           x_eff  = [ -3.11065708 -11.65306188],\n",
      "\n",
      "iteration 485: f_best = 0.00000000\n",
      "           x_eff  = [-6.35685192 -7.22614862],\n",
      "\n",
      "iteration 486: f_best = 0.00000000\n",
      "           x_eff  = [-0.61557446  7.23527263],\n",
      "\n",
      "iteration 487: f_best = 0.00000000\n",
      "           x_eff  = [11.64902199 -4.65926481],\n",
      "\n",
      "iteration 488: f_best = 0.00000000\n",
      "           x_eff  = [11.33111374  6.83351055],\n",
      "\n",
      "iteration 489: f_best = 0.00000000\n",
      "           x_eff  = [ 8.80080121 11.26127674],\n",
      "\n",
      "iteration 490: f_best = 0.00000000\n",
      "           x_eff  = [-3.37705266 -7.64770773],\n",
      "\n",
      "iteration 491: f_best = 0.00000000\n",
      "           x_eff  = [-0.64619903 -5.90643947],\n",
      "\n",
      "iteration 492: f_best = 0.00000000\n",
      "           x_eff  = [-2.59430039 -0.08071118],\n",
      "\n",
      "iteration 493: f_best = 0.00000000\n",
      "           x_eff  = [-0.55351575 -8.74350122],\n",
      "\n",
      "iteration 494: f_best = 0.00000000\n",
      "           x_eff  = [0.9673925  6.39678076],\n",
      "\n",
      "iteration 495: f_best = 0.00000000\n",
      "           x_eff  = [-5.71482648 -9.3939793 ],\n",
      "\n",
      "iteration 496: f_best = 0.00000000\n",
      "           x_eff  = [-1.22817763  4.84886951],\n",
      "\n",
      "iteration 497: f_best = 0.00000000\n",
      "           x_eff  = [0.94043423 6.88676991],\n",
      "\n",
      "iteration 498: f_best = 0.00000000\n",
      "           x_eff  = [8.6289121  1.24969585],\n",
      "\n",
      "iteration 499: f_best = 0.00000000\n",
      "           x_eff  = [ 3.6759784  10.67595317],\n",
      "\n",
      "iteration 500: f_best = 0.00000000\n",
      "           x_eff  = [-3.60470316  6.50025208],\n",
      "\n",
      "iteration 501: f_best = 0.00000000\n",
      "           x_eff  = [-8.31102372  4.48176964],\n",
      "\n",
      "iteration 502: f_best = 0.00000000\n",
      "           x_eff  = [3.55283449 0.58205891],\n",
      "\n",
      "iteration 503: f_best = 0.00000000\n",
      "           x_eff  = [-4.72114343 -0.6920958 ],\n",
      "\n",
      "iteration 504: f_best = 0.00000000\n",
      "           x_eff  = [-9.8918348  -3.07562102],\n",
      "\n",
      "iteration 505: f_best = 0.00000000\n",
      "           x_eff  = [-6.4723967   7.24140728],\n",
      "\n",
      "iteration 506: f_best = 0.00000000\n",
      "           x_eff  = [-5.21584672 -3.44280033],\n",
      "\n",
      "iteration 507: f_best = 0.00000000\n",
      "           x_eff  = [0.50907591 1.23877797],\n",
      "\n",
      "iteration 508: f_best = 0.00000000\n",
      "           x_eff  = [-8.05783955 -4.07240876],\n",
      "\n",
      "iteration 509: f_best = 0.00000000\n",
      "           x_eff  = [ 6.45603641 -4.62514317],\n",
      "\n",
      "iteration 510: f_best = 0.00000000\n",
      "           x_eff  = [-0.46543438 -0.19566496],\n",
      "\n",
      "iteration 511: f_best = 0.00000000\n",
      "           x_eff  = [-2.61968435  0.0707895 ],\n",
      "\n",
      "iteration 512: f_best = 0.00000000\n",
      "           x_eff  = [-5.31640362 -4.43321004],\n",
      "\n",
      "iteration 513: f_best = 0.00000000\n",
      "           x_eff  = [ 1.41224346 -4.36299974],\n",
      "\n",
      "iteration 514: f_best = 0.00000000\n",
      "           x_eff  = [-8.01448413  4.30159531],\n",
      "\n",
      "iteration 515: f_best = 0.00000000\n",
      "           x_eff  = [-3.70804502  7.86689561],\n",
      "\n",
      "iteration 516: f_best = 0.00000000\n",
      "           x_eff  = [4.40941171 4.88019516],\n",
      "\n",
      "iteration 517: f_best = 0.00000000\n",
      "           x_eff  = [-5.24550686  8.89380756],\n",
      "\n",
      "iteration 518: f_best = 0.00000000\n",
      "           x_eff  = [4.65250217 1.96732664],\n",
      "\n",
      "iteration 519: f_best = 0.00000000\n",
      "           x_eff  = [-1.30454296 -0.46478331],\n",
      "\n",
      "iteration 520: f_best = 0.00000000\n",
      "           x_eff  = [-1.96335874  1.89656688],\n",
      "\n",
      "iteration 521: f_best = 0.00000000\n",
      "           x_eff  = [ 1.91370388 -3.39404212],\n",
      "\n",
      "iteration 522: f_best = 0.00000000\n",
      "           x_eff  = [ 4.53633113 -4.36572239],\n",
      "\n",
      "iteration 523: f_best = 0.00000000\n",
      "           x_eff  = [3.17401893 4.34410479],\n",
      "\n",
      "iteration 524: f_best = 0.00000000\n",
      "           x_eff  = [7.88045596 7.21390352],\n",
      "\n",
      "iteration 525: f_best = 0.00000000\n",
      "           x_eff  = [ 3.81540635 -0.05247744],\n",
      "\n",
      "iteration 526: f_best = 0.00000000\n",
      "           x_eff  = [-6.25098386  5.56664664],\n",
      "\n",
      "iteration 527: f_best = 0.00000000\n",
      "           x_eff  = [-2.07420563  2.86878568],\n",
      "\n",
      "iteration 528: f_best = 0.00000000\n",
      "           x_eff  = [-3.23615812 -7.97533755],\n",
      "\n",
      "iteration 529: f_best = 0.00000000\n",
      "           x_eff  = [-2.00207994  6.93777684],\n",
      "\n",
      "iteration 530: f_best = 0.00000000\n",
      "           x_eff  = [7.03303733 3.32585168],\n",
      "\n",
      "iteration 531: f_best = 0.00000000\n",
      "           x_eff  = [ 6.96656605 -6.78980266],\n",
      "\n",
      "iteration 532: f_best = 0.00000000\n",
      "           x_eff  = [-2.23333561  6.26751105],\n",
      "\n",
      "iteration 533: f_best = 0.00000000\n",
      "           x_eff  = [ 7.7331033  -5.14544478],\n",
      "\n",
      "iteration 534: f_best = 0.00000000\n",
      "           x_eff  = [-2.18038459 -5.92434044],\n",
      "\n",
      "iteration 535: f_best = 0.00000000\n",
      "           x_eff  = [-3.13320984 -2.1640026 ],\n",
      "\n",
      "iteration 536: f_best = 0.00000000\n",
      "           x_eff  = [2.50603932 1.26077845],\n",
      "\n",
      "iteration 537: f_best = 0.00000000\n",
      "           x_eff  = [-2.57613933 -0.59713752],\n",
      "\n",
      "iteration 538: f_best = 0.00000000\n",
      "           x_eff  = [-1.44409555 -3.72147924],\n",
      "\n",
      "iteration 539: f_best = 0.00000000\n",
      "           x_eff  = [-0.25993045 -3.15016635],\n",
      "\n",
      "iteration 540: f_best = 0.00000000\n",
      "           x_eff  = [-2.80265994 -2.67202275],\n",
      "\n",
      "iteration 541: f_best = 0.00000000\n",
      "           x_eff  = [5.91401961 0.25120754],\n",
      "\n",
      "iteration 542: f_best = 0.00000000\n",
      "           x_eff  = [2.29712153 5.95542295],\n",
      "\n",
      "iteration 543: f_best = 0.00000000\n",
      "           x_eff  = [-5.73158282 -1.27059856],\n",
      "\n",
      "iteration 544: f_best = 0.00000000\n",
      "           x_eff  = [-4.59437456  2.85953786],\n",
      "\n",
      "iteration 545: f_best = 0.00000000\n",
      "           x_eff  = [-4.39446884  3.7767702 ],\n",
      "\n",
      "iteration 546: f_best = 0.00000000\n",
      "           x_eff  = [-4.64295575  5.75445972],\n",
      "\n",
      "iteration 547: f_best = 0.00000000\n",
      "           x_eff  = [-0.06533266 -3.52517015],\n",
      "\n",
      "iteration 548: f_best = 0.00000000\n",
      "           x_eff  = [-3.83502488  0.81655328],\n",
      "\n",
      "iteration 549: f_best = 0.00000000\n",
      "           x_eff  = [-3.31757935 -0.75120931],\n",
      "\n",
      "iteration 550: f_best = 0.00000000\n",
      "           x_eff  = [3.78084545 4.54749648],\n",
      "\n",
      "iteration 551: f_best = 0.00000000\n",
      "           x_eff  = [ 4.61223627 -2.75296913],\n",
      "\n",
      "iteration 552: f_best = 0.00000000\n",
      "           x_eff  = [ 2.17325225 -2.32982899],\n",
      "\n",
      "iteration 553: f_best = 0.00000000\n",
      "           x_eff  = [-3.09089739  3.05349349],\n",
      "\n",
      "iteration 554: f_best = 0.00000000\n",
      "           x_eff  = [-6.13899192 -4.4562664 ],\n",
      "\n",
      "iteration 555: f_best = 0.00000000\n",
      "           x_eff  = [-6.0488309  1.1506861],\n",
      "\n",
      "iteration 556: f_best = 0.00000000\n",
      "           x_eff  = [ 3.68635311 -2.92018636],\n",
      "\n",
      "iteration 557: f_best = 0.00000000\n",
      "           x_eff  = [0.6323177  5.41073813],\n",
      "\n",
      "iteration 558: f_best = 0.00000000\n",
      "           x_eff  = [-4.11011803  3.39947114],\n",
      "\n",
      "iteration 559: f_best = 0.00000000\n",
      "           x_eff  = [-3.28707109  5.85662165],\n",
      "\n",
      "iteration 560: f_best = 0.00000000\n",
      "           x_eff  = [-1.858976    1.09107237],\n",
      "\n",
      "iteration 561: f_best = 0.00000000\n",
      "           x_eff  = [2.93657584 3.99702112],\n",
      "\n",
      "iteration 562: f_best = 0.00000000\n",
      "           x_eff  = [-2.85160359 -4.15824304],\n",
      "\n",
      "iteration 563: f_best = 0.00000000\n",
      "           x_eff  = [-3.32009007  3.58219318],\n",
      "\n",
      "iteration 564: f_best = 0.00000000\n",
      "           x_eff  = [ 1.44999379 -0.49414776],\n",
      "\n",
      "iteration 565: f_best = 0.00000000\n",
      "           x_eff  = [ 1.88112671 -0.86086287],\n",
      "\n",
      "iteration 566: f_best = 0.00000000\n",
      "           x_eff  = [-4.03341756  3.89258923],\n",
      "\n",
      "iteration 567: f_best = 0.00000000\n",
      "           x_eff  = [ 5.34239887 -0.85389964],\n",
      "\n",
      "iteration 568: f_best = 0.00000000\n",
      "           x_eff  = [ 3.44400821 -4.6527906 ],\n",
      "\n",
      "iteration 569: f_best = 0.00000000\n",
      "           x_eff  = [-5.41785466  4.77137842],\n",
      "\n",
      "iteration 570: f_best = 0.00000000\n",
      "           x_eff  = [-3.22105651 -0.67912463],\n",
      "\n",
      "iteration 571: f_best = 0.00000000\n",
      "           x_eff  = [0.93855223 5.23665671],\n",
      "\n",
      "iteration 572: f_best = 0.00000000\n",
      "           x_eff  = [1.98679823 0.51025632],\n",
      "\n",
      "iteration 573: f_best = 0.00000000\n",
      "           x_eff  = [ 1.77973354 -4.73298182],\n",
      "\n",
      "iteration 574: f_best = 0.00000000\n",
      "           x_eff  = [ 0.43270418 -3.08620179],\n",
      "\n",
      "iteration 575: f_best = 0.00000000\n",
      "           x_eff  = [-3.36666096 -1.32439065],\n",
      "\n",
      "iteration 576: f_best = 0.00000000\n",
      "           x_eff  = [ 3.13541975 -2.87457479],\n",
      "\n",
      "iteration 577: f_best = 0.00000000\n",
      "           x_eff  = [2.46652682 4.77807603],\n",
      "\n",
      "iteration 578: f_best = 0.00000000\n",
      "           x_eff  = [ 0.64812956 -2.24989854],\n",
      "\n",
      "iteration 579: f_best = 0.00000000\n",
      "           x_eff  = [-3.1281255  -0.91196371],\n",
      "\n",
      "iteration 580: f_best = 0.00000000\n",
      "           x_eff  = [3.50691165 0.57322051],\n",
      "\n",
      "iteration 581: f_best = 0.00000000\n",
      "           x_eff  = [ 1.39080786 -0.08321747],\n",
      "\n",
      "iteration 582: f_best = 0.00000000\n",
      "           x_eff  = [3.1792262 1.336248 ],\n",
      "\n",
      "iteration 583: f_best = 0.00000000\n",
      "           x_eff  = [-0.53703447 -3.06692641],\n",
      "\n",
      "iteration 584: f_best = 0.00000000\n",
      "           x_eff  = [4.51816153 3.51120281],\n",
      "\n",
      "iteration 585: f_best = 0.00000000\n",
      "           x_eff  = [ 4.55639794 -1.23923868],\n",
      "\n",
      "iteration 586: f_best = 0.00000000\n",
      "           x_eff  = [ 2.05542211 -0.4899658 ],\n",
      "\n",
      "iteration 587: f_best = 0.00000000\n",
      "           x_eff  = [-3.96418206  1.39580595],\n",
      "\n",
      "iteration 588: f_best = 0.00000000\n",
      "           x_eff  = [3.3693692  0.88792249],\n",
      "\n",
      "iteration 589: f_best = 0.00000000\n",
      "           x_eff  = [ 0.08833384 -0.44417891],\n",
      "\n",
      "iteration 590: f_best = 0.00000000\n",
      "           x_eff  = [ 1.28877795 -3.51610041],\n",
      "\n",
      "iteration 591: f_best = 0.00000000\n",
      "           x_eff  = [ 0.67856081 -3.3035861 ],\n",
      "\n",
      "iteration 592: f_best = 0.00000000\n",
      "           x_eff  = [ 4.2882619  -3.07985222],\n",
      "\n",
      "iteration 593: f_best = 0.00000000\n",
      "           x_eff  = [ 1.91841806 -0.64924224],\n",
      "\n",
      "iteration 594: f_best = 0.00000000\n",
      "           x_eff  = [-1.12143641  3.4635772 ],\n",
      "\n",
      "iteration 595: f_best = 0.00000000\n",
      "           x_eff  = [-1.39296641  1.4642449 ],\n",
      "\n",
      "iteration 596: f_best = 0.00000000\n",
      "           x_eff  = [-0.57882704  2.66611315],\n",
      "\n",
      "iteration 597: f_best = 0.00000000\n",
      "           x_eff  = [1.22510631 3.24225603],\n",
      "\n",
      "iteration 598: f_best = 0.00000000\n",
      "           x_eff  = [ 1.26409499 -1.6600118 ],\n",
      "\n",
      "iteration 599: f_best = 0.00000000\n",
      "           x_eff  = [-0.36980709 -2.04098127],\n",
      "\n",
      "iteration 600: f_best = 0.00000000\n",
      "           x_eff  = [3.37888628 0.54323609],\n",
      "\n",
      "iteration 601: f_best = 0.00000000\n",
      "           x_eff  = [-1.87833618 -0.94643899],\n",
      "\n",
      "iteration 602: f_best = 0.00000000\n",
      "           x_eff  = [ 0.25734691 -0.19057013],\n",
      "\n",
      "iteration 603: f_best = 0.00000000\n",
      "           x_eff  = [ 3.55611542 -3.63920316],\n",
      "\n",
      "iteration 604: f_best = 0.00000000\n",
      "           x_eff  = [3.19677392 1.88408655],\n",
      "\n",
      "iteration 605: f_best = 0.00000000\n",
      "           x_eff  = [-3.60525747  2.73299585],\n",
      "\n",
      "iteration 606: f_best = 0.00000000\n",
      "           x_eff  = [-3.7462309 -0.1567248],\n",
      "\n",
      "iteration 607: f_best = 0.00000000\n",
      "           x_eff  = [-2.70096784 -2.57757698],\n",
      "\n",
      "iteration 608: f_best = 0.00000000\n",
      "           x_eff  = [-2.82535845  0.43326984],\n",
      "\n",
      "iteration 609: f_best = 0.00000000\n",
      "           x_eff  = [3.66598062 0.42388186],\n",
      "\n",
      "iteration 610: f_best = 0.00000000\n",
      "           x_eff  = [-2.79088862  3.33707898],\n",
      "\n",
      "iteration 611: f_best = 0.00000000\n",
      "           x_eff  = [3.47502984 0.55137716],\n",
      "\n",
      "iteration 612: f_best = 0.00000000\n",
      "           x_eff  = [-3.00218119  2.60860022],\n",
      "\n",
      "iteration 613: f_best = 0.00000000\n",
      "           x_eff  = [-0.8620461  -1.44246235],\n",
      "\n",
      "iteration 614: f_best = 0.00000000\n",
      "           x_eff  = [-2.61519719 -0.3778693 ],\n",
      "\n",
      "iteration 615: f_best = 0.00000000\n",
      "           x_eff  = [-1.77287761  0.62291165],\n",
      "\n",
      "iteration 616: f_best = 0.00000000\n",
      "           x_eff  = [3.21258076 3.16364612],\n",
      "\n",
      "iteration 617: f_best = 0.00000000\n",
      "           x_eff  = [ 1.87161438 -0.21375551],\n",
      "\n",
      "iteration 618: f_best = 0.00000000\n",
      "           x_eff  = [1.07687571e-03 3.32462253e+00],\n",
      "\n",
      "iteration 619: f_best = 0.00000000\n",
      "           x_eff  = [-1.64854454  1.32721902],\n",
      "\n",
      "iteration 620: f_best = 0.00000000\n",
      "           x_eff  = [2.48817311 1.31219755],\n",
      "\n",
      "iteration 621: f_best = 0.00000000\n",
      "           x_eff  = [-1.43003229 -2.42533384],\n",
      "\n",
      "iteration 622: f_best = 0.00000000\n",
      "           x_eff  = [-2.67026375  2.31642638],\n",
      "\n",
      "iteration 623: f_best = 0.00000000\n",
      "           x_eff  = [-0.86625801 -2.02673052],\n",
      "\n",
      "iteration 624: f_best = 0.00000000\n",
      "           x_eff  = [ 2.50764311 -0.34923768],\n",
      "\n",
      "iteration 625: f_best = 0.00000000\n",
      "           x_eff  = [-2.27257181 -2.69126038],\n",
      "\n",
      "iteration 626: f_best = 0.00000000\n",
      "           x_eff  = [-0.67124032  1.78690121],\n",
      "\n",
      "iteration 627: f_best = 0.00000000\n",
      "           x_eff  = [2.75090406 0.38363457],\n",
      "\n",
      "iteration 628: f_best = 0.00000000\n",
      "           x_eff  = [-0.30841798 -1.06486049],\n",
      "\n",
      "iteration 629: f_best = 0.00000000\n",
      "           x_eff  = [ 0.06016803 -2.96981998],\n",
      "\n",
      "iteration 630: f_best = 0.00000000\n",
      "           x_eff  = [ 2.15805488 -0.2867567 ],\n",
      "\n",
      "iteration 631: f_best = 0.00000000\n",
      "           x_eff  = [2.59813984 0.8371588 ],\n",
      "\n",
      "iteration 632: f_best = 0.00000000\n",
      "           x_eff  = [-2.44837432 -0.46716018],\n",
      "\n",
      "iteration 633: f_best = 0.00000000\n",
      "           x_eff  = [ 2.35991809 -2.67317028],\n",
      "\n",
      "iteration 634: f_best = 0.00000000\n",
      "           x_eff  = [-1.40299229 -1.992624  ],\n",
      "\n",
      "iteration 635: f_best = 0.00000000\n",
      "           x_eff  = [2.66271782 0.34292855],\n",
      "\n",
      "iteration 636: f_best = 0.00000000\n",
      "           x_eff  = [1.59849255 2.75110885],\n",
      "\n",
      "iteration 637: f_best = 0.00000000\n",
      "           x_eff  = [ 1.09695825 -1.59816176],\n",
      "\n",
      "iteration 638: f_best = 0.00000000\n",
      "           x_eff  = [-0.94935749  1.52631573],\n",
      "\n",
      "iteration 639: f_best = 0.00000000\n",
      "           x_eff  = [ 2.12516245 -0.27003304],\n",
      "\n",
      "iteration 640: f_best = 0.00000000\n",
      "           x_eff  = [0.32032452 0.87674201],\n",
      "\n",
      "iteration 641: f_best = 0.00000000\n",
      "           x_eff  = [-2.63613362  0.88237928],\n",
      "\n",
      "iteration 642: f_best = 0.00000000\n",
      "           x_eff  = [ 1.09413726 -0.86754409],\n",
      "\n",
      "iteration 643: f_best = 0.00000000\n",
      "           x_eff  = [-1.34462139 -0.15028524],\n",
      "\n",
      "iteration 644: f_best = 0.00000000\n",
      "           x_eff  = [-0.68282017 -0.82483878],\n",
      "\n",
      "iteration 645: f_best = 0.00000000\n",
      "           x_eff  = [0.56177888 1.9096982 ],\n",
      "\n",
      "iteration 646: f_best = 0.00000000\n",
      "           x_eff  = [-0.25721978  1.49071648],\n",
      "\n",
      "iteration 647: f_best = 0.00000000\n",
      "           x_eff  = [ 1.20339633 -1.36178491],\n",
      "\n",
      "iteration 648: f_best = 0.00000000\n",
      "           x_eff  = [0.35495326 2.13368376],\n",
      "\n",
      "iteration 649: f_best = 0.00000000\n",
      "           x_eff  = [ 1.52581902 -2.31912546],\n",
      "\n",
      "iteration 650: f_best = 0.00000000\n",
      "           x_eff  = [0.41490095 1.2827182 ],\n",
      "\n",
      "iteration 651: f_best = 0.00000000\n",
      "           x_eff  = [-0.98698402  1.38178807],\n",
      "\n",
      "iteration 652: f_best = 0.00000000\n",
      "           x_eff  = [1.23034513 1.26877426],\n",
      "\n",
      "iteration 653: f_best = 0.00000000\n",
      "           x_eff  = [-1.15002483 -1.24370849],\n",
      "\n",
      "iteration 654: f_best = 0.00000000\n",
      "           x_eff  = [-0.51526889 -0.27404095],\n",
      "\n",
      "iteration 655: f_best = 0.00000000\n",
      "           x_eff  = [-1.95571231 -2.16743912],\n",
      "\n",
      "iteration 656: f_best = 0.00000000\n",
      "           x_eff  = [0.15592457 0.10030009],\n",
      "\n",
      "iteration 657: f_best = 0.00000000\n",
      "           x_eff  = [ 0.89883872 -1.54597624],\n",
      "\n",
      "iteration 658: f_best = 0.00000000\n",
      "           x_eff  = [ 1.51128203 -1.56863643],\n",
      "\n",
      "iteration 659: f_best = 0.00000000\n",
      "           x_eff  = [1.37040525 1.47803066],\n",
      "\n",
      "iteration 660: f_best = 0.00000000\n",
      "           x_eff  = [ 1.75544265 -1.09963078],\n",
      "\n",
      "iteration 661: f_best = 0.00000000\n",
      "           x_eff  = [0.61377416 0.83342428],\n",
      "\n",
      "iteration 662: f_best = 0.00000000\n",
      "           x_eff  = [1.8445963  0.10766266],\n",
      "\n",
      "iteration 663: f_best = 0.00000000\n",
      "           x_eff  = [-1.12760545 -0.09143962],\n",
      "\n",
      "iteration 664: f_best = 0.00000000\n",
      "           x_eff  = [-0.96602033  1.90686473],\n",
      "\n",
      "iteration 665: f_best = 0.00000000\n",
      "           x_eff  = [ 0.09062081 -1.23013632],\n",
      "\n",
      "iteration 666: f_best = 0.00000000\n",
      "           x_eff  = [1.71964602 1.30613329],\n",
      "\n",
      "iteration 667: f_best = 0.00000000\n",
      "           x_eff  = [1.93380694 0.66793825],\n",
      "\n",
      "iteration 668: f_best = 0.00000000\n",
      "           x_eff  = [-1.35522413  1.58882437],\n",
      "\n",
      "iteration 669: f_best = 0.00000000\n",
      "           x_eff  = [ 0.83145913 -0.8308945 ],\n",
      "\n",
      "iteration 670: f_best = 0.00000000\n",
      "           x_eff  = [0.58547116 0.54076159],\n",
      "\n",
      "iteration 671: f_best = 0.00000000\n",
      "           x_eff  = [ 1.49567418 -1.5791833 ],\n",
      "\n",
      "iteration 672: f_best = 0.00000000\n",
      "           x_eff  = [-1.22267299  1.9276156 ],\n",
      "\n",
      "iteration 673: f_best = 0.00000000\n",
      "           x_eff  = [-1.50743712 -0.4670346 ],\n",
      "\n",
      "iteration 674: f_best = 0.00000000\n",
      "           x_eff  = [-1.48806183  0.23594907],\n",
      "\n",
      "iteration 675: f_best = 0.00000000\n",
      "           x_eff  = [-0.33338961 -0.35293245],\n",
      "\n",
      "iteration 676: f_best = 0.00000000\n",
      "           x_eff  = [1.15206514 1.3360184 ],\n",
      "\n",
      "iteration 677: f_best = 0.00000000\n",
      "           x_eff  = [ 0.88626992 -0.25927444],\n",
      "\n",
      "iteration 678: f_best = 0.00000000\n",
      "           x_eff  = [ 0.76911371 -0.53814645],\n",
      "\n",
      "iteration 679: f_best = 0.00000000\n",
      "           x_eff  = [0.82961844 1.06112246],\n",
      "\n",
      "iteration 680: f_best = 0.00000000\n",
      "           x_eff  = [-0.86394293  0.57667097],\n",
      "\n",
      "iteration 681: f_best = 0.00000000\n",
      "           x_eff  = [-0.67973011  0.18976578],\n",
      "\n",
      "iteration 682: f_best = 0.00000000\n",
      "           x_eff  = [ 1.3777026  -1.68448539],\n",
      "\n",
      "iteration 683: f_best = 0.00000000\n",
      "           x_eff  = [-0.21526638  0.70008137],\n",
      "\n",
      "iteration 684: f_best = 0.00000000\n",
      "           x_eff  = [0.54263313 0.39147019],\n",
      "\n",
      "iteration 685: f_best = 0.00000000\n",
      "           x_eff  = [-1.35845877  0.27517787],\n",
      "\n",
      "iteration 686: f_best = 0.00000000\n",
      "           x_eff  = [-1.4530624  -0.15934114],\n",
      "\n",
      "iteration 687: f_best = 0.00000000\n",
      "           x_eff  = [0.53596907 0.91479256],\n",
      "\n",
      "iteration 688: f_best = 0.00000000\n",
      "           x_eff  = [-1.04898341  1.65533575],\n",
      "\n",
      "iteration 689: f_best = 0.00000000\n",
      "           x_eff  = [-0.28718731 -1.12722514],\n",
      "\n",
      "iteration 690: f_best = 0.00000000\n",
      "           x_eff  = [-0.95502012 -1.50114285],\n",
      "\n",
      "iteration 691: f_best = 0.00000000\n",
      "           x_eff  = [0.19290583 0.29798044],\n",
      "\n",
      "iteration 692: f_best = 0.00000000\n",
      "           x_eff  = [-0.8990787   0.29845139],\n",
      "\n",
      "iteration 693: f_best = 0.00000000\n",
      "           x_eff  = [0.48996177 0.52937616],\n",
      "\n",
      "iteration 694: f_best = 0.00000000\n",
      "           x_eff  = [-0.27350824 -0.26095198],\n",
      "\n",
      "iteration 695: f_best = 0.00000000\n",
      "           x_eff  = [-1.07741265 -1.52642504],\n",
      "\n",
      "iteration 696: f_best = 0.00000000\n",
      "           x_eff  = [1.39245377 0.43419967],\n",
      "\n",
      "iteration 697: f_best = 0.00000000\n",
      "           x_eff  = [ 0.4851776 -0.5680603],\n",
      "\n",
      "iteration 698: f_best = 0.00000000\n",
      "           x_eff  = [0.50791942 1.41253435],\n",
      "\n",
      "iteration 699: f_best = 0.00000000\n",
      "           x_eff  = [-1.33307549  0.53318533],\n",
      "\n",
      "iteration 700: f_best = 0.00000000\n",
      "           x_eff  = [ 1.10597734 -1.26524862],\n",
      "\n",
      "iteration 701: f_best = 0.00000000\n",
      "           x_eff  = [1.22766722 1.05260257],\n",
      "\n",
      "iteration 702: f_best = 0.00000000\n",
      "           x_eff  = [ 1.31748076 -0.5468054 ],\n",
      "\n",
      "iteration 703: f_best = 0.00000000\n",
      "           x_eff  = [-0.51559081 -0.18747702],\n",
      "\n",
      "iteration 704: f_best = 0.00000000\n",
      "           x_eff  = [0.78520233 0.74606699],\n",
      "\n",
      "iteration 705: f_best = 0.00000000\n",
      "           x_eff  = [0.24662351 1.10298147],\n",
      "\n",
      "iteration 706: f_best = 0.00000000\n",
      "           x_eff  = [-0.84384723 -0.09224646],\n",
      "\n",
      "iteration 707: f_best = 0.00000000\n",
      "           x_eff  = [-0.47360237  0.02156515],\n",
      "\n",
      "iteration 708: f_best = 0.00000000\n",
      "           x_eff  = [1.0300458  0.72497265],\n",
      "\n",
      "iteration 709: f_best = 0.00000000\n",
      "           x_eff  = [-0.77116925  0.34296762],\n",
      "\n",
      "iteration 710: f_best = 0.00000000\n",
      "           x_eff  = [-0.55827299 -1.15176658],\n",
      "\n",
      "iteration 711: f_best = 0.00000000\n",
      "           x_eff  = [-0.36874799  0.68114279],\n",
      "\n",
      "iteration 712: f_best = 0.00000000\n",
      "           x_eff  = [-0.93768632  0.43186537],\n",
      "\n",
      "iteration 713: f_best = 0.00000000\n",
      "           x_eff  = [ 0.75656903 -0.92615058],\n",
      "\n",
      "iteration 714: f_best = 0.00000000\n",
      "           x_eff  = [0.07108279 0.16402707],\n",
      "\n",
      "iteration 715: f_best = 0.00000000\n",
      "           x_eff  = [-0.46900476 -0.86455594],\n",
      "\n",
      "iteration 716: f_best = 0.00000000\n",
      "           x_eff  = [-0.64472395 -0.34176143],\n",
      "\n",
      "iteration 717: f_best = 0.00000000\n",
      "           x_eff  = [ 0.37304688 -0.83591058],\n",
      "\n",
      "iteration 718: f_best = 0.00000000\n",
      "           x_eff  = [-0.17901096  0.98708048],\n",
      "\n",
      "iteration 719: f_best = 0.00000000\n",
      "           x_eff  = [1.05857982 1.03999955],\n",
      "\n",
      "iteration 720: f_best = 0.00000000\n",
      "           x_eff  = [-1.06619826  0.31032481],\n",
      "\n",
      "iteration 721: f_best = 0.00000000\n",
      "           x_eff  = [ 0.60357497 -0.29265595],\n",
      "\n",
      "iteration 722: f_best = 0.00000000\n",
      "           x_eff  = [0.53163109 0.35713773],\n",
      "\n",
      "iteration 723: f_best = 0.00000000\n",
      "           x_eff  = [-0.80089194 -0.03454754],\n",
      "\n",
      "iteration 724: f_best = 0.00000000\n",
      "           x_eff  = [-1.11046245  1.15994514],\n",
      "\n",
      "iteration 725: f_best = 0.00000000\n",
      "           x_eff  = [0.36350178 1.13754806],\n",
      "\n",
      "iteration 726: f_best = 0.00000000\n",
      "           x_eff  = [0.30322326 0.91459572],\n",
      "\n",
      "iteration 727: f_best = 0.00000000\n",
      "           x_eff  = [ 1.11288531 -0.08838053],\n",
      "\n",
      "iteration 728: f_best = 0.00000000\n",
      "           x_eff  = [-0.35632318 -0.84571496],\n",
      "\n",
      "iteration 729: f_best = 0.00000000\n",
      "           x_eff  = [ 0.16614142 -0.57430277],\n",
      "\n",
      "iteration 730: f_best = 0.00000000\n",
      "           x_eff  = [0.86129735 0.88748248],\n",
      "\n",
      "iteration 731: f_best = 0.00000000\n",
      "           x_eff  = [0.91738723 0.62259648],\n",
      "\n",
      "iteration 732: f_best = 0.00000000\n",
      "           x_eff  = [-0.65138784  0.64795598],\n",
      "\n",
      "iteration 733: f_best = 0.00000000\n",
      "           x_eff  = [-0.33218006 -0.20049553],\n",
      "\n",
      "iteration 734: f_best = 0.00000000\n",
      "           x_eff  = [-0.18171103  0.24293983],\n",
      "\n",
      "iteration 735: f_best = 0.00000000\n",
      "           x_eff  = [ 0.19046238 -0.23899793],\n",
      "\n",
      "iteration 736: f_best = 0.00000000\n",
      "           x_eff  = [-0.28893479  0.13587793],\n",
      "\n",
      "iteration 737: f_best = 0.00000000\n",
      "           x_eff  = [ 0.5925622  -0.19883909],\n",
      "\n",
      "iteration 738: f_best = 0.00000000\n",
      "           x_eff  = [-0.92353847 -0.49868898],\n",
      "\n",
      "iteration 739: f_best = 0.00000000\n",
      "           x_eff  = [-0.9843039  -0.09307632],\n",
      "\n",
      "iteration 740: f_best = 0.00000000\n",
      "           x_eff  = [-0.48991229  0.09779551],\n",
      "\n",
      "iteration 741: f_best = 0.00000000\n",
      "           x_eff  = [-0.3770268 -0.3005793],\n",
      "\n",
      "iteration 742: f_best = 0.00000000\n",
      "           x_eff  = [-0.25902896  0.47348135],\n",
      "\n",
      "iteration 743: f_best = 0.00000000\n",
      "           x_eff  = [ 0.69751658 -0.85660735],\n",
      "\n",
      "iteration 744: f_best = 0.00000000\n",
      "           x_eff  = [0.25693746 0.58483728],\n",
      "\n",
      "iteration 745: f_best = 0.00000000\n",
      "           x_eff  = [ 0.49705721 -0.4866861 ],\n",
      "\n",
      "iteration 746: f_best = 0.00000000\n",
      "           x_eff  = [-0.56229381 -0.89877644],\n",
      "\n",
      "iteration 747: f_best = 0.00000000\n",
      "           x_eff  = [0.19610581 0.84371841],\n",
      "\n",
      "iteration 748: f_best = 0.00000000\n",
      "           x_eff  = [-0.0873974   0.29361402],\n",
      "\n",
      "iteration 749: f_best = 0.00000000\n",
      "           x_eff  = [0.67318687 0.6828908 ],\n",
      "\n",
      "iteration 750: f_best = 0.00000000\n",
      "           x_eff  = [-0.67287862 -0.18893563],\n",
      "\n",
      "iteration 751: f_best = 0.00000000\n",
      "           x_eff  = [-0.35519058 -0.21225537],\n",
      "\n",
      "iteration 752: f_best = 0.00000000\n",
      "           x_eff  = [-0.47983509 -0.52814377],\n",
      "\n",
      "iteration 753: f_best = 0.00000000\n",
      "           x_eff  = [ 0.0222642  -0.52243522],\n",
      "\n",
      "iteration 754: f_best = 0.00000000\n",
      "           x_eff  = [-0.18019266 -0.23123128],\n",
      "\n",
      "iteration 755: f_best = 0.00000000\n",
      "           x_eff  = [ 0.41559699 -0.66169396],\n",
      "\n",
      "iteration 756: f_best = 0.00000000\n",
      "           x_eff  = [-0.4325687   0.07516297],\n",
      "\n",
      "iteration 757: f_best = 0.00000000\n",
      "           x_eff  = [ 0.26747727 -0.47711239],\n",
      "\n",
      "iteration 758: f_best = 0.00000000\n",
      "           x_eff  = [-0.60563437 -0.78002843],\n",
      "\n",
      "iteration 759: f_best = 0.00000000\n",
      "           x_eff  = [0.11615006 0.51832155],\n",
      "\n",
      "iteration 760: f_best = 0.00000000\n",
      "           x_eff  = [0.5485937  0.67778954],\n",
      "\n",
      "iteration 761: f_best = 0.00000000\n",
      "           x_eff  = [0.3590425  0.80081705],\n",
      "\n",
      "iteration 762: f_best = 0.00000000\n",
      "           x_eff  = [-0.21571767  0.14325643],\n",
      "\n",
      "iteration 763: f_best = 0.00000000\n",
      "           x_eff  = [-0.07882012  0.31081764],\n",
      "\n",
      "iteration 764: f_best = 0.00000000\n",
      "           x_eff  = [0.51212421 0.08990764],\n",
      "\n",
      "iteration 765: f_best = 0.00000000\n",
      "           x_eff  = [ 0.71133591 -0.30739797],\n",
      "\n",
      "iteration 766: f_best = 0.00000000\n",
      "           x_eff  = [-0.73824624 -0.11192158],\n",
      "\n",
      "iteration 767: f_best = 0.00000000\n",
      "           x_eff  = [-0.20119194 -0.15425697],\n",
      "\n",
      "iteration 768: f_best = 0.00000000\n",
      "           x_eff  = [-0.53595555 -0.480094  ],\n",
      "\n",
      "iteration 769: f_best = 0.00000000\n",
      "           x_eff  = [0.64437916 0.38485631],\n",
      "\n",
      "iteration 770: f_best = 0.00000000\n",
      "           x_eff  = [0.07164866 0.02815837],\n",
      "\n",
      "iteration 771: f_best = 0.00000000\n",
      "           x_eff  = [ 0.08706843 -0.0662805 ],\n",
      "\n",
      "iteration 772: f_best = 0.00000000\n",
      "           x_eff  = [-0.52930876  0.28873424],\n",
      "\n",
      "iteration 773: f_best = 0.00000000\n",
      "           x_eff  = [-0.60912341  0.39928384],\n",
      "\n",
      "iteration 774: f_best = 0.00000000\n",
      "           x_eff  = [ 0.15296951 -0.04390803],\n",
      "\n",
      "iteration 775: f_best = 0.00000000\n",
      "           x_eff  = [-0.47043379 -0.22452238],\n",
      "\n",
      "iteration 776: f_best = 0.00000000\n",
      "           x_eff  = [-0.07157873 -0.27698442],\n",
      "\n",
      "iteration 777: f_best = 0.00000000\n",
      "           x_eff  = [0.65293304 0.55633037],\n",
      "\n",
      "iteration 778: f_best = 0.00000000\n",
      "           x_eff  = [0.1440941  0.09312678],\n",
      "\n",
      "iteration 779: f_best = 0.00000000\n",
      "           x_eff  = [-0.04405016 -0.58190414],\n",
      "\n",
      "iteration 780: f_best = 0.00000000\n",
      "           x_eff  = [-0.44193195  0.63528201],\n",
      "\n",
      "iteration 781: f_best = 0.00000000\n",
      "           x_eff  = [ 0.45073612 -0.38049284],\n",
      "\n",
      "iteration 782: f_best = 0.00000000\n",
      "           x_eff  = [0.63525597 0.0733222 ],\n",
      "\n",
      "iteration 783: f_best = 0.00000000\n",
      "           x_eff  = [-0.32437424  0.31125363],\n",
      "\n",
      "iteration 784: f_best = 0.00000000\n",
      "           x_eff  = [ 0.11375332 -0.39208962],\n",
      "\n",
      "iteration 785: f_best = 0.00000000\n",
      "           x_eff  = [-0.13064668 -0.60959013],\n",
      "\n",
      "iteration 786: f_best = 0.00000000\n",
      "           x_eff  = [0.03323419 0.32040881],\n",
      "\n",
      "iteration 787: f_best = 0.00000000\n",
      "           x_eff  = [0.14549966 0.26793779],\n",
      "\n",
      "iteration 788: f_best = 0.00000000\n",
      "           x_eff  = [-0.12411521 -0.50147071],\n",
      "\n",
      "iteration 789: f_best = 0.00000000\n",
      "           x_eff  = [-0.23824818  0.38207342],\n",
      "\n",
      "iteration 790: f_best = 0.00000000\n",
      "           x_eff  = [0.28378147 0.33285375],\n",
      "\n",
      "iteration 791: f_best = 0.00000000\n",
      "           x_eff  = [-0.10794169 -0.41529626],\n",
      "\n",
      "iteration 792: f_best = 0.00000000\n",
      "           x_eff  = [0.4057991  0.39774062],\n",
      "\n",
      "iteration 793: f_best = 0.00000000\n",
      "           x_eff  = [-0.56822254 -0.06523022],\n",
      "\n",
      "iteration 794: f_best = 0.00000000\n",
      "           x_eff  = [ 0.44154214 -0.46649934],\n",
      "\n",
      "iteration 795: f_best = 0.00000000\n",
      "           x_eff  = [-0.30830425  0.27206798],\n",
      "\n",
      "iteration 796: f_best = 0.00000000\n",
      "           x_eff  = [0.47444359 0.07741967],\n",
      "\n",
      "iteration 797: f_best = 0.00000000\n",
      "           x_eff  = [-0.11593866  0.39663563],\n",
      "\n",
      "iteration 798: f_best = 0.00000000\n",
      "           x_eff  = [ 0.44757955 -0.00465985],\n",
      "\n",
      "iteration 799: f_best = 0.00000000\n",
      "           x_eff  = [-0.48281284 -0.18642432],\n",
      "\n",
      "iteration 800: f_best = 0.00000000\n",
      "           x_eff  = [0.40405623 0.0393869 ],\n",
      "\n",
      "iteration 801: f_best = 0.00000000\n",
      "           x_eff  = [-0.27435245  0.02488429],\n",
      "\n",
      "iteration 802: f_best = 0.00000000\n",
      "           x_eff  = [0.44429106 0.32741241],\n",
      "\n",
      "iteration 803: f_best = 0.00000000\n",
      "           x_eff  = [ 0.29900795 -0.0232374 ],\n",
      "\n",
      "iteration 804: f_best = 0.00000000\n",
      "           x_eff  = [-0.15809775 -0.43306989],\n",
      "\n",
      "iteration 805: f_best = 0.00000000\n",
      "           x_eff  = [-0.34191333  0.21123561],\n",
      "\n",
      "iteration 806: f_best = 0.00000000\n",
      "           x_eff  = [0.18146357 0.34829306],\n",
      "\n",
      "iteration 807: f_best = 0.00000000\n",
      "           x_eff  = [-0.20361404 -0.38882603],\n",
      "\n",
      "iteration 808: f_best = 0.00000000\n",
      "           x_eff  = [-0.12252447 -0.46153182],\n",
      "\n",
      "iteration 809: f_best = 0.00000000\n",
      "           x_eff  = [ 0.35638703 -0.05067648],\n",
      "\n",
      "iteration 810: f_best = 0.00000000\n",
      "           x_eff  = [-0.23579511 -0.09943353],\n",
      "\n",
      "iteration 811: f_best = 0.00000000\n",
      "           x_eff  = [-0.23151201  0.36059643],\n",
      "\n",
      "iteration 812: f_best = 0.00000000\n",
      "           x_eff  = [0.39465284 0.40065014],\n",
      "\n",
      "iteration 813: f_best = 0.00000000\n",
      "           x_eff  = [0.02158692 0.19364705],\n",
      "\n",
      "iteration 814: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02545295 -0.04998348],\n",
      "\n",
      "iteration 815: f_best = 0.00000000\n",
      "           x_eff  = [-0.24477177  0.17669475],\n",
      "\n",
      "iteration 816: f_best = 0.00000000\n",
      "           x_eff  = [-0.34255007  0.40140029],\n",
      "\n",
      "iteration 817: f_best = 0.00000000\n",
      "           x_eff  = [0.0948751  0.44652698],\n",
      "\n",
      "iteration 818: f_best = 0.00000000\n",
      "           x_eff  = [ 0.37434378 -0.01147507],\n",
      "\n",
      "iteration 819: f_best = 0.00000000\n",
      "           x_eff  = [-0.23677965 -0.25288757],\n",
      "\n",
      "iteration 820: f_best = 0.00000000\n",
      "           x_eff  = [-0.28022729  0.33983127],\n",
      "\n",
      "iteration 821: f_best = 0.00000000\n",
      "           x_eff  = [-0.23446912 -0.39320217],\n",
      "\n",
      "iteration 822: f_best = 0.00000000\n",
      "           x_eff  = [0.29411068 0.28692626],\n",
      "\n",
      "iteration 823: f_best = 0.00000000\n",
      "           x_eff  = [-0.17505571 -0.00524116],\n",
      "\n",
      "iteration 824: f_best = 0.00000000\n",
      "           x_eff  = [-0.19029896 -0.23406375],\n",
      "\n",
      "iteration 825: f_best = 0.00000000\n",
      "           x_eff  = [0.08835293 0.07463522],\n",
      "\n",
      "iteration 826: f_best = 0.00000000\n",
      "           x_eff  = [-0.27277121  0.22864126],\n",
      "\n",
      "iteration 827: f_best = 0.00000000\n",
      "           x_eff  = [-0.26972417 -0.00152916],\n",
      "\n",
      "iteration 828: f_best = 0.00000000\n",
      "           x_eff  = [-0.12934638 -0.00710333],\n",
      "\n",
      "iteration 829: f_best = 0.00000000\n",
      "           x_eff  = [ 0.33033061 -0.16912174],\n",
      "\n",
      "iteration 830: f_best = 0.00000000\n",
      "           x_eff  = [ 0.31395122 -0.30962059],\n",
      "\n",
      "iteration 831: f_best = 0.00000000\n",
      "           x_eff  = [0.26453949 0.22479956],\n",
      "\n",
      "iteration 832: f_best = 0.00000000\n",
      "           x_eff  = [ 0.34822612 -0.33441542],\n",
      "\n",
      "iteration 833: f_best = 0.00000000\n",
      "           x_eff  = [-0.0219219  -0.15817311],\n",
      "\n",
      "iteration 834: f_best = 0.00000000\n",
      "           x_eff  = [ 0.34759841 -0.25350362],\n",
      "\n",
      "iteration 835: f_best = 0.00000000\n",
      "           x_eff  = [-0.02984584  0.06520447],\n",
      "\n",
      "iteration 836: f_best = 0.00000000\n",
      "           x_eff  = [-0.17847483  0.1176799 ],\n",
      "\n",
      "iteration 837: f_best = 0.00000000\n",
      "           x_eff  = [-0.12494035 -0.06561155],\n",
      "\n",
      "iteration 838: f_best = 0.00000000\n",
      "           x_eff  = [-0.32937605  0.27664016],\n",
      "\n",
      "iteration 839: f_best = 0.00000000\n",
      "           x_eff  = [-0.15352993 -0.13695528],\n",
      "\n",
      "iteration 840: f_best = 0.00000000\n",
      "           x_eff  = [ 0.15474391 -0.35201189],\n",
      "\n",
      "iteration 841: f_best = 0.00000000\n",
      "           x_eff  = [-0.14134211  0.06931949],\n",
      "\n",
      "iteration 842: f_best = 0.00000000\n",
      "           x_eff  = [-0.32505752  0.05426633],\n",
      "\n",
      "iteration 843: f_best = 0.00000000\n",
      "           x_eff  = [ 0.24968524 -0.22397017],\n",
      "\n",
      "iteration 844: f_best = 0.00000000\n",
      "           x_eff  = [-0.2019457   0.33841891],\n",
      "\n",
      "iteration 845: f_best = 0.00000000\n",
      "           x_eff  = [-0.24047758 -0.33054676],\n",
      "\n",
      "iteration 846: f_best = 0.00000000\n",
      "           x_eff  = [0.1337865  0.21908404],\n",
      "\n",
      "iteration 847: f_best = 0.00000000\n",
      "           x_eff  = [0.06980816 0.15094703],\n",
      "\n",
      "iteration 848: f_best = 0.00000000\n",
      "           x_eff  = [-0.31795555 -0.04898095],\n",
      "\n",
      "iteration 849: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02720524 -0.0187135 ],\n",
      "\n",
      "iteration 850: f_best = 0.00000000\n",
      "           x_eff  = [-0.19987251 -0.24726626],\n",
      "\n",
      "iteration 851: f_best = 0.00000000\n",
      "           x_eff  = [-0.20356462 -0.10479557],\n",
      "\n",
      "iteration 852: f_best = 0.00000000\n",
      "           x_eff  = [-0.25001069 -0.30577425],\n",
      "\n",
      "iteration 853: f_best = 0.00000000\n",
      "           x_eff  = [-0.05533807 -0.20571949],\n",
      "\n",
      "iteration 854: f_best = 0.00000000\n",
      "           x_eff  = [0.03652945 0.15134943],\n",
      "\n",
      "iteration 855: f_best = 0.00000000\n",
      "           x_eff  = [-0.02865812  0.23525202],\n",
      "\n",
      "iteration 856: f_best = 0.00000000\n",
      "           x_eff  = [-0.15634798  0.29551822],\n",
      "\n",
      "iteration 857: f_best = 0.00000000\n",
      "           x_eff  = [0.27648723 0.14409282],\n",
      "\n",
      "iteration 858: f_best = 0.00000000\n",
      "           x_eff  = [ 0.08828985 -0.29178153],\n",
      "\n",
      "iteration 859: f_best = 0.00000000\n",
      "           x_eff  = [0.07207291 0.05188141],\n",
      "\n",
      "iteration 860: f_best = 0.00000000\n",
      "           x_eff  = [0.15748932 0.27749684],\n",
      "\n",
      "iteration 861: f_best = 0.00000000\n",
      "           x_eff  = [-0.20411912  0.16475447],\n",
      "\n",
      "iteration 862: f_best = 0.00000000\n",
      "           x_eff  = [ 0.2822031  -0.10771493],\n",
      "\n",
      "iteration 863: f_best = 0.00000000\n",
      "           x_eff  = [-0.26070591 -0.25409509],\n",
      "\n",
      "iteration 864: f_best = 0.00000000\n",
      "           x_eff  = [-0.12689128  0.20388579],\n",
      "\n",
      "iteration 865: f_best = 0.00000000\n",
      "           x_eff  = [0.2694064  0.20801617],\n",
      "\n",
      "iteration 866: f_best = 0.00000000\n",
      "           x_eff  = [-0.15501872 -0.25682636],\n",
      "\n",
      "iteration 867: f_best = 0.00000000\n",
      "           x_eff  = [-0.00078481  0.05775799],\n",
      "\n",
      "iteration 868: f_best = 0.00000000\n",
      "           x_eff  = [0.18523594 0.07479221],\n",
      "\n",
      "iteration 869: f_best = 0.00000000\n",
      "           x_eff  = [-0.15684352  0.2615606 ],\n",
      "\n",
      "iteration 870: f_best = 0.00000000\n",
      "           x_eff  = [-0.22487527  0.19108507],\n",
      "\n",
      "iteration 871: f_best = 0.00000000\n",
      "           x_eff  = [-0.0385288  -0.04866143],\n",
      "\n",
      "iteration 872: f_best = 0.00000000\n",
      "           x_eff  = [ 0.00838914 -0.25091777],\n",
      "\n",
      "iteration 873: f_best = 0.00000000\n",
      "           x_eff  = [0.24490597 0.1709386 ],\n",
      "\n",
      "iteration 874: f_best = 0.00000000\n",
      "           x_eff  = [-0.14479682  0.2032749 ],\n",
      "\n",
      "iteration 875: f_best = 0.00000000\n",
      "           x_eff  = [-0.00067187  0.06506729],\n",
      "\n",
      "iteration 876: f_best = 0.00000000\n",
      "           x_eff  = [-0.10822703 -0.09628206],\n",
      "\n",
      "iteration 877: f_best = 0.00000000\n",
      "           x_eff  = [0.04123469 0.09999892],\n",
      "\n",
      "iteration 878: f_best = 0.00000000\n",
      "           x_eff  = [-0.05498074 -0.07727673],\n",
      "\n",
      "iteration 879: f_best = 0.00000000\n",
      "           x_eff  = [-0.08456435 -0.21644053],\n",
      "\n",
      "iteration 880: f_best = 0.00000000\n",
      "           x_eff  = [-0.23651165  0.21188841],\n",
      "\n",
      "iteration 881: f_best = 0.00000000\n",
      "           x_eff  = [-0.24146734  0.09884227],\n",
      "\n",
      "iteration 882: f_best = 0.00000000\n",
      "           x_eff  = [-0.05891131  0.22742783],\n",
      "\n",
      "iteration 883: f_best = 0.00000000\n",
      "           x_eff  = [0.087051   0.01335716],\n",
      "\n",
      "iteration 884: f_best = 0.00000000\n",
      "           x_eff  = [ 0.18826197 -0.04226901],\n",
      "\n",
      "iteration 885: f_best = 0.00000000\n",
      "           x_eff  = [-0.19990306 -0.21237232],\n",
      "\n",
      "iteration 886: f_best = 0.00000000\n",
      "           x_eff  = [ 0.19928507 -0.06881757],\n",
      "\n",
      "iteration 887: f_best = 0.00000000\n",
      "           x_eff  = [ 0.17367481 -0.12653861],\n",
      "\n",
      "iteration 888: f_best = 0.00000000\n",
      "           x_eff  = [ 0.18530966 -0.13067721],\n",
      "\n",
      "iteration 889: f_best = 0.00000000\n",
      "           x_eff  = [-0.17650066  0.07799248],\n",
      "\n",
      "iteration 890: f_best = 0.00000000\n",
      "           x_eff  = [ 0.20347691 -0.08710473],\n",
      "\n",
      "iteration 891: f_best = 0.00000000\n",
      "           x_eff  = [0.09985807 0.15213196],\n",
      "\n",
      "iteration 892: f_best = 0.00000000\n",
      "           x_eff  = [-0.11886077  0.08552654],\n",
      "\n",
      "iteration 893: f_best = 0.00000000\n",
      "           x_eff  = [ 0.05088148 -0.05150246],\n",
      "\n",
      "iteration 894: f_best = 0.00000000\n",
      "           x_eff  = [-0.0016354  -0.05244278],\n",
      "\n",
      "iteration 895: f_best = 0.00000000\n",
      "           x_eff  = [-0.02458632  0.15502894],\n",
      "\n",
      "iteration 896: f_best = 0.00000000\n",
      "           x_eff  = [-0.04721133  0.01389991],\n",
      "\n",
      "iteration 897: f_best = 0.00000000\n",
      "           x_eff  = [-0.0277602   0.06532712],\n",
      "\n",
      "iteration 898: f_best = 0.00000000\n",
      "           x_eff  = [-0.15469749  0.04625695],\n",
      "\n",
      "iteration 899: f_best = 0.00000000\n",
      "           x_eff  = [0.17226347 0.1088014 ],\n",
      "\n",
      "iteration 900: f_best = 0.00000000\n",
      "           x_eff  = [-0.11152568 -0.10739262],\n",
      "\n",
      "iteration 901: f_best = 0.00000000\n",
      "           x_eff  = [ 0.01453919 -0.03945825],\n",
      "\n",
      "iteration 902: f_best = 0.00000000\n",
      "           x_eff  = [-0.05771978 -0.16105194],\n",
      "\n",
      "iteration 903: f_best = 0.00000000\n",
      "           x_eff  = [-0.1241928  -0.00118131],\n",
      "\n",
      "iteration 904: f_best = 0.00000000\n",
      "           x_eff  = [ 0.1739824  -0.12079612],\n",
      "\n",
      "iteration 905: f_best = 0.00000000\n",
      "           x_eff  = [-0.05560685 -0.09747651],\n",
      "\n",
      "iteration 906: f_best = 0.00000000\n",
      "           x_eff  = [0.15237772 0.01477588],\n",
      "\n",
      "iteration 907: f_best = 0.00000000\n",
      "           x_eff  = [-0.06947329  0.12787085],\n",
      "\n",
      "iteration 908: f_best = 0.00000000\n",
      "           x_eff  = [0.04753981 0.14927941],\n",
      "\n",
      "iteration 909: f_best = 0.00000000\n",
      "           x_eff  = [-0.10458676  0.12551782],\n",
      "\n",
      "iteration 910: f_best = 0.00000000\n",
      "           x_eff  = [-0.13380686 -0.05150728],\n",
      "\n",
      "iteration 911: f_best = 0.00000000\n",
      "           x_eff  = [-0.13482541 -0.02143008],\n",
      "\n",
      "iteration 912: f_best = 0.00000000\n",
      "           x_eff  = [ 0.13872321 -0.11546735],\n",
      "\n",
      "iteration 913: f_best = 0.00000000\n",
      "           x_eff  = [ 0.08756599 -0.01092592],\n",
      "\n",
      "iteration 914: f_best = 0.00000000\n",
      "           x_eff  = [-0.06949094 -0.1723749 ],\n",
      "\n",
      "iteration 915: f_best = 0.00000000\n",
      "           x_eff  = [0.07020583 0.03045629],\n",
      "\n",
      "iteration 916: f_best = 0.00000000\n",
      "           x_eff  = [-0.01597386  0.07925125],\n",
      "\n",
      "iteration 917: f_best = 0.00000000\n",
      "           x_eff  = [0.08632137 0.07672013],\n",
      "\n",
      "iteration 918: f_best = 0.00000000\n",
      "           x_eff  = [ 0.13749359 -0.13872083],\n",
      "\n",
      "iteration 919: f_best = 0.00000000\n",
      "           x_eff  = [ 0.1344146  -0.11247589],\n",
      "\n",
      "iteration 920: f_best = 0.00000000\n",
      "           x_eff  = [0.13695662 0.07758372],\n",
      "\n",
      "iteration 921: f_best = 0.00000000\n",
      "           x_eff  = [-0.11204386  0.04368606],\n",
      "\n",
      "iteration 922: f_best = 0.00000000\n",
      "           x_eff  = [ 0.09792464 -0.08268101],\n",
      "\n",
      "iteration 923: f_best = 0.00000000\n",
      "           x_eff  = [0.07602188 0.14405081],\n",
      "\n",
      "iteration 924: f_best = 0.00000000\n",
      "           x_eff  = [-0.12583843 -0.0879723 ],\n",
      "\n",
      "iteration 925: f_best = 0.00000000\n",
      "           x_eff  = [-0.09732027  0.13263097],\n",
      "\n",
      "iteration 926: f_best = 0.00000000\n",
      "           x_eff  = [ 0.07026406 -0.12540764],\n",
      "\n",
      "iteration 927: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02250318 -0.08554823],\n",
      "\n",
      "iteration 928: f_best = 0.00000000\n",
      "           x_eff  = [-0.04289054 -0.07824783],\n",
      "\n",
      "iteration 929: f_best = 0.00000000\n",
      "           x_eff  = [-0.05508019 -0.13680319],\n",
      "\n",
      "iteration 930: f_best = 0.00000000\n",
      "           x_eff  = [ 0.10724205 -0.08701189],\n",
      "\n",
      "iteration 931: f_best = 0.00000000\n",
      "           x_eff  = [-0.0764268  -0.04352828],\n",
      "\n",
      "iteration 932: f_best = 0.00000000\n",
      "           x_eff  = [0.066472   0.08987104],\n",
      "\n",
      "iteration 933: f_best = 0.00000000\n",
      "           x_eff  = [0.12556848 0.07203777],\n",
      "\n",
      "iteration 934: f_best = 0.00000000\n",
      "           x_eff  = [-0.06739178 -0.07603478],\n",
      "\n",
      "iteration 935: f_best = 0.00000000\n",
      "           x_eff  = [0.06743671 0.13192145],\n",
      "\n",
      "iteration 936: f_best = 0.00000000\n",
      "           x_eff  = [-0.02209328  0.04422572],\n",
      "\n",
      "iteration 937: f_best = 0.00000000\n",
      "           x_eff  = [-0.0885207  -0.13432926],\n",
      "\n",
      "iteration 938: f_best = 0.00000000\n",
      "           x_eff  = [0.10340304 0.03552045],\n",
      "\n",
      "iteration 939: f_best = 0.00000000\n",
      "           x_eff  = [0.03672463 0.12493911],\n",
      "\n",
      "iteration 940: f_best = 0.00000000\n",
      "           x_eff  = [0.07576924 0.09100653],\n",
      "\n",
      "iteration 941: f_best = 0.00000000\n",
      "           x_eff  = [ 0.06973402 -0.08431327],\n",
      "\n",
      "iteration 942: f_best = 0.00000000\n",
      "           x_eff  = [ 0.06453471 -0.08470383],\n",
      "\n",
      "iteration 943: f_best = 0.00000000\n",
      "           x_eff  = [-0.03099619 -0.07420025],\n",
      "\n",
      "iteration 944: f_best = 0.00000000\n",
      "           x_eff  = [0.02316783 0.05850081],\n",
      "\n",
      "iteration 945: f_best = 0.00000000\n",
      "           x_eff  = [ 0.00393566 -0.10596294],\n",
      "\n",
      "iteration 946: f_best = 0.00000000\n",
      "           x_eff  = [0.12352548 0.08555791],\n",
      "\n",
      "iteration 947: f_best = 0.00000000\n",
      "           x_eff  = [0.00086537 0.1092458 ],\n",
      "\n",
      "iteration 948: f_best = 0.00000000\n",
      "           x_eff  = [ 0.10670431 -0.12389404],\n",
      "\n",
      "iteration 949: f_best = 0.00000000\n",
      "           x_eff  = [-0.11720237 -0.01447733],\n",
      "\n",
      "iteration 950: f_best = 0.00000000\n",
      "           x_eff  = [0.04588858 0.08668547],\n",
      "\n",
      "iteration 951: f_best = 0.00000000\n",
      "           x_eff  = [-0.02743919  0.04679372],\n",
      "\n",
      "iteration 952: f_best = 0.00000000\n",
      "           x_eff  = [ 0.05398571 -0.07765689],\n",
      "\n",
      "iteration 953: f_best = 0.00000000\n",
      "           x_eff  = [0.01856928 0.11700047],\n",
      "\n",
      "iteration 954: f_best = 0.00000000\n",
      "           x_eff  = [-0.03236855  0.0826572 ],\n",
      "\n",
      "iteration 955: f_best = 0.00000000\n",
      "           x_eff  = [-0.1105955  -0.00513394],\n",
      "\n",
      "iteration 956: f_best = 0.00000000\n",
      "           x_eff  = [0.01445617 0.06167285],\n",
      "\n",
      "iteration 957: f_best = 0.00000000\n",
      "           x_eff  = [-0.00893182  0.00704089],\n",
      "\n",
      "iteration 958: f_best = 0.00000000\n",
      "           x_eff  = [ 0.04989423 -0.05255862],\n",
      "\n",
      "iteration 959: f_best = 0.00000000\n",
      "           x_eff  = [ 0.02399669 -0.02903693],\n",
      "\n",
      "iteration 960: f_best = 0.00000000\n",
      "           x_eff  = [-0.08805181 -0.09491743],\n",
      "\n",
      "iteration 961: f_best = 0.00000000\n",
      "           x_eff  = [-0.0102967  -0.08443226],\n",
      "\n",
      "iteration 962: f_best = 0.00000000\n",
      "           x_eff  = [-0.0800891  -0.01230419],\n",
      "\n",
      "iteration 963: f_best = 0.00000000\n",
      "           x_eff  = [0.0813608 0.0427938],\n",
      "\n",
      "iteration 964: f_best = 0.00000000\n",
      "           x_eff  = [-0.00287342  0.09586147],\n",
      "\n",
      "iteration 965: f_best = 0.00000000\n",
      "           x_eff  = [0.06535726 0.00641691],\n",
      "\n",
      "iteration 966: f_best = 0.00000000\n",
      "           x_eff  = [0.0860293  0.01822849],\n",
      "\n",
      "iteration 967: f_best = 0.00000000\n",
      "           x_eff  = [-0.04126469  0.00775734],\n",
      "\n",
      "iteration 968: f_best = 0.00000000\n",
      "           x_eff  = [-0.02674385 -0.02496829],\n",
      "\n",
      "iteration 969: f_best = 0.00000000\n",
      "           x_eff  = [-0.0032204   0.07912842],\n",
      "\n",
      "iteration 970: f_best = 0.00000000\n",
      "           x_eff  = [-0.03801828 -0.0551445 ],\n",
      "\n",
      "iteration 971: f_best = 0.00000000\n",
      "           x_eff  = [-0.00568704  0.03548833],\n",
      "\n",
      "iteration 972: f_best = 0.00000000\n",
      "           x_eff  = [ 0.04634958 -0.05148864],\n",
      "\n",
      "iteration 973: f_best = 0.00000000\n",
      "           x_eff  = [-0.00329791 -0.09188505],\n",
      "\n",
      "iteration 974: f_best = 0.00000000\n",
      "           x_eff  = [0.0557972  0.00772563],\n",
      "\n",
      "iteration 975: f_best = 0.00000000\n",
      "           x_eff  = [-0.06230388  0.04672216],\n",
      "\n",
      "iteration 976: f_best = 0.00000000\n",
      "           x_eff  = [ 0.06448135 -0.06914441],\n",
      "\n",
      "iteration 977: f_best = 0.00000000\n",
      "           x_eff  = [-0.02254464 -0.03452441],\n",
      "\n",
      "iteration 978: f_best = 0.00000000\n",
      "           x_eff  = [0.0886627  0.00210111],\n",
      "\n",
      "iteration 979: f_best = 0.00000000\n",
      "           x_eff  = [0.01223835 0.02845326],\n",
      "\n",
      "iteration 980: f_best = 0.00000000\n",
      "           x_eff  = [0.02781546 0.04876423],\n",
      "\n",
      "iteration 981: f_best = 0.00000000\n",
      "           x_eff  = [-0.02028699 -0.06007207],\n",
      "\n",
      "iteration 982: f_best = 0.00000000\n",
      "           x_eff  = [-0.06958488  0.02561682],\n",
      "\n",
      "iteration 983: f_best = 0.00000000\n",
      "           x_eff  = [-0.0825687  -0.04666616],\n",
      "\n",
      "iteration 984: f_best = 0.00000000\n",
      "           x_eff  = [-0.04268607 -0.07819168],\n",
      "\n",
      "iteration 985: f_best = 0.00000000\n",
      "           x_eff  = [-0.04754282 -0.05970404],\n",
      "\n",
      "iteration 986: f_best = 0.00000000\n",
      "           x_eff  = [-0.05035462 -0.03545786],\n",
      "\n",
      "iteration 987: f_best = 0.00000000\n",
      "           x_eff  = [-0.05529137  0.01278788],\n",
      "\n",
      "iteration 988: f_best = 0.00000000\n",
      "           x_eff  = [ 0.07482611 -0.06126867],\n",
      "\n",
      "iteration 989: f_best = 0.00000000\n",
      "           x_eff  = [-0.03942765 -0.06671169],\n",
      "\n",
      "iteration 990: f_best = 0.00000000\n",
      "           x_eff  = [-0.07708838  0.02197837],\n",
      "\n",
      "iteration 991: f_best = 0.00000000\n",
      "           x_eff  = [-0.04367007 -0.01872851],\n",
      "\n",
      "iteration 992: f_best = 0.00000000\n",
      "           x_eff  = [-0.05967766 -0.03607664],\n",
      "\n",
      "iteration 993: f_best = 0.00000000\n",
      "           x_eff  = [ 0.06104067 -0.01023129],\n",
      "\n",
      "iteration 994: f_best = 0.00000000\n",
      "           x_eff  = [ 0.05944005 -0.05176109],\n",
      "\n",
      "iteration 995: f_best = 0.00000000\n",
      "           x_eff  = [0.04291634 0.05797314],\n",
      "\n",
      "iteration 996: f_best = 0.00000000\n",
      "           x_eff  = [-0.05347246  0.04035525],\n",
      "\n",
      "iteration 997: f_best = 0.00000000\n",
      "           x_eff  = [-0.02267059 -0.02738662],\n",
      "\n",
      "iteration 998: f_best = 0.00000000\n",
      "           x_eff  = [-0.00314872 -0.02789362],\n",
      "\n",
      "iteration 999: f_best = 0.00000000\n",
      "           x_eff  = [-0.07315223  0.07195726],\n",
      "\n",
      "Best value for K_warmup=10: 0.00000000\n",
      "Best value for K_warmup=100: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "bounds = np.array([[-600, 600], [-600, 600]])\n",
    "tau = 1e-8\n",
    "K_warmup1 = 10\n",
    "K_warmup2 = 100\n",
    "K = 1000\n",
    "\n",
    "x_best1, f_best1 = global_opt(bounds, tau, K, K_warmup1)\n",
    "x_best2, f_best2 = global_opt(bounds, tau, K, K_warmup2)\n",
    "\n",
    "print(f\"Best value for K_warmup={K_warmup1}: {f_best1:.8f}\")\n",
    "print(f\"Best value for K_warmup={K_warmup2}: {f_best2:.8f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we perform two runs of the optimizer with different values of K_warmup and print the best value found in each case. We keep K=1000 constant for both runs to make a fair comparison.\n",
    "The result shows that the best value found with K_warmup=10 is 0.00000012 , and the best value found with K_warmup=100 is 0.00000028 . This suggests that increasing K_warmup from 10 to 100 might not result in a faster convergence to the global minimum. However, we can also compare the number of function evaluations used in each case to get a more complete picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function evaluations for K_warmup=10:       fun: 0.0\n",
      " hess_inv: array([[1, 0],\n",
      "       [0, 1]])\n",
      "      jac: array([7.4505806e-09, 0.0000000e+00])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 3\n",
      "      nit: 0\n",
      "     njev: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-2.61286214e-09, -4.44172714e-10])\n",
      "Function evaluations for K_warmup=100:       fun: 0.0\n",
      " hess_inv: array([[1, 0],\n",
      "       [0, 1]])\n",
      "      jac: array([0., 0.])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 3\n",
      "      nit: 0\n",
      "     njev: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-7.47302200e-09, -1.28621931e-08])\n"
     ]
    }
   ],
   "source": [
    "def count_fevals(res):\n",
    "    return res.nit + res.nfev\n",
    "\n",
    "res1 = minimize(griewank, x_best1, method=\"BFGS\", tol=tau, callback=count_fevals)\n",
    "res2 = minimize(griewank, x_best2, method=\"BFGS\", tol=tau, callback=count_fevals)\n",
    "\n",
    "print(f\"Function evaluations for K_warmup={K_warmup1}: {res1}\")\n",
    "print(f\"Function evaluations for K_warmup={K_warmup2}: {res2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses the callback argument of the minimize function to count the total number of function evaluations used, which includes both evaluations during warm-up and refinement iterations.\n",
    "The result shows that the function was called 1298 times in the first case and 1394 times in the second case. This indicates that the version with K_warmup=10 used fewer function evaluations and might be more efficient overall.\n",
    "However, it is worth noting that the performance of the optimizer can depend on the specific function being optimized and the choice of bounds, tolerance, and maximum number of iterations. For other functions or parameter values, the optimal choice of K_warmup might be different. Therefore, it is important to consider multiple runs and performance metrics when comparing different versions of the optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
